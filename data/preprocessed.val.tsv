Model Uncertainty in Classical Conditioning .	conditioning # t parameters ; # xed generative model ; spurious correlations ; bayesian model ; world model ; conditioning regimes ; model structure ; second-order conditioning ; conditioned inhibition ; reinforcer delivery	<otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	7 1 8	we develop a framework based on <method_3> averaging to explain how animals cope with uncertainty about contingencies in classical conditioning experiments . traditional accounts of <otherscientificterm_0> within a <method_1> of <task_9> ; uncertainty over the <otherscientificterm_6> is not considered . we apply the theory to explain the puzzling relationship between <otherscientificterm_7> and <otherscientificterm_8> , two similar <otherscientificterm_5> that nonetheless result in strongly divergent behavioral outcomes . according to the theory , <otherscientificterm_7> results when limited experience leads animals to prefer a simpler <method_4> that produces <otherscientificterm_2> ; <otherscientificterm_8> results when a more complex model is justi # ed by additional experience .	3 10 -1 0 1 9 6 10 -1 7 8 5 11 10 -1 4 2 10 -1
Continuous Markov Random Fields for Robust Stereo Estimation .	middlebury high resolution imagery ; slanted plane mrf methods ; slanted 3d planes ; occlusion boundaries ; slanted-plane model ; kitti dataset ; hybrid mrf ; random variables ; inference	<material> <method> <otherscientificterm> <otherscientificterm> <method> <material> <method> <otherscientificterm> <task>	2 1 3 ; 4 4 1 ; 0 5 4	in this paper we present a novel <method_4> which reasons jointly about <otherscientificterm_3> as well as depth . we formulate the problem as one of <task_8> in a <method_6> composed of both continuous -lrb- i.e. , <otherscientificterm_2> -rrb- and discrete -lrb- i.e. , <otherscientificterm_3> -rrb- <otherscientificterm_7> . this allows us to define potentials encoding the ownership of the pixels that compose the boundary between segments , as well as potentials encoding which junctions are physically possible . our <method_4> outperforms the state-of-the-art on <material_0> -lsb- 1 -rsb- as well as in the more challenging <material_5> -lsb- 2 -rsb- , while being more efficient than existing <method_1> , taking on average 2 minutes to perform <task_8> on high resolution imagery .	4 3 9 -1 8 6 2 7 10 9 -1 9 -1 0 5 11 12 9 -1
A regularization framework for mobile social network analysis .	evolution of social network information ; learning and clustering communities ; real world data ; modalities of data ; mobile phone data ; mobile phone users ; social network analysis ; human activities ; dynamic scenarios ; regularization framework ; multimodal data ; graph	<task> <task> <material> <otherscientificterm> <material> <material> <task> <task> <task> <method> <material> <otherscientificterm>	9 0 8 ; 2 5 9 ; 4 0 7 ; 4 0 6 ; 9 0 0 ; 9 0 3	mobile phone data provides rich dynamic information on <task_7> in <task_6> . in this paper , we represent data from two different <otherscientificterm_3> as a <otherscientificterm_11> and functions defined on the vertex set of the <otherscientificterm_11> . we propose a <method_9> for the joint utilization of these two <otherscientificterm_3> , which enables us to model <task_0> and efficiently classify relationships among <material_5> . simulations based on <material_2> demonstrate the potential application of our <method_9> in <task_8> , and present competitive results to baseline methods for combining <material_10> in the <task_1> .	7 6 15 16 12 -1 3 11 12 -1 9 0 5 17 18 12 -1 2 8 10 1 4 13 14 12 -1
Reducing time-synchronous beam search effort using stage based look-ahead and language model rank based pruning .	so-call stage based look-ahead technique ; 50k-word mandarin dictation task ; lm rank based pruning ; acoustic model look-ahead ; language model look-ahead ; large vocabulary speech recognition ; time-synchronous beam search ; word error rates ; hypothesis evaluating criteria ; look-ahead technique ; lexical tree ; phoneme node ; search effort ; search algorithm ; word-conditioned search ; look-ahead ; recognition	<method> <material> <method> <method> <method> <task> <task> <metric> <metric> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <task>	4 0 9 ; 3 6 9 ; 4 1 3 ; 6 0 5 ; 1 5 16 ; 3 0 6	in this paper , we present an efficient <method_9> based on both the <method_4> and the <method_3> , for the <task_6> in the <task_5> . in this <method_0> , two predicting processes with different <metric_8> are organized by stages according to the different requirements for pruning the unlikely surviving hypotheses . furthermore , in order to reduce the efforts for distributing the <method_3> over the <otherscientificterm_10> more effectively , the <method_2> is integrated with the extension of each new <otherscientificterm_11> . the <task_16> experiments performed on the <material_1> show that a reduction by 10 percents in the <metric_12> in comparison with the standard <method_14> using <method_3> only , and a reduction of 25 percents in the <metric_7> in comparison with the <method_13> without any <otherscientificterm_15> can be achieved .	9 4 3 6 5 18 19 20 21 23 17 -1 0 8 17 -1 10 2 11 17 -1 16 1 12 22 17 -1
Reconstructing Occluded Surfaces Using Synthetic Apertures : Stereo , Focus and Robust Measures .	synthetic aperture focus ; synthetic apertures ; cost functions ; color medians ; classical shape ; multi-view stereo ; light fields ; 3d reconstruction ; design space ; robustness ; occlusions ; images ; surfaces ; entropy ; oc-clusions ; occlusion ; accuracy ; ssd	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method>	11 0 7 ; 13 0 5 ; 3 0 5 ; 0 0 4 ; 3 1 13 ; 2 0 7	most algorithms for <task_7> from <material_11> use <otherscientificterm_2> based on <method_17> , which assume that the <otherscientificterm_12> being reconstructed are visible to all cameras . this makes it difficult to reconstruct objects which are partially occluded . recently , researchers working with large camera arrays have shown it is possible to '' see through '' <otherscientificterm_14> using a technique called synthetic aperture focus-ing . this suggests that we can design alternative <otherscientificterm_2> that are robust to <otherscientificterm_10> using <otherscientificterm_1> . our paper explores this <otherscientificterm_8> . we compare <otherscientificterm_4> from stereo with shape from <otherscientificterm_0> . we also describe two variants of <method_5> based on <otherscientificterm_3> and <otherscientificterm_13> that increase <metric_9> to <otherscientificterm_14> . we present an experimental comparison of these <otherscientificterm_2> on complex <otherscientificterm_6> , measuring their <metric_16> against the amount of <otherscientificterm_15> .	7 11 2 17 12 19 24 18 -1 18 -1 14 18 -1 10 1 18 -1 8 18 -1 4 0 22 18 -1 20 21 23 18 -1 5 3 13 9 18 -1
The voice-rate dialog system for consumer ratings .	toll-free phone number ; voice rate system ; review synthesis ; telephone playback ; dialog system ; robust name-matching ; voice-rate	<material> <method> <task> <task> <method> <task> <material>	6 6 4 ; 2 0 3	voice-rate is an experimental <method_4> that makes product and business ratings available to consumers via a <material_0> . by calling <material_6> , users can access the ratings of more than one million products , a quarter million local businesses -lrb- restaurants -rrb- , and three thousand national businesses . this paper describes the <method_1> , and solutions to three key technical challenges : <task_5> , efficient disambiguation , and <task_2> for <task_3> . <material_6> can be accessed by calling 1-877-456-data -lrb- toll-free -rrb- within the u.s.	4 0 8 7 -1 6 7 -1 1 5 2 3 9 7 -1 7 -1
Unconstrained On-line Handwriting Recognition with Recurrent Neural Networks .	movement of the pen ; raw or pre-processed data ; raw on-line handwriting data ; sequence labelling algorithms ; proba-bilistic language model ; unconstrained on-line database ; on-line handwriting recognition ; sequence labelling tasks ; recurrent neural network ; raw data ; sequence labelling ; pre-processing ; hmm ; hmms	<otherscientificterm> <material> <material> <method> <method> <material> <task> <task> <method> <material> <task> <method> <method> <method>	1 0 5 ; 6 0 7 ; 13 6 3 ; 8 0 10	on-line handwriting recognition is unusual among <task_7> in that the underlying generator of the observed data , i.e. the <otherscientificterm_0> , is recorded directly . however , the <material_9> can be difficult to interpret because each letter is spread over many pen locations . as a consequence , sophisticated <method_11> is required to obtain inputs suitable for conventional <method_3> , such as <method_13> . in this paper we describe a system capable of directly transcribing <material_2> . the system consists of a <method_8> trained for <task_10> , combined with a <method_4> . in experiments on an <material_5> , we record excellent results using either <material_1> , well outperforming a state-of-the-art <method_12> in both cases .	7 0 16 14 -1 9 14 -1 11 3 13 17 14 -1 2 14 -1 8 10 4 18 14 -1 5 15 14 -1
Source number estimation in reverberant conditions via full-band weighted , adaptive fuzzy c-means clustering .	adaptive fuzzy c-means clustering ; spatial feature vectors ; source number estimation ; adaptive variation ; quality measures ; real-world recordings ; microphone observations ; clustering algorithm ; full-band manner ; fuzzy c-means ; clusters	<method> <otherscientificterm> <task> <otherscientificterm> <metric> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 1 ; 3 0 8	we introduce a novel approach for <task_2> through an <method_0> . <otherscientificterm_1> are extracted from <otherscientificterm_6> , weighted for reliability and then clustered in a <otherscientificterm_8> using an <otherscientificterm_3> on the <otherscientificterm_9> . a number of <metric_4> are combined to produce a weighted sum which is used to find the optimal number of <otherscientificterm_10> at each iteration of the <method_7> . experimental evaluations using <material_5> from a reverberant room -lrb- rt 60 = 390 ms -rrb- demonstrated encouraging performance in both even-and under-determined conditions .	2 0 1 11 -1 6 8 3 9 12 13 11 -1 4 10 7 11 -1 5 11 -1
i , Poet : Automatic Chinese Poetry Composition through a Generative Summarization Framework under Constrained Optimization .	automatic chinese poetry composition ; classical ancient chinese poems ; song dynasty of china ; user specified writing intents ; tonal and rhythm requirements ; artificial intelligence assistance ; iterative term substitutions ; poetry composition task ; gener-ative summarization framework ; human judgments ; computational linguistics ; poetry formats ; generated poem ; linguistic rules ; optimization problem ; strict formats ; rouge scores ; optimization process	<task> <material> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <metric> <method>	8 0 7 ; 6 0 17 ; 8 0 14 ; 14 0 7	part of the long lasting cultural heritage of china is the <material_1> which follow <otherscientificterm_15> and complicated <otherscientificterm_13> . <task_0> by programs is considered as a challenging problem in <otherscientificterm_10> and requires high <task_5> , and has not been well addressed . in this paper , we formulate the <task_7> as an <task_14> based on a <method_8> under several constraints . given the <otherscientificterm_3> , the system retrieves candidate terms out of a large poem corpus , and then orders these terms to fit into <otherscientificterm_11> , satisfying <otherscientificterm_4> . the <method_17> under constraints is conducted via <otherscientificterm_6> till convergence , and outputs the subset with the highest utility as the <material_12> . for experiments , we perform generation on large datasets of 61,960 classic poems from tang and <material_2> . a comprehensive evaluation , using both <material_9> and <metric_16> , has demonstrated the effectiveness of our proposed approach .	1 15 13 0 18 -1 10 5 18 -1 7 14 8 19 21 22 18 -1 3 11 4 18 -1 17 6 20 18 -1 12 18 -1 2 18 -1
Multi-Label Manifold Learning .	local topological structure ; smoothness assumption ; feature manifold ; label space ; label manifold ; multi-label learning ; euclidean space ; manifold	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	4 5 5 ; 3 2 7 ; 3 2 5	this paper gives an attempt to explore the <otherscientificterm_7> in the <otherscientificterm_3> for <task_5> . traditional <otherscientificterm_3> is logical , where no <otherscientificterm_7> exists . in order to study the <otherscientificterm_4> , the <otherscientificterm_3> should be extended to a <otherscientificterm_6> . however , the label man-ifold is not explicitly available from the training examples . fortunately , according to the <otherscientificterm_1> that the points close to each other are more likely to share a label , the <otherscientificterm_0> can be shared between the <otherscientificterm_2> and the <otherscientificterm_4> . based on this , we propose a novel method called ml 2 , i.e. , multi-label manifold learning , to reconstruct and exploit the <otherscientificterm_4> . to our best knowledge , it is one of the first attempts to explore the <otherscientificterm_7> in the <otherscientificterm_3> in <task_5> . extensive experiments show that the performance of <task_5> can be improved significantly with the <otherscientificterm_4> .	7 3 5 8 -1 8 -1 4 6 8 -1 8 -1 1 0 2 8 -1 8 -1 10 11 8 -1 9 8 -1
Mobile Beamforming & Spatially Controlled Relay Communications .	single-source single-destination robotic relay networks ; 2-stage stochastic programming formulation ; lower bound relaxation ; cooperative beam-forming framework ; stochastic decision making ; random causal csi ; nontrivial optimization problem ; total beamforming power ; spatiotemporal stochastic field ; stochastic motion planning ; communication medium ; control policy ; spatial controllers ; predictive character ; relay positions ; relay locations ; relay	<task> <method> <otherscientificterm> <method> <method> <material> <task> <otherscientificterm> <method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	9 3 0 ; 5 0 4 ; 3 0 9 ; 11 0 4 ; 13 2 12 ; 12 5 1	we consider <task_9> in <task_0> , under a <method_3> . assuming that the <otherscientificterm_10> constitutes a <method_8> , we propose a <method_1> of the problem of specifying the positions of the relays , such that the expected reciprocal of their <otherscientificterm_7> is maximized . <method_4> is made on the basis of <material_5> . recognizing the intractability of the original problem , we propose a <otherscientificterm_2> , resulting to a <task_6> with respect to the <otherscientificterm_15> , which is equivalent to a small set of simple , tractable subproblems . our <method_1> results in <method_12> with a <otherscientificterm_13> ; at each time slot , the new <otherscientificterm_14> should be such that the expected power reciprocal at the next time slot is maximized . quite interestingly , the optimal <method_11> to the <method_4> is purely selective ; under a certain sense , only the best <material_16> should move .	9 0 3 18 20 17 -1 10 8 1 7 4 17 -1 5 19 17 -1 2 6 15 17 -1 12 13 22 23 17 -1 14 21 17 -1
Validation of acoustic models of auditory neural prostheses .	cochlear implant speech processor ; auditory neural prostheses ; noise bands ; acoustic models ; cochlear implant ; electrical stimulation ; percepts	<method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 6	acoustic models have been used in numerous studies over the past thirty years to simulate the <otherscientificterm_6> elicited by <method_1> . in these <method_3> , incoming signals are processed the same way as in a <method_0> . the <otherscientificterm_6> that would be caused by <otherscientificterm_5> in a real <otherscientificterm_4> are simulated by modulating the amplitude of either <otherscientificterm_2> or sinusoids . despite their practical usefulness these <method_3> have never been convincingly validated . this study presents a tool to conduct such validation using subjects who have a <otherscientificterm_4> in one ear and have near perfect hearing in the other ear , allowing for the first time a direct perceptual comparison of the output of <method_3> to the stimulation provided by a <otherscientificterm_4> .	6 1 8 7 -1 3 0 7 -1 5 4 2 7 -1 7 -1 7 -1
Adequacy Analysis of Simulation-Based Assessment of Speech Recognition System .	speech recognition systems ; noisy speech recognition ; impulse response accuracies ; acoustic characteristics ; noisy conditions ; lombard effect ; lombard effects ; speech recognition	<method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	2 1 6 ; 5 0 3 ; 4 2 0 ; 6 2 7	the adequacies of the simulation-based assessment of <method_0> under <otherscientificterm_4> are investigated and discussed . to evaluate the <method_0> in various environments , it is desirable to collect the test data uttered in the corresponding environments but it is not realistic since enormous works are required . to conduct evaluations of the <method_0> properly , it is promising to simulate evaluation experiments in the target environments as described below : comparatively small test data are collected , and test data of the target environment are generated by computing convolution of the impulse response of the target environment with the collected data . however , it is well known that changes of the <otherscientificterm_3> are caused by <otherscientificterm_5> , and so it is not necessarily obvious whether the simulation can precisely approximate the experiment in actual environment . this paper clarifies the condition to perform effective simulations of the <task_1> , focusing on the influence of <otherscientificterm_2> and <otherscientificterm_6> on the <task_7> performance .	0 4 11 8 -1 8 -1 8 -1 10 8 -1 3 5 9 12 8 -1
Concept segmentation and labeling for conversational speech .	conditional random fields ; manual transcription of spoken utterances ; stochastic finite state transducers ; genera-tive and discriminative models ; noisy automatic transcriptions ; spoken language understanding ; complementary learning models ; spoken dialog corpora ; automatic concept labeling ; noisy automatic transcription ; discriminative algorithm ; kernel methods ; manual transcriptions ; generative-discriminative model ; robustness ; media ; accuracy	<method> <material> <method> <method> <material> <task> <method> <material> <task> <task> <method> <method> <material> <method> <metric> <material> <metric>	6 0 5 ; 5 0 8 ; 13 0 4 ; 11 0 10	spoken language understanding performs <task_8> and segmentation of speech utterances . for this task , many approaches have been proposed based on both <method_3> . while all these methods have shown remarkable <metric_16> on <material_1> , <metric_14> to <task_9> is still an open issue . in this paper we study algorithms for <task_5> combining <method_6> : <method_2> produce a list of hypotheses , which are re-ranked using a <method_10> based on <method_11> . our experiments on two different <material_7> , <material_15> and luna , show that the combined <method_13> reaches the state-of-the-art such as <method_0> on <material_12> , and <method_13> is robust to <material_4> , outperforming , in some cases , the state-of-the-art .	8 19 17 -1 3 17 -1 16 1 14 9 17 -1 5 6 2 10 11 18 21 17 -1 7 15 13 0 12 20 17 -1
Scalable and Robust Bayesian Inference via the Median Posterior .	geometric median of subset posterior distributions ; ad hoc techniques ; bayesian learning methods ; distributed computing environments ; aggregation step ; posterior distribution ; bayesian learning ; bayesian inference ; massive data ; stochastic approximation	<otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <task> <task> <material> <method>	0 0 4 ; 2 0 8 ; 2 0 3	many <method_2> for <material_8> benefit from working with small subsets of observations . in particular , significant progress has been made in scalable <task_6> via <method_9> . however , <method_2> in <task_3> are often problem-or distribution-specific and use <method_1> . we propose a novel general approach to <task_7> that is scalable and robust to corruption in the data . our technique is based on the idea of splitting the data into several non-overlapping subgroups , evaluating the <otherscientificterm_5> given each independent subgroup , and then combining the results . our main contribution is the proposed <method_4> which is based on finding the <otherscientificterm_0> . presented theoretical and numerical results confirm the advantages of our approach .	2 8 12 10 -1 6 9 10 -1 3 1 13 10 -1 7 10 -1 5 10 -1 4 11 10 -1 0 10 -1
An EM-algorithm approach for the design of orthonormal bases adapted to sparse representations .	probabilistic interpretation of sezer 's algorithm ; missed detection rate ; sparse representations ; dictionary learning ; em algorithm ; optimization procedure	<method> <metric> <method> <task> <method> <method>	3 0 2 ; 1 5 0 ; 4 0 5	in this paper , we consider the problem of <task_3> for <method_2> . several algorithms dealing with this problem can be found in the literature . one of them , introduced by sezer et al. in -lsb- 1 -rsb- optimizes a dictionary made up of the union of orthonor-mal bases . in this paper , we propose a <method_0> and suggest a novel <method_5> based on the <method_4> . comparisons of the performance in terms of <metric_1> show a clear superiority of the proposed <method_0> .	3 2 7 6 -1 6 -1 6 -1 0 5 4 9 6 -1 1 8 6 -1
The PDAF based Active Contour .	d i r ectional approach of measurements ; directional-based m e asurement model ; directional smoothing operator ; gradient-based image potential ; active contour model ; estimation of motion ; velocity-based discrimination ; image motion ; pdaf approach ; walking leg ; image potential ; waving hand ; spatio-velocity space ; image clutter ; optical-ow	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 8 ; 12 2 4 ; 10 1 14 ; 9 1 11	we present a new <method_4> in <otherscientificterm_12> which is based o n t h e p r obability data association lter <method_8> . <method_4> employs a <method_1> of <otherscientificterm_10> and of <otherscientificterm_14> along the contour points . the proposed <method_0> is the basis for the <otherscientificterm_6> between measurements of the object to that of <otherscientificterm_13> . the <method_4> chooses the appropriate measurements which are most consistent with previous <otherscientificterm_5> in the sense of the <method_8> . in order to obtain reliable measurements of <otherscientificterm_7> and of <otherscientificterm_3> , we propose a <method_2> which is the basis for discriminating the objects measurements from that of <otherscientificterm_13> . the <method_2> was applied t o r eal world tracking problems such as a <otherscientificterm_9> and a <otherscientificterm_11> .	4 12 8 17 15 -1 1 10 14 18 15 -1 0 6 13 15 -1 5 16 15 -1 7 3 2 15 -1 19 15 -1
Describing objects by their attributes .	feature selection method ; learning attributes ; recognition paradigm ; identity assignment ; learning attributes ; attribute-based framework ; recognition ; naming	<method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <task> <task>	0 0 1	we propose to shift the goal of <task_6> from <task_7> to describing . doing so allows us not only to name familiar objects , but also : to report unusual aspects of a familiar object -lrb- '' spotty dog '' , not just '' dog '' -rrb- ; to say something about unfamiliar objects -lrb- '' hairy and four-legged '' , not just '' unknown '' -rrb- ; and to learn how to recognize new objects with few or no visual examples . rather than focusing on <task_3> , we make inferring attributes the core problem of <task_6> . these attributes can be semantic -lrb- '' spotty '' -rrb- or discriminative -lrb- '' dogs have it but sheep do not '' -rrb- . <otherscientificterm_4> presents a major new challenge : generalization across object categories , not just across instances within a category . in this paper , we also introduce a novel <method_0> for <otherscientificterm_1> that generalize well across categories . we support our claims by thorough evaluation that provides insights into the limitations of the standard <method_2> of <task_7> and demonstrates the new abilities provided by our <method_5> .	6 7 8 -1 8 -1 3 8 -1 8 -1 4 8 -1 9 8 -1 0 1 8 -1
Implementation of Learning-Based Dynamic Demand Response on a Campus Micro-Grid .	demand response ; polynomial time optimization algorithms ; real time automated dr ; d 2 r algorithms ; dr interval ; curtailment target ; curtailment maximization ; load curtailment ; sparse data ; curtailment requirements ; automated dr ; forecasting models	<task> <method> <material> <method> <otherscientificterm> <otherscientificterm> <task> <task> <material> <otherscientificterm> <task> <method>	11 0 6 ; 3 0 7 ; 8 0 6 ; 11 0 8	demand response -lrb- dr -rrb- allows utilities to curtail electricity consumption during peak demand periods . <material_2> can offer utilities a scalable solution for fine grained control of curtail-ment over small intervals for the duration of the entire dr event . in this work , we demonstrate a system for a real time automated dynamic dr -lrb- d 2 r -rrb- . our system has already been integrated with the electrical infrastructure of the university of southern california , which offers a unique environment to study the impact of <task_10> in a complex social and cultural environment including 170 buildings in a '' city-within-a-city '' scenario . our large scale information processing system coupled with accurate <method_11> for <material_8> and fast <method_1> for <task_6> provide the ability to adapt and respond to changing <otherscientificterm_9> in near real-time . our <method_3> automatically and dynamically select customers for <task_7> to guarantee the achievement of a <otherscientificterm_5> over a given <otherscientificterm_4> .	2 12 -1 12 -1 12 -1 10 12 -1 13 15 16 12 -1 11 8 1 6 9 14 12 -1
Segmentation using superpixels : A bipartite graph partitioning approach .	unbalanced bipartite graph structure ; superpixels -lrb- image segments ; berkeley segmenta-tion database ; bipartite graph partitioning ; linear-time spectral algorithm ; segmentation algorithms ; guide segmentation ; multi-layer superpixels ; segmentation framework ; grouping cues ; superpixels	<otherscientificterm> <otherscientificterm> <material> <method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	8 0 4 ; 2 5 8 ; 8 0 0 ; 5 0 10 ; 3 0 8 ; 8 0 7	grouping cues can affect the performance of segmenta-tion greatly . in this paper , we show that <otherscientificterm_1> -rrb- can provide powerful grouping cues to <task_6> , where <otherscientificterm_10> can be collected easily by -lrb- over -rrb- - segmenting the image using any reasonable existing <method_5> . generated by different algorithms with varying parameters , <otherscientificterm_10> can capture diverse and multi-scale visual patterns of a natural image . successful integration of the cues from a large multitude of su-perpixels presents a promising yet not fully explored direction . in this paper , we propose a novel <method_8> based on <method_3> , which is able to aggregate <otherscientificterm_7> in a principled and very effective manner . computationally , <method_8> is tailored to <otherscientificterm_0> and leads to a highly efficient , <method_4> . our <method_8> achieves significantly better performance on the <material_2> compared to state-of-the-art techniques .	11 -1 1 6 10 5 15 11 -1 11 -1 11 -1 8 3 16 17 11 -1 7 12 14 11 -1 0 4 13 11 -1
Tuning principal component weights to individualize HRTFs .	virtual auditory displays ; reduced order modeling technique ; horizontal plane hrtfs ; localization errors ; tuning procedure ; principal components ; spectral features ; low-dimensional models ; tuning pcws ; hrirs	<method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method>	7 0 0 ; 0 0 2 ; 1 0 0 ; 6 2 0 ; 8 0 0	prior research has investigated development of <method_0> using <method_7> of head related transfer functions -lrb- hrtfs -rrb- as a function of a finite number of <method_5> -lrb- pcs -rrb- and associated weights -lrb- <method_0> -rrb- . this paper investigates the effect of <method_0> on <otherscientificterm_2> derived from a database of <method_9> through analytical optimization experiments . the experiments investigate whether average hrtfs can be tuned to match individual hrtfs . results provide insight on the effect of <method_8> on <otherscientificterm_6> of the <method_0> . a <method_1> is used to compactly represent each <method_0> . subject testing results are provided , showing that a human can conduct the <method_4> and reduce <otherscientificterm_3> .	0 7 5 11 10 -1 2 9 12 10 -1 10 -1 8 6 14 15 10 -1 1 13 10 -1 10 -1
Pranking with Ranking .	mistake bound model ; rank-prediction rule ; eachmovie dataset ; collaborative filtering ; online algorithm ; synthetic data ; online algorithms ; ranking instances ; rank ; ranking ; rating ; integer ; classification	<method> <otherscientificterm> <material> <task> <method> <material> <method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task>	5 1 2 ; 6 0 12 ; 12 0 9 ; 6 0 9	we discuss the problem of <task_7> . in our framework each instance is associated with a <otherscientificterm_8> or a <otherscientificterm_10> , which is an <otherscientificterm_11> from 1 to k . our goal is to find a <otherscientificterm_1> that assigns each instance a <otherscientificterm_8> which is as close as possible to the instance 's true <otherscientificterm_8> . we describe a simple and efficient <method_4> , analyze its performance in the <method_0> , and prove its correctness . we describe two sets of experiments , with <material_5> and with the <material_2> for <task_3> . in the experiments we performed , our algorithm outper-forms <method_6> for regression and <task_12> applied to <task_9> .	7 13 -1 8 10 11 13 -1 1 13 -1 4 0 13 -1 5 2 3 14 13 -1 15 16 17 13 -1
Optimum error nonlinearities for long adaptive filters .	adaptive lters ; optimum nonlinearity ; error nonlinearities ; estimation process ; steady-state error	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	2 2 0	in this paper , we consider the class of <otherscientificterm_0> with <otherscientificterm_2> . in particular , we derive an expression for the <otherscientificterm_1> that minimizes the <otherscientificterm_4> and attains the limit mandated by the cramer-rao bound of the underlying <method_3> .	0 2 6 5 -1 1 4 3 5 -1
A switched DPCM/subband coder for pre-echo reduction .	temporally varying bit allocation scheme ; adaptive subband coders ; adaptive subband coder ; human auditory system ; wavelet packet decomposition ; temporal masking properties ; switched dpcm/subband structure ; pre-echo artifact ; psychoacoustic modelling ; pre-echo problem ; transient signals ; stationary signals ; coder	<method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <material> <method>	4 1 8 ; 4 0 1 ; 12 0 7 ; 1 0 11 ; 6 0 9 ; 8 0 1	recently , <method_1> based on <method_4> and <method_8> have been proposed to achieve transparent quality compression of audio signals -lsb- 1 -rsb- , -lsb- 2 -rsb- . while these <method_1> perform well for <material_11> , there is no special mechanism in the <method_12> to prevent the <otherscientificterm_7> when <otherscientificterm_10> are encoded . in this paper , we propose a <otherscientificterm_6> to remove the <task_9> . this is achieved through a novel <method_0> which is based on the <otherscientificterm_5> of the <method_3> . the proposed coder/decoder output is found to be free from the <otherscientificterm_7> even at a lower bitrate than the <method_2> .	1 4 8 14 15 19 13 -1 11 12 7 10 16 17 13 -1 6 9 18 13 -1 0 5 3 13 -1 13 -1
Land use classification of SAR images using a type II local discriminant basis for preprocessing .	synthetic aperture radar images ; classifying small image blocks ; wavelet packet decomposition ; land use classification ; decision process ; image blocks ; feature extraction ; classification algorithm ; feature vector ; discriminant coordinates ; spatial information ; image block	<material> <task> <method> <task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 3 11 ; 10 3 7 ; 6 0 3 ; 9 3 11 ; 10 3 4	in this paper , we present the application of the type ii local discriminant basis -lrb- ldb -rrb- technique to <task_6> for <task_3> in <material_0> . our <method_7> incorporates <otherscientificterm_10> into the <method_4> by <task_1> , instead of single pixels . a <otherscientificterm_8> composed of all the values in the <otherscientificterm_5> is large for even small <otherscientificterm_5> and , therefore , degrades the performance of many classi-fiers . the <method_7> greatly compresses the dimensionality of the <otherscientificterm_8> , by indicating the most <otherscientificterm_9> within the <method_2> of an <otherscientificterm_11> .	6 3 0 15 12 -1 7 10 4 1 14 17 12 -1 8 5 12 -1 9 2 11 13 16 12 -1
Towards Interactive Text Understanding .	semantics-based text authoring system ; automatic information extraction ; deep semantic analysis ; text understanding ; human intervention ; interactive approach	<method> <task> <method> <task> <otherscientificterm> <method>	5 0 3 ; 0 0 5 ; 5 0 2	this position paper argues for an <method_5> to <task_3> . the proposed <method_5> extends an existing <method_0> by using the input text as a source of information to assist the user in re-authoring its content . the <method_5> permits a reliable <method_2> by combining <task_1> with a minimal amount of <otherscientificterm_4> .	5 3 7 6 -1 0 8 6 -1 2 1 4 9 6 -1
A Hierarchical Dirichlet Process Model with Multiple Levels of Clustering for Human EEG Seizure Modeling .	multi-level clustering hierarchical dirichlet process ; independent human physician clusterings ; mlc-hdp 's clustering ; hierarchical dirich-let process ; epilepsy literature ; modeling seizures ; brain activity ; clustering seizures ; epileptic seizures ; seizure-types ; channels-types ; mlc-hdp	<method> <otherscientificterm> <method> <method> <material> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <method>	6 3 3 ; 0 6 3 ; 2 6 4 ; 2 0 7 ; 10 1 9 ; 11 4 3 ; 10 2 2	driven by the multi-level structure of human intracranial electroencephalogram -lrb- ieeg -rrb- recordings of <material_8> , we introduce a new variant of a <method_3> -- the <method_0> -- that simultaneously clusters datasets on multiple levels . our <method_3> contains <otherscientificterm_6> recorded in typically more than a hundred individual channels for each seizure of each patient . the <method_2> clusters over <otherscientificterm_10> , <otherscientificterm_9> , and patient-types simultaneously . we describe this <method_3> and its implementation in detail . we also present the results of a simulation study comparing the <method_11> to a similar <method_3> , the <method_3> and finally demonstrate the <method_11> 's use in <task_5> across multiple patients . we find the <method_2> to be comparable to <otherscientificterm_1> . to our knowledge , the <method_2> is the first in the <material_4> capable of <task_7> within and between patients .	8 3 0 14 12 -1 6 13 12 -1 2 10 9 17 19 12 -1 12 -1 11 18 12 -1 5 12 -1 1 15 16 12 -1
Low-dimensional models of neural population activity in sensory cortical circuits .	nonlinear receptive field model ; idiosyncratic receptive field shapes ; neural population activity ; shared stimulus drive ; nonlinear stimulus inputs ; latent dynamical model ; online expectation maximization ; neural tuning properties ; fast estimation method ; ongoing cortical activity ; low-dimensional dynamical model ; local circuits ; computational neuroscience ; inference scales ; recording duration ; common noise ; visual cortex ; laplace approximations ; visual stimuli ; stimulus representations ; nonlinear inputs ; population size ; multi-neuron recordings ; multi-channel recordings ; temporal dynamics ; cortical dynamics ; neural responses ; statistical model ; cross-neural correlations ; features	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	0 0 1 ; 3 1 15 ; 0 0 23 ; 26 0 16 ; 0 0 24 ; 18 0 16 ; 6 0 8 ; 17 0 8 ; 8 0 28 ; 8 0 7 ; 29 0 19 ; 18 0 26	neural responses in <otherscientificterm_16> are influenced by <otherscientificterm_18> and by ongoing spiking activity in <otherscientificterm_11> . an important challenge in <method_12> is to develop models that can account for both of these <otherscientificterm_29> in large <material_22> and to reveal how <method_19> interact with and depend on <otherscientificterm_25> . here we introduce a <method_27> of <otherscientificterm_2> that integrates a <method_0> with a <method_5> of <otherscientificterm_9> . this <method_0> captures <otherscientificterm_24> and correlations due to <otherscientificterm_3> as well as <otherscientificterm_15> . moreover , because the <otherscientificterm_4> are mixed by the ongoing dynamics , the <method_0> can account for a multiple <otherscientificterm_1> with a small number of <otherscientificterm_20> to a <method_10> . we introduce a <method_8> using <method_6> with <method_17> , for which <otherscientificterm_13> linearly in both <otherscientificterm_21> and <otherscientificterm_14> . we test this <method_0> to <material_23> from primary <otherscientificterm_16> and show that <method_8> accounts for <otherscientificterm_7> as well as <otherscientificterm_28> .	16 18 11 34 36 42 30 -1 12 29 22 19 25 41 30 -1 27 2 0 5 9 30 -1 24 3 15 32 35 30 -1 4 1 31 30 -1 20 10 37 38 30 -1 8 6 17 13 21 14 33 39 40 30 -1
Efficient iterative mean shift based cosine dissimilarity for multi-recording speaker clustering .	iterative mean shift algorithm ; speaker and cluster impurities ; nist sre 2008 datasets ; speech recognition ; euclidean distance ; speaker diarization ; speaker clustering ; cosine distance	<method> <otherscientificterm> <material> <task> <otherscientificterm> <task> <method> <otherscientificterm>	5 1 3 ; 7 0 0 ; 4 0 0	speaker clustering is an important task in many applications such as <task_5> as well as <task_3> . <method_6> can be done within a single multi-speaker recording -lrb- diarization -rrb- or for a set of different recordings . in this work we are interested by the former case and we propose a simple <method_0> to deal with this problem . traditionally , <method_0> is based on <otherscientificterm_4> . we propose to use the <otherscientificterm_7> in order to build a new version of <method_0> . we report results as measured by <otherscientificterm_1> on <material_2> .	5 3 6 9 8 -1 8 -1 0 8 -1 4 11 8 -1 7 10 8 -1 1 2 8 -1
New results in low bitrate audio coding using a combined harmonic-wavelet representation .	total least squares ; harmonic - wavelet representation ; step -lrb- harmonic analysis ; wavelet ltering schemes ; harmonic analysis-synthesis scheme ; wavelet ltering scheme ; reconstructed harmonic signal ; audio signal quality ; m-band wavelet ; harmonic analysis-scheme ; prony algorithm ; audio coder ; harmonic analysis-synthesis ; audio frame ; encoder bitrates ; dier-ence ; residual	<method> <method> <method> <method> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 9 ; 0 1 10 ; 7 5 11 ; 14 5 11 ; 10 0 9 ; 3 0 11 ; 5 0 6 ; 8 0 16	in this paper , we propose a new combined <method_1> for audio where a <method_4> is used , rst , to approximate each <otherscientificterm_13> as a sum of several sinusoids . then , the <otherscientificterm_15> between the original signal and the <otherscientificterm_6> is analyzed using a <method_5> . after each <method_2> & wavelet ltering -rrb- , parameters are quantized and encoded . compared to previously proposed methods , our <method_11> uses dierent <method_12> and <method_3> . we use the <method_0> - <method_10> for the <task_9> , and an <otherscientificterm_8> transform for analyzing the <otherscientificterm_16> . altogether , our proposed <method_11> is capable of delivering excellent <metric_7> at <otherscientificterm_14> of 60-70 kb/s .	1 4 13 17 -1 15 6 5 24 17 -1 2 17 -1 11 12 3 23 17 -1 0 10 9 8 16 18 19 22 25 17 -1 20 21 17 -1
Application of LDA to speaker recognition .	linear transformation of n-dimensional feature vectors ; linear discriminant analysis ; optimal speaker discriminative space ; feature extraction method ; speaker recognition task ; vector of features ; pattern classification problem ; m-dimensional space ; pattern classification ; speaker recognition ; feature space ; identification	<otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <task> <task> <otherscientificterm> <task>	1 6 3 ; 8 0 4 ; 1 0 11 ; 6 0 9 ; 1 0 0	the <task_4> falls under the general problem of <task_8> . <task_9> as a <task_6> , its ultimate objective is design of a system that classifies the <otherscientificterm_5> in different classes by partitioning the <otherscientificterm_10> into <otherscientificterm_2> . <method_1> is a <method_3> that provides a <otherscientificterm_0> -lrb- or samples -rrb- into <otherscientificterm_7> -lrb- m < n -rrb- , so that samples belonging to the same class are close together but samples from different classes are far apart from each other . in this paper we discuss the issue of the application of <method_1> to our gaussian mixture model -lrb- gmm -rrb- based speaker <task_11> task . applying <method_1> improved the <task_11> performance .	4 8 9 14 12 -1 6 5 10 2 1 16 12 -1 3 0 7 13 17 12 -1 12 -1 11 15 12 -1
Liaison and schwa deletion in French : an effect of lexical frequency and competition ? .	phonological processes of liaison ; lexical frequency ; neighbourhood density ; lexical neighbourhoods ; neighbourhood frequency ; speech corpus ; schwa deletion ; lexical variants ; lexical recognition ; french ; elision	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm>	0 0 7 ; 0 1 6 ; 1 1 10 ; 2 1 4 ; 1 1 2	this study aims to determine whether the production of the <otherscientificterm_7> created by the <method_0> and <otherscientificterm_6> in <material_9> are conditioned by factors linked to <task_8> . we hypothesise that the realisation of these variants would be favoured for words which are lexically '' salient '' in term of frequency and in their <otherscientificterm_3> . this claim was tested by examining a <material_5> for the effects of <otherscientificterm_1> , <otherscientificterm_2> and <otherscientificterm_4> on the production of liaison -lrb- both in linking and linked words and their co-occurrence -rrb- and <otherscientificterm_10> . overall the results do not support our hypothesis : <otherscientificterm_1> and competition do not appear to influence strongly whether liaison and <otherscientificterm_10> are realised or not .	7 0 6 9 8 12 13 11 -1 3 11 -1 5 1 2 4 10 15 16 11 -1 14 11 -1
An Extended Interpreted System Model for Epistemic Logics .	logic of knowledge and certainty ; sound and complete proof system ; interpreted perception system model ; perception system model ; interpreted system model ; s5 epistemic logics ; notion of knowledge ; computationally grounded model ; epis-temic logics ; computer processes ; kc logic ; knowledge modality ; s5	<otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method>	10 6 0 ; 11 3 7	the <method_4> offers a <method_7> , in terms of the states of <method_9> , to <otherscientificterm_5> . this paper extends the <method_4> , and provides a computationally grounded one , called the <method_2> , to those <otherscientificterm_8> other than <method_12> . it is usually assumed , in the <method_4> , that those parts of the environment that are visible to an agent are correctly perceived by the agent as a whole . the essential idea of the <method_2> is that an agent may have incorrect perception or observations to the visible parts of the environment and the agent may not be aware of this . the <otherscientificterm_6> can be defined so that an agent knows a statement iff the statement holds in those states that the agent can not distinguish -lrb- from the current state -rrb- by using only her correct observations . we establish a <otherscientificterm_0> , called <method_10> , with a <method_1> . the <otherscientificterm_11> in this <method_7> is s4 valid . it becomes <method_12> if we assume an agent always has correct observations ; and more interestingly , it can be s4 .2 or s4 .3 under other natural constraints on agents and their sensors to the environment .	4 7 9 5 13 -1 2 8 12 13 -1 13 -1 13 -1 13 -1 6 14 13 -1 0 10 1 15 13 -1 11 13 -1
Robust dialogue-state dependent language modeling using leaving-one-out .	dialogue-state dependent language models ; train timetable information system ; automatic inquiry systems ; word error rate ; robust language models ; dialogue state ; language model ; interpolation weights ; speech recognition ; dutch corpus ; em-algorithm ; leaving-one-out	<method> <method> <task> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <task> <material> <method> <material>	0 0 2 ; 0 0 8	the use of <method_0> in <task_2> can improve <task_8> and understanding if a reasonable prediction of the <otherscientificterm_5> is feasible . in this paper , the <otherscientificterm_5> is defined as the set of parameters which are contained in the <task_2> prompt . for each <otherscientificterm_5> a separate <method_6> is constructed . in order to obtain <method_4> despite the small amount of training data we propose to interpolate all of the <method_0> linearly for each <otherscientificterm_5> and to train the large number of resulting <otherscientificterm_7> with the <method_10> in combination with <material_11> . we present experimental results on a small <material_9> which has been recorded in the netherlands with a <method_1> and show that the perplexity and the <metric_3> can be reduced significantly .	0 2 8 5 13 14 12 -1 12 -1 6 12 -1 4 7 10 11 12 -1 9 12 -1
Labeling audio-visual speech corpora and training an ANN/HMM audio-visual speech recognition system .	institute de la communication parl√©e ; multi-stage labeling process ; audiovisual speech recognition ; audio database numbers95 ; audiovisual recognition system ; video labeling ; audio database ; labeling process ; audio labeling ; bootstrap training ; audiovisual database ; numbers95	<method> <method> <task> <material> <method> <task> <material> <method> <task> <task> <material> <method>	10 0 1 ; 8 4 5 ; 10 0 2	we present a method to label an <material_10> and to setup a system for <task_2> based on a hybrid artificial neural network/hidden markov model -lrb- ann/hmm -rrb- approach . the <method_1> is presented on a new <material_10> recorded at the <method_0> . the <material_10> was generated via transposition of the <material_3> . for the labeling first a large subset of <method_11> is used to achieve a <task_9> of an <method_0> , which can then be employed to label the audio part of the <material_10> . this initial labeling is further improved via readapting the <method_0> to the new <material_10> and reperforming the labeling . from the <task_8> then the <task_5> is derived . tests at different signal to noise ratios -lrb- snr -rrb- are performed to demonstrate the efficiency of the <method_7> . furthermore ways to incorporate information from a large <material_6> into the final <method_4> were investigated .	10 2 15 12 -1 1 0 13 12 -1 3 12 -1 11 9 12 -1 12 -1 14 12 -1 8 5 12 -1 7 12 -1
Microphone array speech recognition : experiments on overlapping speech in meetings .	speech in meetings ; microphone array geometry ; microphone array system ; close-talking lapel microphone ; table-top microphone ; close-talking microphones ; speech recognition ; speech processing ; speaker separation ; speech scenarios ; microphone arrays ; processing technique ; hands-free acquisition	<material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <task> <material> <otherscientificterm> <method> <task>	10 0 0 ; 11 0 10 ; 1 0 10	this paper investigates the use of <otherscientificterm_10> to acquire and recognise <material_0> . meetings pose several interesting problems for <task_7> , as they consist of multiple competing speakers within a small space , typically around a table . due to their ability to provide <task_12> and directional discrimination , <otherscientificterm_10> present a potential alternative to <otherscientificterm_5> in such an application . we first propose an appropriate <method_1> and improved <method_11> for this <otherscientificterm_10> , paying particular attention to <task_8> during possible overlap segments . data collection of a small vocabulary <task_6> corpus -lrb- numbers -rrb- was performed in a real meeting room for a single speaker , and several overlapping <material_9> . in <task_6> experiments on the acquired database , the performance of the <method_2> is compared to that of a <otherscientificterm_3> , and a single <otherscientificterm_4> .	10 0 14 13 -1 7 13 -1 12 5 13 -1 1 11 8 15 16 13 -1 6 13 -1 9 13 -1
Direct image alignment of projector-camera systems with planar surfaces .	planar surfaces of diffuse reflectance properties ; real world objects ; spatial augmented reality ; real world surfaces ; direct alignment ; computer vision ; projector images ; projector-camera systems ; displayed content ; subpixel accuracy ; display ; illumination ; generalization	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <method> <material> <metric> <otherscientificterm> <otherscientificterm> <task>	5 0 7 ; 8 0 4	projector-camera systems use <otherscientificterm_5> to analyze their surroundings and <otherscientificterm_10> feedback directly onto <otherscientificterm_1> , as embodied by <otherscientificterm_2> . to be effective , the <otherscientificterm_10> must remain aligned even when the target object moves , but the added <otherscientificterm_11> causes problems for traditional algorithms . current solutions consider the <material_8> as interference and largely depend on channels orthogonal to visible light . they can not directly align <material_6> with <otherscientificterm_3> , even though this may be the actual goal . we propose instead to model the light emitted by projectors and reflected into cameras , and to consider the <material_8> as additional information useful for <task_4> . we implemented in software an algorithm that successfully executes on <otherscientificterm_0> at almost two frames per second with <metric_9> . although slow , our work proves the viability of the concept , paving the way for future optimization and <task_12> .	5 10 1 2 14 13 -1 11 13 -1 8 13 -1 6 3 13 -1 15 13 -1 4 13 -1 0 9 13 -1
Joint kernel collaborative representation on Tensor manifold for face recognition .	gabor-based region covariance matrix ; collaborative representation-based classifier ; orl and feret datasets ; face feature descriptor ; tensor kernel crc ; kernel learning method ; kernel crc construction ; sparse representation-based classifier ; regionalized grcms ; face recognition ; tensor manifold ; geodesic distances ; grcm descriptor ; speedy computation ; vector-based classifiers ; disconnect	<method> <method> <material> <method> <method> <method> <task> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm>	1 0 7 ; 4 1 8 ; 0 6 3 ; 1 6 14 ; 3 0 9 ; 8 1 4 ; 12 1 14	gabor-based region covariance matrix -lrb- <method_0> -rrb- is an emerging <method_3> , which has been shown promising for <task_9> . the <method_0> lies on <otherscientificterm_10> is inherently non-euclidean , hence a <otherscientificterm_15> exists between <method_12> and <method_14> , such as <method_1> . <method_1> is a strong alternative to <method_7> yet enjoys high efficiency . in this paper , we bridge <method_0> and <method_1> with <method_5> . we investigate several <otherscientificterm_11> on <otherscientificterm_10> that satisfy the mercer 's condition for <task_6> as well as for <task_13> . apart from that , we also devise two strategies to jointly combine the <method_8> with <method_4> . extensive experiments on the <material_2> are conducted to verify the efficacy of the proposed method .	0 3 9 19 21 16 -1 10 15 12 14 1 20 23 16 -1 7 17 16 -1 5 16 -1 11 6 13 16 -1 8 18 22 16 -1 4 16 -1
Preduction : A Common Form of Induction and Analogy .	artificial intelligence ; logical formalization ; mathematical induction ; deduction ; induction ; preduction ; deduction	<material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 1 4	deduction , <otherscientificterm_4> , and analogy pervade all our thinking . in contrast with <method_3> , understanding logical aspects of <otherscientificterm_4> and analogy is still an important and challenging issue of <material_0> . this paper describes a <method_1> , called production , of common conjectural reasoning of both <otherscientificterm_4> and analogy . by introduction of <otherscientificterm_5> , <method_1> is refined into `` <otherscientificterm_5> + <method_3> '' and -lrb- empirical -rrb- inductive reasoning is refined into `` <otherscientificterm_5> + <method_2> '' . we examine generality of <otherscientificterm_5> through applications to various examples on <otherscientificterm_4> and analogy .	4 8 7 -1 3 0 7 -1 1 7 -1 5 2 7 -1 6 7 -1
Subspace-Based Face Recognition in Analog VLSI .	on-chip compensation techniques ; analog-vlsi neural network ; orl database ; device mismatch ; user-programmed coefficients ; 12x12-pixel images ; dimensionality-reduction network ; face recognition ; manhattan distances ; software implementation ; classification performance ; subspace methods ; lda ; coefficients ; classification ; pca	<method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <method> <task> <otherscientificterm> <method> <metric> <method> <task> <otherscientificterm> <task> <method>	1 0 7 ; 6 0 1 ; 0 0 1 ; 11 0 1 ; 4 3 1 ; 14 5 1 ; 0 0 3 ; 15 0 12	we describe an <method_1> for <task_7> based on <method_11> . the <method_1> uses a <method_6> whose <otherscientificterm_13> can be either programmed or learned on-chip to perform <method_15> , or programmed to perform <task_12> . a second <method_1> with <otherscientificterm_4> performs <task_14> with <otherscientificterm_8> . the <method_1> uses <method_0> to reduce the effects of <otherscientificterm_3> . using the <material_2> with <material_5> , our <method_1> achieves up to 85 % <metric_10> -lrb- 98 % of an equivalent <method_9> -rrb- .	1 7 11 17 20 16 -1 6 13 15 12 18 24 16 -1 4 14 8 21 16 -1 0 3 19 23 16 -1 2 5 10 9 22 16 -1
Modeling Organization in Student Essays .	heuristic-based and learning-based approaches ; automated essay scoring ; natural language processing ; annotated corpus ; string kernels ; organization dimension ; technical errors ; alignment kernels ; modeling organization ; sequence alignment ; coherence	<method> <task> <task> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm>	9 1 7 ; 10 1 6 ; 1 6 2 ; 7 1 4	automated essay scoring is one of the most important educational applications of <task_2> . recently , researchers have begun exploring methods of scoring essays with respect to particular dimensions of quality such as <otherscientificterm_10> , <otherscientificterm_6> , and relevance to prompt , but there is relatively little work on <task_8> . we present a new <material_3> and propose <method_0> to scoring essays along the <otherscientificterm_5> , utilizing techniques that involve <method_9> , <otherscientificterm_7> , and <method_4> .	2 14 11 -1 10 6 8 13 11 -1 3 0 5 9 7 4 1 12 15 11 -1
HD Maps : Fine-Grained Road Segmentation by Parsing Ground and Aerial Images .	fine grained segmentation categories ; stereo camera pair ; monocular aerial imagery ; ground images ; aerial images ; joint inference ; parking spots ; gps+imu systems ; sidewalk ; kitti	<otherscientificterm> <otherscientificterm> <material> <material> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	2 1 3 ; 6 6 0 ; 1 0 3 ; 8 6 0 ; 6 1 8	in this paper we present an approach to enhance existing maps with <otherscientificterm_0> such as <otherscientificterm_6> and <otherscientificterm_8> , as well as the number and location of road lanes . towards this goal , we propose an efficient approach that is able to estimate these fine grained categories by doing <otherscientificterm_5> over both , <material_2> , as well as <material_3> taken from a <otherscientificterm_1> mounted on top of a car . important to this is reasoning about the alignment between the two types of imagery , as even when the measurements are taken with sophisticated <method_7> , this alignment is not sufficiently accurate . we demonstrate the effectiveness of our approach on a new dataset which enhances <method_9> -lsb- 8 -rsb- with <material_4> taken with a camera mounted on an airplane and flying around the city of karlsruhe , germany .	0 6 8 12 14 15 10 -1 5 2 3 1 11 13 10 -1 7 10 -1 10 -1
A New Algorithm for Weighted Partial MaxSAT .	weighted partial maxsat solvers ; weighted partial maxsat solver ; sat solver	<method> <method> <method>	1 4 0	we present and implement a <method_1> based on successive calls to a <method_2> . we prove the cor-rectness of our <method_1> and compare our <method_1> with other <method_0> .	1 2 3 -1 0 4 3 -1
Robust statistics on Riemannian manifolds via the geometric median .	geometric median of euclidean data ; geometric median of data ; non-positive sectional curvature ; positively curved manifolds ; 3d rotation group ; geometric median computation ; manifold data ; weiszfeld procedure ; riemannian manifold ; tensor manifolds ; geometric median ; arbitrary manifold ; shape spaces ; euclidean spaces ; vision applications ; robustness ; manifolds ; manifold	<material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <otherscientificterm>	4 6 6 ; 7 0 0 ; 4 1 9 ; 12 6 6 ; 9 1 12 ; 9 6 6 ; 8 0 1 ; 2 2 16	the <otherscientificterm_10> is a classic robust estimator of centrality for data in <otherscientificterm_13> . in this paper we formulate the <material_1> on a <otherscientificterm_8> as the minimizer of the sum of geodesic distances to the data points . we prove existence and uniqueness of the <otherscientificterm_10> on <otherscientificterm_16> with <otherscientificterm_2> and give sufficient conditions for uniqueness on <otherscientificterm_3> . generalizing the <method_7> for finding the <material_0> , we present an algorithm for computing the <otherscientificterm_10> on an <otherscientificterm_11> . we show that this algorithm converges to the unique solution when it exists . this method produces a robust central point for data lying on a <otherscientificterm_17> , and should have use in a variety of <task_14> involving <otherscientificterm_16> . we give examples of the <otherscientificterm_5> and demonstrate its <metric_15> for three types of <material_6> : the <otherscientificterm_4> , <otherscientificterm_9> , and <otherscientificterm_12> .	10 13 18 -1 1 8 25 18 -1 16 2 3 26 18 -1 7 0 11 20 18 -1 18 -1 18 -1 17 14 19 21 22 23 24 18 -1
Localization of impulsive disturbances in archive audio signals using predictive matched filtering .	elimination of impulsive disturbances ; archive audio recordings ; multi-step-ahead prediction errors ; archive audio signals ; model-based signal predictor ; classical detection method ; repetitive shapes ; autoregres-sive modeling ; noise pulses ; click templates	<task> <material> <otherscientificterm> <material> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm>	8 2 1 ; 7 0 5 ; 4 0 2 ; 3 0 0 ; 4 0 9	the problem of <task_0> from <material_3> is considered and its new solution , called predictive matched filtering , is proposed . the new approach is based on the observation that a large percentage of <material_8> corrupting <material_1> have highly <otherscientificterm_6> that match several typical '' patterns '' , called <otherscientificterm_9> . to localize <material_8> , <otherscientificterm_9> can be correlated with the sequence of <otherscientificterm_2> yielded by the <method_4> . it is shown that predictive matched filtering is an efficient and com-putationally affordable disturbance localization technique -- when combined with the <method_5> based on <method_7> , it can significantly improve restoration results .	0 3 14 10 -1 8 1 6 9 11 10 -1 2 4 13 15 10 -1 5 7 12 10 -1
Developments in large vocabulary , continuous speech recognition of German .	large vocabulary continuous speech recognition system ; oocial word error rate ; french and american english ; word error rate ; ger-eval95 test set ; sqale adjudication process ; system development ; limsi recognizerr1 ; german language ; german	<method> <metric> <material> <metric> <material> <method> <task> <method> <material> <material>	3 5 0 ; 1 5 0	in this paper we describe our <method_0> for the <material_8> , the development of which was partly carried out within the context of the european lre project 62-058 sqale . the <method_0> is the <method_7> -rsb- originally developed for <material_2> , which has been adapted to <material_9> . speciicities of <material_9> , as relevant to the <method_0> , are presented . these speciicities have been accounted for during the recognizer 's adaptation process . we present experimental results on a rst test set ger-dev95 to measure progress in <task_6> . results are given with the <method_0> using diierent acoustic model sets on two test sets ger-dev95 and ger-eval95 . this <method_0> achieved a <metric_3> of 17.3 % -lrb- <metric_1> of 16.1 % after <method_5> -rrb- on the <material_4> .	0 8 10 -1 7 2 9 10 -1 10 -1 10 -1 6 10 -1 10 -1 11 12 10 -1
Learning to Rank Using Privileged Information .	privileged information ; computer vision problems ; bounding boxes ; computer vision ; asymmetric distribution ; image tags ; object classification ; maximum-margin techniques ; rationales ; learning ; attributes	<otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm>	10 1 2 ; 2 1 5 ; 5 1 8	many <task_1> have an <otherscientificterm_4> of information between training and test time . in this work , we study the case where we are given additional information about the training data , which however will not be available at test time . this situation is called <task_9> using <otherscientificterm_0> . we introduce two <method_7> that are able to make use of this additional source of information , and we show that the framework is applicable to several scenarios that have been studied in <task_3> before . experiments with <otherscientificterm_10> , <otherscientificterm_2> , <otherscientificterm_5> and <otherscientificterm_8> as additional information in <task_6> show promising results .	1 4 11 -1 11 -1 9 0 11 -1 7 3 11 -1 10 2 5 8 6 12 13 14 11 -1
A study of using locality preserving projections for feature extraction in speech recognition .	resource management data set ; principal components analysis ; linear discriminant analysis ; locality preserving projections ; automatic speech recognition ; word error rate ; manifold based dimensionality reduction algorithms ; manifold based dimensionality reduction algorithm ; lpp based dimensionality reduction ; linear di-mensionality reduction algorithms ; nonlin-ear embedding subspace ; batch mode implementation ; feature analysis ; input features ; mfcc features ; linear projection ; asr features ; local relations ; feature vectors ; unseen data	<material> <method> <method> <method> <task> <metric> <method> <method> <task> <method> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	4 6 7 ; 18 0 10 ; 15 0 16 ; 4 0 18 ; 0 5 8 ; 2 6 9 ; 1 6 9 ; 6 0 11 ; 4 4 9 ; 12 0 4 ; 1 1 2 ; 15 0 7	this paper presents a new approach to <task_12> in <task_4> based on <method_3> . <task_4> is a <method_7> which can be trained and applied as a <method_15> to <otherscientificterm_16> . conventional <method_6> are generally restricted to <task_11> and <task_4> is difficult in practice to apply them to <material_19> . it is argued that <task_4> can model <otherscientificterm_18> that are assumed to lie on a <otherscientificterm_10> by preserving <otherscientificterm_17> among <otherscientificterm_13> , so <task_4> has a potential advantage over conventional <method_9> like <method_1> and <method_2> . experimental results obtained on the <material_0> showed that when <task_8> was applied in the context of mel frequency cepstrum coefficient -lrb- mfcc -rrb- based <task_12> , a significant reduction of <metric_5> was obtained with respect to standard <otherscientificterm_14> .	12 4 3 30 20 -1 7 15 16 21 23 32 20 -1 6 11 19 28 20 -1 18 10 17 13 9 1 2 22 24 26 27 29 31 20 -1 0 8 25 20 -1
Groebner basis techniques in multidimensional multirate systems .	multidimensional multirate systems ; one-dimensional multirate systems ; md multirate systems theory ; euclidean algorithm ; groebner bases	<method> <method> <method> <method> <material>	3 0 1	the <method_3> is a frequently used tool in the analysis of <method_1> . this tool is however not available for <method_0> . in this paper we discus how groebner basis techniques can ll this gap . after presenting the relevant facts about <material_4> , we will show in a few examples how this technique can contribute to <method_2> .	3 1 6 5 -1 0 5 -1 5 -1 4 2 5 -1
Semi-supervised noise dictionary adaptation for exemplar-based noise robust speech recognition .	continuous digits recognition ; noise robust asr ; speech exem-plars ; unknown noise ; low snrs ; speech features ; recognition errors ; noise exem-plars ; exemplar-based approaches ; training data ; noise exemplars	<task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <material> <otherscientificterm>	2 1 10	the <method_8> , which model signals as a sparse linear combination of exemplars of signals , are proved to have state-of-the-art performance in <task_1> , especially on <otherscientificterm_4> . however , since both the <otherscientificterm_2> and <otherscientificterm_10> are built from <material_9> and are fixed throughout the process of enhancing <otherscientificterm_5> , the conventional approach is especially weak for unknown types of noise . therefore , in this paper , we propose a semi-supervised approach which automatically adapt <otherscientificterm_7> to the target noise , while keeping the speech exemplars fixed . <task_0> experiments show that this approach is much more robust for <otherscientificterm_3> . the <metric_6> are reduced by 36.2 % .	8 1 4 11 -1 2 10 9 5 12 11 -1 7 0 11 -1 11 -1 3 11 -1
Neural System Model of Human Sound Localization .	psychophysical and neural system modeling approach ; spatial location of the sound source ; auditory image model of cochlear processing ; human subject 's head-related transfer functions ; temporal and spectral information ; broadband and bandpass stimuli ; human auditory localization process ; time-delay neural network ; directional acoustical cues ; variable bandwidth ; human-like localization ; system model ; center-frequency sounds ; bandpass noise ; neural network ; biological constraints ; sound stimuli ; hrtfs	<method> <otherscientificterm> <method> <material> <otherscientificterm> <material> <task> <method> <otherscientificterm> <otherscientificterm> <task> <method> <material> <otherscientificterm> <method> <otherscientificterm> <material> <method>	15 3 6 ; 0 1 14 ; 7 0 1 ; 11 0 6 ; 17 0 16 ; 10 0 5 ; 4 0 7 ; 2 0 0 ; 9 1 12 ; 7 0 2 ; 13 0 16	this paper examines the role of <otherscientificterm_15> in the <task_6> . a <method_0> was undertaken in which performance comparisons between competing models and a human subject explore the relevant biologically plausible `` realism constraints '' . the <otherscientificterm_8> , upon which <task_6> is based , were derived from the <material_3> -lrb- <method_17> -rrb- . <material_16> were generated by convolving <otherscientificterm_13> with the <method_17> and were presented to both the subject and the <method_0> . the input stimuli to the <method_0> was processed using the <method_2> . the <method_2> was then analyzed by a <method_7> which integrated <otherscientificterm_4> to determine the <otherscientificterm_1> . the combined <method_0> and <method_14> provided a <method_11> of the <task_6> . <task_10> performance was qualitatively achieved for <material_5> when the <method_11> incorporated frequency division -lrb- or tonotopicity -rrb- , and was trained using <otherscientificterm_9> and <material_12> .	15 6 19 18 -1 0 18 -1 8 3 17 16 18 -1 13 23 29 18 -1 2 26 18 -1 7 4 21 25 28 18 -1 1 20 22 18 -1 14 11 10 24 27 18 -1
Phase adjustment in waveform interpolation .	waveform interpolation speech coder ; slowly-evolving waveform ; rapidly-evolving waveform ; female and male speech ; natural speech quality ; quantized rew spectrum ; synthesized signal ; phase information ; rew spectrum ; noise sensitivity	<method> <method> <otherscientificterm> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	1 1 2	this paper describes a method of improving the quality of the <method_0> by adjustment of the <otherscientificterm_7> . in <method_0> , a <method_1> and a <otherscientificterm_2> represent the periodic and the non-periodic part of the signal . the phase of the <otherscientificterm_6> is determined by the <method_1> and rew , and thus the correct quantiza-tion of these parameters are important to producing <metric_4> . a method is described , whereby the phase of the <otherscientificterm_6> is adjusted by modifying the <otherscientificterm_5> as a function of the fundamental frequency . this essentialy attempts to correct the discrepancies in phase that arise due to variation in pitch and also accounts for the difference in <metric_9> between <material_3> -lsb- 5 -rsb- . the overall effect would be the same if multiple codebooks -lrb- depending on pitch -rrb- were used to code the <otherscientificterm_8> . experimental results confirm that the new method results in significantly improved performance .	0 7 10 -1 1 2 11 10 -1 6 4 10 -1 5 10 -1 10 -1 9 3 10 -1 8 10 -1
Design of successive approximation lattice vector quantizers .	large vector quantization codebooks ; lattice vq -lrb- l v q -rrb- ; renement l v q stages ; rst lvq stage ; entropy code ; residual vq ; renement lattices ; entropy coding ; product codes ; residuals	<method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	1 0 7 ; 2 0 9 ; 4 0 3 ; 1 1 8	two methods to overcome the problems with <method_0> are <method_1> and <otherscientificterm_8> . the approach described in this paper takes advantage of both methods by applying <method_5> with <method_1> at all stages . using <method_1> in conjunction with <method_7> is strongly motivated by the fact that entropy constrained but structurally unconstrained vq design leads to more equally sized vq cells . the <method_4> of the <otherscientificterm_3> should aim at exploiting the statistical properties of the source . the <otherscientificterm_2> quantize the <otherscientificterm_9> . simulations show that there exist certain scales of the <otherscientificterm_6> yielding extraordinary performance . we focus on the search of these scales .	0 1 8 14 10 -1 5 10 -1 7 11 10 -1 4 3 13 10 -1 2 9 12 10 -1 6 10 -1 10 -1
Using Lookaheads with Optimal Best-First Search .	bidi-rectional pathmax ; best-first search ; depth-first search ; breadth-first search ; inconsistent heuristics ; lookahead phase ; time speedup ; lookahead depth ; memory ; bfs	<method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	1 1 2	we present an algorithm that exploits the complimentary benefits of <method_1> and <method_2> by performing limited dfs lookaheads from the frontier of <method_9> . we show that this continuum requires significantly less <otherscientificterm_8> than <method_9> . in addition , a <otherscientificterm_6> is also achieved when choosing the <otherscientificterm_7> correctly . we demonstrate this idea for <method_3> and for a * . additionally , we show that when using <method_4> , <method_0> , can be implemented very easily on top of the <otherscientificterm_5> . experimental results on several domains demonstrate the benefits of all our ideas .	1 2 9 11 10 -1 8 10 -1 6 7 10 -1 3 10 -1 4 0 5 10 -1 10 -1
Subband based voice conversion .	voice conversion system ; discrete wavelet transform ; segmental codebooks ; voice conversion method ; full-band based output ; subjective listening tests ; abx listening tests ; speaker transformation algorithm ; faster voice conversion ; film dubbing ; subband decomposition ; speech spectrum ; sampling rates ; sampling rate ; computational complexity ; conversion ; 16khz ; looping	<task> <method> <method> <method> <otherscientificterm> <method> <material> <method> <task> <task> <task> <otherscientificterm> <metric> <metric> <metric> <task> <method> <task>	12 5 3 ; 9 1 17 ; 10 0 11 ; 1 0 10 ; 1 0 11 ; 2 0 7 ; 5 5 3 ; 3 0 0	a new <method_3> that improves the quality of the voice <task_15> output at higher <metric_12> is proposed . <method_7> using <method_2> is modified to process source and target speech spectra in different subbands . the new <method_3> ensures better <task_15> at <metric_12> above <method_16> . <method_1> is employed for <task_10> to estimate the <otherscientificterm_11> better with higher resolution . <task_8> is achieved since the <metric_14> decreases at a lower <metric_13> . a <task_0> is implemented using the proposed <method_3> with necessary tools . the performance of the proposed <method_3> is demonstrated by both <method_5> and applications to <task_9> and <task_17> . in <material_6> , the listeners preferred the subband based output by 92.1 % as compared to the <otherscientificterm_4> .	3 15 12 7 18 -1 2 24 18 -1 16 1 19 18 -1 10 11 8 21 22 23 18 -1 14 13 18 -1 0 26 18 -1 5 9 17 20 25 18 -1 18 -1
Robust and Efficient Foreground Analysis for Real-Time Video Surveillance .	real time video surveillance system ; mixture of gaussians models ; intensity and texture information ; fixed camera view ; gaussian mixture model ; static foreground regions ; color images ; static regions ; background subtraction ; motion information ; mmx optimization ; grayscale images ; foreground analysis ; background model ; gaussian mixtures ; tracking ; fragmentation ; shadows ; foreground	<task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	13 0 3 ; 4 0 5 ; 2 0 17 ; 6 1 11 ; 4 0 12 ; 14 0 13	we present a new method to robustly and efficiently analyze <otherscientificterm_18> when we detect <otherscientificterm_13> for a <otherscientificterm_3> by using <method_1> and multiple cues . the <otherscientificterm_13> is modeled by three <method_14> as in the work of stauffer and grimson -lsb- 11 -rsb- . then the <otherscientificterm_2> are integrated to remove <otherscientificterm_17> and to enable the algorithm working for quick lighting changes . for <task_12> , the same <method_4> is employed to detect the <otherscientificterm_5> without using any <method_15> or <otherscientificterm_9> . then the whole <otherscientificterm_7> are pushed back to the <otherscientificterm_13> to avoid a common problem in <otherscientificterm_8> -- <otherscientificterm_16> -lrb- one object becomes multiple parts -rrb- . the method was tested on our <task_0> . it is robust and run about 130 fps for <material_6> and 150 fps for <material_11> at size 160x120 on a 2gb pentium iv machine with <method_10> .	18 13 3 1 20 19 -1 14 25 19 -1 2 17 22 19 -1 12 4 5 15 9 21 24 19 -1 7 8 19 -1 16 19 -1 0 23 19 -1
A new speaker verification spoofing countermeasure based on local binary patterns .	local binary patterns ; spoofed , converted voice signals ; automatic speaker verification systems ; acoustic feature vectors ; detecting converted voice ; artificial signals ; voice conversion ; prior knowledge ; speech synthesis ; false acceptance	<method> <material> <method> <otherscientificterm> <task> <material> <task> <otherscientificterm> <material> <metric>	0 0 3 ; 8 1 5	this paper presents a new countermeasure for the protection of <method_2> from <material_1> . the new countermeasure is based on the analysis of a sequence of <otherscientificterm_3> using <method_0> . compared to existing approaches the new countermeasure is less reliant on <otherscientificterm_7> and affords robust protection from not only <task_6> , for which it is optimised , but also spoofing attacks from <material_8> and <material_5> , all of which otherwise provoke significant increases in <metric_9> . the work highlights the difficulty in <task_4> and also discusses the need for formal evaluations to develop new countermeasures which are less reliant on <otherscientificterm_7> and thus more reflective of practical use cases .	2 1 10 -1 3 0 11 10 -1 7 6 8 5 9 12 10 -1 4 10 -1
Can tongue be recovered from face ? the answer of data-driven statistical models .	multi linear regression method ; jaw / lips / tongue tip synergy ; hidden markov models ; gaussian mixture models ; french corpus of articulatory data ; face-to-tongue articulatory inversion problem ; phonetic class distribution ; front high vowels ; centralisation effects ; coronal consonants ; electromagnetography ; hmms ; speech	<method> <otherscientificterm> <method> <method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <material>	2 1 3 ; 2 1 0 ; 11 0 6 ; 3 4 11 ; 3 1 11 ; 3 0 6	this study revisits the <task_5> in <material_12> . we compare the <method_0> with two more sophisticated methods based on <method_2> and <method_3> , using the same <material_4> acquired by <method_10> . <method_3> give overall results better than <method_11> , but <method_3> does poorly . <method_3> and <method_11> maintain the original <otherscientificterm_6> , though with some <otherscientificterm_8> , effects still much stronger with <method_3> . a detailed analysis shows that , if the <otherscientificterm_1> helps recovering <otherscientificterm_7> and <otherscientificterm_9> , the velars are not recovered at all . it is therefore not possible to recover reliably tongue from face .	5 12 13 -1 0 2 3 4 10 14 15 13 -1 11 17 13 -1 6 8 16 18 19 13 -1 1 7 9 13 -1 13 -1
Learning Image Matching by Simply Watching Video .	unsupervised learning based approach ; real-world video sequences ; empirically designed methods ; convolutional neural network ; inter-frame correspondences ; unsupervised manner ; temporal coherency ; image matching ; analysis-by-synthesis ; frame-interpolation ; cnn	<method> <material> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <task> <method>	0 0 7 ; 3 0 9 ; 5 0 9 ; 9 0 4 ; 5 0 10 ; 10 0 9 ; 0 4 2	this work presents an <method_0> to the ubiquitous computer vision problem of <task_7> . we start from the insight that the problem of <task_9> implicitly solves for <otherscientificterm_4> . this permits the application of <method_8> : we firstly train and apply a <method_3> for <task_9> , then obtain correspondences by inverting the learned <method_10> . the key benefit behind this <method_0> is that the <method_10> for <task_9> can be trained in an <method_5> by exploiting the <otherscientificterm_6> that is naturally contained in <material_1> . the present <method_0> therefore learns <task_7> by simply '' watching videos '' . besides a promise to be more generally applicable , the presented <method_0> achieves surprising performance comparable to traditional <method_2> .	0 7 11 -1 9 4 15 11 -1 8 3 10 13 11 -1 5 6 1 14 16 17 11 -1 12 11 -1 18 11 -1
A practical , self-adaptive voice activity detector for speaker verification with noisy telephone and microphone data .	mel-frequency cepstral coefficients ; voice activity detector ; speech and nonspeech models ; likelihood ratio based vad ; speech enhancement preprocessing ; energy vad variants ; vad error analysis ; robust speaker verification ; noise-free conditions ; energy vad ; training labels ; utterance-by-utterance basis ; noisy conditions ; i-vector system ; speaker verification	<method> <method> <method> <method> <method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	1 0 7 ; 3 4 5 ; 6 1 14 ; 3 0 2 ; 6 5 3	a <method_1> plays a vital role in <task_7> , where <method_9> is most commonly used . <method_1> works well in <otherscientificterm_8> but deteriorates in <otherscientificterm_12> . one way to tackle this is to introduce <method_4> . we study an alternative , <method_3> that trains <method_2> on an <otherscientificterm_11> from <method_0> . the <otherscientificterm_10> are obtained from enhanced <method_9> . as the <method_2> are retrained for each utterance , minimum assumptions of the background noise are made . according to both <method_6> and <task_14> results utilizing state-of-the-art <method_13> , the proposed <method_3> outperforms <method_5> by a wide margin . we provide open-source implementation of the <method_3> .	1 7 9 16 15 -1 8 12 15 -1 4 15 -1 3 2 11 0 19 15 -1 10 15 -1 15 -1 6 14 13 5 17 18 20 15 -1 15 -1
Evaluation and design of variable step size adaptive algorithms .	variable step size adaptive algorithms ; transient and steady-state behaviors ; mean square error ; system identification applications ; learning plane ; algorithm optimization ; optimum trajectory ; step size	<method> <otherscientificterm> <metric> <task> <method> <task> <otherscientificterm> <otherscientificterm>	5 0 3 ; 7 1 2	this paper presents a new methodology for evaluation and design of <method_0> . the new methodology is based on a <method_4> , which combines the evolutions of both the <otherscientificterm_7> and the <metric_2> . it includes both <otherscientificterm_1> and can be used to compare performances of different algorithms against an <otherscientificterm_6> in the <method_4> . the new technique can also be used for <task_5> in <task_3> .	0 8 -1 4 7 2 10 8 -1 1 6 8 -1 5 3 9 8 -1
A novel search algorithm for LSF VQ .	crvq-cs -lrb- constrained range vector quantization ; weighted euclidean distance measure ; weighted euclidean distance ; component searching -rrb- ; lsf vector quantizers ; euclidean distance measure ; search vq ; computational complexity	<method> <metric> <otherscientificterm> <method> <method> <metric> <method> <metric>	0 0 0 ; 5 0 0 ; 2 0 4 ; 2 0 0 ; 1 0 0 ; 0 6 0	because classical fast vector quantization -lrb- <method_0> -rrb- algorithms ca n't be used in the <method_4> that use varying <otherscientificterm_2> , a novel <method_0> -- <method_0> based on <method_3> is presented in this paper . the <method_0> works well with the varying <otherscientificterm_2> and yields the same result as full <method_6> with reduced <metric_7> does . although the <method_0> is proposed for <method_0> using varying <metric_1> , <method_0> is also suitable for <method_0> using simple <metric_5> .	0 4 2 3 11 14 8 -1 6 7 12 8 -1 1 5 9 10 13 8 -1
Variational inference for conditional random fields .	structured variational inference ; conditional random fields ; factorized variational inference ; conditional random fields -lrb- crfs ; idiap human motion database ; variation inference methods ; human motion recognition ; contextual pattern classification ; variational inference methods ; state structure ; variational distribution ; classification accuracy ; indirect calculation ; variational distributions ; baseline crfs ; conditional probability ; viterbi approximation	<method> <method> <method> <method> <material> <method> <task> <task> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <method> <otherscientificterm> <method>	3 4 14 ; 1 0 7 ; 0 0 9 ; 0 3 3 ; 5 0 3 ; 16 0 3 ; 2 1 0 ; 16 0 5 ; 16 0 14 ; 11 5 3 ; 11 5 0 ; 5 0 14 ; 2 3 3	conditional random fields -lrb- <method_3> -rrb- have been popular for <task_7> . this paper presents two <method_8> for direct approximation of a <otherscientificterm_15> instead of <method_12> through <method_16> of a marginal probability . the <method_3> with the <method_2> and the <method_0> are proposed and investigated for <task_6> . in general , <method_0> assumes a factorization of <otherscientificterm_13> of individual states for representation of <otherscientificterm_15> while <method_0> preserves the <otherscientificterm_9> in the <otherscientificterm_10> . in the experiments on using <material_4> , we found that <method_3> using <method_5> performed better than <method_14> using <method_16> . <method_3> with <method_0> obtained higher <metric_11> than those with <method_0> .	3 7 19 17 -1 8 15 12 16 17 -1 2 0 6 21 24 30 17 -1 13 9 10 20 17 -1 4 5 14 18 22 23 25 26 29 17 -1 11 27 28 17 -1
Maintaining Coherent Perceptual Information Using Anchoring .	spatial and olfactory sensors ; correspondence between sensor data ; extended periods of time ; mobile robotic system ; priori symbolic concepts ; user requested tasks ; anchoring framework ; symbolic descriptions ; perceptual maintenance ; sensor-data	<otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <material> <method> <otherscientificterm> <task> <material>	0 0 3 ; 6 0 8 ; 3 0 5	the purpose of this paper is to address the problem of maintaining coherent perceptual information in a <method_3> working over <otherscientificterm_2> , interacting with a user and using multiple sensing modalities to gather information about the environment and specific objects . we present a <method_3> which is able to use <otherscientificterm_0> to patrol a corridor and execute <material_5> . to cope with <task_8> we present an extension of the <method_6> capable of maintaining the <material_1> and the <otherscientificterm_7> referring to objects . <method_3> is also capable of tracking and acquiring information from observations derived from <material_9> as well as information from a <otherscientificterm_4> . the general <method_3> is described and an experimental validation on a <method_3> is presented .	3 2 10 -1 0 5 11 13 10 -1 8 6 1 7 12 10 -1 9 10 -1 4 10 -1
Burst deblurring : Removing camera shake through fourier burst accumulation .	inverse and inherently ill-posed deconvolution problem ; fourier burst accumulation algorithm ; real camera data ; fourier spectrum magnitude ; random nature ; image blur ; fourier domain ; on-board implementation ; digital cameras ; blur estimation ; inverse problem ; camera shake ; modality ; images ; photographer	<task> <method> <material> <metric> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <material> <method>	1 0 7 ; 2 5 1 ; 9 1 10	numerous recent approaches attempt to remove <otherscientificterm_5> due to <otherscientificterm_11> , either with one or multiple input <material_13> , by explicitly solving an <task_0> . if the <method_14> takes a burst of <material_13> , a <otherscientificterm_12> available in virtually all modern <otherscientificterm_8> , we show that it is possible to combine them to get a clean sharp version . this is done without explicitly solving any <method_9> and subsequent <task_10> . the proposed algorithm is strikingly simple : it performs a weighted average in the <material_6> , with weights depending on the <metric_3> . the method 's rationale is that <otherscientificterm_11> has a <otherscientificterm_4> and therefore each image in the burst is generally blurred differently . experiments with <material_2> show that the proposed <method_1> achieves state-of-the-art results an order of magnitude faster , with simplicity for <task_7> on camera phones .	5 11 13 0 15 -1 14 12 8 15 -1 9 10 18 15 -1 6 3 15 -1 15 -1 4 16 17 15 -1
Machine Translation Evaluation Meets Community Question Answering .	machine translation evaluation methods ; pairwise neural network architecture ; rich syntactic and semantic embeddings ; pairwise nn architecture ; community question answering ; mte features ; non-linear interactions ; ranking	<method> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <task>	5 1 2	we explore the applicability of <method_0> to a very different problem : answer <task_7> in <task_4> . in particular , we adopt a <method_1> , which incorporates <method_5> , as well as <otherscientificterm_2> , and which efficiently models complex <otherscientificterm_6> . the evaluation results show state-of-the-art performance , with sizeable contribution from both the <method_5> and from the <method_3> .	0 7 4 8 -1 1 5 2 6 9 8 -1 3 8 -1
Interactive Construction of 3D Models from Panoramic Mosaics .	soft and hard linear constraints ; linearly-constrained least-squares problem ; texture-mapped 3d models ; panoramic image mosaics ; interactive modeling system ; partition constraints ; qr factorization ; panoramic mosaic ; geometrical constraints ; 3d models ; transformation matrix	<otherscientificterm> <task> <method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	6 0 1 ; 3 0 4 ; 3 0 9 ; 1 0 4 ; 8 0 9 ; 4 0 9	this paper presents an <method_4> that constructs <method_9> from a collection of <material_3> . a <otherscientificterm_7> consists of a set of images taken around the same viewpoint , and a <otherscientificterm_10> associated with each input image . our <method_4> first recovers the camera pose for each mosaic from known line directions and points , and then constructs the <method_9> using all available <otherscientificterm_8> . we <otherscientificterm_5> into <otherscientificterm_0> so that the <method_4> can be formulated as a <task_1> , which can be solved efficiently using <method_6> . the results of extracting wire frame and <method_2> from single and multiple panoramas are presented .	4 9 3 13 14 17 11 -1 7 10 11 -1 8 16 11 -1 5 0 1 6 12 15 11 -1 2 11 -1
Perception-based selective encryption of G. 729 speech .	low-complexity , perception-based partial encryption scheme ; widely-used speech coding algorithm ; formal listening tests ; mobile multimedia applications ; customer privacy ; content protection ; telephone-bandwidth speech ; full encryption ; low-power techniques ; speech-content protection ; wireless services ; cs-acelp ; encryp-tion	<method> <method> <method> <task> <otherscientificterm> <task> <material> <otherscientificterm> <method> <task> <method> <method> <method>	5 5 11 ; 5 1 4 ; 8 0 3	mobile multimedia applications , the focus of many forthcoming <method_10> , increasingly demand <method_8> implementing <task_5> and <otherscientificterm_4> . in this paper a <method_0> for <material_6> is presented . speech compressed by a <method_1> , itu-t g. 729 <method_11> at 8 kb/s , is partitioned in two classes , one , the most perceptually relevant , to be encrypted , the other , to be left unprotected . <method_12> of about 45 % of the <method_11> achieves <task_5> equivalent to <otherscientificterm_7> of the <method_11> , as verified by both objective measures and <method_2> . low-power , portable devices can , therefore , implement very high levels of <task_9> at a fraction of the computational load of current techniques , freeing resources for other tasks and enabling longer battery life .	10 8 5 4 15 16 13 -1 0 6 13 -1 1 11 12 13 -1 7 2 14 13 -1 13 -1
Multi-view 3D Models from Single Images with a Convolutional Network .	surface mesh ; cluttered background ; depth map ; arbitrary view ; 3d representation ; depth maps ; point cloud ; rgb image ; convolutional network	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method>	8 0 4	we present a <method_8> capable of inferring a <method_4> of a previously unseen object given a single image of this object . concretely , the <method_8> can predict an <material_7> and a <otherscientificterm_2> of the object as seen from an <otherscientificterm_3> . several of these <otherscientificterm_5> fused together give a full <otherscientificterm_6> of the object . the <otherscientificterm_6> can in turn be transformed into a <otherscientificterm_0> . the <method_8> is trained on renderings of synthetic 3d models of cars and chairs . <method_8> successfully deals with objects on <otherscientificterm_1> and generates reasonable predictions for real images of cars .	8 4 10 9 -1 7 2 3 9 -1 5 6 9 -1 0 9 -1 9 -1 1 9 -1
No-Regret Learning in Bayesian Games .	bayesian coarse correlated equilibrium ; no-regret learning dynamics ; incomplete information games ; coarse correlated equilibria ; near-optimal welfare ; incomplete information ; bayesian games ; bayesian game	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method>	1 0 0 ; 4 2 1	recent price-of-anarchy analyses of games of complete information suggest that <otherscientificterm_3> , which characterize outcomes resulting from <otherscientificterm_1> , have <otherscientificterm_4> . this work provides two main technical results that lift this conclusion to games of <otherscientificterm_5> , a.k.a. , <material_6> . first , <otherscientificterm_4> in <material_6> follows directly from the smoothness-based proof of <otherscientificterm_4> in the same game when the private information is public . second , <otherscientificterm_1> converge to <otherscientificterm_0> in these <otherscientificterm_2> . these results are enabled by interpretation of a <method_7> as a stochastic game of complete information .	3 1 4 10 8 -1 5 6 8 -1 8 -1 0 2 9 8 -1 7 8 -1
Joint uncertainty decoding with the second order approximation for noise robust speech recognition .	vector taylor series ; joint uncertainty decoding algorithm ; joint uncertainty decoding ; aurora 2 database ; mathematically consistent framework ; second-order taylor expansion ; regression class ; front-end uncertainty ; regression classes ; computational cost ; recognition accuracy ; taylor expansion ; hmm mixture	<method> <method> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <metric> <method> <otherscientificterm>	10 5 1 ; 3 5 1 ; 9 5 1 ; 2 4 0 ; 11 4 0 ; 11 0 2 ; 5 0 1 ; 3 5 0 ; 10 5 0 ; 11 0 12 ; 9 5 0	joint uncertainty decoding has recently achieved promising results by integrating the <otherscientificterm_7> into the back-end in a <method_4> . in this paper , <method_2> is compared with the widely used <method_0> . we show that the two methods are identical except that <method_2> applies the <method_11> on each <otherscientificterm_6> whereas <method_0> applies <method_11> to each <otherscientificterm_12> . the relatively rougher expansion points used in <method_2> make <method_11> computationally cheaper than <method_0> but inevitably worse on <metric_10> . to overcome this drawback , this paper proposes an improved <method_1> which employs <method_5> on each <otherscientificterm_6> in order to reduce the expansion errors . special considerations are further given to limit the overall <metric_9> by adopting different number of <otherscientificterm_8> for different orders in the <method_11> . experiments on the <material_3> show that the proposed <method_1> is able to beat <method_0> on <metric_10> and <metric_9> with relative improvement up to 6 % and 60 % , respectively .	7 4 13 -1 2 0 17 13 -1 11 6 12 19 23 13 -1 10 18 13 -1 1 5 20 13 -1 13 -1 9 8 14 15 16 21 22 24 13 -1
A Variational Principle for Model-based Morphing .	multidimensional data set ; boundary value problem ; mixture models ; arc length ; extremal motionj ; euler-lagrange equations	<material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 4	given a <material_0> and a model of its density , we consider how to define the optimal interpolation between two points . this is done by assigning a cost to each path through space , based on two competing goals-one to interpolate through regions of high density , the other to minimize <otherscientificterm_3> . from this path functional , we derive the <otherscientificterm_5> for <otherscientificterm_4> given two points , the desired interpolation is found by solving a <task_1> . we show that this interpolation can be done efficiently , in high dimensions , for gaussian , dirichlet , and <method_2> .	0 6 -1 3 6 -1 5 4 1 7 6 -1 2 6 -1
Using the Structure of a Conceptual Network in Computing Semantic Relatedness .	computing semantic relatedness of concepts ; german counterpart of wordnet ; artificial conceptual glosses ; german dataset ; life sciences ; corpus analysis ; conceptual networks ; semantic re-latedness ; textual definitions ; semantic relatedness ; conceptual network ; germanet	<task> <material> <otherscientificterm> <material> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	3 5 11 ; 6 0 9 ; 10 0 2	we present a new method for <task_0> . the method relies solely on the structure of a <method_10> and eliminates the need for performing additional <task_5> . the <method_10> is employed to generate <otherscientificterm_2> . they replace <otherscientificterm_8> proper written by humans and are processed by a dictionary based metric of <otherscientificterm_9> -lsb- 1 -rsb- . we implemented the metric on the basis of <method_11> , the <material_1> , and evaluated the results on a <material_3> of 57 word pairs rated by human subjects for their <otherscientificterm_7> . our approach can be easily applied to compute <otherscientificterm_9> based on alternative <method_6> , e.g. in the domain of <material_4> .	0 12 -1 10 5 12 -1 2 15 12 -1 8 9 12 -1 11 1 3 7 13 12 -1 14 12 -1
Multiresolution eigenimages for texture classification .	fuzzy c-means algorithm ; gaussian properties of eigenimages ; classification of the texture ; r largest resulting coefficients ; fixed size Œ¥¬µŒ¥ ; brodatz album ; multiresolution eigenimages ; texture classification ; hotelling coefficients ; classification process ; sub-images ; classification ; Œ¥ ; hotelling	<method> <material> <task> <otherscientificterm> <otherscientificterm> <material> <material> <task> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method>	3 0 2 ; 0 0 11 ; 10 0 2	following an idea from -lsb- 1 -rsb- , based on the <material_1> , this paper presents a new technique for <task_7> using <material_6> . the input image , composed of two textures from the <material_5> , is subdivided into n <otherscientificterm_10> of <otherscientificterm_4> , which are blurred with a gaussian and normalized . the application of <method_13> transform decomposes each sub-image into <method_12> 2 eigenimages . the <otherscientificterm_3> can be used for <task_2> present in the <otherscientificterm_10> . <task_11> is done using the <method_0> and the performance is measured with an appropriate quality factor . we discuss the successful application of this technique , as well as the influence of the different parameters of the <method_9> on several pairs of textures . moreover , combination of <otherscientificterm_8> obtained with different values of <method_12> is shown to improve the performance , based on the idea of analyzing the texture at different levels of resolution .	1 7 6 14 -1 5 10 4 14 -1 13 12 14 -1 3 2 11 15 17 14 -1 0 16 14 -1 14 -1 9 14 -1
Unsupervised Modeling of Dialog Acts in Asynchronous Conversations .	lexical and structural similarity metrics ; mod-eling dialog acts ; graph-theoretic deter-ministic framework ; probabilistic conversation models ; modeling dialog acts ; graph-structural order ; hmm model ; temporal order ; asynchronous conversations ; unsupervised approaches ; conversation models ; hmm ; emails	<metric> <otherscientificterm> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <material> <method> <method> <method> <material>	8 2 4 ; 7 0 10 ; 10 4 6 ; 0 0 2 ; 9 0 4	we present <method_9> to the problem of <task_4> in <material_8> ; i.e. , conversations where participants collaborate with each other at different times . in particular , we investigate a <method_2> and two <method_3> -lrb- i.e. , <method_11> and hmm+m ix -rrb- for <otherscientificterm_1> in <material_12> and forums . we train and test our <method_10> on -lrb- a -rrb- <otherscientificterm_7> and -lrb- b -rrb- <otherscientificterm_5> of the datasets . empirical evaluation suggests -lrb- i -rrb- the <method_2> that relies on <metric_0> is not the right model for this task , -lrb- ii -rrb- <method_10> perform better on the <otherscientificterm_5> than the <otherscientificterm_7> of the datasets and -lrb- iii -rrb- hmm+m ix is a better <method_10> than the simple <method_6> .	9 4 8 14 18 13 -1 2 3 11 1 12 13 -1 10 7 5 15 13 -1 0 16 17 13 -1
Grounded Models as a Basis for Intuitive Reasoning .	generation of logical categories ; axiomatic theories ; intuitive reasoning ; autonomous agents ; language game ; spatial reasoning ; grounded models ; grounded model ; disjunction ; implication ; conjunction ; negation	<task> <otherscientificterm> <task> <method> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 1 10 ; 11 1 8 ; 8 1 9 ; 9 6 0 ; 7 0 5 ; 4 0 0 ; 10 6 0 ; 10 1 9 ; 10 1 8 ; 8 6 0	grounded models -lrb- siena 2001b -rrb- differ from <otherscientificterm_1> in establishing explicit connections between language and reality that are learned through language games -lrb- wittgen-stein 1953 -rrb- . this paper describes how <method_6> are constructed by <method_3> as a side effect of their activity playing different types of language games -lrb- steels 1999 -rrb- , and explains how they can be used for <task_2> . it proposes a particular <method_4> which can be used for simulating the <task_0> -lrb- such as <otherscientificterm_11> , <otherscientificterm_10> , <otherscientificterm_8> , <otherscientificterm_9> or equivalence -rrb- , and describes some experiments in which a couple of visually grounded agents construct a <method_7> that can be used for <task_5> .	1 12 -1 6 3 2 12 -1 4 0 11 10 8 9 13 14 15 16 17 18 19 20 21 22 12 -1
A Framework for Image Based Authentication .	compression and transmission techniques ; personal digital assistants ; image based authentication ; human difficulty ; user authentication ; heterogeneous networks ; image scalability ; mobile phones ; image tiling ; interactivity protocol ; embedded bitstream ; image exchange ; password ; images ; laptops ; images ; passwords	<method> <otherscientificterm> <task> <otherscientificterm> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <material> <otherscientificterm> <material> <otherscientificterm>	13 4 16 ; 1 1 14 ; 8 1 9 ; 7 1 1 ; 0 0 11 ; 14 1 5 ; 6 1 10 ; 10 1 8 ; 6 1 8	this paper presents an innovative framework for <task_4> based on <material_15> . common <task_4> based on <otherscientificterm_16> has the main drawback of the <otherscientificterm_3> in recalling them . <material_13> are instead easier to remember than <otherscientificterm_16> . moreover , modern <method_0> make <task_11> between different devices -lrb- e.g. <material_7> , <otherscientificterm_1> , <otherscientificterm_14> , and workstations -rrb- in <method_5> practically feasible . in the proposed approach , <material_15> are coded using the emerging jpeg2000 standard and taking advantage of many of its features -lrb- e.g. <otherscientificterm_6> , <otherscientificterm_10> , <otherscientificterm_8> , and <otherscientificterm_9> -rrb- . the described <task_2> is more secure than the common approach based on <material_12> .	4 15 17 -1 16 3 13 17 -1 18 17 -1 0 11 7 1 14 5 19 21 22 23 17 -1 6 10 8 9 20 24 25 26 17 -1 2 17 -1
WordTopic-MultiRank : A New Method for Automatic Keyphrase Extraction .	supervised and unsupervised graph-based ranking methods ; automatic keyphrase extraction task ; multi-relational word network ; automatic keyphrase extraction ; data sets ; latent topics ; heterogeneous relations ; ranking algorithm ; keyphrase extraction ; wordtopic-multirank ; robustness	<method> <task> <method> <task> <material> <otherscientificterm> <otherscientificterm> <method> <task> <method> <metric>	9 6 7 ; 9 0 8	automatic <task_8> aims to pick out a set of terms as a representation of a document without manual assignment efforts . <method_0> have been studied for this task . however , previous methods usually computed importance scores of words under the assumption of single relation between words . in this work , we propose <method_9> as a new method for <task_8> , based on the idea that words relate with each other via multiple relations . first we treat various <otherscientificterm_5> in documents as <otherscientificterm_6> between words and construct a <method_2> . then , a novel <method_7> , named <method_9> , is applied to score the importance of words and topics simultaneously , as words and topics are considered to have mutual influence on each other . experimental results on two different <material_4> show the outstanding performance and <metric_10> of our proposed approach in <task_1> .	8 0 11 -1 11 -1 11 -1 9 13 11 -1 5 6 2 11 -1 7 12 11 -1 11 -1
Geospatial Correspondences for Multimodal Registration .	change detection problems ; markov random field ; mid-level sensor-invariant representation ; ground truth transfer ; land-cover changes ; aerial images ; locality priors ; image regions ; multi-sensor images ; geographical areas ; spatial distribution ; non-uniform errors ; nonlinear mis-registrations	<task> <method> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 12 ; 2 0 7	the growing availability of very high resolution -lrb- < 1 m/pixel -rrb- satellite and <material_5> has opened up unprecedented opportunities to monitor and analyze the evolution of land-cover and land-use across the world . to do so , images of the same <otherscientificterm_9> acquired at different times and , potentially , with different sensors must be efficiently parsed to update maps and detect <otherscientificterm_4> . however , a na ¬® ƒ±ve transfer of ground truth labels from one location in the source image to the corresponding location in the target image is generally not feasible , as these images are often only loosely registered -lrb- with up to ¬± 50m of <otherscientificterm_11> -rrb- . furthermore , <otherscientificterm_4> in an area over time must be taken into account for an accurate <task_3> . to tackle these challenges , we propose a <method_2> that encodes <otherscientificterm_7> in terms of the <otherscientificterm_10> of their spectral neighbors . we incorporate this <method_2> in a <method_1> to simultaneously account for <otherscientificterm_12> and enforce <otherscientificterm_6> to find matches between <material_8> . we show how our approach can be used to assist in several mul-timodal land-cover update and <task_0> .	5 13 -1 9 4 13 -1 13 -1 11 13 -1 3 15 13 -1 2 7 10 14 13 -1 1 12 6 8 13 -1
Approximating Posterior Distributions in Belief Networks Using Mixtures .	densely connected bayesian networks ; sigmoid belief networks ; mean field distributions ; mean-field approximating distribution ; mean field distribution ; mean field theory ; approximation schemes ; tractable algorithm ; approximating distributions ; mixture parameters ; log likelihood ; mixture components	<method> <method> <otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	3 0 10	exact inference in <method_0> is computation-ally intractable , and so there is considerable interest in developing effective <method_6> . one approach which has been adopted is to bound the <otherscientificterm_10> using a <method_3> . while this leads to a <method_7> , the <method_4> is assumed to be factorial and hence unimodal . in this paper we demonstrate the feasibility of using a richer class of <otherscientificterm_8> based on mixtures of <otherscientificterm_2> . we derive an efficient algorithm for updating the <otherscientificterm_9> and apply it to the problem of learning in <method_1> . our results demonstrate a systematic improvement over simple <method_5> as the number of <method_11> is increased .	0 6 12 -1 10 3 13 12 -1 7 4 12 -1 8 2 12 -1 9 1 12 -1 12 -1
Spectral analysis of discrete signals generated by multiplicative and additive iterative procedures .	mul-tiplicative and additive iterative procedures ; additive signals ; generating vectors ; power spectra ; generation level ; features ; fourier	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	2 0 1	the discrete <method_6> transform of signals constructed through <method_0> is determined and its specific <otherscientificterm_5> are considered . it is shown that -- in spite of the rather different structure of multiplicative and <otherscientificterm_1> -- the <method_6> transforms of both types of signals exhibit the property of self-affinity . the <otherscientificterm_3> of <otherscientificterm_1> produced by different <method_2> have similar forms and can be divided into similar branches . the number of branches depends on the <otherscientificterm_4> and the symmetry of the power spectrum of the generating vector .	6 0 5 7 -1 1 7 -1 3 2 8 7 -1 4 7 -1
Reasoning about Occlusions during Hypothesis Verification .	object topology ; recognition hypotheses ; con-nectivity relationships ; topology reasoning ; verification strategies ; object recognition ; features ; occlusions ; verification	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <task>	4 0 5	in this paper we study the limitations of current <method_4> in <task_5> and suggest how <method_4> may be enhanced . on the whole <otherscientificterm_0> is exploited little during <task_8> . in practice , understanding the <otherscientificterm_2> between <otherscientificterm_6> in the image , or on the object , can lead to significantly more accurate evaluations of <otherscientificterm_1> . we study how <method_3> allows us to hypothesize the presence of <otherscientificterm_7> in the image . analysis of these hypotheses provides information which turns out to be crucial to the quality of our overall <task_8> results .	4 5 10 9 -1 0 8 9 -1 2 6 1 9 -1 3 7 9 -1 9 -1
A Probabilistic Approach to Integrating Multiple Cues in Visual Tracking .	linked hidden markov models ; message passing scheme ; hidden markov model ; chain topol-ogy ; probabilistic approach ; hierarchical integration ; visual cues ; particle filters ; visual tracking ; belief propagation ; particle filter ; edges ; color ; robustness	<method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <task> <task> <method> <otherscientificterm> <otherscientificterm> <metric>	1 0 7 ; 7 1 9 ; 12 1 11 ; 11 6 6 ; 12 6 6 ; 4 0 8	this paper presents a novel <method_4> to integrating multiple cues in <task_8> . we perform <task_8> in different cues by interacting processes . each process is represented by a <method_2> , and these parallel processes are arranged in a <method_3> . the resulting <method_0> naturally allow the use of <method_7> and <task_9> in a unified framework . in particular , a target is tracked in each cue by a <method_10> , and the <method_7> in different cues interact via a <method_1> . the general framework of our <method_4> allows a customized combination of different cues in different situations , which is desirable from the implementation point of view . our examples selectively integrate four <otherscientificterm_6> including <otherscientificterm_12> , <otherscientificterm_11> , motion and contours . we demonstrate empirically that the ordering of the cues is nearly inconsequential , and that our <method_4> is superior to other approaches such as independent integration and <method_5> in terms of flexibility and <metric_13> .	4 8 20 14 -1 14 -1 2 3 14 -1 0 7 9 16 14 -1 10 1 15 14 -1 14 -1 17 18 19 14 -1 6 12 11 14 -1
Dual Averaging and Proximal Gradient Descent for Online Alternating Direction Multiplier Method .	alternating direction multiplier method ; online proximal gradient descent type method ; on-line proximal gradient descent ; stochastic optimization techniques ; regular-ized dual averaging ; overlapped group lasso ; stochastic optimization methods ; composite function ; structured sparsity ; learning tasks ; online variants ; structured regularizations	<method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm>	0 0 7 ; 5 6 8 ; 2 1 4 ; 6 0 11 ; 0 3 6 ; 8 5 6 ; 3 1 0	we develop new <method_6> that are applicable to a wide range of <otherscientificterm_11> . basically our <method_6> are combinations of basic <method_3> and <method_0> . <method_0> is a general framework for optimizing a <otherscientificterm_7> , and has a wide range of applications . we propose two types of <method_10> of <method_0> , which correspond to <otherscientificterm_2> and <otherscientificterm_4> respectively . the proposed <method_6> are computationally efficient and easy to implement . our <method_6> yield o -lrb- 1 / ‚àö t -rrb- convergence of the expected risk . moreover , the <method_1> yields o -lrb- log -lrb- t -rrb- / t -rrb- convergence for a strongly convex loss . numerical experiments show effectiveness of our <method_6> in <task_9> with <otherscientificterm_8> such as <otherscientificterm_5> .	6 11 16 12 -1 3 0 17 19 12 -1 7 13 12 -1 10 2 4 15 12 -1 12 -1 12 -1 1 12 -1 14 18 12 -1
Analysis of Privacy Loss in Distributed Constraint Optimization .	distributed constraint optimization ; distributed contraint reasoning design decisions ; agent privacy ; centralized approaches ; privacy-efficiency tradeoffs ; multiagent coordination ; constraint-graph topology ; dpop ; adopt	<method> <task> <task> <method> <otherscientificterm> <task> <method> <method> <method>	7 1 8 ; 7 6 0 ; 2 0 0 ; 0 4 3 ; 0 0 5 ; 8 6 0	distributed constraint optimization -lrb- dcop -rrb- is rapidly emerging as a prominent technique for <task_5> . however , despite <task_2> being a key motivation for applying <method_0> in many applications , rigorous quantitative evaluations of privacy loss in <method_0> have been lacking . recently , -lsb- maheswaran et al. 2005 -rsb- introduced a framework for quantitative evaluations of privacy in <method_0> , showing that some <method_0> lose more privacy than purely <method_3> and questioning the motivation for applying <method_0> . this paper addresses the question of whether state-of-the art <method_0> suffer from a similar shortcoming by investigating several of the most efficient <method_0> , including both <method_7> and <method_8> . furthermore , while previous work investigated the impact on efficiency of <task_1> -lrb- e.g. <method_6> , asynchrony , message-contents -rrb- , this paper examines the privacy aspect of such <task_1> , providing an improved understanding of <otherscientificterm_4> .	5 14 9 -1 2 0 12 9 -1 3 13 9 -1 10 11 15 9 -1 7 8 9 -1
Ensemble selection from libraries of models .	forward stepwise selection ; learning algorithms ; ensemble selection ; mean precision ; parameter settings ; cross entropy ; roc area ; ensemble selection ; accuracy	<method> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <metric> <task> <metric>	5 1 3 ; 1 1 4 ; 3 1 6 ; 8 1 3 ; 8 1 5	we present a method for constructing ensembles from libraries of thousands of models . model libraries are generated using different <method_1> and <otherscientificterm_4> . <method_0> is used to add to the ensemble the models that maximize its performance . <task_2> allows ensembles to be optimized to performance metric such as <metric_8> , <otherscientificterm_5> , <metric_3> , or <metric_6> . experiments with seven test problems and ten metrics demonstrate the benefit of <task_7> .	9 -1 1 4 0 11 9 -1 2 9 -1 8 5 3 6 10 12 13 14 9 -1 7 9 -1
A Siamese Long Short-Term Memory Architecture for Human Re-identification .	siamese long short-term memory architecture ; market-1501 , cuhk03 and viper datasets ; human re-identification ; local feature representation ; internal gating mechanism ; visual surveillance ; contextual information ; feedback connections ; feature extraction ; image regions ; spatial dependencies ; matching pedestrians ; lstm units	<method> <material> <task> <method> <method> <task> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 10 ; 0 0 9 ; 7 1 0 ; 7 1 4	matching pedestrians across multiple camera views known as <task_2> is a challenging problem in <task_5> . in the existing works concentrating on <task_8> , representations are formed locally and independent of other regions . we present a novel <method_0> that can process <otherscientificterm_9> sequentially and enhance the discriminative capability of <method_3> by leverag-ing <otherscientificterm_6> . the <material_7> and <method_4> of the <method_0> enable our <method_0> to memorize the <otherscientificterm_10> and selectively propagate relevant <otherscientificterm_6> through the network . we demonstrate improved performance compared to the baseline algorithm with no <otherscientificterm_12> and promising results compared to state-of-the-art methods on <material_1> . visualization of the internal mechanism of <method_0> shows meaningful patterns can be learned by our <method_0> .	2 5 13 -1 8 13 -1 0 9 3 6 15 13 -1 7 4 10 14 16 17 13 -1 12 1 13 -1 13 -1
Trace Quotient Problems Revisited .	optimal projection pursuing ; generalized eigenvalue decomposition approach ; computer vision problems ; final distance measurement ; trace difference problem ; quotient trace formulation ; trace quotient problem ; objective function value ; non-singular linear transformation ; quotient trace problem ; quotient trace ; orthogonal transformations ; face recognition ; classification capability ; trace quotient ; former formulation ; iterative procedure ; grassmann manifold	<method> <method> <task> <metric> <task> <method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <method> <method> <otherscientificterm>	6 1 4 ; 12 5 0	the formulation of <otherscientificterm_14> is shared by many <task_2> ; however , it was conventionally approximated by an essentially different formulation of <otherscientificterm_10> , which can be solved with the <method_1> . in this paper , we present a direct solution to the <method_15> . first , considering that the feasible solutions are constrained on a <otherscientificterm_17> , we present a necessary condition for the optimal solution of the <task_6> , which then naturally elicits an <method_16> for pursuing the optimal solution . the proposed algorithm , referred to as <method_0> , has the following characteristics : 1 -rrb- <method_0> directly optimizes the <otherscientificterm_14> , and is theoretically optimal ; 2 -rrb- <method_0> does not suffer from the solution uncertainty issue existing in the <method_5> that the <otherscientificterm_7> is invariant under any <otherscientificterm_8> , and <method_0> is invariant only under <otherscientificterm_11> , which does not affect <metric_3> ; and 3 -rrb- <method_0> reveals the underlying equivalence between the <task_6> and the corresponding <task_4> . extensive experiments on <task_12> validate the superiority of <method_0> over the solution of the corresponding <task_9> in both <otherscientificterm_7> and <metric_13> .	14 2 10 1 18 -1 15 18 -1 17 6 16 18 -1 0 19 18 -1 5 7 8 11 3 4 20 18 -1
Towards optimal query design for relevance feedback in image retrieval .	greedy active learning based relevance feedback methods ; real image retrieval ; active learning approach ; image retrieval ; relevance feedbacks ; precession/recall rate	<method> <task> <method> <task> <otherscientificterm> <metric>	5 5 2 ; 1 5 2 ; 4 5 2	we analyze the sub-optimality of traditional <method_0> in <task_3> , and propose a novel <method_2> to query labels of multiple images together , which minimize the needed round of feedbacks and achieve satisfactory result in a near optimal manner . our experiments on <task_1> demonstrate that our <method_2> can yield comparable <metric_5> by significantly less <otherscientificterm_4> .	0 3 2 6 -1 1 5 4 7 8 9 6 -1
Fine-Grained Categorization by Alignments .	cu-2011 birds and stanford dogs fine-grained datasets ; matching oriented features ; fine-grained sub-categories ; human interaction ; fine-grained categorization ; fisher vectors ; localized information ; training images ; super-class shape ; classification-oriented encodings ; part annotations ; detectors ; hog	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	7 0 10 ; 9 0 6 ; 5 6 9 ; 5 0 6 ; 5 6 2	the aim of this paper is <task_4> without <otherscientificterm_3> . different from prior work , which relies on <method_11> for specific object parts , we propose to localize distinctive details by roughly aligning the objects using just the overall shape , since implicit to <task_4> is the existence of a <otherscientificterm_8> shared among all classes . the alignments are then used to transfer <otherscientificterm_10> from <material_7> to test images -lrb- supervised alignment -rrb- , or to blindly yet consistently segment the object in a number of regions -lrb- unsupervised alignment -rrb- . we furthermore argue that in the distinction of <otherscientificterm_2> , <otherscientificterm_9> like <method_5> are better suited for describing <otherscientificterm_6> than popular <otherscientificterm_1> like <method_12> . we evaluate the method on the <material_0> , outperforming the state-of-the-art .	4 3 13 -1 11 8 13 -1 10 7 14 13 -1 15 16 17 18 13 -1 2 9 5 6 1 12 13 -1
Minimum Bayes-risk System Combination .	unified multi-system minimum bayes-risk technique ; minimum bayes-risk system combination ; minimum risk translation ; mbr decision rule ; system combination methods ; single-system-based mbr decoding ; consensus decoding ; linear combination ; probability distributions ; smt models ; mbr methods ; finite-length strings ; bleu score ; smt system ; system combination ; heterogeneous structure ; approximation ; bleu	<method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <method> <metric>	1 3 9 ; 7 0 1 ; 6 1 14 ; 14 3 0 ; 10 0 13 ; 7 0 2	we present <method_1> , a method that integrates <method_6> and <method_14> into a <method_0> . unlike other <method_10> that re-rank translations of a single <method_13> , <method_1> uses the <otherscientificterm_3> and a <method_7> of the component systems ' <otherscientificterm_8> to search for the <otherscientificterm_2> among all the <otherscientificterm_11> over the output vocabulary . we introduce expected <metric_17> , an <method_16> to the <metric_12> that allows to efficiently apply <metric_17> in these conditions . <method_1> is a general method that is independent of specific <method_9> , enabling us to combine systems with <otherscientificterm_15> . experiments show that our approach bring significant improvements to <task_5> and achieves comparable results to different state-of-the-art <method_4> .	1 6 14 0 21 22 18 -1 10 13 3 7 8 2 11 20 23 24 18 -1 17 16 12 18 -1 9 15 19 18 -1 18 -1
Improved `` TEO '' feature-based automatic stress detection using physiological and acoustic speech sensors .	vibrations of the vocal tract ; stand-alone speech data collection devices ; relative average error rate reductions ; teo-cb-autoenv-based automatic stress recognition system ; acoustic and physiological microphone data ; alternative speech collection sensors ; weighted composite decision scheme ; acoustic and physiological sensors ; law enforcement training scenario ; automatic speech recognition systems ; stress level assessment ; speech production organs ; acoustic pressure microphone ; background noise ; gel-based device ; vocal folds ; feature relation ; physiological microphone ; speech data ; teo-cb-autoenv feature ; sensitivity	<otherscientificterm> <method> <metric> <method> <material> <method> <method> <method> <task> <task> <task> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <metric>	14 0 15 ; 19 0 8 ; 14 0 0 ; 7 1 1 ; 18 0 9 ; 5 0 9 ; 4 0 6 ; 16 0 10 ; 12 0 18 ; 12 0 9 ; 14 0 13	the <method_12> has served as the primary instrument for collecting <material_18> for <task_9> . the <method_12> suffers from limitations , such as <metric_20> to <otherscientificterm_13> and relatively far proximity to <material_11> . <method_5> may serve to enhance the effectiveness of <task_9> . in this study , we first consider an experimental evaluation of the <otherscientificterm_19> in an actual <task_8> . we consider <otherscientificterm_16> to <task_10> over time . next , we explore the use of the <method_17> , a <method_14> placed next to the <otherscientificterm_15> on the outside of the throat used to measure <otherscientificterm_0> and minimize <otherscientificterm_13> , as we investigate the effectiveness of a <method_3> . we employ both <method_7> as <method_1> as well as consider both sensors concurrently . for the latter , we devise a <method_6> using both the <material_4> that yields <metric_2> of 32 % and 6 % versus sole employment of <material_4> , respectively , in a realistic stressful environment .	12 18 9 26 30 31 21 -1 20 13 11 5 21 -1 27 21 -1 19 8 23 21 -1 16 10 29 21 -1 17 14 15 0 22 24 32 21 -1 3 25 21 -1 7 1 28 21 -1
Balance between Complexity and Quality : Local Search for Minimum Vertex Cover in Massive Graphs .	state of the art local search algorithms ; minimum vertex cover ; real world massive graphs ; local search algorithms ; local search algorithm ; local search method ; high-complexity heuristics ; heuristic algorithms ; low-complexity heuristics ; np-hard problem ; graph	<method> <method> <material> <method> <method> <method> <otherscientificterm> <method> <method> <task> <otherscientificterm>	1 0 1 ; 7 0 1 ; 2 5 1 ; 3 0 1 ; 5 0 7	the problem of finding a <method_1> in a <otherscientificterm_10> is a well known <task_9> with important applications . there has been much interest in developing <method_7> for finding a '' good '' vertex cover in graphs . in practice , most <method_7> for <method_1> are based on the <method_5> . previously , <method_3> for <method_1> have focused on solving academic benchmarks where the graphs are of relatively small size , and they are not suitable for solving massive graphs as they usually have <otherscientificterm_6> . in this paper , we propose a simple and fast <method_4> called <method_1> for solving <method_1> in massive graphs , which is based on two <method_8> . experimental results on a broad range of <material_2> show that <method_1> finds much better vertex covers -lrb- and thus also independent sets -rrb- than <method_0> for <method_1> .	1 10 9 11 -1 7 11 -1 5 13 16 11 -1 3 6 15 11 -1 4 12 11 -1 8 14 11 -1
A new pitch modeling approach for Mandarin speech .	mean and shape of syllable pitch contour ; closed and open tests ; model syllable pitch contour ; pitch mean model ; prosodic phrase boundaries ; pitch modeling approach ; mandarin speech ; em algorithm ; inter-syllable locations ; reconstructed pitch ; prosodic states ; linguistic knowledge ; rmses	<otherscientificterm> <material> <task> <method> <otherscientificterm> <method> <material> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric>	9 0 1 ; 12 0 1 ; 2 0 6	in this paper , a new approach to <task_2> for <material_6> is proposed . it takes the <otherscientificterm_0> as two basic modeling units and considers several affecting factors that contribute to their variations . parameters of the two models are automatically estimated by the <method_7> . experimental results showed that <metric_12> of 0.551 ms and 0.614 ms in the <material_9> were obtained for the <material_1> , respectively . all inferred values of those affecting factors agreed well with our prior <otherscientificterm_11> . besides , the <otherscientificterm_10> automatically labeled by the <method_3> provided useful cues to determine the <otherscientificterm_4> occurred at <otherscientificterm_8> without punctuation marks . so it is a promising <method_5> .	2 6 16 13 -1 0 13 -1 7 13 -1 12 9 1 14 15 13 -1 11 13 -1 10 3 4 13 -1 8 13 -1
Durational characteristics of hindi stop consonants .	annotated and time-aligned hindi speech database ; durational characteristics of hindi stop consonants ; durations of closure ; spoken sentences ; post-release duration ; continuous speech ; closure duration ; gemination ; vowel ; aspiration	<material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 1 7	a study of the <otherscientificterm_1> in <material_3> was carried out . an <material_0> was used in the experiment . the influences of <otherscientificterm_9> , voicing and <otherscientificterm_7> on the <otherscientificterm_2> and post-release segments of plosives as well as the duration of the preceding <otherscientificterm_8> were studied . it was observed that the <otherscientificterm_4> of a plosive changes systematically with manner of articulation . however , due to its large variation in <material_5> , the <otherscientificterm_4> alone is not sufficient to identify the manner of articulation of hindi stops as hypothesised in earlier studies . a low value of the ratio of the duration of a <otherscientificterm_8> to the <otherscientificterm_6> of the following plosive is a reliable indicator of <otherscientificterm_7> in hindi stop consonants in <material_5> .	1 3 10 -1 0 10 -1 9 7 2 8 11 10 -1 4 10 -1 5 10 -1 10 -1
Nonlinear average consensus based on weight morphing .	unknown noise levels ; signal-adaptive morphing coefficients ; convex-optimization weights ; metropolis-hastings weights ; weight design ; average consensus ; abrupt changes ; dynamic scenarios	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <task>	3 1 2 ; 4 0 5 ; 6 1 0 ; 4 0 7 ; 3 1 1	we present a novel <method_4> for <otherscientificterm_5> that improves its transient and stead-state performance . the idea is to blend <method_3> and <otherscientificterm_2> via <otherscientificterm_1> . the resulting <method_4> is shown to be particularly useful in <task_7> where the measurements feature <otherscientificterm_6> or <otherscientificterm_0> .	4 5 10 8 -1 3 2 1 9 13 8 -1 7 6 0 11 12 8 -1
Sparse Variation Dictionary Learning for Face Recognition with a Single Training Sample per Person .	sparse variation dictionary learning method ; large-scale cmu multi-pie , frgc and lfw databases ; face recognition ; sparse representation based classification ; sparse representation based classification ; sparse variation dictionary ; query sample representation ; query sample ; gallery set ; face images ; projection ; pose ; expression ; illumination ; occlusion	<method> <material> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	14 6 9 ; 3 0 5 ; 2 0 6 ; 13 1 12 ; 14 1 11 ; 13 6 9 ; 0 0 8 ; 12 6 9 ; 5 0 6 ; 11 6 9 ; 12 1 14 ; 2 0 5	face recognition -lrb- <task_2> -rrb- with a single training sample per person -lrb- <task_2> -rrb- is a very challenging problem due to the lack of information to predict the variations in the <otherscientificterm_7> . <method_4> has shown interesting results in robust <task_2> ; however , its performance will deteriorate much for <task_2> with <task_2> . to address this issue , in this paper we learn a <otherscientificterm_5> from a generic training set to improve the <method_6> by <task_2> . instead of learning from the generic training set independently w.r.t. the <material_8> , the proposed <method_0> is adaptive to the <material_8> by jointly learning a <otherscientificterm_10> to connect the generic training set with the <material_8> . the learnt <otherscientificterm_5> can be easily integrated into the framework of <method_3> so that various variations in <otherscientificterm_9> , including <otherscientificterm_13> , <otherscientificterm_12> , <otherscientificterm_14> , <otherscientificterm_11> , etc. , can be better handled . experiments on the <material_1> demonstrate the promising performance of <task_2> on <task_2> with <task_2> .	2 7 4 15 -1 15 -1 5 6 18 24 27 15 -1 8 0 22 15 -1 10 16 17 19 20 21 23 25 26 15 -1 3 9 13 12 14 11 15 -1
Articulatory features from deep neural networks and their role in speech recognition .	wall street journal corpus ; deep neural network ; corpus of synthetic english words ; continuous speech recognition task ; vocal tract variables ; deep neural networks ; automatic speech recognition ; articulatory trajectory estimation ; articulatory trajectories ; input speech ; articulatory features ; cepstral features ; task-dynamic model ; training data ; hidden variables ; speech recognition ; articulatory information ; word recognition ; speech signal ; index terms ; feature ; accuracy ; aurora-4	<material> <method> <material> <task> <otherscientificterm> <method> <task> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <metric> <material>	15 5 17 ; 4 6 19 ; 6 1 4 ; 1 0 8 ; 8 6 19 ; 1 0 15 ; 6 6 19 ; 14 0 1 ; 8 1 5 ; 10 0 15 ; 4 1 5 ; 8 1 4 ; 20 0 1 ; 10 2 17 ; 6 1 8 ; 1 0 16	this paper presents a <method_1> to extract <otherscientificterm_16> from the <material_18> and explores different ways to use such information in a <task_3> . the <method_1> was trained to estimate <otherscientificterm_8> from <material_9> , where the <material_13> is a <material_2> generated by the haskins laboratories ' <method_12> of speech production . speech parameterized as <otherscientificterm_11> were used to train the <method_1> , where we explored different <otherscientificterm_11> to observe their role in the <metric_21> of <task_7> . the best <otherscientificterm_20> was used to train the final <method_1> , where the <method_1> was used to predict <otherscientificterm_8> for the training and testing set of <material_22> , the noisy <material_0> . this study also explored the use of <otherscientificterm_14> in the <method_1> as a potential acoustic <otherscientificterm_20> candidate for <task_15> and the results were encouraging . <task_17> results from <material_22> indicate that the <otherscientificterm_10> from the <method_1> provide improvement in <task_15> performance when fused with other standard <otherscientificterm_11> ; however when tried by themselves , they failed to match the baseline performance . <otherscientificterm_19> -- <task_6> , <otherscientificterm_8> , <otherscientificterm_4> , <method_5> .	1 16 18 3 39 23 -1 8 9 13 2 12 23 -1 11 21 7 23 -1 20 27 36 23 -1 22 0 31 23 -1 14 15 17 24 29 33 37 23 -1 10 19 25 26 28 30 32 34 35 38 23 -1
Approximation of complex-valued 2-D frequency response specifications by separable-denominator digital filters .	real-valued 2-d iir sd digital lter ; real-valued 2-d fir digital lter ; fir-to-iir approximation problem ; approximation problem ; frequency response ; complex-valued spec-ication ; theorem	<otherscientificterm> <otherscientificterm> <task> <task> <method> <otherscientificterm> <otherscientificterm>	4 0 5	in this paper the approximation of a <otherscientificterm_5> by the <method_4> of a 2-d iir separable denominator -lrb- sd -rrb- digital lter is considered . the <task_3> is transformed into an equivalent one , where a <otherscientificterm_0> with some additional characteristics has to be determined that approximates a given <otherscientificterm_1> . a <otherscientificterm_6> is presented that helps to reduce the number of parameters in the <task_2> and a procedure to solve the problem numerically is given .	5 4 8 7 -1 3 0 1 7 -1 6 2 7 -1
Optimum channel shortening for discrete multitone transceivers .	maximum shortening snr method ; optimum channel shortening method ; discrete multitone dmt transceivers ; input energy distribution ; bit rate ; dmt symbol ; isi paths ; snr ; noise ; subchannel	<method> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 4 1 ; 8 1 6 ; 1 0 2	we propose an <method_1> for <method_2> . the proposed <method_1> shortens a given channel to a desired length while maximizing the number of bits transmitted on a <otherscientificterm_5> . the key to the optimum solution is the deenition of the <otherscientificterm_7> in a <otherscientificterm_9> using the equivalent signal , <otherscientificterm_8> , and <otherscientificterm_6> in the system . our simulation results show that the proposed <method_1> outperforms the best existing <method_1> with a 18 increase in the <metric_4> . we show that the <method_0> is a special case of the proposed <method_1> and both methods are nearly equivalent when the <otherscientificterm_3> is constant o v er all subchannels .	1 2 13 10 -1 5 10 -1 7 9 8 6 12 10 -1 4 11 10 -1 0 3 10 -1
Jacobian adaptation based on the frequency-filtered spectral energies .	mel-frequency cepstral coefficients ; frequency-filtered spectral energies ; jacobian adaptation ; jacobian linear transformation ; vocal tract length ; robust speech recognition ; adaptation technique ; jacobian adaptation ; channel distortion ; degrading factors ; ja technique ; acoustic models ; ja ; features ; recognition	<method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task>	0 2 7 ; 8 6 9 ; 14 5 10 ; 10 0 13 ; 4 6 9 ; 11 0 5 ; 6 0 5 ; 8 1 4	‚Ä† <method_2> of the <method_11> is an efficient <method_6> for <task_5> . several improvements for the <method_12> have been proposed in the last years , either to generalize the <method_3> for the case of large noise mismatch between training and testing or to extend the adaptation to other <otherscientificterm_9> , like <otherscientificterm_8> and <otherscientificterm_4> . however , the <method_10> has only been used so far with the conventional <method_0> . in this paper , the <method_10> is applied to an alternative type of <otherscientificterm_13> , the <otherscientificterm_1> , resulting in a more computationally efficient <method_10> . furthermore , in experimental tests with the database aurora1 , this new <method_10> has shown an improved <task_14> performance with respect to the <task_7> with <method_0> .	2 11 6 5 21 22 15 -1 12 3 9 8 4 17 20 23 15 -1 10 0 15 -1 13 1 19 15 -1 16 18 15 -1
Branch-and-price global optimization for multi-view multi-target tracking .	3d human pose tracking ; configuration of the cameras ; temporal correlations between objects ; combinato-rial optimization problem ; reconstruction and tracking ; graph structure ; assignment problem ; min-cost problem ; multi-view images ; global optimization ; spatial correlations ; dantzig-wolfe decomposition ; branching	<task> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <task> <task> <material> <task> <otherscientificterm> <method> <otherscientificterm>	11 1 12 ; 7 0 6	we present a new algorithm to jointly track multiple objects in <material_8> . while this has been typically addressed separately in the past , we tackle the problem as a single <task_9> . we formulate this <task_6> as a <task_7> by defining a <otherscientificterm_5> that captures both <otherscientificterm_2> as well as <otherscientificterm_10> enforced by the <otherscientificterm_1> . this leads to a complex <task_3> that we solve using <method_11> and <otherscientificterm_12> . our formulation allows us to solve the problem of <task_4> in a single step by taking all available evidence into account . in several experiments on multiple people tracking and <task_0> , we show our method outperforms state-of-the-art approaches .	8 13 -1 9 13 -1 6 7 5 2 10 1 15 13 -1 3 11 12 14 13 -1 4 13 -1 13 -1
Reducing multiclass to binary by coupling probability estimates .	pairwise coupling of probability estimates ; calibrated class membership probability estimates ; obtaining class membership probability estimates ; arbitrary code matrices ; multiclass classification problems ; probability estimates ; loss-based decoding ; classification accuracy ; binary classifiers	<task> <task> <task> <method> <task> <method> <method> <metric> <method>	8 0 5	this paper presents a method for <task_2> for <task_4> by coupling the <method_5> produced by <method_8> . this is an extension for <method_3> of a method due to hastie and tibshirani for <task_0> . experimental results with boosted naive bayes show that our method produces <task_1> , while having similar <metric_7> as <method_6> , a method for obtaining the most likely class that does not generate <method_5> .	2 4 5 8 10 9 -1 3 0 9 -1 1 7 6 9 -1
Continuous listening for unconstrained spoken dialog .	domain-independent , multi-modal computational architecture ; runtime behavior of presenter ; powerpoint slide shows ; spoken dialog systems ; spoken requests ; prototype system ; bayesian models ; recorded lecture ; continuous listening ; push-to-talk device ; spoken dialog ; decision-theoretic approach ; presenter	<method> <method> <material> <method> <material> <method> <method> <material> <method> <method> <material> <method> <method>	12 6 5 ; 11 0 3	a major hindrance to rendering <method_3> capable of ongoing , <method_8> without requiring a <method_9> is the <method_3> of distinguishing speech which is intended for the system from that which is overheard . we present a <method_11> to this <method_3> that exploits <method_6> of <material_10> at four levels of analysis within a <method_0> called quartet . we applied quartet to the task of navigating <material_2> during a spoken presentation in a <method_5> called <method_12> . we describe the <method_1> as well as the results of an experimental study comparing the performance of <method_12> to human subjects in discriminating arbitrarily formed <material_4> for <material_2> during a <material_7> .	3 8 9 13 -1 11 6 10 0 15 13 -1 2 5 12 14 13 -1 1 13 -1
Low-complexity sinusoidal component selection using loudness patterns .	perceptual sinusoidal component selection strategies ; low perceptual sinusoidal synthesis error ; hybrid loudness estimation scheme ; quantitative or perceptual criterion ; sinusoidal modeling of audio ; sinusoidal selection algorithm ; multi-tone signal ; loudness patterns ; real-time applications ; computational complexity	<method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <task> <metric>	2 0 6 ; 2 0 5 ; 0 0 8	sinusoidal modeling of audio at low-bit rates involves selecting a limited number of parameters according to a <otherscientificterm_3> . most <method_0> are computationally intensive and not suitable for <task_8> . in this paper , a computationally efficient <method_5> based on a novel <method_2> is presented . the <method_2> first estimates efficiently the loudness of a <otherscientificterm_6> from the <otherscientificterm_7> of its constituent sinusoidal components . then it refines this estimate by performing a full evaluation of loudness but only in select critical bands . experimental results show that the proposed technique maintains a <otherscientificterm_1> at a much lower <metric_9> .	3 10 -1 0 8 13 10 -1 5 2 12 10 -1 6 7 11 10 -1 10 -1 1 9 10 -1
When Does Schwartz Conjecture Hold ? .	schwartz 's conjecture ; polynomial time ; œÑ	<method> <otherscientificterm> <method>	1 2 2	in 1990 , thomas schwartz proposed the conjecture that every nonempty tournament has a unique minimal œÑ-retentive set -lrb- <method_2> stands for tournament equilibrium set -rrb- . a weak variant of <method_0> was recently proposed by felix brandt . however , both conjectures were disproved very recently by two counterexamples . in this paper , we prove sufficient conditions for infinite classes of tournaments that satisfy <method_0> and brandt 's conjecture . moreover , we prove that <method_2> can be calculated in <otherscientificterm_1> in several infinite classes of tournaments . furthermore , our results reveal some structures that are forbidden in every counterexample to <method_0> .	2 3 -1 0 3 -1 3 -1 3 -1 1 4 3 -1 3 -1
Monocular 3D Object Detection for Autonomous Driving .	candidate class-specific object proposals ; object proposal generation approach ; 3d object detection ; high-quality object detections ; published monocular competitors ; cnn pipeline ; contextual information ; autonomous driving ; semantic seg-mentation ; monocular approaches ; proposal generation ; object shape ; kitti benchmark ; image plane ; monocular image ; ground-plane ; detection	<otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <method> <task> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <task>	5 0 3 ; 1 4 9 ; 5 0 0 ; 14 0 2 ; 7 0 2 ; 8 1 6 ; 1 0 16	the goal of this paper is to perform <task_2> from a single <material_14> in the domain of <task_7> . our method first aims to generate a set of <otherscientificterm_0> , which are then run through a standard <method_5> to obtain <otherscientificterm_3> . the focus of this paper is on <task_10> . in particular , we propose an <method_1> that places object candidates in 3d using the fact that objects should be on the <otherscientificterm_15> . we then score each candidate box projected to the <otherscientificterm_13> via several intuitive potentials encoding <otherscientificterm_8> , <otherscientificterm_6> , size and location priors and typical <otherscientificterm_11> . our experimental evaluation demonstrates that our <method_1> significantly outperforms all <method_9> , and achieves the best <task_16> performance on the challenging <metric_12> , among <otherscientificterm_4> .	2 14 7 21 22 17 -1 0 5 3 18 20 17 -1 10 17 -1 1 15 17 -1 13 8 6 23 17 -1 11 19 24 17 -1
Pipeline Iteration .	union of un-constrained parses ; finite-state shallow parser ; pcfg parsing pipeline ; pipeline iteration ; base-phrase constraints ; parsing pipeline ; heavily-constrained parses	<method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm>	4 0 2	this paper presents <task_3> , an approach that uses output from later stages of a <task_3> to constrain earlier stages of the same <task_3> . we demonstrate significant improvements in a state-of-the-art <method_2> using <otherscientificterm_4> , derived either from later stages of the <method_5> or from a <method_1> . the best performance is achieved by reranking the <method_0> and relatively <otherscientificterm_6> .	3 7 -1 2 4 5 1 8 7 -1 0 6 7 -1
An efficient top-down parsing algorithm for understanding speech by using stochastic syntactic and semantic models .	syntactic and semantic knowledge ; speech understanding system ; pronunciation layer ; consistency problems ; high efficiency ; top-down strategy ; parse tree ; semantic content ; acoustic-phonetic knowledge ; chart-parsing technique ; understanding speech ; incremental algorithm ; integrated search ; probabilistic models ; word hypotheses ; structure-sharing ; grammar ; recognizer	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <material> <otherscientificterm> <method> <task> <method> <method> <method> <otherscientificterm> <method> <method> <method>	15 2 9 ; 12 0 7	the paper is concerning an approach for <task_10> using a new form of <method_13> to represent <otherscientificterm_0> of a restricted domain . one important feature of our <method_16> is that the <otherscientificterm_6> directly represents the <material_7> of the utterance . since we determine that <material_7> by an <method_12> , we avoid <otherscientificterm_3> at the interface between the <method_17> and the language understanding part of the <method_1> . we succeeded in designing such an <method_11> , which integrates semantic , syntactic , and <otherscientificterm_8> in a seamless , consistent way . <metric_4> is achieved by using a <method_9> with <method_15> and a strict <method_5> for opening new <otherscientificterm_14> in the <otherscientificterm_2> .	10 13 0 18 -1 16 6 7 18 -1 12 3 17 1 20 18 -1 11 8 4 18 -1 9 15 19 18 -1
On Region Merging : The Statistical Soundness of Fast Sorting , with Applications .	occlu-sions and/or hard noise levels ; grey-level and color images ; fast segmentation algorithm ; numerical feature spaces ; image segmentation ; computer vision ; processing images ; c-code	<otherscientificterm> <material> <method> <otherscientificterm> <task> <task> <task> <method>	3 0 2 ; 2 0 6	this work explores a statistical basis for a process often described in <task_5> : <task_4> by region merging following a particular order in the choice of regions . we exhibit a particular blend of algorithmics and statistics whose error is , as we formally show , close to the best possible . this approach can be approximated in a very <method_2> for <task_6> described using most common <otherscientificterm_3> . simple modifications of the algorithm allow to cope with <otherscientificterm_0> . experiments on <material_1> , obtained with a short <method_7> , display the quality of the segmentations obtained .	5 4 8 -1 8 -1 2 6 3 9 10 8 -1 0 8 -1 1 7 8 -1
A 4D Light-Field Dataset and CNN Architectures for Material Recognition .	light-field dataset of materials ; view-dependent reflectance effects ; 2d image classification ; multiple sub-aperture views ; light-field images ; image segmentation ; recognition networks ; material recognition ; deep learning ; 4d images ; object detection ; 4d light-field ; mid-size dataset ; lytro illum ; cnn architectures ; view interpolation ; light-field applications ; light-fields	<method> <otherscientificterm> <method> <otherscientificterm> <material> <task> <method> <task> <method> <material> <task> <otherscientificterm> <material> <method> <method> <task> <task> <otherscientificterm>	5 6 17 ; 7 0 11 ; 10 6 17 ; 15 6 17 ; 5 1 15 ; 10 1 5 ; 3 1 1 ; 12 0 4 ; 14 0 16 ; 8 0 7	we introduce a new <method_0> , and take advantage of the recent success of <method_8> to perform <task_7> on the <otherscientificterm_11> . our <method_0> contains 12 material categories , each with 100 images taken with a <method_13> , from which we extract about 30,000 patches in total . to the best of our knowledge , <method_0> is the first <material_12> for <material_4> . our main goal is to investigate whether the additional information in a light-field -lrb- such as <otherscientificterm_3> and <otherscientificterm_1> -rrb- can aid <task_7> . since <method_6> have not been trained on <material_9> before , we propose and compare several novel <method_14> to train on <material_4> . in our experiments , the best performing <method_14> achieves a 7 % boost compared with <method_2> -lrb- 70 % ‚Üí 77 % -rrb- . these results constitute important baselines that can spur further research in the use of <method_14> for <task_16> . upon publication , our <method_0> also enables other novel applications of <otherscientificterm_17> , including <task_10> , <task_5> and <task_15> .	0 8 7 11 20 28 18 -1 13 18 -1 12 4 26 18 -1 3 1 25 18 -1 6 9 18 -1 14 18 -1 2 27 18 -1 16 19 21 22 23 24 18 -1
Address Block Location with a Neural Net System .	sp arc2 processor board ; net32k neural net chips ; digital signal processors ; modular hardware platform ; mail pieces ; address blocks ; cleaner images ; skew angle ; noisy images ; layout analysis ; writing style ; board ; images	<otherscientificterm> <method> <method> <method> <material> <otherscientificterm> <material> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <material>	1 3 11 ; 2 3 11 ; 0 1 11 ; 0 3 11 ; 1 1 0	eric cosatto we developed a system for finding <otherscientificterm_5> on <material_4> that can process four <material_12> per second . besides locating the <otherscientificterm_5> , our system also determines the <otherscientificterm_10> , handwritten or machine printed , and moreover , it measures the <otherscientificterm_7> of the text lines and cleans <material_8> . a <method_9> of all the elements present in the image is performed in order to distinguish drawings and dirt from text and to separate text of advertisement from that of the destination address . a speed of more than four <material_12> per second is obtained on a <method_3> , containing a <otherscientificterm_11> with two of the <method_1> , a <otherscientificterm_0> , and a <otherscientificterm_11> with 2 <method_2> . the system has been tested with more than 100,000 <material_12> . its performance depends on the quality of the <material_12> , and lies between 85 % correct location in very <material_8> to over 98 % in <material_6> .	5 4 12 13 -1 10 7 8 13 -1 9 13 -1 3 14 15 16 17 18 13 -1 11 1 0 2 13 -1 13 -1
Learning for Deep Language Understanding .	tractable learning algorithms ; algorithm complexity ; syntactic-semantic grammar ; hypothesis space ; a-priori knowledge ; grammars	<method> <metric> <method> <otherscientificterm> <otherscientificterm> <method>	4 1 3 ; 3 1 1	the paper addresses the problem of learning to parse sentences to logical representations of their underlying meaning , by inducing a <method_2> . the approach uses a class of <method_5> which has been proven to be learnable from representative examples . in this paper , we introduce <method_0> for learning this class of <method_5> , comparing them in terms of <otherscientificterm_4> needed by the learner , <otherscientificterm_3> and <metric_1> . we present experimental results on learning tense , aspect , modality and negation of verbal constructions .	2 6 -1 5 6 -1 0 4 3 1 7 8 6 -1 6 -1
Gaussian Mixture Gain Priors for Regularized Nonnegative Matrix Factorization in Single-Channel Source Separation .	single-channel source separation applications ; nonnegative matrix factorization ; log-normalized gain prior model ; weight combination patterns ; trained basis vectors ; nmf decomposition weights ; weighted linear combination ; nmf based scss ; statistical prior information ; nmf reconstruction error ; statistical priors ; nmf solution ; nmf solutions ; log-likelihood ; spectra	<task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm>	12 0 13 ; 1 0 0 ; 2 0 11	we propose a new method to incorporate <method_10> on the solution of the <method_1> for <task_0> . the gaussian mixture model -lrb- gmm -rrb- is used as a <method_2> for the <method_11> . the normalization makes the prior <method_2> energy independent . in <method_7> , nmf is used to decompose the <otherscientificterm_14> of the observed mixed signal as a <method_6> of a set of <otherscientificterm_4> . in this work , the <otherscientificterm_5> are enforced to consider <otherscientificterm_8> on the <otherscientificterm_3> that the <otherscientificterm_4> can jointly receive for each source in the observed mixed signal . the <method_12> for the weights are encouraged to increase the <otherscientificterm_13> with the trained gain prior gmms while reducing the <otherscientificterm_9> at the same time .	10 1 0 17 15 -1 2 11 18 15 -1 15 -1 7 14 6 4 15 -1 5 8 3 15 -1 12 16 15 -1
Stochastic Inference for Scalable Probabilistic Modeling of Binary Matrices .	proba-bilistic matrix factorization methods ; fully observed binary matrices ; data subsampling strategies ; stochastic inference algorithm ; batch algorithms ; convergence rates ; data matrix ; parameter updates ; uniform subsampling	<method> <material> <method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <method>	4 0 0 ; 5 5 4 ; 2 4 8 ; 3 4 4 ; 2 3 3 ; 5 5 3 ; 3 0 0	fully observed large binary matrices appear in a wide variety of contexts . to model them , <method_0> are an attractive solution . however , current <method_4> for <method_0> can be inefficient because <method_4> need to analyze the entire <otherscientificterm_6> before producing any <otherscientificterm_7> . we derive an efficient <method_3> for <method_0> of <material_1> . our <method_3> exhibits faster <metric_5> than more expensive <method_4> and has better predictive performance than scalable alternatives . the proposed <method_3> includes new <method_2> which produce large gains over standard <method_8> . we also address the task of automatically selecting the size of the minibatches of data used by our <method_3> . for this , we derive an <method_3> that adjusts this hyper-parameter online .	9 -1 0 9 -1 4 6 7 10 9 -1 3 1 16 9 -1 5 11 13 15 9 -1 2 8 12 14 9 -1 9 -1 9 -1
Efficient vector quantisation of line spectral frequencies using the switched split vector quantiser .	coding linear predictive coding parameters ; switched split vector quantiser ; computational complexity ; bit-rate and distortion ; line spectral frequencies ; split vector quantiser ; split vq ; spectral distortion ; timit database ; memory requirements ; lpc parameters	<task> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	1 4 6 ; 1 0 0 ; 1 0 10 ; 2 5 1	in this paper , we investigate the use of a <method_1> for <task_0> . the <method_1> is applied to quantise the <otherscientificterm_10> in terms of <otherscientificterm_4> from the <material_8> and its performance is compared with the <method_5> . experimental results show that the <method_1> provides a better trade-off between <otherscientificterm_3> performance than the <method_6> . in addition , the <method_1> has a lower <metric_2> than the <method_6> , though this is attained at the expense of an increase in <otherscientificterm_9> . in order to achieve a <otherscientificterm_7> of 1 db , the <method_1> with an 8 directional switch requires 23 bits/frame , 4.41 kflops/frame of computations and 8272 floats of memory , while the corresponding values for a traditional three-part <method_6> are 25 bits/frame , 13.3 kflops/frame and 3328 floats , respectively .	1 0 13 11 -1 10 4 8 5 14 11 -1 3 6 11 -1 2 9 12 15 11 -1 7 11 -1
A Linguistic Feature Vector for the Visual Interpretation of Sign Language .	temporal transitions of individual signs ; classifier bank of markov chains ; 2 stage classification procedure ; sign language recognition ; independent component analysis ; minimal training data ; classification rates ; sign linguistics ; temporal activities ; classification stage ; conceptual level ; classification	<otherscientificterm> <otherscientificterm> <method> <task> <method> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	11 0 0 ; 1 0 0	this paper presents a novel approach to <task_3> that provides extremely high <metric_6> on <material_5> . key to this approach is a <method_2> where an initial <otherscientificterm_9> extracts a high level description of hand shape and motion . this high level description is based upon <otherscientificterm_7> and describes actions at a <otherscientificterm_10> easily understood by humans . moreover , such a description broadly generalises <otherscientificterm_8> naturally overcoming variability of people and environments . a second stage of <task_11> is then used to model the <otherscientificterm_0> using a <otherscientificterm_1> combined with <method_4> . we demonstrate <metric_6> as high as 97.67 % for a lexicon of 43 words using only single instance training outperforming previous approaches where thousands of training examples are required .	3 6 5 12 -1 2 9 12 -1 7 10 12 -1 8 12 -1 11 0 1 4 13 14 12 -1 12 -1
Graph Traversal Methods for Reasoning in Large Knowledge-Based Systems .	cyc 's predicate-type hierarchy ; q/a and script construction ; heuristic graph traversal methods ; connection graph-based techniques ; plausible inference chains ; commonsense reasoning ; cognitive systems ; script-like structures ; accuracy	<method> <task> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <metric>	3 0 7 ; 2 0 4 ; 8 5 2	commonsense reasoning at scale is a core problem for <method_6> . in this paper , we discuss two ways in which <method_2> can be used to generate <otherscientificterm_4> . first , we discuss how <method_0> can be used to get reasonable answers to queries . second , we explain how <method_3> can be used to identify <otherscientificterm_7> . finally , we demonstrate through experiments that these <method_2> lead to significant improvement in <metric_8> for both <task_1> .	6 9 -1 2 4 11 9 -1 0 9 -1 3 7 10 9 -1 8 1 5 12 9 -1
Knowledge-Based Support Vector Machine Classifiers .	data-based linear support vector machine classifiers ; linear support vector machine classifier ; test set accuracy ; breast cancer prognosis ; real world examples ; prior knowledge rules ; dna sequencing ; linear program ; prior knowledge ; prior knowledge ; linear classifier	<method> <method> <metric> <task> <material> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method>	6 1 3 ; 2 5 0 ; 3 6 4 ; 8 3 0 ; 8 0 10 ; 6 6 4	prior knowledge in the form of multiple polyhedral sets , each belonging to one of two categories , is introduced into a reformulation of a <method_1> . the resulting formulation leads to a <method_7> that can be solved efficiently . <material_4> , from <task_6> and <task_3> , demonstrate the effectiveness of the proposed method . numerical results show improvement in <metric_2> after the incorporation of <otherscientificterm_8> into ordinary , <method_0> . one experiment also shows that a <method_10> , based solely on <otherscientificterm_8> , far outperforms the direct application of <otherscientificterm_5> to classify data .	1 11 -1 7 4 11 -1 6 3 12 14 17 11 -1 2 8 0 13 15 11 -1 10 5 9 16 11 -1
A new approach to the temporal evolution of a family of curves .	theory of spline curves ; family of curves ; curve evolution modeling ; oceanic satellite data ; motion tracking ; curve evolution ; modeling tool ; linear structures ; spatial relationships ; spatial modeling ; vector field ; image processing	<otherscientificterm> <otherscientificterm> <task> <material> <task> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	6 0 9 ; 9 0 4 ; 3 5 6 ; 6 0 4	in this study the problem of modeling a <otherscientificterm_1> is addressed . the need of such modeling appears frequently in many aspects of <task_11> where many <otherscientificterm_7> keep <otherscientificterm_8> during their evolution . we come up with a <method_6> well suited to the <method_9> of a <otherscientificterm_1> , and which can be very useful for <task_4> and <task_5> as well . the <otherscientificterm_1> is represented as the line paths -lrb- orbits -rrb- of a '' spline <otherscientificterm_10> '' , i.e. a <otherscientificterm_10> interpolating data using a framework similar to the <otherscientificterm_0> . the <method_6> is exemplified with <material_3> . its usefullness for <task_2> is also presented .	1 12 -1 11 7 8 12 -1 6 9 4 5 13 14 16 12 -1 10 0 12 -1 3 15 12 -1 12 -1
Exploiting N-best Hypotheses for SMT Self-Enhancement .	statistical machine translation ; word and n-gram posterior probabilities ; target language n-grams ; nist chinese-to-english task ; rescoring framework ; posterior knowledge ; re-decoding framework ; posterior probabilities ; n-best hypotheses ; bleu score ; nist-2005 set ; translation phrase-pairs	<task> <otherscientificterm> <method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <material> <task>	8 2 1 ; 8 0 11 ; 7 0 11 ; 5 0 0 ; 1 0 0 ; 8 3 6 ; 8 0 5	word and n-gram <otherscientificterm_7> estimated on <otherscientificterm_8> have been used to improve the performance of <task_0> in a <method_4> . in this paper , we extend the idea to estimate the <otherscientificterm_7> on <otherscientificterm_8> for <task_11> , <method_2> , and source word re-orderings . the <task_0> is self-enhanced with the <otherscientificterm_5> learned from <otherscientificterm_8> in a <method_6> . experiments on <material_3> show performance improvements for all the strategies . moreover , the combination of the three strategies achieves further improvements and outperforms the baseline by 0.67 <metric_9> on nist-2003 set , and 0.64 on <material_10> , respectively .	7 8 0 4 13 17 12 -1 11 2 14 15 12 -1 5 6 16 18 19 12 -1 3 12 -1 9 10 1 12 -1
A prosody-based approach to end-of-utterance detection that does not require speech recognition .	prosodic and/or language models ; word and alignment ; prosodic end-of-utterance detector ; alignment information ; end-of-utterance detection ; pause-length thresholding ; dialog systems ; utterance endpoints ; prosodic knowledge ; speech recognizer ; endpointing ; recog-nizer ; latency	<method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <metric>	4 0 6 ; 1 0 0 ; 0 0 7 ; 0 0 6	in previous work we showed that state-of-the-art <task_4> -lrb- as used , for example , in <method_6> -rrb- can be improved significantly by making use of <method_0> that predict <otherscientificterm_7> , based on <otherscientificterm_1> output from a <method_9> . however , using a <method_11> in <task_10> might not be practical in certain applications . in this paper we demonstrate that the improvements due to the <otherscientificterm_8> can be realized largely without <otherscientificterm_3> , i.e. , without requiring a <method_9> . a <method_2> using only speech/nonspeech detection output is still considerably more accurate and has lower <metric_12> than a baseline system based on <otherscientificterm_5> .	4 6 0 7 1 9 14 15 16 17 13 -1 11 10 13 -1 8 3 13 -1 2 12 13 -1
The Impact of Balancing on Problem Hardness in a Highly Structured Domain .	quasigroup completion problem ; structured problem domain ; random problem distributions ; generalized sudoku instances ; random problem distributions ; square shape ; qcp/qwh instances ; balancing strategies ; constraint satisfaction ; problem hardness ; block regions ; sudoku puzzle ; parameter settings ; worst-case complexity ; rectangular shape ; computational hardness ; boolean satisfiability ; backbone variables ; real-world applications	<method> <material> <task> <material> <task> <otherscientificterm> <material> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <task>	3 0 12 ; 8 1 16 ; 7 0 9 ; 1 0 4 ; 15 5 3	random problem distributions have played a key role in the study and design of algorithms for <task_8> and <otherscientificterm_16> , as well as in our understanding of <metric_9> , beyond standard <metric_13> . we consider <task_4> from a highly <material_1> that generalizes the <method_0> and quasigroup with holes -lrb- qwh -rrb- , a widely used domain that captures the structure underlying a range of <task_18> . our problem domain is also a generalization of the well-known <otherscientificterm_11> : we consider sudoku instances of arbitrary order , with the additional generalization that the <otherscientificterm_10> can have <otherscientificterm_14> , in addition to the standard <otherscientificterm_5> . we evaluate the <metric_15> of <material_3> , for different <otherscientificterm_12> . our experimental hardness results show that we can generate instances that are considerably harder than <material_6> of the same size . more interestingly , we show the impact of different <method_7> on <metric_9> . we also provide insights into <otherscientificterm_17> in <material_3> and how they correlate to <metric_9> .	8 16 9 13 21 19 -1 4 1 0 18 23 19 -1 11 10 14 19 -1 5 20 24 19 -1 15 3 12 19 -1 6 22 19 -1 7 19 -1
Physical modeling of drums by transfer function methods .	multidimensional physical systems ; transfer function models ; partial differential equations ; physics based digital sound synthesis algorithms ; initial and boundary conditions ; digital signal processors ; two-dimensional drum models ; excitation functions ; spatial dimension ; one-dimensional systems	<method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method>	1 0 3 ; 2 0 0 ; 4 1 7	multidimensional -lrb- md -rrb- physical systems are usually given in terms of <otherscientificterm_2> . similar to <method_9> , they can also be described by <method_1> . in addition to including <otherscientificterm_4> as well as <otherscientificterm_7> exactly , the <method_1> can also be discretized in a simple way . this leads to suitable implementations for <task_5> . therefore it is possible to implement <method_3> derived from <method_1> in real-time . this paper extends the recently presented solution for vibrating strings with one <otherscientificterm_8> to <method_6> .	2 12 10 -1 9 1 10 -1 4 7 13 10 -1 5 10 -1 3 11 10 -1 8 6 0 10 -1
A new acoustic measure for aspiration noise detection .	detecting aspiration noise in vowels ; automatic detection of aspiration noise ; vocal tract responses ; spectral slope measures ; frequency bands ; acoustic measure ; aspiration noise ; glottal excitation	<task> <task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	3 0 5 ; 3 0 1 ; 5 0 0 ; 2 0 7 ; 5 0 1	in this paper , we propose a new <method_5> for <task_0> . the <method_5> is an index of synchronization between <otherscientificterm_4> around the first and third formants . the <method_5> is based on the principle that the <otherscientificterm_2> to the <otherscientificterm_7> are synchronized between these <otherscientificterm_4> when <otherscientificterm_6> is absent , and uncorrelated otherwise . evaluation results show that the proposed <method_5> can be used together with <method_3> for <task_1> .	5 0 11 8 -1 4 8 -1 2 7 6 12 8 -1 3 1 9 10 13 8 -1
Efficient anisotropic wavelet packet basis selection in JPEG2000 .	top-down anisotropic wavelet packet selection scheme ; isotropic wavelet packet basis selection algorithms ; anisotropic wavelet basis selection ; jpeg2000 part 2 ; quality assessment tools ; psnr evaluations ; coding framework ; jpeg2000	<method> <method> <task> <method> <method> <task> <method> <method>	4 0 5	jpeg2000 part 2 allows the application of arbitrary wavelet decomposition structures -lrb- wavelet packet bases -rrb- . efficient anisotropic wavelet packet basis selection for the <method_6> of <method_7> has been developed and evaluated . previous work focused on <method_1> for <method_7> , which serves as basis for the performance of the assessment of <task_2> . several cost functions are applied in a <method_0> . our evaluations employ state-of-the-art <method_4> supplementary to <task_5> .	8 -1 6 7 8 -1 1 2 8 -1 0 8 -1 4 5 3 9 8 -1
Fast and memory efficient JBIG2 encoder .	text image compression ; multi-page document images ; singleton exclusion dictionary ; jbig2 standard ; physical memory ; horizontal stripes ; multi-page document ; single-page documents ; encoding time ; updating processes ; modified-class dictionary ; encoding strategy ; compression	<task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <metric> <method> <material> <method> <task>	11 0 0 ; 9 0 1 ; 9 0 2 ; 9 0 12 ; 3 0 11 ; 8 1 4	in this paper we propose a fast and memory efficient <method_11> for <task_0> with the <otherscientificterm_3> . the encoder splits up the input image into <otherscientificterm_5> and encodes one stripe at a time . construction of the current dictionary is based on updating dictionaries from previous stripes . we describe separate <method_9> for the <otherscientificterm_2> and for the <material_10> . experiments show that , for both dictionaries , splitting the page into two stripes can save 30 % of <metric_8> and 40 % of <otherscientificterm_4> with a small loss of about 1.5 % in <task_12> . further gains can be obtained by using more stripes but with diminishing returns . the same <method_9> are also applied to compressing <material_1> and shown to improve <task_12> by 8-10 % over coding a <material_6> as a collection of <material_7> .	11 0 3 14 18 13 -1 5 13 -1 13 -1 9 2 10 16 13 -1 8 4 12 19 13 -1 13 -1 15 17 13 -1
A fast and simple algorithm for training neural probabilistic language models .	neural probabilistic language models ; microsoft research sentence completion challenge dataset ; estimating unnormalized continuous distributions ; penn treebank corpus ; neural language models ; log-likelihood gradients ; n-gram models ; noise-contrastive estimation ; training times ; 80k-word vocabulary ; training nplms ; 47m-word corpus ; importance sampling ; moderately-sized datasets	<method> <material> <task> <material> <method> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <method> <material> <method> <material>	0 4 6 ; 1 5 4 ; 0 0 2 ; 9 0 4 ; 11 5 4	in spite of their superior performance , <method_0> remain far less widely used than <method_6> due to their notoriously long <metric_8> , which are measured in weeks even for <material_13> . <method_10> is computationally expensive because <method_10> are explicitly normalized , which leads to having to consider all words in the vocabulary when computing the <otherscientificterm_5> . we propose a fast and simple algorithm for training <method_0> based on <method_7> , a newly introduced procedure for <task_2> . we investigate the behaviour of the algorithm on the <material_3> and show that it reduces the <metric_8> by more than an order of magnitude without affecting the quality of the resulting models . the algorithm is also more efficient and much more stable than <method_12> because it requires far fewer noise samples to perform well . we demonstrate the scalability of the proposed approach by training several <method_4> on a <material_11> with a <otherscientificterm_9> , obtaining state-of-the-art results on the <material_1> .	0 6 8 13 10 15 14 -1 5 14 -1 7 2 17 14 -1 3 14 -1 14 -1 12 16 18 19 14 -1
Recycling Randomness with Structure for Sublinear time Kernel Expansions .	recycling gaussian random vectors ; random feature maps ; kernel methods ; statistical variance ; sublin-ear time ; random embeddings ; approximation quality ; low-displacement matrices ; random features ; kernel functions ; low-displacement rank ; structured matrices ; coherence ; randomness ; structure	<task> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 0 9 ; 11 0 2 ; 4 2 9	we propose a scheme for <task_0> into <otherscientificterm_11> to approximate various <otherscientificterm_9> in <otherscientificterm_4> via <otherscientificterm_5> . our framework includes the fastfood construction of le et al. -lrb- 2013 -rrb- as a special case , but also extends to circulant , toeplitz and hankel matrices , and the broader family of <otherscientificterm_11> that are characterized by the concept of <otherscientificterm_10> . we introduce notions of <otherscientificterm_12> and graph-theoretic structural constants that control the <metric_6> , and prove unbiasedness and low-variance properties of <otherscientificterm_1> that arise within our framework . for the case of <method_7> , we show how the degree of <otherscientificterm_14> and <otherscientificterm_13> can be controlled to reduce <metric_3> at the cost of increased computation and storage requirements . empirical results strongly support our theory and justify the use of a broader family of <otherscientificterm_11> for scaling up <method_2> using <otherscientificterm_8> .	0 11 9 4 5 16 18 15 -1 10 15 -1 12 6 1 15 -1 7 15 -1 14 13 3 17 15 -1
Model Learning and Real-Time Tracking Using Multi-Resolution Surfel Maps .	multi-resolution 3d shape and texture representations ; iterative closest points algorithm ; full-view models of objects ; probabilistic optimization framework ; models of objects ; mobile manipulation task ; registering maps ; sensor view ; model learning ; rgb-d benchmarks ; rgb-d images ; real-time tracking ; efficiency ; cpu ; accuracy ; livestreams ; robustness	<task> <method> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm> <task> <material> <material> <task> <metric> <otherscientificterm> <metric> <otherscientificterm> <metric>	10 0 0 ; 12 1 11 ; 1 0 6 ; 8 1 11 ; 12 1 8 ; 12 1 16	for interaction with its environment , a robot is required to learn <otherscientificterm_4> and to perceive these models in the <otherscientificterm_15> from its sensors . in this paper , we propose a novel approach to <task_8> and <task_11> . we extract <task_0> from <material_10> at high frame-rates . an efficient variant of the <method_1> allows for <task_6> in real-time on a <otherscientificterm_13> . our approach learns <otherscientificterm_2> in a <method_3> in which we find the best alignment between multiple views . finally , we track the pose of the camera with respect to the learned model by registering the current <otherscientificterm_7> to the model . we evaluate our approach on <material_9> and demonstrate its <metric_14> , <metric_12> , and <metric_16> in <task_8> and <task_11> . we also report on the successful public demonstration of our approach in a <task_5> .	4 15 17 -1 8 11 17 -1 0 10 18 17 -1 1 6 13 20 17 -1 2 3 17 -1 17 -1 7 19 21 22 23 17 -1 9 14 12 16 17 -1
Active learning for misspecified generalized linear models .	un-biased estimators of generalization ; convex optimization problem ; sequential active learning ; generalized linear models ; model misspecifica-tion ; non-linear settings ; algorithmic frameworks ; active learning ; multi-class classification ; learning method ; binary classification ; sampling distributions ; mercer kernels ; generalization error ; regression	<method> <task> <task> <method> <method> <otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method>	8 1 14 ; 14 6 3 ; 1 0 11 ; 8 6 3 ; 7 0 3 ; 10 6 3 ; 10 1 8	active learning refers to <method_6> aimed at selecting training data points in order to reduce the number of required training data points and/or improve the generalization performance of a <method_9> . in this paper , we present an asymptotic analysis of <method_7> for <method_3> . our analysis holds under the common practical situation of <method_4> , and is based on realistic assumptions regarding the nature of the <otherscientificterm_11> , which are usually neither independent nor identical . we derive <method_0> performance , as well as estimators of expected reduction in <otherscientificterm_13> after adding a new training data point , that allow us to optimize its <otherscientificterm_11> through a <task_1> . our analysis naturally leads to an algorithm for <task_2> which is applicable for all tasks supported by <method_3> -lrb- e.g. , <method_10> , <method_8> , <method_14> -rrb- and can be applied in <otherscientificterm_5> through the use of <method_12> .	6 9 15 -1 7 3 20 15 -1 4 11 15 -1 0 13 18 15 -1 1 16 17 19 21 22 15 -1
DARTs : Efficient scale-space extraction of DAISY keypoints .	viewpoint and illumination invariant keypoints ; computer vision applications ; daisy-like layout ; daisy descriptor ; computational cost ; precision ; recall ; sift ; surf	<otherscientificterm> <task> <otherscientificterm> <method> <metric> <metric> <metric> <method> <method>	5 1 6 ; 7 1 8	winder et al. -lsb- 15 , 14 -rsb- have recently shown the superiority of the <method_3> -lsb- 12 -rsb- in comparison to other widely extended descriptors such as <method_7> -lsb- 8 -rsb- and <method_8> -lsb- 1 -rsb- . motivated by those results , we present a novel algorithm that extracts <otherscientificterm_0> and describes them with a particular implementation of a <otherscientificterm_2> . we demonstrate how to efficiently compute the scale-space and re-use this information for the descriptor . comparison to similar approaches such as <method_7> and <method_8> show higher <metric_5> vs <metric_6> performance of the proposed method . moreover , we dramatically reduce the <metric_4> by a factor of 6x and 3x , respectively . we also prove the use of the proposed method for <task_1> .	3 7 8 9 -1 0 2 9 -1 9 -1 5 6 10 11 9 -1 9 -1 4 9 -1
Multiple View Region Matching as a Lagrangian Optimization Problem .	rate-distortion budget-constrained allocation problem ; lagrangian optimization techniques ; matching regions ; constrained optimization ; color similarity	<task> <method> <otherscientificterm> <method> <otherscientificterm>	3 0 2	a method to establish correspondences between regions belonging to independent segmentations of multiple views of a scene is presented . the trade-off between <otherscientificterm_4> and projective similarity of the <otherscientificterm_2> is formulated in terms of a <method_3> , analogous to a <task_0> , and solved using <method_1> .	5 -1 4 2 3 0 1 6 5 -1
Exemplar-based pitch accent categorisation using the generalized context model .	psychologically motivated exemplar-theoretic model of categorisation ; pitch accent categorisation simulation ; pitch accents ; categorisation process ; tonal features ; exemplar-based comparison	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method>	5 0 2	this paper presents the results of a <method_1> which attempts to classify l * h and h * l <otherscientificterm_2> using a <method_0> . <otherscientificterm_2> are represented in terms of six linguistically meaningful parameters describing their shape . no additional information is employed in the <method_3> . the results indicate that these <otherscientificterm_2> can be successfully categorised , via <method_5> , using a limited number of purely <otherscientificterm_4> .	1 2 0 6 -1 6 -1 3 6 -1 5 4 7 6 -1
Learning to Adapt to Unknown Users : Referring Expression Generation in Spoken Dialogue Systems .	user-adaptive referring expression generation policies ; user 's domain knowledge ; reinforcement learning framework ; user 's domain expertise ; adaptive hand-coded baseline policies ; statistical user simulation ; spoken dialogue systems ; supervised learning methods ; non-adaptive human-machine interaction ; hand-coded policy ; technical domains ; adaptation accuracy ; referring expressions ; referring expressions ; reg policies ; adaptive behaviour ; adaptive policies ; rl framework ; data-driven approach ; dialogue time	<method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <metric>	18 0 6 ; 18 0 0 ; 18 0 14 ; 17 0 8 ; 17 1 5 ; 18 0 1 ; 8 0 16 ; 0 0 6	we present a <method_18> to learn <method_0> for <method_6> . <otherscientificterm_12> can be difficult to understand in <otherscientificterm_10> where users may not know the technical ` jargon ' names of the domain entities . in such cases , <method_18> must be able to model the <otherscientificterm_1> and use appropriate <otherscientificterm_13> . we present a <method_2> in which the <method_18> learns <method_14> which can adapt to unknown users online . furthermore , unlike <method_7> which require a large corpus of expert <otherscientificterm_15> to train on , we show that effective <method_16> can be learned from a small dialogue corpus of <otherscientificterm_8> , by using a <method_17> and a <method_5> . we show that in comparison to <method_4> , the learned policy performs significantly better , with an 18.6 % average increase in <metric_11> . the best learned policy also takes less <metric_19> -lrb- average 1.07 min less -rrb- than the best <otherscientificterm_9> . this is because the learned policies can adapt online to changing evidence about the <otherscientificterm_3> .	18 0 6 12 21 22 28 20 -1 10 20 -1 1 13 26 20 -1 2 14 23 20 -1 7 15 16 8 24 25 27 20 -1 17 5 20 -1 4 11 20 -1 19 9 20 -1
Pronunciation variant-based multi-path HMMs for syllables .	37-hour corpus of dutch read speech ; initialisation of the parallel paths ; syllable-length acoustic models ; multi-path model topologies ; data-driven solution ; multi-path models ; triphone recogniser ; syllable level ; pronunciation variation ; context-dependent phones ; phonetic knowledge ; complexity ; recognition	<material> <task> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <task>	2 4 9 ; 10 0 1	recent research suggests that it is more appropriate to model <task_8> with <method_2> than with <method_9> . due to the large number of factors contributing to <task_8> at the <otherscientificterm_7> , the creation of <otherscientificterm_3> appears necessary . in this paper , we propose a novel approach for constructing <method_5> for frequent syllables . the suggested approach uses <otherscientificterm_10> for the <task_1> , and a <method_4> for their re-estimation . when applied to 94 frequent syllables in a <material_0> , it leads to improved <task_12> performance when compared with a <method_6> of similar <metric_11> .	8 2 9 14 13 -1 7 3 13 -1 5 13 -1 10 1 4 15 13 -1 0 12 6 11 13 -1
Detection of digital transmission systems for voice quality measurements .	digital transmission systems ; active speech level ; echo delay ; recognition rate ; echo attenuation ; active speech ; noise level ; transient failures ; telephone link ; perceived quality ; telephone call ; frame losses ; quality-defining criteria ; speech signal ; quality ; features	<method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <metric> <material> <metric> <otherscientificterm>	4 1 1 ; 13 0 15 ; 1 6 12 ; 2 6 12 ; 4 6 12 ; 2 1 6 ; 4 1 6 ; 6 6 12 ; 2 1 1 ; 6 1 7 ; 4 1 2 ; 11 1 7 ; 11 6 12 ; 2 1 11 ; 7 6 12 ; 6 1 11 ; 1 1 6 ; 1 1 11	in-service , non-intrusive measurement devices -lrb- inmd -rrb- estimate the <metric_9> of the <method_8> by extracting <metric_12> like <otherscientificterm_4> , <otherscientificterm_2> , <otherscientificterm_1> , <otherscientificterm_6> , <otherscientificterm_11> and <otherscientificterm_7> from a <otherscientificterm_10> . in addition , the <metric_14> depends on the used <method_0> -lrb- codec systems -rrb- . this paper proposes a method to distinguish between two codec classes . with the help of <otherscientificterm_15> determined from the <material_13> , a classi-fier decides about the class affiliation of the signal . the <metric_3> for signals with 16 seconds of <material_5> is about 97 % .	9 8 12 4 2 1 6 11 7 10 17 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 16 -1 14 0 16 -1 16 -1 15 13 18 16 -1 3 5 16 -1
A phone-dependent confidence measure for utterance rejection .	database of spoken company names ; acceptanceerejection of recognition hypotheses ; word sequence conndence ; average phone conn-dence ; continuous speech utterances ; acoustic conndence measure ; acoustic observation ; speech dissuencies ; phone-based approach ; global threshold ; out-of-vocabulary words ; hypothesis rejection ; computational expense ; ller-model approach ; phone duration ; phone conn-dence	<material> <task> <task> <metric> <material> <metric> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <task> <metric> <method> <otherscientificterm> <task>	9 0 11 ; 5 0 4 ; 5 0 1 ; 3 0 2 ; 1 0 4 ; 0 0 5 ; 10 1 7	an <metric_5> for <task_1> for <material_4> is proposed . this <metric_5> is useful for rejecting utterances that are out of domain , or contain <otherscientificterm_10> or <material_7> . a <method_8> is implemented so that a single <otherscientificterm_9> can be applied to <task_11> for any w ord sequence . <task_15> is computed for each frame of speech as the posterior phone probability g i v en the <otherscientificterm_6> . <task_2> is evaluated as the <metric_3> , either by w eighting all frames equally or by normalizing by <otherscientificterm_14> . the <metric_5> is tested on a <material_0> . when normalized by <otherscientificterm_14> , <metric_5> achieves , in some cases with less <metric_12> , rejection performance comparable to a baseline system implementing a common <method_13> . when all frames are equally weighted , performance is substantially poorer .	5 1 4 18 19 21 16 -1 10 7 23 16 -1 8 9 11 15 17 16 -1 6 2 16 -1 3 14 20 16 -1 0 22 16 -1 16 -1 12 13 16 -1
Issues in measuring the benefits of multimodal interfaces .	sensory dimensions of sight ; collabo-rative distributed c omputing ; intellectual abilities of humans ; distributed information resources ; collective decision making ; human/machine/human communication ; networked system ; multimodal interfaces ; machine mediation ; multimedia interfaces ; hu-man/machine communication ; digital networking ; human abilities	<otherscientificterm> <task> <otherscientificterm> <material> <method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <task> <method> <otherscientificterm>	6 0 1 ; 7 3 6 ; 9 0 10 ; 8 4 12 ; 3 1 4	multimedia <otherscientificterm_9> are r apidly evolving to facilitate <task_10> . most of the technologies on which they are b ased a r e , as yet , imperfect . but , the <otherscientificterm_9> do begin to allow information exchange in ways familiar and comfortable to the human | principally through natural actions in the <otherscientificterm_0> , sound and touch . further , as <method_11> becomes ubiquitous , the opportunity grows for collaborative work through confer-enced c omputing . in this context the machine takes on the role of mediator in <task_5> | the ideal being to extend the <otherscientificterm_2> through access to <material_3> and <method_4> . the challenge is how to design <task_8> so that <task_8> extends , not impedes , <otherscientificterm_12> . this report describes evolving work to incorporate <otherscientificterm_7> into a <method_6> for <task_1> . <task_8> also addresses strategies for quantifying the synergies that may be gained .	9 10 16 13 -1 13 -1 0 13 -1 11 13 -1 5 2 18 13 -1 3 4 17 13 -1 8 12 14 15 13 -1 7 6 1 13 -1
Web-Scale N-gram Models for Lexical Disambiguation .	supervised and unsupervised systems ; context-sensitive spelling correction ; lexical disambiguation ; preposition selection ; web counts ; language research ; disambiguation error ; web-scale data	<method> <task> <task> <task> <material> <task> <otherscientificterm> <material>	7 0 5 ; 4 0 2 ; 3 1 1	web-scale data has been used in a diverse range of <task_5> . most of this research has used <material_4> for only short , fixed spans of context . we present a unified view of using <material_4> for <task_2> . unlike previous approaches , our <method_0> combine information from multiple and overlapping segments of context . on the tasks of <task_3> and <task_1> , the <method_0> reduces <otherscientificterm_6> by 20-24 % over the current state-of-the-art .	5 9 8 -1 4 8 -1 2 10 8 -1 0 8 -1 3 1 6 7 11 8 -1
Predicting Opinion Dependency Relations for Opinion Analysis .	opinion dependency parser ; annotated syntactic structures ; opinion syntactic structures ; supervised learning methods ; opinion dependency relations ; human friendly materials ; language resources ; dependency trees ; parsing trees ; chinese treebank ; syntactic structures ; syntactic labels ; opinion analysis ; annotation processing ; dependency relations ; syntactic structures ; parsing tree ; features ; annotators	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <material> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method>	8 1 15 ; 8 0 18 ; 10 0 12 ; 16 0 2 ; 8 1 7 ; 3 0 17 ; 8 0 13 ; 8 4 7	syntactic structures have been good <otherscientificterm_17> for <task_12> , but it is not easy to use them . to find these <otherscientificterm_17> by <method_3> , correct <otherscientificterm_11> are indispensible . two possible sources to acquire <otherscientificterm_15> are <task_8> and <otherscientificterm_7> . for the <task_13> , <task_8> are more readable for <method_18> , while <otherscientificterm_7> are easier to use by programs . to use <otherscientificterm_15> as <otherscientificterm_17> , this paper tried to annotate on <material_5> and transform these annotations to the corresponding machine friendly materials . we annotated the gold answers of <otherscientificterm_2> on the <task_16> from <material_9> , and then proposed methods to find their corresponding <otherscientificterm_14> on the <otherscientificterm_7> generated from the same sentence . with these relations , we could train a model to annotate <otherscientificterm_4> automatically to provide an <method_0> , which is language independent if <material_6> are incorporated . experiment results show that the <otherscientificterm_1> and their corresponding <otherscientificterm_14> improve at least 8 % of the performance of <task_12> .	17 12 22 19 -1 3 11 25 19 -1 15 8 7 20 24 19 -1 13 18 21 26 27 19 -1 5 19 -1 2 16 9 23 19 -1 14 19 -1 4 0 6 19 -1
Minimizing Human Effort in Interactive Tracking by Incremental Learning of Model Parameters .	infant-mother interaction dataset ; sequence-specific model parameters ; maximum margin framework ; virat dataset ; interactive tracking ; model parameters ; precision	<material> <otherscientificterm> <method> <material> <task> <otherscientificterm> <metric>	3 1 0 ; 1 0 4	we address the problem of minimizing human effort in <task_4> by learning <otherscientificterm_1> . determining the optimal <otherscientificterm_5> for each sequence is a critical problem in <task_4> . we demonstrate that by using the optimal <otherscientificterm_5> for each sequence we can achieve high precision <task_4> results with significantly less effort . we leverage the sequential nature of <task_4> to formulate an efficient method for learning <otherscientificterm_5> through a <method_2> . by using our method we are able to save ‚àº 60 ‚àí 90 % of human effort to achieve high <metric_6> on two datasets : the <material_3> and an <material_0> .	4 1 9 7 -1 5 7 -1 7 -1 2 7 -1 6 3 0 8 7 -1
Close the loop : Joint blind image restoration and recognition with sparse representation prior .	joint blind image restoration and recognition method ; ill-posed blind image restoration ; treating restoration and recognition ; simultaneous restoration and recognition ; image restoration task ; sparse representation prior ; degraded input image ; visual recognition systems ; blind image restoration ; face recognition ; sparest representation ; real-world degradations ; unknown degradations ; face datasets ; low resolution ; motion blur ; degradation model ; out-of-focus blur ; low-quality images ; recognition task ; classifier	<method> <method> <task> <task> <task> <otherscientificterm> <otherscientificterm> <method> <task> <task> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <task> <method>	11 0 7 ; 17 6 11 ; 15 6 11 ; 4 1 19 ; 13 5 0 ; 14 6 11 ; 14 1 15 ; 18 0 9 ; 5 0 0 ; 8 0 9 ; 16 0 9 ; 10 0 8 ; 10 0 9 ; 15 1 17	most previous <method_7> simply assume ideal inputs without <otherscientificterm_11> , such as <otherscientificterm_14> , <otherscientificterm_15> and <otherscientificterm_17> . in presence of such <otherscientificterm_12> , the conventional approach first resorts to <task_8> and then feeds the restored image into a <method_20> . <task_2> separately , such a straightforward approach , however , suffers greatly from the defective output of the <method_1> . in this paper , we present a <method_0> based on the <otherscientificterm_5> to handle the challenging problem of <task_9> from <material_18> , where the <method_16> is realistic and totally unknown . the <otherscientificterm_5> states that the <otherscientificterm_6> , if correctly restored , will have a good sparse representation in terms of the training set , which indicates the identity of the test image . the proposed <method_0> achieves <task_3> by iteratively solving the <task_8> in pursuit of the <method_10> for <task_9> . based on such a <otherscientificterm_5> , we demonstrate that the <task_4> and the <task_19> can benefit greatly from each other . extensive experiments on <material_13> under various degradations are carried out and the results of our <method_0> shows significant improvements over conventional methods of treating the two tasks independently .	7 11 14 15 17 22 23 24 27 28 35 21 -1 12 8 20 2 21 -1 1 21 -1 0 5 9 18 16 29 30 32 21 -1 6 21 -1 31 33 34 21 -1 3 10 25 21 -1 4 19 26 21 -1
Combined acoustic and linguistic look-ahead for one-pass time-synchronous decoding .	one-pass trigram decoding of broadcast news ; crossword hmms and m-gram language models ; large vocabulary speech recognition ; active search space ; time-synchronous beam search ; base error rate ; pruning technique ; speed-up decoding ; hub4 evaluation ; phonetic arc ; lexical tree ; real-time decoding ; decoding pass ; decoder ; pruning ; accuracy	<task> <method> <task> <otherscientificterm> <method> <metric> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <task> <method> <method> <task> <metric>	6 0 7 ; 10 0 13 ; 4 0 13 ; 6 0 2 ; 8 5 11 ; 6 0 0 ; 10 1 4	this paper describes an enhanced <method_6> aimed at a further reduction of the <otherscientificterm_3> in <task_2> , to <task_7> while maintaining the <metric_15> . the <method_6> is based on anticipating both the linguistic and acoustic contribution of a <otherscientificterm_9> , before expanding that arc in the search . the <method_13> is based on a <method_4> and a <otherscientificterm_10> . <method_1> are integrated in a single <method_12> . the new <method_6> has been evaluated for <task_0> . with respect to the baseline , the search eeort can be halved at almost no degradation . when <task_14> more aggressively to get a speed-up of 10 , <task_11> is achieved on <metric_8> , however , with an increase of the <metric_5> by one third .	6 3 2 7 15 17 20 16 -1 9 16 -1 13 4 10 1 18 19 23 16 -1 12 16 -1 0 22 16 -1 16 -1 14 21 16 -1
Discovery of Term Variation in Japanese Web Search Queries .	english spelling correction of web queries ; string and semantic similarity features ; japa-nese web search queries ; term variation identification task ; web search queries ; semantic similarity features ; click-through logs ; term variations ; spelling mistakes ; mart algorithm ; model features ; term variants ; writing system ; statistical model ; error rate ; precision ; transliterations ; recall	<task> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <metric> <otherscientificterm> <metric>	5 0 4 ; 9 0 13 ; 8 6 11 ; 15 5 3	in this paper we address the problem of identifying a broad range of <otherscientificterm_7> in <task_2> , where these variations pose a particularly thorny problem due to the multiple character types employed in its <method_12> . our method extends the techniques proposed for <task_0> to handle a wider range of <otherscientificterm_11> including <otherscientificterm_8> , valid alternative spellings using multiple character types , <otherscientificterm_16> and abbreviations . the core of our method is a <method_13> built on the <method_9> -lrb- friedman , 2001 -rrb- . we show that both <otherscientificterm_1> contribute to identifying term variation in <otherscientificterm_4> ; specifically , the <otherscientificterm_5> used in our <method_13> are learned by mining user session and <otherscientificterm_6> , and are useful not only as <otherscientificterm_10> but also in generating term variation candidates efficiently . the proposed method achieves 70 % <metric_15> on the <task_3> with the <metric_17> slightly higher than 60 % , reducing the <metric_14> of a na√Øve baseline by 38 % .	7 2 12 18 -1 0 11 8 16 21 18 -1 13 9 20 18 -1 1 4 19 18 -1 5 6 10 22 18 -1
Pitch estimation using phase locked loops .	harmonic decomposition of the speech signal ; pitch estimation algorithms ; band-pass filter bank ; pitch contour ; laryngograph-labeled speech ; pitch estimation ; phase locked-loop ; phase-locked-loop devices ; phase-locked-loops ; harmonic	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 0 0 ; 2 1 8	in this paper we present a new method for <task_5> using a system based on <otherscientificterm_7> . three main blocks define our system . the aim of the first one is to make an <otherscientificterm_0> . this stage is implemented using a <otherscientificterm_2> and <otherscientificterm_8> cascaded to the output of each filter . a second block enhances the <otherscientificterm_9> corresponding to the fundamental frequency and attenuates all other harmonics . finally a third stage re-synthesizes a new signal with high energy at the fundamental frequency and extracts <otherscientificterm_3> from that signal using another <otherscientificterm_6> . performance is evaluated over two databases of <material_4> and compared to various well known <method_1> .	5 7 10 -1 10 -1 0 10 -1 2 8 11 12 10 -1 9 10 -1 3 6 10 -1 10 -1
Fully unsupervised small-vocabulary speech recognition using a segmental Bayesian model .	connected digit recognition task ; supervised speech technology ; unlabelled speech data ; categorical linguistic structure ; word error rates ; unlabelled input speech ; gibbs sampler ; fixed-dimensional space ; unsupervised transcription ; transcribed speech ; hmm-based system ; bayesian model ; word-like units ; unsupervised methods ; unsupervised output ; pronunciation dictionaries ; seg-mentation ; audio	<task> <method> <material> <otherscientificterm> <metric> <material> <method> <otherscientificterm> <material> <material> <method> <method> <otherscientificterm> <method> <material> <material> <otherscientificterm> <material>	13 0 3 ; 9 0 1 ; 14 0 0 ; 9 1 15 ; 15 0 1 ; 11 0 12	current <method_1> relies heavily on <material_9> and <material_15> . in settings where <material_2> alone is available , <method_13> are required to discover <otherscientificterm_3> directly from the <material_17> . we present a novel <method_11> which segments <material_5> into <otherscientificterm_12> , resulting in a complete <material_8> of the speech in terms of discovered word types . in our <method_11> , a potential word segment -lrb- of arbitrary length -rrb- is embedded in a <otherscientificterm_7> ; the model -lrb- implemented as a <method_6> -rrb- then builds a whole-word acoustic model in this space while jointly doing <otherscientificterm_16> . we report <metric_4> in a <task_0> by mapping the <material_14> to ground truth transcriptions . our model outperforms a previously developed <method_10> , even when the model is not constrained to discover only the 11 word types present in the data .	1 9 15 20 22 23 18 -1 2 13 3 17 19 18 -1 11 5 12 8 24 18 -1 7 6 16 18 -1 4 21 18 -1 0 14 18 -1
Word-level invariant representations from acoustic waveforms .	unsupervised learning of invariant sensory representations ; sound waveform of speech units ; extracting discriminant , transformation-invariant features ; acoustic , temporal domain ; spectral properties of speech ; speech recognition systems ; raw audio signals ; frame-level acoustic modeling ; word level ; raw waveform ; one-dimensional distributions ; mfcc-based representation ; speaker variability ; speech recognition ; word classification ; spectral encoding ; accent ; gender ; preprocess-ing ; signature ; dialect ; features	<task> <otherscientificterm> <task> <material> <material> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	20 1 17 ; 0 0 19 ; 7 0 4 ; 16 1 17 ; 7 0 5 ; 6 0 2 ; 3 0 21 ; 16 1 20 ; 15 1 18	extracting discriminant , transformation-invariant <otherscientificterm_21> from <material_6> remains a serious challenge for <task_13> . the issue of <otherscientificterm_12> is central to this problem , as changes in <otherscientificterm_16> , <otherscientificterm_20> , <otherscientificterm_17> , and age alter the <otherscientificterm_1> at multiple levels -lrb- phonemes , words , or phrases -rrb- . approaches for dealing with this variability have typically focused on analyzing the <material_4> at the level of frames , on par with <method_7> usually applied to <method_5> . in this paper , we propose a framework for representing speech at the <otherscientificterm_8> and extracting <otherscientificterm_21> from the <material_3> , without the need for <task_15> or <task_18> . leveraging recent work on <task_0> , we extract a <otherscientificterm_19> for a word by first projecting its <otherscientificterm_9> onto a set of templates and their transformations , and then forming empirical estimates of the resulting <otherscientificterm_10> via histograms . the representation and relevant parameters are evaluated for <task_14> on a series of datasets with increasing speaker-mismatch difficulty , and the results are compared to those of an <method_11> .	21 6 13 28 22 -1 12 16 20 17 1 23 26 30 22 -1 4 7 5 25 27 22 -1 8 3 29 31 22 -1 15 18 24 22 -1 0 19 9 10 22 -1
Detecting audio events for semantic video search .	290-hour corpus of sound effects ; european project vidivideo ; audio event detection ; overlapping audio events ; real-life videos ; svm classifiers ; semantic concepts ; features ; detectors ; f-measure	<material> <material> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <method> <metric>	3 2 4 ; 8 0 6	this paper describes our work on <task_2> , one of our tasks in the <material_1> . preliminary experiments with a small corpus of sound effects have shown the potential of this type of corpus for training purposes . this paper describes our experiments with <method_5> , and different <otherscientificterm_7> , using a <material_0> , which allowed us to build <method_8> for almost 50 <otherscientificterm_6> . although the performance of these <method_8> on the development set is quite good -lrb- achieving an average <metric_9> of 0.87 -rrb- , preliminary experiments on documentaries and films showed that the task is much harder in <material_4> , which so often include <otherscientificterm_3> .	2 1 10 -1 10 -1 5 7 0 8 6 12 10 -1 9 11 10 -1
Explaining the Ineffable : AI on the Topics of Intuition , Insight and Inspiration .	intelligent computer systems ; `` ineffable '' phenomena ; artificial intelligence methods ; human simulation ; human intelligence ; intuition	<task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm>	2 0 4 ; 2 0 0 ; 5 6 1	artificial intelligence methods may be used to model <otherscientificterm_4> or to build <task_0> . al has already reached the stage of <task_3> where it can model such <otherscientificterm_1> as <otherscientificterm_5> , insight and inspiration . this paper reviews the empirical evidence for these capabilities .	4 0 7 8 6 -1 3 1 5 9 6 -1 2 6 -1
Exploratory Interaction with a Bayesian Argumentation System .	activation of concepts ; exploratory responses ; argument grammar ; probabilistic patterns ; interactive behaviour ; bayesian networks ; interactive system ; attentional mechanism	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method>	3 1 2 ; 7 0 4 ; 5 0 6	we describe an <method_6> which supports the exploration of arguments generated from <method_5> . in particular , we consider key features which support <otherscientificterm_4> : -lrb- 1 -rrb- an <method_7> which updates the <otherscientificterm_0> as the interaction progresses ; -lrb- 2 -rrb- a set of <otherscientificterm_1> ; and -lrb- 3 -rrb- a set of <otherscientificterm_3> and an <method_2> which support the generation of natural language arguments from <method_5> . a preliminary evaluation assesses the effect of our <otherscientificterm_1> on users ' beliefs .	6 5 11 8 -1 4 7 0 1 3 2 9 10 8 -1 8 -1
A V1 Model of Pop Out and Asymmetty in Visual Search .	roles of gure and ground ; unique features of targets ; visual search ; intracortical interactions ; target detection ; visual search ; features ; v1 ; asymmetry ; segmentation	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	8 2 5	visual search is the task of nding a target in an image against a background of distractors . <otherscientificterm_1> enable them to pop out against the background , while targets deened by lacks of <otherscientificterm_6> or conjunctions of <otherscientificterm_6> are more diicult to spot . it is known that the ease of <task_4> can change when the <otherscientificterm_0> are switched . the mechanisms underlying the ease of pop out and <otherscientificterm_8> in <task_5> have been elusive . this paper shows that a model of <otherscientificterm_9> in <method_7> based on <otherscientificterm_3> can explain many of the qualitative aspects of <task_5> .	1 10 -1 6 10 -1 4 0 10 -1 8 5 11 10 -1 9 7 3 10 -1
Information Retrieval Oriented Word Segmentation based on Character Association Strength Ranking .	chinese information retrieval ; ranking-style word segmentation approach ; internal associative strength ; word segmentation methods ; training corpus ; dictionary information ; query items ; overlapping ambiguity ; seg-mentation decision ; mutual information ; ranking model ; statistical features ; rsvm-seg ; ranking ; t-test ; frequency ; granular-ity	<task> <method> <metric> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 7 ; 9 1 14 ; 13 0 8 ; 15 6 11 ; 14 6 11 ; 5 6 11 ; 14 1 15 ; 1 4 3 ; 1 0 8 ; 12 6 1 ; 1 0 0 ; 15 1 5 ; 9 6 11	this paper presents a novel , <method_1> , called <method_12> , which is well tailored to <task_0> . this <method_1> makes <task_8> based on the <otherscientificterm_13> of the <metric_2> between each pair of adjacent characters of the sentence . on the <material_4> composed of <otherscientificterm_6> , a <method_10> is learned by a widely-used tool ranking svm , with some useful <otherscientificterm_11> , such as <otherscientificterm_9> , difference of <otherscientificterm_14> , <otherscientificterm_15> and <otherscientificterm_5> . experimental results show that , this <method_1> is able to eliminate <otherscientificterm_7> much more effectively , compared to the current <method_3> . furthermore , as this <method_1> naturally generates segmentation results with different <otherscientificterm_16> , the performance of <task_0> is improved and achieves the state of the art .	1 12 0 27 28 17 -1 8 13 2 20 26 17 -1 4 6 10 11 9 14 15 5 19 21 22 23 24 29 30 17 -1 7 3 18 25 17 -1 17 -1
Temporal Milestones in HTNs .	task abstraction boundaries ; hierarchical task networks ; end time ; start time ; temporal milestone ; landmark variables ; structural properties ; temporal milestones	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 1 2 ; 7 0 1	we present <otherscientificterm_7> for <method_1> to enable the complex synchronization of tasks . a <otherscientificterm_4> of a task is an intermediate event that occurs during the execution of a complex task , e.g. , the <otherscientificterm_3> , the <otherscientificterm_2> or a milestone of any of its subtasks . unlike <otherscientificterm_5> , introduced in existing work , <otherscientificterm_7> respect the <otherscientificterm_0> and preserve <otherscientificterm_6> enabling much more efficient reasoning . furthermore , <otherscientificterm_7> are as expressive as <otherscientificterm_5> . we provide analytical and empirical evidence to support these claims .	7 1 10 8 -1 4 3 2 9 8 -1 5 0 6 8 -1 8 -1 8 -1
Application of Machine Learning To Epileptic Seizure Detection .	brain 's electrical activity ; median false detection rate ; machine learning framework ; median detection delay ; machine learning approach ; patient-specific classifiers ; scalp eeg ; brain activity ; continuous eeg ; epileptic seizure ; non-invasive measure ; chb-mit database ; false detections ; features	<otherscientificterm> <metric> <method> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <metric> <material> <metric> <otherscientificterm>	1 5 4 ; 3 5 4 ; 4 0 5 ; 8 5 4 ; 3 1 1	we present and evaluate a <method_4> to constructing <method_5> that detect the onset of an <otherscientificterm_9> through analysis of the <otherscientificterm_6> , a <metric_10> of the <otherscientificterm_0> . this problem is challenging because the <otherscientificterm_0> is composed of numerous classes with overlapping characteristics . the key steps involved in realizing a high performance <method_4> included shaping the problem into an appropriate <method_2> , and identifying the <otherscientificterm_13> critical to separating seizure from other types of <otherscientificterm_7> . when trained on 2 or more seizures per patient and tested on 916 hours of <material_8> from 24 patients , our <method_4> detected 96 % of 173 test seizures with a <metric_3> of 3 seconds and a <metric_1> of 2 <metric_12> per 24 hour period . we also provide information about how to download the <material_11> , which contains the data used in this study .	4 5 9 6 10 0 17 14 -1 14 -1 2 13 7 14 -1 8 15 16 18 19 14 -1 3 1 12 14 -1
Scalable Metric Learning via Weighted Approximate Rank Component Analysis .	weighted approximate rank component analysis ; large scale market-1501 and cuhk03 datasets ; stochastic gradient descent algorithm ; non-linear extension of warca ; metric learning formulation ; kernel space embedding ; low-rank matrix optimization ; matrix rank degeneration ; person re-identification datasets ; weighted rank loss ; inarbitrary distance measures ; kernel trick ; mahalanobis distance ; person re-identification ; non-isolated minima ; data dimension ; computer vision ; precision ; ranks ; features ; regularizer	<method> <material> <method> <method> <method> <method> <method> <task> <material> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <otherscientificterm> <method>	14 0 6 ; 11 0 0 ; 0 6 4 ; 13 6 16 ; 7 2 6 ; 20 0 6	our goal is to learn a <otherscientificterm_12> by minimizing a loss defined on the weighted sum of the <metric_17> at different <otherscientificterm_18> . our core motivation is that minimizing a <otherscientificterm_9> is a natural criterion for many problems in <task_16> such as <task_13> . we propose a novel <method_4> called <method_0> . we then derive a scalable <method_2> for the resulting <task_16> . we also derive an efficient <method_3> by using the <method_11> . <method_5> decouples the training and prediction costs from the <otherscientificterm_15> and enables us to plug <method_10> which are more natural for the <otherscientificterm_19> . we also address a more general problem of <task_7> & <otherscientificterm_14> in the <method_6> by using new type of <method_20> which approximately enforces the or-thonormality of the learned matrix very efficiently . we validate this new method on nine standard <material_8> including two <material_1> and show that we improve upon the current state-of-the-art methods on all of them .	12 17 18 21 -1 9 16 13 25 21 -1 4 0 24 21 -1 2 21 -1 3 11 5 23 21 -1 15 10 19 21 -1 22 26 27 21 -1 7 14 6 20 21 -1
Hidden information detection based on quantized Laplacian distribution .	discrete cosine transform coefficients ; detection of hidden information ; hidden information detection ; jpeg image compression ; quantified laplacian distribution ; false alarm ; jpeg image ; dct coefficients ; statistical decision ; hidden bits ; statistical test	<otherscientificterm> <task> <task> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <method>	3 0 7 ; 0 0 10	the goal of this paper is to propose the optimal <method_10> based on the modeling of <otherscientificterm_0> with a <otherscientificterm_4> . this paper focuses on the <task_1> embedded in bits of the <otherscientificterm_7> of a <material_6> . this <task_1> is difficult , in terms of <task_8> , for two main reasons : first , the number of <otherscientificterm_7> used to conceal the <otherscientificterm_9> is random ; second , the <method_3> induces a strong quantization of <otherscientificterm_7> . the proposed test explicitly takes into account the randomness of the number of <otherscientificterm_7> used . it maximizes the probability of <task_2> by ensuring a prescribed level of <otherscientificterm_5> .	10 0 4 13 11 -1 1 7 6 11 -1 8 9 3 12 11 -1 11 -1 2 11 -1
Optimal graph laplacian regularization for natural image denoising .	non-local means ; per-patch optimal metric space g ; graph 's edge weights ; graph laplacian regu-larizer ; graph laplacian regularizer ; local graph-based filtering ; image denoising algorithm ; graph laplacian reg-ularizer ; graph-signal h d ; non-local pixel patches ; continuous functional sœâ ; image denoising ; pixel patch ; gradient estimates ; edge weights ; graph-signal domain ; image priors ; laplacian l ; g ; œâ ; filtering	<otherscientificterm> <method> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	1 5 0 ; 17 0 20 ; 1 0 6 ; 18 0 17 ; 2 0 16	image denoising is an under-determined problem , and hence it is important to define appropriate <otherscientificterm_16> for regularization . one recent popular prior is the <method_4> , where a given <otherscientificterm_12> is assumed to be smooth in the <material_15> . the strength and direction of the resulting <otherscientificterm_16> are computed from the <otherscientificterm_2> . in this paper , we derive the optimal <otherscientificterm_14> for <task_5> using <method_13> from <otherscientificterm_9> that are self-similar . to analyze the effects of the <method_13> on the <otherscientificterm_7> , we first show theoretically that , given <method_8> is a set of discrete samples on continuous function h -lrb- x , y -rrb- in a closed region <otherscientificterm_19> , <method_4> -lrb- h d -rrb- t lh d converges to a <method_10> integrating gradient norm of h in metric space <method_18> -- i.e. , -lrb- ‚àá h -rrb- t <method_18> ‚àí 1 -lrb- ‚àá h -rrb- -- over <otherscientificterm_19> . we then derive the optimal metric space <method_18> : one that leads to a <method_3> that is discriminant when the <method_13> are accurate , and robust when the <method_13> are noisy . finally , having derived <method_18> we compute the corresponding <otherscientificterm_14> to define the <otherscientificterm_17> used for <task_20> . experimental results show that our <method_6> using the <method_1> outperforms <otherscientificterm_0> by up to 1.5 db in <otherscientificterm_0> .	16 21 -1 4 12 15 21 -1 2 26 21 -1 14 5 13 9 21 -1 7 8 21 -1 19 10 18 21 -1 3 23 25 21 -1 17 22 24 21 -1
Neural Responding Machine for Short-Text Conversation .	neural responding machine ; recurrent neural networks ; latent representation of the input text ; neural network-based response generator ; retrieval-based and smt-based models ; generation of response ; one-round conversation data ; microblogging service ; decoding process ; encoder-decoder framework ; short-text conversation ; decoding ; encoding	<method> <method> <material> <method> <method> <task> <material> <material> <method> <method> <task> <method> <otherscientificterm>	0 6 3 ; 7 0 6 ; 3 0 10 ; 2 0 8 ; 6 0 0	we propose <method_0> , a <method_3> for <task_10> . <method_0> takes the general <method_9> : <method_0> formalizes the <task_5> as a <method_8> based on the <material_2> , while both <otherscientificterm_12> and <method_11> are realized with <method_1> . the <method_0> is trained with a large amount of <material_6> collected from a <material_7> . empirical study shows that <method_0> can generate grammatically correct and content-wise appropriate responses to over 75 % of the input text , outperforming state-of-the-arts in the same setting , including <method_4> .	0 3 10 14 16 13 -1 9 5 8 2 12 11 1 17 13 -1 6 7 15 18 13 -1 4 13 -1
Ranking via Robust Binary Classification .	explicit feature vectors ; large scale problems ; robust classification ; evaluation metrics ; wall-clock time ; competitor algorithm ; ranking algorithm ; learning ; computation ; robirank	<otherscientificterm> <task> <task> <metric> <otherscientificterm> <method> <method> <task> <task> <method>	4 2 8 ; 4 2 5 ; 6 0 7 ; 9 6 6	we propose <method_9> , a <method_6> that is motivated by observing a close connection between <metric_3> for <task_7> to rank and loss functions for <task_2> . <method_9> shows competitive performance on standard benchmark datasets against a number of other representative algorithms in the literature . we also discuss extensions of <method_9> to <task_1> where <otherscientificterm_0> and scores are not given . we show that <method_9> can be efficiently parallelized across a large number of machines ; for a task that requires 386 , 133 √ó 49 , 824 , 519 pairwise interactions between items to be ranked , robi-rank finds solutions that are of dramatically higher quality than that can be found by a state-of-the-art <method_5> , given the same amount of <otherscientificterm_4> for <task_8> .	9 6 3 7 2 13 14 10 -1 10 -1 1 0 10 -1 11 12 10 -1
Understanding Performance Tradeoffs in Algorithms for Solving Oversubscribed Scheduling .	squeaky wheel optimization ; taskswap ; schedule-space repair search procedure ; oversubscribed scheduling problems ; real-world scheduling problem ; permutation-space scheduling procedure ; permutation-based search methods ; schedule-space search methods ; resource over-subscription ; schedule builder ; schedule-space methods ; permutation-based methods ; mapping	<method> <method> <method> <task> <task> <method> <method> <method> <otherscientificterm> <method> <method> <method> <method>	1 4 0 ; 0 6 5 ; 10 1 11 ; 6 4 7	in recent years , planning and scheduling research has paid increasing attention to problems that involve <otherscientificterm_8> , where cumulative demand for resources out-strips their availability and some subset of goals or tasks must be excluded . two basic classes of techniques to solve <task_3> have emerged : searching directly in the space of possible schedules and searching in an alternative space of task permutations -lrb- by relying on a <method_9> to provide a <method_12> to schedule space -rrb- . in some problem contexts , <method_6> have been shown to outperform <method_7> , while in others the opposite has been shown to be the case . we consider two techniques for which this behavior has been observed : <method_1> , a <method_2> , and <method_0> , a <method_5> . we analyze the circumstances under which one can be expected to dominate the other . starting from a <task_4> where <method_0> has been shown to outperform <method_1> , we construct a series of problem instances that increasingly incorporate characteristics of a second <task_4> , where <method_1> has been found to outperform <method_0> . experimental results provide insights into when <method_10> and <method_11> may be most appropriate .	8 13 -1 3 9 12 13 -1 6 7 17 13 -1 15 13 -1 1 2 0 5 13 -1 14 13 -1 4 16 13 -1
Cross-domain robust acoustic training .	ibm viavoice product engine ; 8khz closing talking microphone ; weighted multi-style training ; language model tasks ; reduced phone sets ; hybrid acoustic models ; decision tree size ; phone set design ; cross-domain acoustic training ; flat grammars ; hybrid system ; general dictation ; spanish ; atis ; accuracy	<method> <task> <method> <task> <material> <method> <metric> <method> <task> <method> <method> <task> <material> <method> <metric>	10 0 11 ; 13 1 11 ; 10 0 3 ; 13 6 3 ; 10 0 1 ; 9 5 10	this paper describes our efforts towards <task_8> for large vocabulary continuous speech recognition -lrb- lvcsr -rrb- systems . we used <method_2> by pooling insufficient telephony landline and cellular data with down sampled wide band clean data to develop better <method_5> . we explored the effects on <metric_6> to <metric_14> by approximately 10 % . the results show that by fixing number of parameters , system with smaller number of context dependent hmm states yields better <metric_14> . it leads to a smaller <method_7> . we then investigated the performance degradation on two <material_4> for <material_12> . based on these studies , we are able to develop a <method_10> for <task_1> , telephony landline and cellular phone environments . the <method_10> is evaluated on both <method_9> , digit and name at department , and <task_3> , <method_13> and <task_11> , using the <method_0> .	8 15 -1 2 5 15 -1 6 14 15 -1 15 -1 7 15 -1 4 12 15 -1 20 15 -1 10 1 16 17 18 19 21 15 -1
Bypassing Combinatorial Protections : Polynomial-Time Algorithms for Single-Peaked Electorates .	combinatorial covering challenges ; weighted coalition manipulation ; combinatorially rich structures ; central political-science model ; np-hard bribery problems ; single-peaked preferences ; scoring protocols ; single-peaked electorates ; election systems ; polynomial time ; hardness protections ; partitions ; complexity ; covers ; constructions	<task> <method> <otherscientificterm> <method> <task> <otherscientificterm> <task> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task>	9 0 7 ; 5 0 0 ; 1 0 6 ; 13 6 2 ; 11 6 2 ; 11 1 13	for many <method_8> , bribery -lrb- and related -rrb- attacks have been shown np-hard using <task_14> on <otherscientificterm_2> such as <otherscientificterm_11> and <otherscientificterm_13> . this paper shows that for voters who follow the most <method_3> of electorates -- <otherscientificterm_5> -- those <otherscientificterm_10> vanish . by using <otherscientificterm_5> to simplify <task_0> , we for the first time show that <task_4> -- including those for kemeny and llull elections -- fall to <otherscientificterm_9> for <material_7> . by using <otherscientificterm_5> to simplify <task_0> , we for the first time show that <task_4> fall to <otherscientificterm_9> for <material_7> . we show that for <material_7> , the winner problems for dodgson and kemeny elections , though Œ∏ p 2-complete in the general case , fall to <otherscientificterm_9> . and we completely classify the <metric_12> of <method_1> for <task_6> in <material_7> .	8 14 2 11 13 19 20 21 15 -1 3 5 10 15 -1 0 4 9 7 15 -1 16 17 15 -1 15 -1 18 15 -1
DFW-based spectral smoothing for concatenative speech synthesis .	derivative logarithmic magnitude spectra ; euclidean spectral distance measurements ; phonetic point of view ; spectral smoothing technique ; autoregressive filter coefficients ; smoothed frequency responses ; interpolated formant trajectories ; weighted linear interpolation ; dynamic programming ; lsp interpolation ; dp backtracking ; autocorrelation coefficients ; spectral representations	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <method>	8 0 12 ; 7 0 5 ; 3 0 0	this paper proposes and evaluates a new <method_3> whose performance is comparable with <method_9> in terms of <otherscientificterm_1> but whose <otherscientificterm_6> are more reasonable from a <otherscientificterm_2> . the <method_3> firstly estimates <otherscientificterm_0> from both the source and the target frame represented by <otherscientificterm_4> . then , <method_8> yields the best alignment between these two <method_12> . <otherscientificterm_5> are achieved by <method_7> between the corresponding source and target spectral lines whose alignment was found by <method_10> . finally , the spectrum is converted to <otherscientificterm_4> with the intermediate stage of <otherscientificterm_11> .	3 9 1 6 2 13 -1 0 4 16 13 -1 8 12 5 14 13 -1 7 10 15 13 -1 11 13 -1
TextonBoost : Joint Appearance , Shape and Context Modeling for Multi-class Object Recognition and Segmentation .	high classification and segmentation accuracy ; semantic segmentation of photographs ; 7-class corel subset ; general lighting conditions ; conditional random field ; random feature selection ; 7-class sowerby database ; 21-object class database ; automatic visual recognition ; piecewise training methods ; discrimi-native model ; image segmentation ; unary classification ; shared boosting ; feature selection ; object classes ; features ; classifier	<metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <material> <task> <method> <method> <task> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method>	13 0 14 ; 2 1 6 ; 13 0 17 ; 17 0 11 ; 5 1 9 ; 4 0 11 ; 8 1 1 ; 12 1 14	this paper proposes a new approach to learning a <method_10> of <otherscientificterm_15> , incorporating appearance , shape and context information efficiently . the learned model is used for <task_8> and <task_1> . our dis-criminative model exploits novel <otherscientificterm_16> , based on textons , which jointly model shape and texture . <task_12> and <method_14> is achieved using <method_13> to give an efficient <method_17> which can be applied to a large number of classes . accurate <task_11> is achieved by incorporating these <method_17> in a <otherscientificterm_4> . efficient training of the model on very large datasets is achieved by exploiting both <method_5> and <method_9> . <metric_0> are demonstrated on three different databases : i -rrb- our own <material_7> of photographs of real objects viewed under <otherscientificterm_3> , poses and viewpoints , ii -rrb- the <otherscientificterm_2> and iii -rrb- the <material_6> used in -lsb- 1 -rsb- . the proposed algorithm gives competitive results both for highly textured -lrb- e.g.	10 15 18 -1 8 1 25 18 -1 16 12 18 -1 14 13 17 19 21 26 18 -1 11 4 22 24 18 -1 5 23 18 -1 9 0 20 18 -1 7 3 2 6 18 -1
Efficient filter flow for space-variant multiframe blind deconvolution .	noisy magnetic resonance images ; space-variant blind deconvolution ; space-variant filters ; atmospheric turbulences ; astronomical imaging ; linear transformations ; matrix-vector-multiplications	<material> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	3 0 4	ultimately being motivated by facilitating <otherscientificterm_1> , we present a class of <otherscientificterm_5> , that are expressive enough for <method_2> , but at the same time especially designed for efficient <otherscientificterm_6> . successful results on <task_4> through <otherscientificterm_3> and on <material_0> of constantly moving objects demonstrate the practical significance of our approach .	1 5 2 6 7 -1 4 3 0 8 7 -1
Parsing speech into articulatory events .	mel frequency cepstral coefficient representation ; recurrent neural network classifiers ; speech production process state ; place and manner features ; frame and segment levels ; posterior probabilities of classes ; variable depth lattice generator ; language and duration constraints ; variable depth lattices ; categorical articulatory features ; articulatory feature detection ; viterbi decoder ; articulatory feature ; product lattices ; viterbi algorithm ; timit data ; feature ; classifiers	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method>	9 0 2 ; 6 1 11 ; 17 0 10 ; 8 0 16	in this paper , the <method_2> is defined by a number of <otherscientificterm_9> . we describe a detector that outputs a stream -lrb- sequence of classes -rrb- for each <otherscientificterm_12> given the <method_0> of the input speech . the detector consists of a bank of <method_1> , a <method_6> and <method_11> . a bank of <method_17> has been previously used for <task_10> by many researchers . however , we extend their work first by creating <otherscientificterm_8> for each <otherscientificterm_16> and then by combining <otherscientificterm_8> into <otherscientificterm_13> for rescoring using the <method_14> . during the rescor-ing we incorporate <otherscientificterm_7> along with the <otherscientificterm_5> provided by the <method_0> . we present our results for <otherscientificterm_3> using <material_15> , and compare the results to a baseline system . we report performance improvements both at the <otherscientificterm_4> .	2 9 19 18 -1 12 0 18 -1 1 6 11 20 18 -1 17 10 21 18 -1 8 16 13 14 22 18 -1 7 18 -1 5 18 -1 3 15 18 -1
Spatio-temporal resolution enhancement of video sequence based on super-resolution reconstruction .	high-resolution and high frame rate video sequences ; spatio-temporal resolution enhancement method ; feature point correspondence ; motion estimation function ; super-resolution reconstruction ; observation model ; video sequences ; warping matrix ; optimization formula ; constraint introduction ; constraint	<material> <method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm>	3 0 5 ; 3 3 7 ; 2 0 5 ; 10 0 8 ; 8 0 5	this paper proposes a new <method_1> of <material_6> based on <method_4> . the proposed method derives a new <method_5> based on <otherscientificterm_2> between successive frames . the <method_5> is defined by including the <otherscientificterm_3> in computing the <otherscientificterm_7> . also , a new <otherscientificterm_10> is introduced to the <method_8> for estimating the parameters of the <method_5> , in order to achieve effective resolution-enhancement . by the newly obtained matrix and the new <method_9> make accurate <material_0> . simulation results are shown to confirm the high performance of the proposed method .	1 6 4 11 -1 5 2 14 11 -1 3 7 12 13 11 -1 10 8 15 16 11 -1 9 0 11 -1 11 -1
On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems .	recurrent neural network encoder-decoder ; continuous space dialogue representation ; on-line learning framework ; noisy user feedback ; dialogue policy learning ; gaussian process model ; explicit user feedback ; data annotation costs ; dialogue policy ; reinforcement learning ; unsupervised fashion ; reward signal ; reward function ; real-world applications ; reward model ; active learning	<method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <task> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <method>	1 0 2 ; 9 0 8 ; 12 0 8 ; 15 0 2 ; 7 5 2 ; 5 0 14 ; 10 0 2 ; 0 0 10 ; 15 0 14 ; 15 0 8 ; 2 0 3 ; 0 0 1	the ability to compute an accurate <otherscientificterm_12> is essential for optimising a <task_8> via <method_9> . in <task_13> , using <otherscientificterm_6> as the <otherscientificterm_11> is often unreliable and costly to collect . this problem can be mitigated if the user 's intent is known in advance or data is available to pre-train a task success predictor off-line . in practice neither of these apply for most real world applications . here we propose an <method_2> whereby the <task_8> is jointly trained alongside the <method_14> via <method_15> with a <method_5> . this <method_2> operates on a <method_1> generated in an <method_10> using a <method_0> . the experimental results demonstrate that the proposed <method_2> is able to significantly reduce <metric_7> and mitigate <otherscientificterm_3> in <task_4> .	12 8 9 18 19 16 -1 13 6 11 16 -1 16 -1 16 -1 2 14 15 5 20 22 25 26 16 -1 1 10 17 23 24 28 16 -1 0 21 27 16 -1
Improved entropic gain for speech signals analysis/synthesis based on an adaptive time-frequency segmentation scheme .	wavelet packet decomposition ; adaptive representation of speech signals ; entropy of the base ; lack of temporal segmentation ; low cost extended tree ; basis search algorithm ; experimental speech signals ; local entropic criterion ; frequency adaptation skills ; entropic test ; dyadic structure ; eecient tool ; temporal segmentation ; classical wpd ; global analysis ; reconstruction	<method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <material> <metric> <method> <otherscientificterm> <method> <method> <material> <method> <task>	7 0 12 ; 4 0 0	in the search for <task_1> , the <method_0> has been proved to be a <method_11> because of its <metric_8> through the best <method_5> . the en-tropic minimization of this algorithm is bounded by two artifacts : the <otherscientificterm_10> of the decomposition and the <otherscientificterm_3> . we propose here a <otherscientificterm_4> in the <method_0> which improves the best basis search by reducing the <otherscientificterm_2> and which is still compatible with the <material_13> . the decomposition also allows perfect <task_15> . the <method_9> is updated to take into account the new basis . the preliminary use of a <method_12> , based on the <material_7> highly improves the entropic gain of the <method_14> . the results are shown on <material_6> comparing the gain of our scheme versus a usual <method_0> .	1 0 11 8 5 16 -1 10 3 16 -1 4 2 13 18 16 -1 15 16 -1 9 16 -1 12 17 16 -1 7 14 16 -1
Speech Utterance Classification Model Training without Manual Transcriptions .	manually transcribed and annotated training data ; classification model training approach ; speech utterance classification systems ; unsupervised language model adaptation ; spoken language understanding tasks ; data-driven statistical learning approach ; speech utterance classification ; training speech utterances ; command and control ; classification accuracy ; classification destinations ; manual transcriptions ; modeling training ; dialog systems ; manual transcription ; wave files ; call routing	<material> <method> <method> <method> <task> <method> <task> <material> <otherscientificterm> <metric> <otherscientificterm> <material> <task> <task> <material> <material> <task>	13 6 4 ; 6 0 4 ; 9 5 1 ; 16 1 13 ; 3 0 1 ; 8 6 4 ; 16 6 4 ; 13 1 8 ; 5 0 2	speech utterance classification has been widely applied to a variety of <task_4> , including <task_16> , <task_13> , and <otherscientificterm_8> . most <method_2> adopt a <method_5> , which requires <material_0> . in this paper we introduce a novel <method_1> based on <method_3> . <method_1> only requires <material_15> of the <material_7> and their corresponding <otherscientificterm_10> for <task_12> . no <material_14> of the utterances is necessary . experimental results show that this <method_1> , which is much cheaper to implement , has achieved <metric_9> at the same level as the model trained with <material_11> .	4 16 13 8 18 19 21 23 24 25 17 -1 2 5 0 26 17 -1 1 3 22 17 -1 15 7 10 12 17 -1 14 17 -1 9 11 6 20 17 -1
Unsupervised Dependency Parsing with Transferring Distribution via Parallel Guidance and Entropy Regularization .	unsupervised and projected parsing systems ; google universal dependency treebanks ; unsupervised dependency parsers ; labeled training data ; probabilistic parsing models ; entropy reg-ularization ; cross-lingual knowledge ; data sets ; human translations ; resource-rich language ; resource-poor languages ; treebanks ; languages	<method> <material> <method> <material> <method> <method> <otherscientificterm> <material> <otherscientificterm> <material> <material> <material> <material>	1 1 11 ; 5 2 6 ; 4 0 10 ; 1 6 7	we present a novel approach for inducing <method_2> for <material_12> that have no <material_3> , but have translated text in a <material_9> . we train <method_4> for <material_10> by transferring <otherscientificterm_6> from <material_9> with <method_5> . our method can be used as a purely monolingual dependency parser , requiring no <otherscientificterm_8> for the test data , thus making <method_4> applicable to a wide range of <material_10> . we perform experiments on three <material_7> -- version 1.0 and version 2.0 of <material_1> and <material_11> from conll shared-tasks , across ten <material_12> . we obtain state-of-the art performance of all the three data sets when compared with previously studied <method_0> .	2 12 3 9 13 -1 4 10 6 5 15 13 -1 8 16 13 -1 7 1 11 14 17 13 -1 13 -1
Classification of emotional content of sighs in dyadic human interactions .	acoustic and gestural features ; spontaneous affective dialogs ; emotionally valenced sighs ; negative emotion ; valence axis ; emotional sighs ; human communication ; multimodal characteristics ; unweighted accuracy ; sighs ; sighs ; cries ; laughter ; classification	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	4 2 5 ; 3 2 10 ; 11 1 9 ; 12 1 11	emotions are an important part of <otherscientificterm_6> and are expressed both verbally and non-verbally . common non-verbal vocalizations such as <otherscientificterm_12> , <otherscientificterm_11> and <otherscientificterm_9> carry important emotional content in conversations . <otherscientificterm_10> often are associated with <otherscientificterm_3> . in this work , we show that <otherscientificterm_5> exist along both ends of the <otherscientificterm_4> -lrb- positive-emotion vs. negative-emotion <otherscientificterm_9> -rrb- in <otherscientificterm_1> and that they have certain distinct <otherscientificterm_7> . <task_13> results show that it is possible to differentiate between the two types of <material_2> , using a combination of <otherscientificterm_0> with an overall <metric_8> of 58.26 % .	6 14 -1 12 11 9 10 17 18 14 -1 3 16 14 -1 5 4 1 7 13 15 14 -1 2 0 8 14 -1
Sparse Kernel Orthonormalized PLS for feature extraction in large data sets .	analysis of integrated short-time music features ; uci data sets ; multivariate analysis method ; kernel pls ; genre prediction ; feature extraction ; expressive power ; labelled data ; sparsity constrains ; features	<task> <material> <method> <method> <task> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	2 4 3	in this paper we are presenting a novel <method_2> . our <method_2> is based on a novel kernel orthonormalized partial least squares -lrb- pls -rrb- variant for <task_5> , imposing <otherscientificterm_8> in the solution to improve scalabil-ity . the <method_2> is tested on a benchmark of <material_1> , and on the <task_0> for <task_4> . the upshot is that the <method_2> has strong <otherscientificterm_6> even with rather few <otherscientificterm_9> , is clearly outperforming the ordinary <method_3> , and therefore is an appealing <method_2> for <task_5> of <material_7> .	2 10 -1 5 8 10 -1 1 0 4 10 -1 6 9 3 7 11 10 -1
Sparse representations for multiple measurement vectors -LRB- MMV -RRB- in an over-complete dictionary .	single measurement vector ; multiple measurement vector ; sparse representations ; efficient methods ; 0-norm minimization ; sparse representation ; 1-norm minimization ; theoretical analysis ; over-complete dictionary	<method> <task> <method> <method> <task> <method> <task> <method> <material>	3 0 2 ; 1 6 5 ; 1 0 1	multiple measurement vector -lrb- mmv -rrb- is a newly emerged problem in <method_5> in an <material_8> ; it poses new challenges . <method_3> have been designed to search for <method_2> -lsb- 1 , 2 -rsb- ; however , we have not seen substantial development in the <method_7> , considering what has been done in a simpler case -- <method_0> -- in which many theoretical results are known , e.g. , -lsb- 9 , 3 , 4 , 5 , 6 -rsb- . this paper extends the known results of <task_1> to mmv . our theoretical results show the fundamental limitation on when a <method_5> is unique . moreover , the relation between the solutions of <task_4> and the solutions of <task_6> indicates a compu-tationally efficient approach to find a <method_5> . interestingly , simulations show that the predictions made by these theorems tend to be conservative .	5 8 3 11 9 -1 2 7 0 10 9 -1 1 12 9 -1 9 -1 9 -1 4 6 9 -1
Open-set speaker identification using adapted Gaussian mixture models .	open-set , text-independent speaker identification ; nist sre2003 1-speaker detection task ; unconstrained co-hort normalisation ; gaussian mixture models ; score normalisation methods ; osti-si framework ; speaker verification ; fast-scoring method ; t-norm ; tz-norm	<task> <material> <method> <method> <method> <method> <task> <method> <method> <method>	8 1 9 ; 2 1 8 ; 3 0 0 ; 7 0 6	this paper presents an investigation into the use of adapted <method_3> in the context of <task_0> . the study includes a scheme for using the <method_7> which has been proposed for <task_6> . furthermore , it provides an evaluation of various <method_4> in the proposed <method_5> . the dataset used for the experimental investigation is based on <material_1> . it is shown that significant improvements can be achieved if only a single mixture is used in the fast-scoring technique . furthermore , it is experimentally observed that comparable performance is obtained using <method_2> , <method_8> and <method_9> . the paper provides a detailed description of the experimental set up , and presents an analysis of the results obtained .	3 0 13 10 -1 7 6 14 10 -1 4 5 10 -1 1 10 -1 10 -1 2 8 9 11 12 10 -1 10 -1
Hill-climbing feature selection for multi-stream ASR .	clean and noisy data sets ; ensemble -rrb- automatic speech recognition ; hill-climbing algorithm ; multi-layer-perceptron-based numbers asr system ; opitz 's scoring formula ; single-classifier word recognition accuracy ; automated feature selection ; ogi numbers corpus ; hc process ; ensemble accuracy ; hc scripts ; performance score ; ensemble diversity ; noise types ; feature	<material> <task> <method> <method> <method> <metric> <task> <material> <method> <metric> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 1 ; 10 0 0 ; 12 2 4 ; 7 0 0 ; 5 1 12 ; 5 5 4 ; 7 3 3 ; 5 1 9 ; 2 0 1	we performed <task_6> for multi-stream -lrb- i.e. , <task_1> , using a <method_2> that changes one <otherscientificterm_14> at a time if the change improves a <metric_11> . for both <material_0> -lrb- using the <material_7> -rrb- , <method_10> usually improved performance on held out data compared to the initial system it started with , even for <otherscientificterm_13> that were not seen during the <method_8> . overall , we found that using <method_4> , which blends <metric_5> and <otherscientificterm_12> , worked better than <metric_9> as a <metric_11> for guiding <method_10> in cases of extreme mismatch between the snr of training and test sets . our noisy version of the <material_7> , our <method_3> , and our <method_10> are available online .	6 1 2 14 11 16 24 15 -1 0 7 10 13 8 17 19 15 -1 4 5 12 9 18 20 21 23 15 -1 22 15 -1
The RoboCup Synthetic Agent Challenge 97 .	dynamic , real-time , multi-agent domain ; multi-agent team planning ; intelligent agent researchers ; robocup challenge oers ; machine learning	<material> <method> <task> <method> <task>	3 0 4	robocup challenge oers a set of challenges for <task_2> using a friendly competition in a <material_0> . while <method_3> in general envisions longer range challenges over the next few decades , <method_3> presents three specic challenges for the next two years : -lrb- i -rrb- learning of individual agents and teams ; -lrb- ii -rrb- <method_1> and plan-execution in service of teamwork ; and -lrb- iii -rrb- opponent mod-eling . <method_3> provides a novel opportunity for <task_4> , planning , and multi-agent researchers | <method_3> not only supplies a concrete domain to evalute their techniques , but also challenges researchers to evolve these techniques to face key constraints fundamental to this domain : real-time , uncertainty , and teamwork .	2 0 5 -1 3 1 5 -1 4 6 5 -1
Speaker normalization based on test to reference speaker mapping .	vocal tract envelope and excitation model ; formant based nonlinear frequency warping approach ; estimated frequency warping function ; teaching and training system ; vocal tract envelope ; reference speaker excitation ; speaker normalization technique ; time-frequency speech representation ; vocal tract shape ; vocal tract normalization ; spectral distance ; excitation characteristics ; speech decomposition ; inter-speaker variability ; synthesis framework ; normalization ; variance ; analysis	<method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	14 0 6 ; 1 0 9 ; 2 0 4 ; 12 3 0	the paper presents the <method_6> we implemented in a <method_3> for hearing handicapped children with the goal to reduce <otherscientificterm_13> in <task_7> . in an effort to reduce <otherscientificterm_16> caused by variation in <otherscientificterm_8> among speakers , a <method_1> to <task_9> is investigated . the proposed <method_6> can be efficiently realized in an <task_17> by <method_14> . after the <task_12> into the <method_0> , the <otherscientificterm_4> is warped by the <otherscientificterm_2> , while the <otherscientificterm_11> are mapped to the <otherscientificterm_5> . the results have shown significant <otherscientificterm_10> decrease for correctly pronounced words between test and the reference speaker after the <otherscientificterm_15> has been applied , while for poor pronunciation by the test speaker the <otherscientificterm_10> remains relatively high .	6 3 13 7 18 -1 16 8 1 9 20 18 -1 17 14 19 18 -1 12 0 4 2 11 5 21 22 18 -1 10 18 -1
Solving POMDPs : RTDP-Bel vs. Point-based Algorithms .	parallel value iteration ; discretization function ; approximate methods ; tabular representation ; goal pomdps ; representational gap ; discounted pomdps ; value function ; point-based algorithms ; point-based algorithms ; rtdp-bel	<task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <method> <method> <material>	10 0 10 ; 6 0 4 ; 10 4 6 ; 10 4 9 ; 8 0 10 ; 3 1 1 ; 9 4 6	point-based algorithms and <material_10> are <method_2> for solving <material_10> that replace the full updates of <task_0> by faster and more effective updates at selected beliefs . an important difference between the two methods is that the former adopt sondik 's representation of the <otherscientificterm_7> , while the latter uses a <method_3> and a <otherscientificterm_1> . the algorithms , however , have not been compared up to now , because they target different <material_10> : <material_6> on the one hand , and <method_4> on the other . in this paper , we bridge this <otherscientificterm_5> , showing how to transform <material_6> into <method_4> , and use the transformation to compare <material_10> with <method_9> over the existing <material_6> . the results appear to contradict the conventional wisdom in the area showing that <material_10> is competitive , and sometimes superior to <method_9> in both quality and time .	10 2 0 12 16 11 -1 7 3 1 17 11 -1 6 4 11 -1 5 13 14 18 11 -1 9 15 11 -1
NOKIA Research Center Beijing Chinese Word Segmentation System for the SIGHAN Bakeoff 2007 .	state language commission of p.r.c. ; chinese word segmentation system ; open and closed track ; post processing strategies ; n-gram model ; preprocessing module ; out-of-vocabulary words ; segmentation ; sighan	<task> <method> <material> <method> <method> <method> <otherscientificterm> <task> <method>	5 0 7 ; 5 0 6 ; 4 0 3 ; 4 0 7	this paper presents the <method_1> developed by nokia research center -lrb- nrc -rrb- , which was evaluated in the fourth international chinese language processing bakeoff and the first cips chinese language processing evaluation organized by <method_8> . in our <method_1> , a <method_5> was used to discover the <otherscientificterm_6> which occur repeatedly in the text , then an improved <method_4> was used for <task_7> and some <method_3> are adopted in <method_1> to recognize the organization names and new words . we took part in three tracks , which are called the <material_2> on corpora <task_0> , and closed track on corpora shanxi university -lrb- sxu -rrb- . our <method_1> achieved good performance , especially in the open track on <task_0> , our <method_1> ranks 1 st among 11 systems .	1 8 9 -1 5 6 4 7 3 10 11 12 13 9 -1 2 0 9 -1 9 -1
Linear stereo matching .	o methods ; o approaches ; local stereo matching algorithms ; stereo matching algorithms ; disparity refinement pipeline ; cost aggregation step ; window size ; colour images ; integral his-tograms ; global approaches ; adaptive-weight strategy ; complexity ; aggregation ; accuracy	<method> <method> <method> <method> <method> <method> <otherscientificterm> <material> <method> <method> <method> <metric> <method> <metric>	2 4 9 ; 5 4 3 ; 5 0 4 ; 7 0 5 ; 10 0 2 ; 11 2 5 ; 10 0 9	recent <method_2> based on an <method_10> achieve <metric_13> similar to <method_9> . one of the major problems of these <method_2> is that they are computationally expensive and this <metric_11> increases proportionally to the <otherscientificterm_6> . this paper proposes a novel <method_5> with <metric_11> independent of the <otherscientificterm_6> -lrb- i.e. o -lrb- 1 -rrb- -rrb- that outperforms state-of-the-art <method_0> . moreover , compared to other <method_1> , our <method_5> does not rely on <method_8> enabling <method_12> using <material_7> instead of grayscale ones . finally , to improve the results of the proposed <method_5> a <method_4> is also proposed . the overall <method_5> produces results comparable to those of state-of-the-art <method_3> .	2 10 13 9 15 19 21 14 -1 11 6 14 -1 5 0 20 14 -1 1 8 12 7 18 14 -1 4 17 14 -1 16 14 -1
Semantic Frames to Predict Stock Price Movement .	semantic frame parsing ; binary classification tasks ; general nlp problems ; support vector machines ; semantic frame parsers ; polarity task ; linguistic resource ; semantic frames ; tree kernels ; financial news ; predic-tive models ; tree representation ; text representations ; features	<method> <task> <task> <method> <method> <task> <material> <method> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm>	5 5 0 ; 5 5 13 ; 3 0 11 ; 4 0 2 ; 1 2 12 ; 0 0 13 ; 3 0 8	semantic frames are a rich <material_6> . there has been much work on <method_4> , but less that applies them to <task_2> . we address a task to predict change in stock price from <material_9> . <method_7> help to generalize from specific sentences to scenarios , and to detect the -lrb- positive or negative -rrb- roles of specific companies . we introduce a novel <method_11> , and use <method_11> to train <method_10> with <otherscientificterm_8> using <method_3> . our experiments test multiple <method_12> on two <task_1> , change of price and polarity . experiments show that <otherscientificterm_13> derived from <method_0> have significantly better performance across years on the <task_5> .	6 14 -1 4 2 18 14 -1 9 7 14 -1 14 -1 11 10 8 3 17 21 14 -1 12 1 19 14 -1 13 0 15 16 20 14 -1
Phase recovery in NMF for audio source separation : an insightful benchmark .	nonnegative matrix factorization ; time-frequency domain ; nmf-based source separation techniques ; supervised model learning ; phase recovery ; audio signals ; estimation methods ; source separation ; prior information ; audible artifacts ; expressive power ; blind separation ; oracle separation	<method> <material> <method> <method> <task> <material> <method> <task> <otherscientificterm> <material> <otherscientificterm> <task> <task>	8 1 3 ; 8 1 12 ; 3 1 12 ; 4 0 2	nonnegative matrix factorization -lrb- nmf -rrb- is a powerful tool for decomposing mixtures of <material_5> in the <material_1> . in applications such as <task_7> , the <task_4> for each extracted component is a major issue since it often leads to <material_9> . in this paper , we present a methodology for evaluating various <method_2> involving <task_4> . for each model considered , a comparison between two approaches -lrb- <task_11> without <otherscientificterm_8> and <task_12> with <method_3> -rrb- is performed , in order to inquire about the room for improvement for the <method_6> . experimental results show that the high resolution nmf -lrb- hrnmf -rrb- model is particularly promising , because it is able to take phases and correlations over time into account with a great <otherscientificterm_10> .	5 1 13 -1 7 4 9 13 -1 2 17 13 -1 11 8 12 3 6 14 15 16 13 -1 13 -1
A wavelet based noise reduction algorithm for speech signal corrupted by coloured noise .	node dependent wavelet threshold-ing approach ; voiced or unvoiced nature ; common level dependent method ; infinitely smooth soft threshold ; decomposition tree ; noise power ; recursive method ; coloured noises ; speech signals ; japanese database ; node	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <material> <material> <otherscientificterm>	6 0 5 ; 9 5 0	in this paper , we present a <method_0> in order to remove strongly <material_7> from <material_8> . the <otherscientificterm_5> in each <otherscientificterm_10> is first estimated using a <method_6> . given the <otherscientificterm_1> of the frame , the signal is expanded onto a predefined best basis . then a <otherscientificterm_3> is applied depending on each <otherscientificterm_10> of the <otherscientificterm_4> . finally the estimated clean signal is reconstructed . experimental results on a <material_9> , for various <material_7> , demonstrate the effectiveness of the proposed <method_0> , even at low snr . compared with the <method_2> , this <method_0> provides better denoising results .	0 7 8 11 -1 5 10 6 12 11 -1 1 11 -1 3 4 11 -1 11 -1 9 13 11 -1 2 11 -1
Non-Gaussian Component Analysis : a Semi-parametric Framework for Linear Dimension Reduction .	ngca -lrb- non-gaussian component analysis -rrb- ; data analysis process ; high dimensional data ; data visualization ; semi-parametric framework ; non-gaussian components ; projection methods ; non-gaussian subspace ; dimension reduction ; paramet-ric rate ; ngca components ; denoising ; clustering ; classification	<method> <task> <material> <task> <method> <otherscientificterm> <method> <otherscientificterm> <task> <metric> <method> <otherscientificterm> <task> <task>	12 1 11 ; 3 1 12 ; 3 6 1 ; 12 6 1 ; 4 0 0 ; 0 0 8 ; 0 0 5 ; 11 6 1 ; 13 6 1 ; 11 1 13	we propose a new <method_0> for <task_8> to identify <otherscientificterm_5> in <material_2> . our <method_0> , <method_0> , uses a very general <method_4> . in contrast to existing <method_6> we define what is uninteresting -lrb- gaussian -rrb- : by projecting out uninterestingness , we can estimate the relevant <otherscientificterm_7> . we show that the estimation error of finding the <otherscientificterm_5> tends to zero at a <metric_9> . once <method_10> are identified and extracted , various tasks can be applied in the <task_1> , like <task_3> , <task_12> , <otherscientificterm_11> or <task_13> . a numerical study demonstrates the usefulness of our <method_0> .	0 8 5 2 20 21 14 -1 4 19 14 -1 6 7 14 -1 9 14 -1 10 1 3 12 11 13 15 16 17 18 22 23 24 14 -1 14 -1
High dynamic range image tone mapping by maximizing a structural fidelity measure .	tone mapping operators ; visually appealing images ; tone mapping approach ; gradient ascent direction ; computational structure ; objective measure	<method> <material> <method> <otherscientificterm> <otherscientificterm> <metric>	4 0 0 ; 0 0 1	tone mapping operators -lrb- <method_0> -rrb- that convert high dynamic range -lrb- hdr -rrb- images to standard low dynamic range -lrb- ldr -rrb- images are highly desirable for the visualization of these images on standard displays . although many existing <method_0> produce <material_1> , it is until recently validated objective measures that can assess their quality have been proposed . without such objective measures , the design of traditional <method_0> can only be based on intuitive ideas , lacking clear goals for further improvement . in this paper , we propose a substantially different <method_2> , where instead of explicitly designing a new <otherscientificterm_4> for <method_0> , we search in the space of images to find better quality images in terms of a recent <metric_5> that can assess the structural fidelity between two images of different dynamic ranges . specifically , starting from any initial image , the proposed algorithm moves the image along the <otherscientificterm_3> and stops until it converges to a maximal point . our experiments show that the proposed algorithm reliably produces better quality images upon a number of state-of-the-art <method_0> .	0 6 -1 1 8 6 -1 6 -1 2 7 6 -1 4 5 6 -1 3 6 -1
A Class-Based Agreement Model for Generating Accurately Inflected Translations .	target-side , class-based agreement model ; bitext or phrase table annotations ; weakly inflected source language ; richer grammatical features ; fine-grained morpho-syntactic classes ; morpho-syntactic agreement errors ; translation hypothesis ; english-to-arabic translation ; phrase-based decoders ; decoding ; feature ; english ; agreement	<method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <task> <otherscientificterm> <material> <method>	4 0 9 ; 9 0 6 ; 11 6 2	when automatically translating from a <material_2> like <material_11> to a target language with <otherscientificterm_3> such as gender and dual number , the output commonly contains <otherscientificterm_5> . to address this issue , we present a <method_0> . <method_12> is promoted by scoring a sequence of <otherscientificterm_4> that are predicted during <task_9> for each <otherscientificterm_6> . for <task_7> , our <method_0> yields a +1.04 bleu average improvement over a state-of-the-art baseline . the <method_0> does not require <otherscientificterm_1> and can be easily implemented as a <otherscientificterm_10> in many <method_8> .	2 11 3 5 16 13 -1 0 12 13 -1 4 9 6 14 15 13 -1 7 13 -1 1 10 8 13 -1
Articulated and Restricted Motion Subspaces and Their Signatures .	extraction of the corresponding motion parameters ; articulated or otherwise restricted motion ; allowable translation directions ; static 3d reconstruction ; real data sets ; dynamic semantics ; algebraic constraints ; rotating blackboard ; low-rank constraints ; fixed axes ; articulated objects ; motion-restricted parts ; motion parameters ; matrix manipulations ; rigid parts ; linear algebra ; relative transformations ; linear subspaces ; restricted motion ; rotation axes ; automatic detection ; signature	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	19 6 5 ; 5 2 3 ; 20 0 3 ; 1 0 20 ; 7 6 4 ; 13 2 12 ; 8 6 6 ; 21 0 16 ; 2 6 5 ; 19 1 2	articulated objects represent an important class of objects in our everyday environment . <task_20> of the type of <otherscientificterm_1> and <otherscientificterm_0> are therefore of high value , e.g. in order to augment an otherwise <task_3> with <otherscientificterm_5> , such as <otherscientificterm_19> and <otherscientificterm_2> for certain <otherscientificterm_14> or objects . hence , in this paper , a novel theory to analyse <otherscientificterm_16> between two <otherscientificterm_11> will be presented . the analysis is based on <otherscientificterm_17> spanned by <otherscientificterm_16> . moreover , a <otherscientificterm_21> for <otherscientificterm_16> will be introduced which uniquely specifies the type of <otherscientificterm_18> encoded in these <otherscientificterm_16> . this theoretic framework enables the derivation of novel <otherscientificterm_6> , such as <otherscientificterm_8> for subsequent rotations around two <otherscientificterm_9> for example . lastly , given the type of <otherscientificterm_18> as predicted by the <otherscientificterm_21> , the paper shows how to extract all the <otherscientificterm_12> with <otherscientificterm_13> from <otherscientificterm_15> . our theory is verified on several <material_4> , such as a <otherscientificterm_7> or a wheel rolling on the floor amongst others .	20 22 -1 1 0 3 5 19 2 14 23 24 25 26 31 32 22 -1 16 11 22 -1 17 22 -1 21 18 30 22 -1 29 22 -1 6 8 9 28 22 -1 12 13 15 27 22 -1
Comparing features for forming music streams in automatic music transcription .	formating temporal sequences of notes ; timbre of musical instruments ; pitch relation consistency ; music stream formation ; polyphonic music ; direction proximity ; pitch transition ; timbre similarity ; frequency components ; power-related features ; timber extraction ; features	<task> <otherscientificterm> <metric> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm>	5 1 6 ; 7 5 3 ; 11 1 5 ; 6 1 2 ; 11 1 7 ; 7 1 6 ; 9 0 10 ; 7 1 5	in <task_0> played by the same instrument -lrb- referred to as music streams -rrb- , <otherscientificterm_1> may be a predominant feature . in <material_4> , the performance of <task_10> based on <otherscientificterm_9> deteriorates , because such <otherscientificterm_11> are blurred when two or more <method_8> are superimposed in the same frequency . to cope with this problem , we integrated <otherscientificterm_7> and <otherscientificterm_5> with success , but left using other <otherscientificterm_11> as future work . in this paper , we investigate four <otherscientificterm_11> , <otherscientificterm_7> , <otherscientificterm_5> , <otherscientificterm_6> and <metric_2> to clarify the precedence among them in <task_3> . experimental results with quartet music show that <otherscientificterm_5> is the most dominant feature , and <otherscientificterm_6> is the secondary . in addition , the performance of <task_3> was improved from 63.3 % by only <otherscientificterm_7> to 84.9 % by integrating four <otherscientificterm_11> .	0 1 12 -1 4 10 9 11 8 19 12 -1 7 5 12 -1 6 2 3 13 15 16 17 18 20 12 -1 12 -1 14 12 -1
Set-Theoretic Alignment for Comparable Corpora .	jaccard similarity coefficient ; parallel sentences ; comparable corpora ; noisiest datasets ; stacc ; board	<otherscientificterm> <material> <material> <material> <method> <otherscientificterm>	3 5 4 ; 0 0 4	we describe and evaluate a simple method to extract <material_1> from <material_2> . the approach , termed <method_4> , is based on expanded lexical sets and the <otherscientificterm_0> . we evaluate our <method_4> against state-of-the-art methods on a large range of datasets in different domains , for ten language pairs , showing that <method_4> either matches or outper-forms current methods across the <otherscientificterm_5> and gives significantly better results on the <material_3> . <method_4> is a portable method , requiring no particular adaptation for new domains or language pairs , thus enabling the efficient mining of <material_1> in <material_2> .	1 2 6 -1 4 0 8 6 -1 5 3 7 6 -1 6 -1
Comparisons of sequence labeling algorithms and extensions .	hidden markov model ; conditional random fields ; averaged perceptron ; search and learning algorithm ; max margin markov networks ; structured learning models ; structured learning problems ; state-of-art models	<method> <method> <method> <method> <method> <method> <task> <method>	0 1 1 ; 0 1 2 ; 7 0 6	in this paper , we survey the current <method_7> for <task_6> , including <method_0> , <method_1> , <method_2> , structured svms -lrb- <i> svm <sup> struct </sup> -rrb- </i> , <method_4> -lrb- m <sup> 3 </sup> n -rrb- , and an integration of <method_3> -lrb- searn -rrb- . with all due tuning efforts of various parameters of each <method_7> , on the data sets we have applied the <method_7> to , we found that svm <i> <sup> struct </sup> </i> enjoys better performance compared with the others . in addition , we also propose a new method which we call the structured learning ensemble -lrb- sle -rrb- to combine these <method_5> . empirical results show that our sle algorithm provides more accurate solutions compared with the best results of the individual <method_7> .	7 6 0 1 2 4 3 9 10 11 8 -1 8 -1 8 -1 5 8 -1
Dramatis : A Computational Model of Suspense .	computational model of suspense ; dramatis components ; suspense phenomenon ; suspense level ; suspense ratings ; dramatis	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	5 6 0	we introduce <method_5> , a <method_0> based on a reformulation of a psychological definition of the <otherscientificterm_2> . in this reformulation , suspense is correlated with the audience 's ability to generate a plan for the protagonist to avoid an impending negative outcome . <method_5> measures the <otherscientificterm_3> by generating such a plan and determining its perceived likelihood of success . we report on three evaluations of <method_5> , including a comparison of <method_5> output to the suspense reported by human readers , as well as ablative tests of <method_1> . in these studies , we found that <method_5> output corresponded to the <otherscientificterm_4> given by human readers for stories in three separate domains .	5 0 2 7 6 -1 6 -1 3 6 -1 1 6 -1 6 -1
Estimation , Optimization , and Parallelism when Data is Sparse .	large-scale learning tasks ; high-dimensional statistical learning ; stochastic optimization problems ; sample complexity ; sparse data ; minimax rate ; learning ; sparsity ; optimization ; parallelism	<task> <task> <task> <metric> <material> <metric> <task> <method> <task> <otherscientificterm>	5 5 8 ; 8 1 6	we study <task_2> when the data is sparse , which is in a sense dual to current perspectives on <task_1> and <task_8> . we highlight both the difficulties -- in terms of increased <metric_3> that <material_4> necessitates -- and the potential benefits , in terms of allowing <otherscientificterm_9> and asynchrony in the design of algorithms . concretely , we derive matching upper and lower bounds on the <metric_5> for <task_8> and <task_6> with <material_4> , and we exhibit algorithms achieving these rates . we also show how leveraging <method_7> leads to -lrb- still minimax optimal -rrb- parallel and asynchronous algorithms , providing experimental evidence complementing our theoretical results on several medium to <task_0> .	2 1 8 10 -1 3 4 9 10 -1 5 6 11 12 10 -1 7 10 -1
Flexible Modeling of Latent Task Structures in Multitask Learning .	flexible , nonparametric bayesian model ; low-rank or linear/non-linear subspace assumption ; regression and classification problems ; priori known latent structure ; synthetic and real-world datasets ; vari-ational inference algorithm ; latent task structures ; multitask learning problem ; factor analyzers structure ; latent task structure ; multitask learning algorithms ; data-driven manner ; nonparametric aspect ; mean-regularized tasks ; clustered tasks	<method> <otherscientificterm> <task> <otherscientificterm> <material> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm>	13 1 14 ; 9 0 7 ; 2 5 5 ; 5 0 0 ; 4 5 5 ; 12 0 0	multitask learning algorithms are typically designed assuming some fixed , a <otherscientificterm_3> shared by all the tasks . however , <method_0> is usually unclear what type of <otherscientificterm_9> is the most appropriate for a given <task_7> . ideally , the '' right '' <otherscientificterm_9> should be learned in a <method_11> . we present a <method_0> that posits a mixture of <otherscientificterm_8> on the tasks . the <method_12> makes the <method_0> expressive enough to subsume many existing <method_0> of <otherscientificterm_6> -lrb- e.g , <otherscientificterm_13> , <otherscientificterm_14> , <otherscientificterm_1> on tasks , etc. -rrb- . moreover , <method_0> can also learn more general task structures , addressing the shortcomings of such <method_0> . we present a <method_5> for our <method_0> . experimental results on <material_4> , on both <task_2> , demonstrate the effectiveness of the proposed <method_5> .	3 15 -1 0 9 7 17 15 -1 11 15 -1 8 15 -1 12 6 13 14 1 16 21 15 -1 15 -1 19 15 -1 5 18 20 15 -1
State based sub-band Wiener filters for speech enhancement in car environments .	bmw and volvo car noise databases ; temporal-spectral composition of speech ; timit continuous speech database ; estimation of parameters ; subband wiener filters ; wiener filter structure ; parallel model combination ; correlation values ; speech processes ; power spectra ; bayesian method ; wiener filters ; parameter estimates ; noisy speech ; model decomposition ; noise ; accuracy ; quality	<material> <material> <material> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <task> <otherscientificterm> <metric> <metric>	4 0 1 ; 2 0 6 ; 3 0 4 ; 14 0 3 ; 4 0 12 ; 0 2 2	the performance of <method_11> in restoring the <metric_17> and intelligibility of <material_13> depends on : -lrb- i -rrb- the <metric_16> of the estimates of the <otherscientificterm_9> or the <metric_7> of the <otherscientificterm_15> and the <otherscientificterm_8> , and -lrb- ii -rrb- on the <otherscientificterm_5> . in this paper a <method_10> is proposed where model combination and <task_14> are employed for the <otherscientificterm_3> required to implement <method_4> . the use of <method_4> provides advantages in terms of improved <method_12> and also in restoring the <material_1> . the <method_10> is evaluated , and compared with the <method_6> , using the <material_2> with <material_0> .	11 17 13 16 9 7 15 8 5 18 -1 10 14 3 4 21 22 18 -1 12 1 19 23 18 -1 6 2 0 20 24 18 -1
Effect of prosodic changes on speech intelligibility .	prosody-related intelligibility gain ; word identification rate ; explicit instruction ; speech modifications ; durational modifications ; acous-tic/prosodic parameters ; energetic masking ; relative intelligibility ; plain speech ; energetic masking ; environmental noise ; speech styles ; prosodic changes ; unfilled pauses ; durational increases ; intelligibility ; elongations	<otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 1 2 ; 8 4 4 ; 3 1 15	talkers adopt different <otherscientificterm_11> in response to factors such as the perceived needs of the interlocutor , <otherscientificterm_10> and <otherscientificterm_2> . some styles have been shown to be beneficial for listeners but many aspects of the relationship between <otherscientificterm_3> and <otherscientificterm_15> remain unclear , particularly for <otherscientificterm_12> . the current study measures the <otherscientificterm_7> in noise of speech spoken in 5 <otherscientificterm_11> -- plain , infant - , computer-and foreigner-directed , and shouted -- and relates listener scores to <otherscientificterm_5> and quantitative estimates of <task_6> . intelligibility changes over <material_8> correlated well with <method_4> , which included <otherscientificterm_16> of all segments as well as increases in the number of <otherscientificterm_13> . both mean fundamental frequency and its range displayed great variation across styles but with no clear <otherscientificterm_15> benefits . <task_9> per unit time was similar in each style but the total amount of speech which escaped masking was a good predictor of <metric_1> . these findings suggest that much of the <otherscientificterm_0> is derived from <otherscientificterm_14> .	11 10 2 18 17 -1 3 15 12 20 17 -1 7 5 6 17 -1 8 4 16 19 17 -1 13 17 -1 9 17 -1 1 17 -1
Wide-angle micro sensors for vision on a tight budget .	power and mass constraints ; computer vision tasks ; template-based optical convolution ; miniature vision sensors ; computer vision ; micro-scale devices ; analytic tools ; optical design ; detecting faces ; tracking targets ; milli-scale prototypes ; power requirements ; design space ; convolution ; edges ; volume	<otherscientificterm> <task> <otherscientificterm> <method> <task> <task> <method> <method> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 1 ; 15 1 3 ; 8 6 1 ; 5 0 4 ; 9 1 8 ; 3 0 11 ; 2 0 3 ; 6 0 12 ; 9 6 1	achieving <task_4> on <task_5> is a challenge . on these <task_4> , the <otherscientificterm_0> are severe enough for even the most common computations -lrb- matrix manipulations , <otherscientificterm_13> , etc. -rrb- to be difficult . this paper proposes and analyzes a class of <method_3> that can help overcome these constraints . these <method_3> reduce <otherscientificterm_11> through <otherscientificterm_2> , and <method_3> enable a wide field-of-view within a small form through a novel <method_7> . we describe the trade-offs between the field of view , <otherscientificterm_15> , and mass of these <method_3> and we provide <method_6> to navigate the <otherscientificterm_12> . we also demonstrate <method_10> for <task_1> such as locating <otherscientificterm_14> , <task_9> , and <task_8> .	4 5 20 16 -1 0 13 16 -1 3 16 -1 11 2 7 22 23 16 -1 15 6 12 18 24 16 -1 17 19 21 25 16 -1
Duality and Geometry in SVM Classifiers .	support vector machine ; linearly separable and inseparable data ; reduced convex hull formulation ; 2-norm and 1-norm svm ; inseparable svm ; point algorithms ; maximum margin ; convex hulls ; classification	<method> <material> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task>	2 0 4 ; 0 0 8	we develop an intuitive geometric interpretation of the standard <method_0> for <task_8> of both <material_1> and provide a rigorous derivation of the concepts behind the geometry . for the separable case finding the <otherscientificterm_6> between the two sets is equivalent to finding the closest points in the smallest convex sets that contain each class -lrb- the <otherscientificterm_7> -rrb- . we now extend this argument to the inseparable case by using a <otherscientificterm_2> reduced away from out-liers . we prove that solving the <otherscientificterm_2> is exactly equivalent to solving the standard <method_4> for appropriate choices of parameters . some additional advantages of the new formulation are that the effect of the choice of parameters becomes geometrically clear and that the formulation may be solved by fast nearest <method_5> . by changing norms these arguments hold for both the standard <method_3> .	0 8 1 11 9 -1 6 7 9 -1 2 9 -1 4 10 9 -1 9 -1 5 9 -1
Rapidly building domain-specific entity-centric language models using semantic web knowledge sources .	domain-specific speech recognition tasks ; statistical language model component ; language modeling techniques ; speech recognition engines ; query click logs ; statistical language models ; web language model ; semantic web sources ; recognition system ; language model ; knowledge graphs ; movies domain ; n-gram models ; text data ; domain-specific knowledge ; voice queries ; crowd sourcing ; natural language ; first-pass decoding	<task> <method> <method> <method> <otherscientificterm> <method> <method> <material> <method> <method> <otherscientificterm> <material> <method> <material> <otherscientificterm> <material> <method> <material> <method>	13 0 1 ; 4 1 10 ; 10 6 14 ; 4 6 14 ; 10 6 7 ; 5 0 0 ; 1 0 0 ; 12 6 18 ; 3 0 18 ; 12 6 3 ; 14 0 7	for <task_0> , it is best if the <method_1> is trained with <material_13> that is content-wise and style-wise similar to the targeted domain for which the application is built . for state-of-the-art <method_2> that can be used in real-time within <method_3> during <method_18> -lrb- e.g. , <method_12> -rrb- , the above constraints have to be fulfilled in the training data . however collecting such data , even through <method_16> , is expensive and time consuming , and can still be not representative of how a much larger user population would interact with the <method_8> . in this paper , we address this problem by employing several <material_7> that already contain the <otherscientificterm_14> , such as <otherscientificterm_4> and <otherscientificterm_10> . we build <method_5> that meet the requirements listed above for <task_0> where <material_17> is used and the user queries are about name entities in a specific domain . as a case study , in the <material_11> where users ' <material_15> are movie related , compared to a generic <method_6> , a <method_9> trained with the above resources not only yields significant perplexity and word-error-rate improvements , but also presents an approach where such <method_9> can be rapidly developed for other domains .	0 1 13 20 26 19 -1 2 3 18 12 27 28 29 19 -1 16 8 19 -1 21 22 23 24 30 19 -1 7 14 4 10 25 19 -1 5 17 19 -1
A Consensus-Based Framework for Distributed Bundle Adjustment .	consensus based optimization methods ; bundle adjustment formulation ; bundle adjustment problem ; large-scale optimization problems ; real image datasets ; multi-view geometry ; structure-from-motion pipeline ; proximal splitting ; problem size ; concise derivation ; bundle adjustment ; complexity	<method> <method> <task> <task> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <metric>	5 2 3 ; 7 0 9	in this paper we study <task_3> in <task_5> , in particular the <task_2> . in its conventional formulation , the <metric_11> of existing solvers scale poorly with <otherscientificterm_8> , hence this component of the <method_6> can quickly become a bottleneck . here we present a novel formulation for solving <task_10> in a truly distributed manner using <method_0> . our algorithm is presented with a <otherscientificterm_9> based on <otherscientificterm_7> , along with a theoretical proof of convergence and brief discussions on <metric_11> and implementation . experiments on a number of <material_4> convincingly demonstrates the potential of the proposed method by outperforming the conventional <method_1> by orders of magnitude .	3 5 2 13 12 -1 11 8 6 12 -1 10 0 12 -1 9 7 14 12 -1 4 12 -1
Context as Supervisory Signal : Discovering Objects with Predictable Context .	iterative region prediction and context alignment approach ; visually consistent object clusters ; leave-one-out context prediction task ; weakly-supervised object discovery approaches ; statistical hypothesis testing ; visual object cluster ; stuff appearance models ; un-supervised object discovery ; weakly-supervised approaches ; context prediction ; keypoint annotations ; unsupervised clustering ; supervisory signal ; object patch ; fine-grained correspondences ; segmentation mask	<method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <task> <method> <task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method>	12 0 1 ; 15 1 14 ; 8 0 7 ; 0 0 5 ; 4 0 9	this paper addresses the well-established problem of <task_7> with a novel method inspired by <method_8> . in particular , the ability of an <method_13> to predict the rest of the object -lrb- its context -rrb- is used as <otherscientificterm_12> to help discover <otherscientificterm_1> . the main contributions of this work are : 1 -rrb- framing <method_11> as a <task_2> ; 2 -rrb- evaluating the quality of <task_9> by <method_4> between thing and <method_6> ; and 3 -rrb- an <method_0> that gradually discovers a <otherscientificterm_5> together with a <method_15> and <otherscientificterm_14> . the proposed method outperforms previous unsupervised as well as <method_3> , and is shown to provide correspondences detailed enough to transfer <task_10> .	7 8 19 16 -1 13 12 1 17 16 -1 11 2 9 4 6 0 5 15 14 18 20 21 16 -1 16 -1
Lattice decoding and rescoring with long-Span neural network language models .	long-span neural network language models ; babel assamese keyword search ; lattice-based speech recognition techniques ; word error rate improvements ; refined pruning techniques ; full lattice rescoring ; lattice decoding ; search effort ; speech recognition ; search space ; lstms ; lattices	<method> <task> <method> <metric> <method> <task> <task> <metric> <task> <otherscientificterm> <method> <otherscientificterm>	10 0 1 ; 4 0 7	with <method_0> , considerable improvements have been obtained in <task_8> . however , it is difficult to apply these models if the underlying <otherscientificterm_9> is large . in this paper , we combine previous work on <task_6> with long short-term memory -lrb- lstm -rrb- neural network language models . by adding <method_4> , we are able to reduce the <metric_7> by a factor of three . furthermore , we introduce two novel approximations for <task_5> , which opens the potential of <method_2> . compared to 1000-best lists , we find that we can increase the <metric_3> obtained with <method_10> from 8.2 % to 10.7 % relative over a state-of-the-art baseline , while the resulting <otherscientificterm_11> are even considerably smaller . in addition , we investigate the use of <method_10> for <task_1> , obtaining significant improvements of 2.5 % relative .	0 8 12 -1 9 12 -1 6 12 -1 4 7 14 12 -1 5 2 12 -1 3 10 12 -1 11 13 12 -1
Learning to Classify Observed Motor Behavior .	abstract movement concepts ; unsupervised learning system ; temporal structure ; representational format ; oxbow	<otherscientificterm> <method> <otherscientificterm> <method> <method>	1 0 0 ; 4 6 1	we present a <method_3> for observed movements the representation has a <otherscientificterm_2> relating components of a single complex movement . we also present <method_4> , an <method_1> , which constructs classes of these movements . empirical results indicate that the <method_1> builds <otherscientificterm_0> with appropriate component structure allowing <method_1> to predict the latter portions of a partially observed movement .	3 2 5 -1 4 1 7 5 -1 0 6 5 -1
Backdoors into Heterogeneous Classes of SAT and CSP .	detecting strong and weak backdoor sets ; heterogeneous base classes ; heterogeneous base class ; backdoor sets ; complexity landscape ; backdoor variables ; csp	<task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material>	3 0 1 ; 4 0 0	in this paper we extend the classical notion of strong and weak backdoor sets by allowing that different instantiations of the <otherscientificterm_5> result in instances that belong to different base classes ; the union of the base classes forms a <otherscientificterm_2> . <material_3> to <otherscientificterm_1> can be much smaller than backdoor sets to homogeneous ones , hence they are much more desirable but possibly harder to find . we draw a detailed <otherscientificterm_4> for the problem of <task_0> into <otherscientificterm_1> for sat and <material_6> .	5 2 3 7 -1 1 8 7 -1 4 0 6 9 7 -1
Recovery of Reflectances and Varying Illuminants from Multiple Views .	geometry of the scene ; linear and non-linear implementations ; geometric reconstruction techniques ; photometric stereo approaches ; surface albedoes ; real images ; unknown illuminants ; lambertian case ; radiometric reconstruction ; images	<otherscientificterm> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <material> <task> <material>	9 0 8	we introduce a new methodology for <task_8> from multiple <material_9> . it opens new possibilities because it allows simultaneous recovery of varying <otherscientificterm_6> -lrb- one per image -rrb- , <otherscientificterm_4> , and cameras ' radiometric responses . designed to complement <method_2> , it only requires as input the <otherscientificterm_0> and of the cameras . unlike <method_3> , it is not restricted to <material_9> taken from a single viewpoint . <method_1> in the <material_7> are proposed ; simulation results are discussed and compared to related work to demonstrate the gain in stability ; and results on <material_5> are shown .	8 9 11 10 -1 6 4 10 -1 2 0 10 -1 3 1 10 -1 7 5 10 -1
Room impulse response shortening with infinity-norm optimization .	room impulse response shortening ; equiripple filter design method ; shortened global impulse response ; unwanted temporal range ; d50 measure ; shortening filter ; shortening filters ; design errors	<method> <method> <otherscientificterm> <otherscientificterm> <metric> <method> <method> <otherscientificterm>	4 0 5	the purpose of <method_0> is to improve the intelligibility of the received signal by pre-filtering the source signal before it is played with a loudspeaker in a closed room . in this paper , we propose to use the infinity-norm as optimization criterion for the design of <method_6> of <method_0> . similar to the <method_1> , <otherscientificterm_7> will be uniformly distributed over the <otherscientificterm_3> of the <otherscientificterm_2> . the <metric_4> is exploited during the design of the <method_5> , which makes it possible to significantly reduce the length of the prefilter without affecting the perceived performance .	0 8 -1 6 8 -1 1 7 3 2 8 -1 4 5 9 8 -1
Using Unlabeled Data for Supervised Learning .	asymptotic accuracy level ; supervised training framework ; unlabeled examples ; distribution information ; classification problems ; class label ; supervised learner ; accuracy	<metric> <method> <material> <otherscientificterm> <task> <otherscientificterm> <method> <metric>	7 5 6 ; 2 0 3	many <task_4> have the property that the only costly part of obtaining examples is the <otherscientificterm_5> . this paper suggests a simple method for using <otherscientificterm_3> contained in <material_2> to augment labeled examples in a <method_1> . empirical tests show that the technique described in this paper can significantly improve the <metric_7> of a <method_6> when the learner is well below its <metric_0> .	4 5 8 -1 3 2 1 10 8 -1 7 6 0 9 8 -1
Discriminative Gaussian Mixture Models : A Comparison with Kernel Classifiers .	relevance vector machines ; support vector machines ; gaussian mixture models ; discrimi-native gmm classifier ; genera-tive gmm classifiers ; training procedure ; baum-welch algorithm ; kernel classifiers ; speech recognition ; classifier ; sparsity ; accuracy	<method> <method> <method> <method> <method> <method> <method> <method> <task> <method> <metric> <metric>	11 5 3 ; 10 2 3 ; 2 0 9 ; 4 1 3 ; 0 6 7 ; 11 5 9 ; 6 0 5 ; 6 0 8 ; 4 1 7 ; 10 5 4 ; 1 6 7 ; 1 1 0 ; 11 5 4 ; 8 0 5	we show that a <method_9> based on <method_2> can be trained dis-criminatively to improve <metric_11> . we describe a <method_5> based on the extended <method_6> used in <task_8> . we also compare the <metric_11> and degree of <metric_10> of the new <method_3> with those of <method_4> , and of <method_7> , such as <method_1> and <method_0> .	9 2 11 15 18 12 -1 5 6 8 19 20 26 12 -1 10 3 4 7 1 0 13 14 16 17 21 22 23 24 25 12 -1
Deep neural network context embeddings for model selection in rich-context HMM synthesis .	statistical parametric speech synthesis ; rich context approach ; rich-context hmm-based synthesiser ; decision tree-tied models ; deep neural network ; linguistic contexts ; neural network ; tied model ; parametric synthesis ; context embeddings ; rich-context synthesis ; bottleneck layer ; gaussian distributions ; synthesis	<task> <method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task>	11 0 9 ; 9 0 8 ; 11 0 8 ; 6 0 9 ; 4 0 8	this paper introduces a novel form of <method_8> that uses <otherscientificterm_9> produced by the <otherscientificterm_11> of a <method_4> to guide the selection of models in a <method_2> . <task_10> -- in which <otherscientificterm_12> estimated from single <otherscientificterm_5> seen in the training data are used for <task_13> , rather than more conventional <method_3> -- was originally proposed to address over-smoothing due to averaging across contexts . our previous investigations have confirmed experimentally that averaging across different contexts is indeed one of the largest factors contributing to the limited quality of <task_0> . however , a possible weakness of the <method_1> as previously formulated is that a conventional <method_7> is still used to guide selection of gaussians at <task_13> time . our proposed <method_7> replaces <method_8> with <otherscientificterm_9> derived from a <method_6> .	8 9 11 4 2 10 15 16 17 19 14 -1 12 5 13 3 14 -1 0 14 -1 1 14 -1 7 18 14 -1
U-invariant sampling and stable reconstruction in atomic spaces .	arbitrary hilbert space h ; u-invariant sampling scheme ; atomic subspaces ; linear filter ; signal recovery	<otherscientificterm> <method> <otherscientificterm> <method> <task>	3 0 4 ; 0 0 1	given a <method_1> on an <otherscientificterm_0> . this paper characterizes <otherscientificterm_2> a of h such that every signal x ‚àà a can be reconstructed from its samples acquired with this <method_1> . if <task_4> is possible a <method_3> is derived which reconstructs the signal from the samples .	1 0 7 5 -1 2 5 -1 4 3 6 5 -1
Analyzing Positions and Topics in Political Discussions of the German Bundestag .	transcriptions of political speeches ; supervised and unsupervised approaches ; topic modeling techniques ; textual data ; party manifestos	<material> <method> <method> <material> <material>	0 6 3	we present ongoing doctoral work on automatically understanding the positions of politicians with respect to those of the party they belong to . to this end , we use <material_3> , namely <material_0> from meetings of the ger-man bundestag , and <material_4> , in order to automatically acquire the positions of political actors and parties , respectively . we discuss a variety of possible <method_1> to determine the topics of interest and compare positions , and propose to explore an approach based on <method_2> for these tasks .	5 -1 3 0 4 6 5 -1 1 2 5 -1
Combining Statistical and Knowledge-Based Spoken Language Understanding in Conditional Models .	conditional random fields ; spoken language understanding ; generative hmm/cfg composite model ; data-driven statistical learning framework ; extracting semantic meaning ; natural language processing ; easy-to-obtain domain knowledge ; conditional model framework ; slot error rate ; statistical learning approach ; data requirement ; new domain ; slu accuracy ; language engineering ; annotated data ; speech recognition ; statistical learning ; atis data ; model training ; knowledge-based approach ; perceptron learning ; hmm/cfg model	<method> <method> <method> <method> <task> <task> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <material> <metric> <task> <material> <task> <method> <material> <task> <method> <method> <method>	14 0 9 ; 9 0 18 ; 6 3 3 ; 15 1 13 ; 20 1 0 ; 12 5 21 ; 13 0 11 ; 17 5 21 ; 14 0 18 ; 1 0 4 ; 8 5 7 ; 20 0 1 ; 5 1 15 ; 12 5 7	spoken language understanding -lrb- <method_1> -rrb- addresses the problem of <task_4> conveyed in an utterance . the traditional <method_19> to this problem is very expensive-it requires joint expertise in <task_5> and <task_15> , and best practices in <task_13> for every <material_11> . on the other hand , a <method_9> needs a large amount of <material_14> for <task_18> , which is seldom available in practical applications outside of large research labs . a <method_2> , which integrates <otherscientificterm_6> into a <method_3> , has previously been introduced to reduce <otherscientificterm_10> . the major contribution of this paper is the investigation of integrating prior knowledge and <method_16> in a <method_7> . we also study and compare <method_0> with <method_20> for <method_1> . experimental results show that the <method_7> achieve more than 20 % relative reduction in <metric_8> over the <method_21> , which had already achieved an <metric_12> at the same level as the best results reported on the <material_17> .	1 4 32 22 -1 19 5 15 13 11 26 29 35 22 -1 9 14 18 23 24 31 22 -1 2 6 3 10 25 22 -1 22 -1 16 7 27 34 22 -1 0 20 28 30 33 36 22 -1
From compressive to adaptive sampling of neural and ECG recordings .	brain machine interfaces ; compressive sensing framework ; integrate-and-fire ; shift invariant basis ; neural spike trains ; ambulatory cardiac monitoring ; local time structure ; adaptive sampling scheme ; neu-ral recordings ; data rates ; digital representations ; local characteristics ; global constraints ; miniaturization	<method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <material> <metric> <method> <otherscientificterm> <otherscientificterm> <task>	2 0 0 ; 7 0 5 ; 0 1 5 ; 7 0 0	the <task_13> required for interfacing with the brain demands new methods of transforming neuron responses -lrb- spikes -rrb- into <method_10> . the sparse nature of <material_8> is evident when represented in a <otherscientificterm_3> . although a <method_1> may seem suitable in reducing the <metric_9> , we show that the time varying sparsity in the signals makes <method_7> difficult to apply . furthermore , we present an <method_7> which takes advantage of the <otherscientificterm_11> of the <method_4> and electrocardiograms -lrb- ecg -rrb- . in contrast to the <otherscientificterm_12> imposed in cs our <method_7> is sensitive to the <otherscientificterm_6> of the input . the simplicity in the design of the <method_2> make <method_7> a viable <method_7> in current <method_0> and <task_5> .	13 10 14 -1 8 3 14 -1 1 9 7 14 -1 11 4 14 -1 12 6 14 -1 15 16 17 18 14 -1
Multi-Agent Dynamic Coupling for Cooperative Vehicles Modeling .	cooperative intelligent transportation systems ; multi-model open-source vehicular-traffic simulator ; real traffic data ; multi-agent based modeling ; multi-agent mod-eling	<method> <method> <material> <method> <task>	0 0 4 ; 3 0 0 ; 2 0 3	cooperative intelligent transportation systems -lrb- <method_0> -rrb- are complex systems well-suited to a <task_4> . we propose a <method_3> of a <method_0> , that couples 3 dynamics -lrb- physical , informational and control dynamics -rrb- in order to ensure a smooth cooperation between non cooperative and cooperative vehicles , that communicate with each other -lrb- v2v communication -rrb- and the infrastructure -lrb- i2v and v2i communication -rrb- . we present our <method_3> , tested through simulations using <material_2> and integrated into our extension of the <method_1> .	0 4 6 5 -1 3 7 5 -1 2 1 8 5 -1
An Algorithm for Generating Referential Descriptions with Flexible Interfaces .	perceptive and linguistics data ; object descriptors ; linguistic constraints ; lexical expression ; referring expression ; processing components ; core algorithm	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	1 1 3	most algorithms dedicated to the generation of referential descriptions widely suffer from a fundamental problem : they make too strong assumptions about adjacent <method_5> , resulting in a limited coordination with their <material_0> , that is , the provider for <otherscientificterm_1> and the <otherscientificterm_3> by which the chosen descriptors is ultimately realized . motivated by this deficit , we present a new algorithm that -lrb- 1 -rrb- allows for a widely unconstrained , incremental , and goal-driven selection of descriptors , -lrb- 2 -rrb- integrates <otherscientificterm_2> to ensure the expressibility of the chosen descriptors , and -lrb- 3 -rrb- provides means to control the appearance of the created <otherscientificterm_4> . hence , the main achievement of our approach lies in providing a <method_6> that makes few assumptions about other <method_5> and improves the flow of control between modules .	5 0 1 3 8 7 -1 2 7 -1 4 7 -1
Blitz : A Principled Meta-Algorithm for Scaling Sparse Optimization .	stopping criteria ; set methods ; algorithmic parameters ; subproblem size ; 1-regularized learning ; blitz ; iterations ; heuristics ; makeup ; sparsity ; optimization	<metric> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	8 1 0 ; 3 1 8 ; 7 0 8	by reducing <task_10> to a sequence of small subproblems , working <method_1> achieve fast convergence times for many challenging problems . despite excellent performance , theoretical understanding of working sets is limited , and implementations often resort to <method_7> to determine <otherscientificterm_3> , <otherscientificterm_8> , and <metric_0> . we propose <method_5> , a fast working set algorithm accompanied by useful guarantees . making no assumptions on data , our theory relates <otherscientificterm_3> to progress toward convergence . this result motivates methods for optimizing <otherscientificterm_2> and discarding irrelevant variables as <otherscientificterm_6> progress . applied to <task_4> , <method_5> convincingly outperforms existing solvers in sequential , limited-memory , and distributed settings . <method_5> is not specific to <task_4> , making the algorithm relevant to many applications involving <otherscientificterm_9> or constraints .	10 1 11 -1 7 3 8 0 12 13 14 11 -1 5 11 -1 11 -1 2 6 11 -1 4 11 -1 11 -1
You are Here : Mimicking the Human Thinking Process in Reading Floor-Plans .	floor-plan-based localization methods ; human thinking process ; matching-localization algorithm ; human logic ; real-time applications ; floor-plan	<method> <task> <method> <otherscientificterm> <task> <otherscientificterm>	3 0 2	a human can easily find his or her way in an unfamiliar building , by walking around and reading the <otherscientificterm_5> . we try to mimic and automate this <task_1> . more precisely , we introduce a new and useful task of locating an user in the <otherscientificterm_5> , by using only a camera and a <otherscientificterm_5> without any other prior information . we address the problem with a novel <method_2> that is inspired by <otherscientificterm_3> . we demonstrate through experiments that our method outperforms state-of-the-art <method_0> by a large margin , while also being highly efficient for <task_4> .	5 6 -1 1 6 -1 6 -1 2 3 7 6 -1 0 4 6 -1
CL Research 's Knowledge Management System .	knowledge management system ; general and topic-based summarization ; web question answering ; document exploration functionality ; dynamic ontology creation ; information extraction ; document exploration ; user modeling ; text summarization	<method> <task> <task> <task> <method> <task> <task> <method> <task>	0 0 2 ; 2 1 1 ; 1 1 5 ; 5 1 6	cl research began experimenting with massive xml tagging of texts to answer questions in trec 2002 . in duc 2003 , the experiments were extended into <task_8> . based on these experiments , the <method_0> was developed to combine these two capabilities and to serve as a unified basis for other types of <task_6> . <method_0> has been extended to include <task_2> , both <task_1> , <task_5> , and <task_6> . the <task_3> includes identification of semantically similar concepts and <method_4> . as development of <method_0> has continued , <method_7> has become a key research issue : how will different users want to use the information they identify .	9 -1 8 9 -1 0 6 9 -1 2 1 5 10 11 12 13 9 -1 3 4 9 -1 7 9 -1
A predictive model of music preference using pairwise comparisons .	degree music preference ; collaborative filtering methods ; gaussian process priors ; personalized viewpoint ; music recommendation ; recommendation setting ; streaming services ; covariance function ; multi-media systems ; random predictions ; leave-one-out accuracy ; pairwise comparisons ; inference	<otherscientificterm> <method> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <task>	10 5 5 ; 1 0 4 ; 4 6 8 ; 6 1 8	music recommendation is an important aspect of many <method_6> and <method_8> , however , <task_4> is typically based on so-called <method_1> . in this paper we consider the recommendation task from a <otherscientificterm_3> and examine to which <otherscientificterm_0> can be elicited and predicted using simple and robust queries such as <method_11> . we propose to model-and in turn predict-the pairwise music preference using a very flexible model based on <method_2> for which we describe the required <task_12> . we further propose a specific <otherscientificterm_7> and evaluate the pre-dictive performance on a novel dataset . in a <method_5> we obtain a <metric_10> of 76 % compared to 50 % with <otherscientificterm_9> , showing potential for further refinement and evaluation .	6 8 4 1 15 16 17 13 -1 3 0 11 13 -1 2 12 13 -1 7 13 -1 5 14 13 -1
Hierarchical-PEP model for real-world face recognition .	probabilistic elastic part model ; fine-grained structures of the face parts ; compact and invariant face representation ; image-based and video-based face verification ; uncon-strained face recognition problem ; face part representations layer-by-layer ; lfw and youtube faces ; real-world face recognition systems ; pose-invariant part-based face representations ; face part/face representations ; face part representations ; face recognition challenge ; deep hierarchical architecture ; visual tasks ; supervised information ; public benchmarks ; pose variation ; hierarchy ; accuracy ; dimensionality	<method> <otherscientificterm> <method> <task> <task> <method> <material> <method> <method> <method> <method> <task> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm>	14 0 9 ; 0 0 4 ; 14 0 0 ; 6 6 15 ; 5 0 2 ; 15 5 0 ; 0 0 8 ; 12 0 13 ; 11 6 15 ; 0 0 1	pose variation remains one of the major factors adversely affect the <metric_18> of <method_7> . inspired by the recently proposed <method_0> and the success of the <method_12> in a number of <task_13> , we propose the <method_0> to approach the <task_4> . we apply the <method_0> hierarchically to decompose a face image into face parts at different levels of details to build <method_8> . following the <otherscientificterm_17> from bottom-up , we stack the <method_10> at each layer , discriminatively reduce its <otherscientificterm_19> , and hence aggregate the <method_5> to build a <method_2> . the <method_0> exploits the <otherscientificterm_1> at different levels of details to address the pose variations . <method_0> is also guided by <otherscientificterm_14> in constructing the <method_9> . we empirically verify the <method_0> on two <material_15> -lrb- i.e. , the <material_6> -rrb- and a <task_11> -lrb- i.e. , the pasc grand challenge -rrb- for <task_3> . the state-of-the-art performance demonstrates the potential of our <method_0> .	18 7 20 -1 0 12 13 4 22 28 20 -1 8 27 20 -1 17 10 19 5 2 25 20 -1 1 30 20 -1 21 23 20 -1 14 9 24 26 29 20 -1 15 6 11 3 20 -1
Planning in the Presence of Cost Functions Controlled by an Adversary .	robot path planning problem ; zero-sum matrix game ; markov decision process ; linear programming formulation ; cost function ; cost vectors ; fast algorithms ; matrix games ; value iteration ; deterministic policies ; policy ; rows ; mdps	<task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 0 12 ; 1 0 0	we investigate methods for planning in a <method_2> where the <otherscientificterm_4> is chosen by an adversary after we fix our <otherscientificterm_10> . as a running example , we consider a <task_0> where costs are influenced by sensors that an adversary places in the environment . we formulate the <task_0> as a <otherscientificterm_1> where <otherscientificterm_11> correspond to <otherscientificterm_9> for the planning player and columns correspond to <otherscientificterm_5> the adversary can select . for a fixed cost vector , <method_6> -lrb- such as <method_8> -rrb- are available for solving <method_12> . we develop efficient algorithms for <task_7> where such best response oracles exist . we show that for our <task_0> these algorithms are at least an order of magnitude faster than direct solution of the <method_3> .	2 4 10 13 -1 0 13 -1 1 11 9 5 15 13 -1 6 8 12 14 13 -1 7 13 -1 13 -1
Generating Aspect-oriented Multi-Document Summarization with Event-aspect model .	automatic generation of aspect-oriented summaries ; event-aspect lda model ; integer linear programming ; random walk model ; sentence compression algorithm ; sentence selection ; parser tree ; dependency tree ; rouge metric ; lexrank algorithm ; sentence ranking ; cluster	<task> <method> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	7 0 4 ; 7 1 6 ; 6 0 4 ; 2 0 5	in this paper , we propose a novel approach to <task_0> from multiple documents . we first develop an <method_1> to <otherscientificterm_11> sentences into aspects . we then use extended <method_9> to rank the sentences in each <otherscientificterm_11> . we use <method_2> for <task_5> . key features of our method include automatic grouping of semantically related sentences and <otherscientificterm_10> based on extension of <method_3> . also , we implement a new <method_4> which use <otherscientificterm_7> instead of <otherscientificterm_6> . we compare our method with four baseline methods . quantitative evaluation based on <method_8> demonstrates the effectiveness and advantages of our method .	0 12 -1 1 11 12 -1 9 12 -1 2 5 16 12 -1 10 3 12 -1 4 7 6 13 14 15 12 -1 12 -1 8 12 -1
A Pot of Gold : Rainbows as a Calibration Cue .	semi-automatic and fully automatic methods ; estimate of camera location ; geometry of a rainbow ; calibrating outdoor imagery ; estimating camera calibration ; calibration cues ; capture time ; solar-refractive phenomena ; natural images ; calibration accuracy ; rainbow geometry ; rainbow appearance ; horizon line ; geometric properties ; rainbow images ; sun dogs ; rainbows ; parhelion ; rainbows	<method> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 11 ; 16 0 3 ; 17 6 7 ; 15 6 7	rainbows are a natural cue for <task_3> . while ephemeral , they provide unique <otherscientificterm_5> because they are centered exactly opposite the sun and have an outer radius of 42 degrees . in this work , we define the <otherscientificterm_2> and describe minimal sets of constraints that are sufficient for <task_4> . we present both <method_0> to calibrate a camera using an image of a rainbow . to demonstrate our <method_0> , we have collected a large database of <material_14> and use these to evaluate <metric_9> and to create an empirical <method_0> of <otherscientificterm_11> . we show how this <method_0> can be used to edit <otherscientificterm_11> in <material_8> and how <otherscientificterm_10> , in conjunction with a <otherscientificterm_12> and <otherscientificterm_6> , provides an <otherscientificterm_1> . while we focus on <otherscientificterm_18> , many of the <otherscientificterm_13> and algorithms we present also apply to other <otherscientificterm_7> , such as <otherscientificterm_17> , often called <otherscientificterm_15> , and the 22 degree solar halo .	3 21 19 -1 5 19 -1 2 4 19 -1 0 19 -1 14 9 11 19 -1 20 19 -1 8 10 12 6 1 22 23 19 -1
BUT 2014 Babel system : analysis of adaptation in NN based systems .	fundamental frequency estimates ; stacked bottleneck features ; hierarchy of neural networks ; full gmm-and dnn-based systems ; un-transcribed data ; bottleneck features ; nn structure ; com-pressive layers ; semi-supervised training ; babel languages ; lvcsr systems ; features	<method> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <task> <otherscientificterm>	4 1 8 ; 5 3 10 ; 7 3 2 ; 2 0 11	features based on a <method_2> with <otherscientificterm_7> -- <method_1> -- were recently shown to provide excellent performance in <task_10> . this paper summarizes several techniques investigated in our work towards babel 2014 evaluations : -lrb- 1 -rrb- using several versions of <method_0> , -lrb- 2 -rrb- <method_8> on <material_4> and mainly -lrb- 3 -rrb- adapting the <otherscientificterm_6> at different levels . they are tested on three 2014 <material_9> with <method_3> . separately and in combination , they are shown to out-perform the baselines and confirm the usefulness of <otherscientificterm_5> in current <task_10> .	2 7 1 10 15 16 12 -1 0 8 4 6 13 12 -1 9 3 12 -1 5 11 14 12 -1
Large tagset labeling using Feed Forward Neural Networks . Case study on Romanian Language .	highly inflectional languages ; lexicon morpho-syntactic descriptions ; neural network architecture ; tiered tagging methodology ; linguistic knowledge ; local optimizations ; data sparseness ; standard methods ; morpho-syntactic features ; tiered tagging ; part-of-speech tagging ; neural networks ; recoverable features	<material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm>	6 0 7 ; 11 1 5 ; 7 0 10	standard methods for <task_10> suffer from <otherscientificterm_6> when used on <material_0> -lrb- which require large lexical tagset inventories -rrb- . for this reason , a number of alternative methods have been proposed over the years . one of the most successful methods used for this task , fdoohg7lhuhg7djjlqj7xil , 1999 -rrb- , exploits a reduced set of tags derived by removing several <otherscientificterm_12> from the <otherscientificterm_1> . a second phase is aimed at recovering the full set of <otherscientificterm_8> . in this paper we present an alternative method to <method_9> , based on <method_5> with <method_11> and we show how , by properly encoding the input sequence in a general <method_2> , we achieve results similar to the <method_3> , significantly faster and without requiring extensive <otherscientificterm_4> as implied by the previously mentioned method .	10 6 0 14 16 13 -1 13 -1 12 1 13 -1 8 13 -1 9 5 11 15 13 -1
Introducing phonetically motivated information into ASR .	multi-band system speech recognition ; automatic speech recognition ; phonetically related phonemes ; numbers recognition task ; pho-netically motivated information ; phonetic expert ; dimensionality problem ; acoustic model ; discriminative information ; mlp ; fullband	<task> <task> <otherscientificterm> <task> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm>	4 0 1 ; 9 0 5 ; 10 1 0	in this paper we present an approach to introducing more <otherscientificterm_4> into <task_1> in the form of a phonetic ` expert ' . to avoid the curse of <task_6> , the expert information is introduced at the level of the <method_7> . two types of experts are used , each providing <otherscientificterm_8> regarding groups of <otherscientificterm_2> . the <method_5> is implemented using an <method_9> . experiments on a <task_3> show that , when using the expert in conjunction with both a <otherscientificterm_10> and a <task_0> performances are increased .	4 1 12 11 -1 6 7 11 -1 8 2 11 -1 5 9 13 11 -1 3 10 0 14 11 -1
A General Expression of the Fundamental Matrix for Both Perspective and Affine Cameras .	recovery of structure and motion ; aane epipolar geometry ; uncalibrated images ; lens distortion ; full perspective ; projective reconstruction ; aane projection ; projection model ; aane images ; linear algebra ; aane reconstruction ; epipolar geometry ; triangulation	<task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <method> <method> <material> <otherscientificterm> <task> <task> <method>	11 1 5 ; 4 1 6 ; 8 0 10 ; 4 6 3 ; 5 1 10	this paper addresses the <task_0> from two <material_2> of a scene under <otherscientificterm_4> or under <method_6> . <task_11> , <task_5> , and <task_10> are elaborated in a way such that everyone having knowledge of <otherscientificterm_9> can understand the discussion without diiculty . a general expression of the fundamental matrix is derived which is valid for any <method_7> without <otherscientificterm_3> -lrb- including <otherscientificterm_4> and aane camera -rrb- . a new technique for <task_10> from two <material_8> is developed , which consists in rst estimating the <otherscientificterm_1> and then performing a <method_12> for each point match with respect to an implicit common aane basis . this technique is very ef-cient .	0 2 4 6 11 15 13 -1 5 10 9 14 18 13 -1 7 3 17 13 -1 8 1 12 16 13 -1 13 -1
Retroflex and bunched English / r / with physical models of the human vocal tract .	retroflex and bunched / r / models ; acoustic analysis ; tongue position ; sliding blocks ; physical model ; narrow constriction ; lip rounding ; pronunciation	<method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	3 0 4	it is known that american english / r / can be produced as a retroflex or bunched / r / , but it can be challenging to teach students how to articulate both . we already developed a <method_4> for retroflex / r / and demonstrated that the <method_4> produces the / r / sound . however , almost no studies have reported a <method_4> for bunched / r / . we developed a new <method_4> using <otherscientificterm_3> for the lips and tongue to help teach students how to produce bunched / r / . we recorded several sets of sounds produced by the <method_4> , analyzed the output signals , and used <method_4> for perceptual experiments . <task_1> and perceptual experiments confirmed that the <method_0> produced clear american / r / sounds , and that the <otherscientificterm_5> placed between 5-7 cm from the lips seems to be the key in producing these sounds . furthermore , bunched / r / with <otherscientificterm_6> produced the most clear / r / sound . both <method_4> are helpful for practicing <task_7> because learners can readily see there are two ways to produce / r / , they can see and alter the <otherscientificterm_2> manually , and they can hear the output sounds .	8 -1 4 8 -1 8 -1 3 9 8 -1 8 -1 1 8 -1 0 5 8 -1 6 8 -1
Blind predictive decision-feedback equalization via the constant modulus algorithm .	equalization of the coded modulation signals ; mean square algorithm ; nonblind linear mmse equalizer ; small residue intersymbol interference ; cm linear equalizer ; noise predictive structure ; cm cost function ; xed forward lter ; convergence rate ; forward lter ; feedback lter ; cm cost ; nonblind design ; closed form ; pcm-dfe ; dfe	<task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <method> <metric> <method> <otherscientificterm> <method> <method>	3 2 7 ; 8 5 10 ; 5 0 0 ; 4 0 14 ; 15 0 0 ; 6 0 10	the <otherscientificterm_5> of <method_15> is attractive for the <task_0> . in this paper , a blind predictive constant modulus -lrb- cm -rrb- decision feedback equalizer -lrb- <method_14> -rrb- is presented and analyzed . the <method_14> employs the <method_4> as its <method_9> and a <method_10> that optimizes the <metric_11> of the decision variable . it is shown that for any <method_7> with reasonable <otherscientificterm_3> , the <otherscientificterm_6> for the <method_10> is approximately convex and its global minimum can be approximated in <otherscientificterm_13> . we demonstrate that the <metric_8> of the <method_10> is similar to the least <method_1> used in the <method_12> . we show that the <method_14> performs better than the <otherscientificterm_2> in simulations .	5 15 0 19 21 16 -1 14 16 -1 4 9 10 11 20 16 -1 7 3 6 13 17 22 16 -1 8 1 12 18 16 -1 16 -1
A Comprehensive Approach to On-Board Autonomy Verification and Validation .	on-board autonomous reasoning engine ; deep space missions ; plan generation ; space systems ; on-board autonomy ; reasoning capabilities ; formal model ; model-based reasoning ; run-time diagnosis ; controlled platform ; validation ; execution ; monitoring ; fdir	<method> <otherscientificterm> <task> <method> <task> <method> <method> <method> <method> <otherscientificterm> <task> <task> <task> <method>	13 6 5 ; 12 6 5 ; 10 1 11 ; 11 1 12 ; 11 6 5 ; 10 1 12 ; 12 1 13 ; 2 1 11 ; 13 1 8 ; 10 6 5 ; 8 6 5 ; 2 6 5 ; 2 1 10 ; 11 1 13	deep space missions are characterized by severely constrained communication links . to meet the needs of future missions and increase their scientific return , future <method_3> will require an increased level of autonomy on-board . in this work , we propose a comprehensive approach to <task_4> relying on <method_7> , and encompassing many important <method_5> such as <task_2> , <task_10> , <task_11> and <task_12> , <method_13> , and <method_8> . the <otherscientificterm_9> is represented symbolically , and the <method_5> are seen as symbolic manipulation of such <method_6> . we have developed a prototype of our framework , implemented within an <method_0> . we have evaluated our approach on two case-studies inspired by real-world , ongoing projects , and characterized it in terms of reliability , availability and performance .	14 -1 3 14 -1 4 7 5 2 10 11 12 13 8 15 16 17 18 19 20 21 22 23 24 25 26 27 28 14 -1 9 6 14 -1 14 -1 0 14 -1
Revising Imprecise Probabilistic Beliefs in the Framework of Probabilistic Logic Programming .	probabilistic logic program ; instantiation of revision operators ; probabilistic conditional event ; imprecise probabilistic knowledge ; single probability distribution ; probabilistic logic programming ; jeffrey 's rule ; bayesian conditioning ; propositional formula ; conditional events ; probability intervals ; representation theorem ; knowledge base ; postulates	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	10 2 12 ; 10 2 9 ; 11 0 13 ; 6 1 7 ; 9 2 12	probabilistic logic programming is a powerful technique to represent and reason with <otherscientificterm_3> . a <method_0> is a <material_12> which contains a set of <otherscientificterm_9> with <otherscientificterm_10> . in this paper , we investigate the issue of revising such a <method_0> in light of receiving new information . we propose <otherscientificterm_13> for revising <method_0> when a new piece of evidence is also a <otherscientificterm_2> . our <otherscientificterm_13> lead to <otherscientificterm_6> and <method_7> when the original <method_0> defines a <otherscientificterm_4> . furthermore , we prove that our <otherscientificterm_13> are extensions to darwiche and pearl -lrb- dp -rrb- <otherscientificterm_13> when new evidence is a <method_8> . we also give the <method_11> for the <otherscientificterm_13> and provide an <method_1> satisfying the proposed <otherscientificterm_13> .	3 14 -1 0 12 9 10 15 16 19 14 -1 14 -1 13 2 14 -1 6 7 4 18 14 -1 14 -1 8 17 14 -1
A Parameterized Runtime Analysis of Evolutionary Algorithms for the Euclidean Traveling Salesperson Problem .	euclidean traveling salesperson problem -lrb- euclidean tsp -rrb- ; runtime of evolutionary algorithms ; randomized local search ; evolutionary algorithms ; euclidean tsp ; geometric constraints ; structural properties	<task> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm>	3 0 4 ; 6 0 1 ; 6 0 3 ; 3 0 0	we contribute to the theoretical understanding of <method_3> and carry out a parameterized analysis of <method_3> for the <task_0> . we exploit <otherscientificterm_6> related to the optimization process of <method_3> for this problem and use <otherscientificterm_6> to bound the <method_1> . our analysis studies the runtime in dependence of the number of inner points k and shows that simple <method_3> solve the <method_4> in expected time o -lrb- n 4k -lrb- 2k ‚àí 1 -rrb- ! -rrb- . moreover , we show that , under reasonable <otherscientificterm_5> , a locally optimal 2-opt tour can be found by <method_2> in expected time o -lrb- n 2k k ! -rrb- .	3 0 11 7 -1 6 1 9 10 7 -1 4 8 7 -1 5 2 7 -1 7 -1 7 -1
Multipath exploitation in sparse scene recovery using sensing-through-wall distributed radar sensor configurations .	distributed multistatic radar units ; distributed radar network configuration ; target and wall positions ; multipath signal model ; interior wall positions ; stationary target localization ; indoor scattering environment ; multipath exploitation ; wall locations ; joint optimization ; ghosts targets ; sparse reconstruction	<method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <task>	7 1 11 ; 3 0 8 ; 1 0 8 ; 3 0 1	in this paper , we consider <task_7> and <task_11> in a network of <method_0> for <task_5> behind walls . <task_7> leverages prior information of the <otherscientificterm_6> to eliminate <otherscientificterm_10> . however , uncertainties in <otherscientificterm_4> severely impair the effectiveness of <task_7> . we develop a <method_3> for the <method_1> , which parameterizes the <otherscientificterm_8> , and perform <method_9> for simultaneously recovering the <otherscientificterm_2> . supporting simulation results are provided , which validate the effectiveness of the proposed <method_3> .	7 11 0 5 13 12 -1 6 10 12 -1 4 12 -1 3 1 8 9 2 14 15 16 12 -1 12 -1
Search Result Clustering Using Label Language Model .	language modeling approach ; search results clustering ; search result clustering ; label language model ; label selection ; dmoz	<method> <method> <task> <method> <task> <method>	5 0 4 ; 0 0 5 ; 0 0 4	search results clustering helps users to browse the search results and locate what they are looking for . in the <task_2> , the <task_4> which annotates a meaningful phrase for each cluster becomes the most fundamental issue . in this paper , we present a new method of using the <method_0> over <method_5> for <task_4> , namely <method_3> . experimental results show that our method is helpful to obtain meaningful clustering labels of search results .	6 -1 2 4 6 -1 0 5 3 7 8 9 6 -1 1 6 -1
Combining packet loss compensation methods for robust distributed speech recognition .	distributed speech recognition ; aurora connected digits task ; wsjcam0 large vocabulary task ; packet loss compensation system ; packet loss conditions ; feature vector stream ; burst lengths ; decoding process ; terminal device ; recognition accuracy ; missing vectors ; interleaving ; recognition	<task> <material> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <method> <task>	5 0 12 ; 1 1 2 ; 10 0 5 ; 3 0 0	this paper presents a combined <method_3> for <task_0> . compensation is applied at three stages within the <task_0> beginning with <method_11> on the <method_8> to reduce <otherscientificterm_6> in the received <otherscientificterm_5> . on the receiver side estimation of <otherscientificterm_10> is applied to reconstruct the <otherscientificterm_5> prior to <task_12> . finally , the <method_7> of the recogniser is modified to take into account the varying reliability of these estimated feature vectors . experiments performed on both the <material_1> and the <material_2> show substantial gains in <metric_9> across a range of <otherscientificterm_4> .	3 0 17 13 -1 11 8 6 5 13 -1 10 12 14 16 13 -1 7 13 -1 1 2 9 4 15 13 -1
Utilizing Scatter for Pixel Subspace Selection .	eigenvector decomposition of large matrices ; low dimensional feature sub-space ; content based indexing ; matrix eigenvector decomposition ; selection of pixels ; statistical pattern recognition ; discrete optimization technique ; computational procedures ; scatter measures ; principal components ; linear time ; linear discriminants ; subspace size ; linear combinations ; features ; scatter ; clustering	<otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <task> <method> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	10 2 6 ; 0 0 7 ; 16 1 2 ; 6 0 4 ; 9 1 11 ; 3 0 7 ; 6 0 8 ; 4 0 8	measures of <otherscientificterm_15> are used in <task_5> to identify and select important <otherscientificterm_14> , computed as <otherscientificterm_13> of the given <otherscientificterm_14> . examples include <method_9> and <otherscientificterm_11> . the classic <method_7> require <otherscientificterm_0> , and in the case of images they are only practical for identifying a <otherscientificterm_1> . we investigate the case in which the selected <otherscientificterm_14> are required to be a subset of the given <otherscientificterm_14> . it is shown that the same <metric_8> used in the general case can also be used in this discrete selection case , but the <method_7> no longer involves <method_3> . instead , the <otherscientificterm_4> that optimize <metric_8> can be accomplished by a very simple and efficient <method_6> that runs in <otherscientificterm_10> regardless of the <otherscientificterm_12> . applications to <method_16> and <task_2> are discussed .	15 5 14 13 17 -1 9 11 22 17 -1 7 0 1 19 17 -1 17 -1 8 3 23 17 -1 18 21 24 25 17 -1 4 6 10 12 20 17 -1
1-D continuous non-minimum phase retrieval using the wavelet transform .	1-d continuous , non-minimum phase retrieval algorithm ; noisy fourier magnitude information ; structured system of equations ; linear system of equations ; priori signal information ; continuous phase retrieval ; phase retrieval problem ; inverse fourier transform ; iterative algorithm ; wavelet expansions ; wavelet bases ; stagnation problems ; phase information ; non-iterative algorithms ; iterative algorithms	<method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method>	14 4 13 ; 4 0 10 ; 14 0 11	the <task_6> arises when a signal must be reconstructed from only the magnitude of its fourier transform ; if the <otherscientificterm_12> were also available , the signal could simply be synthesized using the <otherscientificterm_7> . in <task_5> , most previous solutions rely on discretizing the problem and then employing an <method_8> . we a void this approximation by using <method_9> to transform this uncountably innnite problem into a <method_3> . the <otherscientificterm_10> permit a solution by incorporating a <otherscientificterm_4> and they provide a <method_2> which results in a fast algorithm . our solutions obviate the <task_11> associated with <method_14> , they are computationally simpler and more stable than previous <method_13> , and they can accommodate <otherscientificterm_1> . this paper develops our <method_0> and illustrates its eeectiveness with numerical examples .	6 12 7 15 -1 5 8 15 -1 9 3 15 -1 10 4 2 17 15 -1 11 14 16 18 15 -1 13 1 15 -1
Fingerprinting to Identify Repeated Sound Events in Long-Duration Personal Audio Recordings .	body-worn solid-state audio recorders ; audio fingerprinting technique ; electronic telephone rings ; garage door openings ; background noise levels ; recurrent sound events ; energy peaks ; structured sound ; music recordings ; framing issues ; noise ; time-frequency ; jingles	<method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 6 7 ; 6 0 1 ; 1 0 5 ; 11 0 1 ; 1 0 8 ; 12 6 7 ; 1 0 4 ; 12 1 2	body-worn solid-state audio recorders can easily and cheaply capture the bearer 's entire acoustic environment throughout the day ; we refer to such recordings as '' personal audio '' . extracting useful information , and providing access and navigation tools for this data is a challenge ; in this paper we investigate the use of an <method_1> , originally developed for identifying <material_8> corrupted by <otherscientificterm_10> , as a tool to rapidly identify <material_5> within long -lrb- multi-day -rrb- recordings . the <method_1> is based on <otherscientificterm_6> in <otherscientificterm_11> , largely removing <task_9> and making <method_1> intrinsically robust to <otherscientificterm_4> . we show that the <method_1> is very effective at identifying exact repetitions of <material_7> -lrb- such as <otherscientificterm_12> and <material_2> -rrb- but is unable to find repeats of more ` organic ' sound events such as <otherscientificterm_3> .	13 -1 1 8 10 5 16 18 13 -1 6 11 9 4 15 17 20 13 -1 14 19 21 13 -1
Dependency Between Error Variance of the a Priori Information and a Modified Channel Noise Variance in Turbo-Equalisation .	modification of the channel noise variance ; modified channel noise variance ; priori information statistics ; equaliser input ; turbo-equalisers	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 1 2	in this paper , we propose a method based on the <otherscientificterm_0> at the <otherscientificterm_3> in order to improve the performance of a turbo-equaliser . we will show a relation between the <otherscientificterm_1> and the a <otherscientificterm_2> . the simulation are done for 2 types of <otherscientificterm_4> .	0 3 5 -1 1 2 6 5 -1 4 5 -1
Structured light 3D scanning in the presence of global illumination .	direct and global components of scene radiance ; structured light-based 3d scanning ; structured light-based shape recovery ; structured light patterns ; global illumination effects ; global illumination effects ; logical operations ; global illumination ; scanning systems ; combinatorial mathematics ; direct component ; capture time ; inter-reflections ; overhead ; diffusion	<otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	12 6 5 ; 3 0 4 ; 14 6 5 ; 7 0 2 ; 12 1 14	global illumination effects such as <otherscientificterm_12> , <otherscientificterm_14> and sub-surface scattering severely degrade the performance of <task_1> . in this paper , we analyze the errors caused by <otherscientificterm_7> in <task_2> . based on this analysis , we design <otherscientificterm_3> that are resilient to individual <otherscientificterm_4> using simple <method_6> and tools from <method_9> . scenes exhibiting multiple phenomena are handled by combining results from a small ensemble of such <otherscientificterm_3> . this combination also allows us to detect any residual errors that are corrected by acquiring a few additional images . our techniques do not require explicit separation of the <otherscientificterm_0> and hence work even in scenarios where the separation fails or the <method_10> is too low . our methods can be readily incorporated into existing <method_8> without significant <otherscientificterm_13> in terms of <otherscientificterm_11> or hardware . we show results on a variety of scenes with complex shape and material properties and challenging <otherscientificterm_4> .	12 14 1 16 18 20 15 -1 7 2 19 15 -1 3 4 6 9 17 15 -1 15 -1 15 -1 15 -1 0 10 15 -1 8 13 11 15 -1
Intonation modelling for the synthesis of structured documents .	rnn -lrb- recurrent neural network -rrb- intonation model ; feature selection process ; read isolated sentences ; text type ; intonation models ; read documents ; intonation contours ; structured documents ; data-driven techniques ; intonation modelling ; text-level features ; isolated sentences ; prosody model ; text structure ; features ; type-setting	<method> <method> <material> <otherscientificterm> <method> <material> <otherscientificterm> <material> <method> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	13 1 15 ; 3 1 13 ; 13 6 10 ; 15 6 10 ; 3 6 10	human readings of <material_7> exhibit a much richer intonation than that observed in <material_2> . it is a challenge to capture this richness in an automatic way using <method_8> . in this paper , we extend our previous research on <task_9> for <material_11> in different respects : -lrb- i -rrb- the <method_0> is now trained and evaluated on <material_5> , -lrb- ii -rrb- the <method_0> is evaluated as part of the overall <method_12> , -lrb- iii -rrb- the <method_1> is completely automated , and -lrb- iv -rrb- the importance of <otherscientificterm_10> such as <otherscientificterm_3> , <otherscientificterm_13> and <otherscientificterm_15> are investigated . it is demonstrated that acceptable <method_4> can be constructed starting from a database that does not contain any explicit hand labelling of the <otherscientificterm_6> . it also appears that <otherscientificterm_3> and <otherscientificterm_13> are important <otherscientificterm_14> whereas <otherscientificterm_15> is not .	7 2 16 -1 8 16 -1 9 11 0 5 12 1 10 3 13 15 17 18 19 20 21 16 -1 16 -1 4 6 16 -1
A Blind Algorithm Based on Difference of Norms for Equalization of Biorthogonal Signals .	intersymbol interference ; biorthogonal modulation ; adaptive equalization of bom signals ; blind equalization of bom signals ; classical adaptive equalization techniques ; equalization of bom signals ; mmse and lms-based equalizers ; blind algorithm ; biorthogonal signaling ; nar-rowband systems ; numerical simulations ; bpsk ; mmse ; peculiarities	<task> <method> <task> <otherscientificterm> <method> <task> <otherscientificterm> <method> <task> <method> <method> <method> <method> <otherscientificterm>	4 0 5 ; 12 6 7 ; 7 0 8 ; 7 0 2	motivated by increasing interest in energy efficient modulations , we investigate a <method_7> for <task_8> . while this modulation has historically been considered only for use in <method_9> without <task_0> , recent attention has been given to its use in <task_0> . due to the fact that <method_1> results in a source that is not i.i.d. , however , <method_4> can not be directly applied to <task_5> . we review the <otherscientificterm_6> , and then identify some <otherscientificterm_13> that arise in <otherscientificterm_3> when compared to more traditional modulations like <method_11> . next , we present a novel <method_7> , called <method_12> , for the <task_2> . we discuss the convergence properties of this <method_7> , and demonstrate its performance with <method_10> .	7 8 17 14 -1 9 0 14 -1 1 4 5 15 14 -1 6 13 3 11 14 -1 16 18 14 -1 12 2 14 -1
Active Music Listening Interfaces Based on Signal Processing .	active music listening interfaces ; timbre of instrument sounds ; active music listening ; active music listening ; song lyrics ; music-understanding technologies ; compact-disc recordings ; active interactions ; signal processing	<method> <otherscientificterm> <method> <task> <material> <method> <material> <otherscientificterm> <method>	8 0 5	this paper introduces our research aimed at building '' <method_0> '' . this research approach is intended to enrich end-users ' music listening experiences by applying <method_5> based on <method_8> . <method_2> is a way of listening to music through <otherscientificterm_7> . we have developed seven interfaces for <task_3> , such as interfaces for skipping sections of no interest within a musical piece while viewing a graphical overview of the entire song structure , for displaying virtual dancers or <material_4> synchronized with the music , for changing the <otherscientificterm_1> in <material_6> , and for browsing a large music collection to encounter interesting musical pieces or artists . these interfaces demonstrate the importance of <method_5> and the bene ¬ø t they offer to end users . our hope is that this work will help change music listening into a more active , immersive experience .	0 9 -1 5 8 2 10 9 -1 7 9 -1 3 4 1 6 9 -1 9 -1 9 -1
Learning Representation and Control in Continuous Markov Decision Processes .	spectral analysis of the state space manifold ; parametric radial basis function method ; least-squares policy iteration method ; continuous markov decision processes ; proto-value functions ; nystr√∂m extension ; control policy ; mountain car ; value function ; graph laplacian ; inverted pendulum ; subspace ; sensitivity	<otherscientificterm> <method> <method> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	2 0 6 ; 10 1 7	this paper presents a novel framework for simultaneously learning representation and control in <task_3> . our approach builds on the framework of <otherscientificterm_4> , in which the underlying representation or basis functions are automatically derived from a <otherscientificterm_0> . the <otherscientificterm_4> correspond to the eigenfunctions of the <otherscientificterm_9> . we describe an approach to extend the eigenfunctions to novel states using the <method_5> . a <method_2> is used to learn the <method_6> , where the underlying <otherscientificterm_11> for approximating the <otherscientificterm_8> is spanned by the learned <otherscientificterm_4> . a detailed set of experiments is presented using classic benchmark tasks , including the <otherscientificterm_10> and the <method_7> , showing the <metric_12> in performance to various parameters , and including comparisons with a <method_1> .	3 13 -1 4 0 13 -1 9 13 -1 5 13 -1 2 6 11 8 14 13 -1 15 13 -1
Parameter clustering and sharing in variable-parameter HMMs for noise robust speech recognition .	cubic-spline-based variable-parameter hidden markov model ; parameter clustering and sharing algorithm ; mean and variance parameters ; gaussian mixture components ; relative wer reduction ; cubic spline functions ; spline functions ; parameter sharing ; aurora-3 corpus ; environment-dependent parameters ; model parameters ; well-matched condition ; clustering algorithm ; noise robustness ; hmm	<method> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <method>	0 0 13 ; 0 4 14 ; 11 2 14 ; 8 5 0	recently we proposed a <method_0> whose <otherscientificterm_2> vary according to some <otherscientificterm_5> of additional <otherscientificterm_9> . we have shown good properties of the <method_0> and demonstrated on the <material_8> that <method_0> greatly outperforms the mce-trained conventional <method_14> at the cost of increased total number of <otherscientificterm_10> . in this paper , we propose to share <otherscientificterm_6> across different <method_3> to reduce the total number of <otherscientificterm_10> and develop a <method_12> to do so . we demonstrate the effectiveness of our <method_1> for the <method_0> on <material_8> and show that proper <method_7> can reduce the number of parameters from 4 times of that used in the conventional <method_14> to 1.13 times and still get 18 % <metric_4> over the mce trained conventional <method_14> under the <otherscientificterm_11> . effective <method_7> makes the <method_0> an attractive model for <metric_13> .	0 2 5 9 15 -1 8 14 10 17 19 15 -1 6 3 12 15 -1 1 7 18 15 -1 4 11 16 15 -1
Comparison of neural network natural and ordinary gradient algorithms for satellite down link identification .	identification of satellite communication channels ; classical multi-layer perceptron structure ; neural network architecture ; non-normalized power amplifier ; multi-layer perceptron family ; down link ; ordinary gradient ; natural gradient ; space telecommunications	<task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 1 7 ; 2 0 4 ; 0 3 8	in this paper , we present a <method_2> that belongs to the <method_4> , associated with two different algorithms : the <otherscientificterm_6> and the <otherscientificterm_7> , we compare performances of those algorithms . the identification of a <method_3> yielded to the introduction of an additional weight in the <otherscientificterm_1> . the application of this <method_2> is <method_8> : <task_0> , and especially the <otherscientificterm_5> . this link is made up with two elements . the first one is a high power amplifier -lrb- non-linearity -rrb- . the second one is a filter -lrb- memory -rrb- .	2 4 6 7 10 11 9 -1 3 1 9 -1 8 0 5 12 9 -1 9 -1 9 -1 9 -1
Bayes risk-based optimization of dialogue management for document retrieval system with speech interface .	minimization of bayes risk ; generating responses or confirmations ; average number of turns ; success rate of retrieval ; n-best candidates of asr ; document knowledge base ; information navigation system ; correct information presentation ; question-answering capability ; contextual information ; redundant turns ; dialogue management ; information access ; reward ; penalty	<task> <task> <metric> <metric> <otherscientificterm> <material> <task> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <metric>	3 1 2 ; 13 1 14 ; 6 0 1 ; 2 5 0 ; 13 0 0 ; 11 0 6 ; 13 0 7 ; 14 0 0 ; 4 1 9 ; 9 0 6 ; 14 0 10 ; 2 0 12 ; 4 0 6 ; 3 5 0 ; 5 0 6	we propose an efficient <method_11> for an <task_6> based on a <material_5> . it is expected that incorporation of appropriate <otherscientificterm_4> and <otherscientificterm_9> will improve the <task_6> performance . the <task_6> also has several choices in <task_1> . in this paper , this selection is optimized as <task_0> based on <metric_13> for <metric_7> and <metric_14> for <otherscientificterm_10> . we have evaluated this <task_0> with our spoken dialogue <task_6> '' dialogue navigator for kyoto city '' , which also has <otherscientificterm_8> . effectiveness of the proposed <task_0> was confirmed in the <metric_3> and the <metric_2> for <otherscientificterm_12> .	11 6 5 21 30 15 -1 4 9 24 25 28 15 -1 1 18 15 -1 0 13 7 14 10 17 20 22 23 26 15 -1 8 15 -1 3 2 12 16 19 27 29 15 -1
Joint source-channel coding for scalable video using models of rate-distortion functions .	unequal error protection ; universal rate-distortion characteristic plots ; residual bit error rate ; joint source-channel coding scheme ; snr scalable video coder ; end-to-end distortion ; source rate ; optimization algorithm ; scalable layers ; computational complexity ; total distortion ; channel coding ; scalable video ; error rate ; layer	<method> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <metric> <method> <otherscientificterm> <metric> <otherscientificterm> <method> <material> <metric> <otherscientificterm>	3 0 12 ; 1 0 7 ; 0 0 4 ; 9 5 4	a <method_3> for <material_12> is developed in this paper . an <method_4> is used and <method_0> is allowed for each scalable <otherscientificterm_14> . our problem is to allocate the available bit rate across <otherscientificterm_8> and , within each <otherscientificterm_14> , between source and <method_11> , while minimizing the <otherscientificterm_5> of the received video sequence . the resulting <method_7> we propose utilizes <otherscientificterm_1> . these plots show the contribution of each <otherscientificterm_14> to the <otherscientificterm_10> as a function of the <metric_6> of the <otherscientificterm_14> and the <metric_2> -lrb- the <metric_13> that remains after the use of <method_11> -rrb- . models for these plots are proposed in order to reduce the <metric_9> of the <method_4> . experimental results demonstrate the effectiveness of the proposed <method_3> .	3 12 16 15 -1 4 0 14 18 15 -1 8 11 5 15 -1 7 1 17 15 -1 10 6 2 13 15 -1 19 15 -1 9 15 -1
Training a Quantum Neural Network .	quantum learning algorithm ; quantum neural network ; machine intelligence ; quantum learning ; classical networks	<method> <method> <task> <method> <method>	3 0 2	quantum learning holds great promise for the field of <task_2> . the most studied <method_0> is the <method_1> . many such <method_0> have been proposed , yet none has become a standard . in addition , these <method_0> usually leave out many details , often excluding how they intend to train their networks . this paper discusses one approach to the problem and what advantages it would have over <method_4> .	2 6 5 -1 0 1 5 -1 5 -1 5 -1 4 3 5 -1
PLOW : A Collaborative Task Learning Agent .	knowledge representation and reasoning ; deep natural language understanding ; executable task models ; collaborative learning session ; ai technologies ; machine learning ; dialogue systems ; plan-ning/agent-based systems	<method> <task> <method> <method> <method> <task> <method> <method>	7 6 4 ; 6 1 5 ; 7 1 5 ; 6 6 4 ; 6 1 7 ; 1 6 4	to be effective , an agent that collaborates with humans needs to be able to learn new tasks from humans they work with . this paper describes a system that learns <method_2> from a single <method_3> consisting of demonstration , explanation and dialogue . to accomplish this , the system integrates a range of <method_4> : <task_1> , <method_0> , <method_6> , <method_7> and <task_5> . a formal evaluation shows the approach has great promise .	8 -1 2 3 8 -1 4 1 0 6 7 5 9 10 11 12 13 14 8 -1 8 -1
Periodic Motion Detection and Segmentation via Approximate Sequence Alignment .	detecting and segmenting periodic motion ; local motion and shape ; periodic motion detection ; dynamic geometric transformations ; time-linear matrix functions ; video sequences ; constant translation ; ransac procedure ; periodic views ; space-time points ; periodic motion ; fundamental matrices ; non-rigid backgrounds ; motion segmentation ; dynamic quantities ; image sequence ; sequence alignment ; periodicity ; homographies ; detection ; cue	<task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	16 0 2 ; 18 0 4	a method for <task_0> is presented . we exploit <otherscientificterm_17> as a <otherscientificterm_20> and detect <otherscientificterm_10> in complex scenes where common methods for <task_13> are likely to fail . we note that <task_2> can be seen as an approximate case of <task_16> where an <material_15> is matched to itself over one or more periods of time . to use this observation , we first consider alignment of two <material_5> obtained by independently moving cameras . under assumption of <otherscientificterm_6> , the <otherscientificterm_11> and the <otherscientificterm_18> are shown to be <otherscientificterm_4> . these <otherscientificterm_14> can be estimated by matching corresponding <otherscientificterm_9> with similar <otherscientificterm_1> . for <otherscientificterm_10> , we match corresponding points across periods and develop a <method_7> to simultaneously estimate the period and the <otherscientificterm_3> between <otherscientificterm_8> . using this method , we demonstrate <task_19> and segmentation of human <otherscientificterm_10> in complex scenes with <otherscientificterm_12> , moving camera and motion parallax .	0 21 -1 17 20 10 13 21 -1 2 16 15 22 21 -1 5 21 -1 6 11 18 4 23 21 -1 14 9 21 -1 1 21 -1 7 3 8 21 -1
Correction of B0 inhomogeneity distortion in magnetic resonance spectroscopic imaging .	echo-planar spectroscopic imaging sequence ; total variation regularization ; sparsity of the spectral data ; 3-d mr spectroscopic data ; multi-slice proton imaging data ; 0 b inhomogeneity artifact ; 0 b field map ; uniform spectral peaks ; epsi one ; reconstruction ; shimming	<material> <method> <material> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method>	0 0 3 ; 1 0 7 ; 10 0 4 ; 6 0 5	in this paper we reconstruct the <material_3> acquired using an <material_0> . we propose to compensate for <otherscientificterm_5> by using the <otherscientificterm_6> and * 2 t decay estimated from a higher resolution , <material_4> scanned with similar <method_10> to the <otherscientificterm_8> . we employ <method_1> to obtain more <otherscientificterm_7> and lineshapes , and exploit the <material_2> by using the 1 a norm in the <task_9> .	3 0 12 11 -1 5 6 4 10 8 14 15 11 -1 1 7 2 9 13 11 -1
Active learning for spoken language understanding .	statistical call classification system ; at&t customer care ; active learning methods ; certainty-based active learning ; call classification system ; committee-based active learning ; active learning ; classifiers ; classifier	<method> <task> <method> <method> <method> <method> <method> <method> <method>	3 0 2 ; 4 0 1 ; 5 0 2 ; 4 0 2	in this paper , we describe <method_2> for reducing the labeling effort in a <method_0> . <method_6> aims to minimize the number of labeled utterances by automatically selecting for labeling the utterances that are likely to be most informative . the first <method_2> , inspired by <method_3> , selects the examples that the <method_8> is least confident about . the second <method_2> , inspired by <method_5> , selects the examples that multiple <method_7> do not agree on . we have evaluated these <method_2> using a <method_4> used for <task_1> . our results indicate that it is possible to reduce human labeling effort at least by a factor of two .	2 0 6 9 -1 9 -1 3 8 10 9 -1 5 7 12 9 -1 4 1 11 13 9 -1 9 -1
Multi-scale Orderless Pooling of Deep Convolutional Activation Features .	sun397 and mit indoor scenes classification datasets ; deep convolutional neural networks ; supervised or unsupervised recognition tasks ; inria holidays retrieval datasets ; global cnn activations ; orderless vlad pooling ; local patches ; generic feature ; image classification ; universal representation ; discriminative power ; cnn activations ; ilsvrc2012/2013 classification ; instance-level retrieval ; geometric invariance ; recognition ; robustness	<material> <method> <task> <material> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <task> <task> <otherscientificterm> <task> <metric>	14 0 4 ; 13 6 2 ; 12 1 3	deep convolutional neural networks -lrb- cnn -rrb- have shown their promise as a <method_9> for <task_15> . however , <otherscientificterm_4> lack <otherscientificterm_14> , which limits their <metric_16> for <task_15> and matching of highly variable scenes . to improve the invariance of <method_11> without degrading their <otherscientificterm_10> , this paper presents a simple but effective scheme called multi-scale orderless pooling -lrb- mop-cnn -rrb- . this scheme extracts <method_11> for <otherscientificterm_6> at multiple scale levels , performs <method_5> of these <method_11> at each level separately , and concatenates the result . the resulting mop-cnn representation can be used as a <method_7> for either <task_2> , from <task_8> to <task_13> ; it consistently outperforms <otherscientificterm_4> without requiring any joint training of prediction layers for a particular target dataset . in absolute terms , it achieves state-of-the-art results on the challenging <material_0> , and competitive results on <task_12> and <material_3> .	9 15 17 -1 4 14 16 18 17 -1 11 10 17 -1 6 5 17 -1 7 19 17 -1 2 8 13 20 17 -1
Statistical analysis of a subspace method for blind channel identification .	blind channel estimation of multi channel fir lters ; asymptotically correct weighting matrix ; mobile communication systems ; subspace estimate ; noise subspace ; asymptotic properties ; channel matrix ; digital signalling ; subspace method ; multiplicative constant ; orthogonality property	<task> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	7 0 2 ; 10 0 8 ; 4 1 6 ; 4 2 10	this paper considers the problem of <task_0> . this is a problem arising in e.g. <method_2> using <otherscientificterm_7> . by using the <otherscientificterm_10> between the <otherscientificterm_4> and the <otherscientificterm_6> , it has been shown in earlier work that the <otherscientificterm_6> is identiiable up to a <otherscientificterm_9> . in this article , the <otherscientificterm_5> of a <method_8> using this <otherscientificterm_10> is presented . an <otherscientificterm_1> is derived , demonstrating an attainable lower theoretical bound using the <method_3> .	0 11 -1 2 7 12 11 -1 10 4 6 9 14 15 11 -1 5 8 13 11 -1 1 3 11 -1
Correspondence Expansion for Wide Baseline Stereo .	error tolerance constraint ; derived geometric structure ; wide baseline images ; point correspondences ; epipolar geometry ; image pairs ; motion algorithms ; ransac ; constraint	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <material> <method> <method> <otherscientificterm>	7 0 4	we present a new method for generating large numbers of accurate <otherscientificterm_3> between two <material_2> . this is important for structure from <method_6> , which rely on many correct matches to reduce error in the <otherscientificterm_1> . given a small initial correspondence set we iteratively expand the set with nearby points exhibiting strong affine correlation , and then we constrain the set to an <method_4> using <method_7> . a key point to our algorithm is to allow a high error tolerance in the <otherscientificterm_8> , allowing the correspondence set to expand into many areas of an image before applying a lower <otherscientificterm_0> . we show that this method successfully expands a small set of initial matches , and we demonstrate it on a variety of <material_5> .	3 2 9 -1 6 1 9 -1 4 7 10 9 -1 8 9 -1 0 9 -1
Exploring the Planet of the APEs : a Comparative Study of State-of-the-art Methods for MT Automatic Post-Editing .	internal decoding process ; statistical ape methods ; mt output quality ; language pairs ; mt quality ; translation quality ; systematic analysis ; downstream processing ; mt system ; fo-cusing ; english	<method> <method> <metric> <material> <metric> <metric> <method> <method> <method> <method> <material>	1 0 9 ; 7 0 5	downstream processing of machine translation -lrb- mt -rrb- output promises to be a solution to improve <metric_5> , especially when the <method_8> 's <method_0> is not accessible . both rule-based and statistical automatic post-editing -lrb- ape -rrb- methods have been proposed over the years , but with contrasting results . a missing aspect in previous evaluations is the assessment of different methods : i -rrb- under comparable conditions , and ii -rrb- on different <material_3> featuring variable levels of <metric_4> . <method_9> on <method_1> -lrb- more portable across languages -rrb- , we propose the first <method_6> of two approaches . to understand their potential , we compare them in the same conditions over six <material_3> having <material_10> as source . our results evidence consistent improvements on all <material_3> , a relation between the extent of the gain and <metric_2> , slight but statistically significant performance differences between the two methods , and their possible complementarity .	5 8 0 13 11 -1 11 -1 3 4 9 11 -1 1 6 12 11 -1 11 -1 10 11 -1
A General Projection Property for Distribution Families .	markov decision processes ; natural risk criteria ; univariate inequalities ; worst-case analyses ; portfolio selection ; unimodality ; log-concavity ; optimization ; symmetry ; classification	<task> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task>	5 1 6 ; 9 1 4 ; 4 1 0 ; 3 0 1 ; 7 1 4 ; 9 1 7 ; 8 1 5	surjectivity of linear projections between distribution families with fixed mean and covariance -lrb- regardless of dimension -rrb- is re-derived by a new proof . we further extend this property to distribution families that respect additional constraints , such as <otherscientificterm_8> , <otherscientificterm_5> and <otherscientificterm_6> . by combining our results with classic <otherscientificterm_2> , we provide new <method_3> for <task_1> arising in <task_9> , <task_7> , <task_4> and <task_0> .	10 -1 8 5 6 11 17 10 -1 2 3 1 9 7 4 0 12 13 14 15 16 10 -1
Structuring Techniques for Constraint Satisfaction Problems .	discrete constraint satisfaction problems ; compact representations ; iterative application ; structuring method ; csp ; interchangeabilities	<task> <method> <method> <method> <method> <otherscientificterm>	5 0 3 ; 3 0 0	we present a <method_3> for <task_0> . <method_3> takes advantage of <otherscientificterm_5> to represent sets of equivalent values by meta-values and thus obtain more <method_1> . strongly related variables are clustered into meta-variables to create occurrences of inter-changeabilities . by <method_2> , a <method_4> can be transformed into an hierarchy of equivalent <task_0> , where each problem is signiicantly simpler than the original one . this structure is particularly advantageous when a large set of possible solutions must be inspected .	3 0 8 6 -1 5 1 7 6 -1 6 -1 2 4 6 -1 6 -1
A convex and feature-rich discriminative approach to dependency grammar induction .	convex and feature-rich discriminative approach ; dependency grammar induction√©douard abstract ; unsupervised dependency parsing ; non-convex optimization problem ; dependency grammar induction ; unsupervised learning problems ; generative models ; optimization algorithm ; frank-wolfe algorithm ; features ; initial-ization	<method> <method> <task> <task> <task> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm>	0 0 1	a <method_0> to <method_1> in this paper , we introduce a new method for the problem of <task_2> . most current approaches are based on <method_6> . learning the parameters of such models relies on solving a <task_3> , thus making them sensitive to <otherscientificterm_10> . we propose a new convex formulation to the task of <task_4> . our approach is discriminative , allowing the use of different kinds of <otherscientificterm_9> . we describe an efficient <method_7> to learn the parameters of our model , based on the <method_8> . our method can easily be generalized to other <task_5> . we evaluate our approach on ten languages belonging to four different families , showing that our method is competitive with other state-of-the-art methods .	0 1 2 12 11 -1 6 11 -1 3 10 11 -1 4 11 -1 9 11 -1 7 8 11 -1 5 11 -1 11 -1
Joint Recovery of Dense Correspondence and Cosegmentation in Two Images .	hierarchical markov random field model ; cosegmen-tation and dense per-pixel correspondence ; manually obtained ground truth ; iterated graph cuts ; energy minimization framework ; nested image regions ; piecewise similarity transformations ; joint inference ; correspondence field ; image pairs ; hierarchical methods ; correspondence estimation ; structure ; mapping ; inference ; labeling ; cosegmentation ; segmentation	<method> <otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <method> <task> <otherscientificterm> <task> <task> <otherscientificterm> <task> <method>	3 0 4 ; 17 2 0 ; 5 0 0 ; 4 0 7 ; 0 0 14 ; 6 0 8 ; 16 1 11	we propose a new technique to jointly recover <otherscientificterm_1> in two images . our method parameterizes the <otherscientificterm_8> using <otherscientificterm_6> and recovers a <task_13> between the estimated common '' foreground '' regions in the two images allowing them to be precisely aligned . our formulation is based on a <method_0> with <method_17> and transformation labels . the <method_0> uses <otherscientificterm_5> to constrain <task_14> across multiple scales . unlike prior <method_10> which assume that the <otherscientificterm_12> is given , our proposed iterative technique dynamically recovers the <otherscientificterm_12> along with the <otherscientificterm_15> . this <task_7> is performed in an <method_4> using <method_3> . we evaluate our method on a new dataset of 400 <material_9> with <material_2> , where it outperforms state-of-the-art methods designed specifically for either <task_16> or <task_11> .	1 18 -1 8 6 13 24 18 -1 0 17 20 18 -1 5 14 21 23 18 -1 10 12 15 18 -1 7 4 3 19 22 18 -1 25 18 -1
Interference-free multi-user MIMO-OFDM .	multiuser downlink mimo-ofdm scheme ; transmit power constraint ; multiple access technique ; linear processing ; multiuser interference ; sdma ; fdma	<method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method>	6 1 5 ; 2 0 6	a <method_0> is considered . perfect channel knowledge is assumed at the base station and <method_3> is used at both the transmit and receive sides . the objective is to optimize the mean ber of the system while satisfying a <otherscientificterm_1> and fulfilling each user 's rate . <method_6> and <method_5> are investigated . we show how the <otherscientificterm_4> induced by <method_5> can be annihilated and exhibit that this <method_2> should be preferred to <method_6> .	0 7 -1 3 7 -1 1 6 7 -1 5 8 7 -1 4 2 9 7 -1
A noiseless code length method -LRB- NCLM -RRB- to estimate dimensionality of hyperspectral data .	dimension estimation step ; noiseless data error ; noisy data error ; hyperspectral image analysis ; estimation of dimensionality ; error comparison approach ; optimum subset ; nested subsets ; hyperspectral imagery ; hyperspec-tral data ; dimension estimation ; noiseless error ; hyperspectral data ; denoising ; accuracy	<metric> <otherscientificterm> <otherscientificterm> <task> <task> <method> <otherscientificterm> <otherscientificterm> <material> <material> <method> <otherscientificterm> <material> <task> <metric>	4 2 8 ; 14 5 0 ; 12 6 7	hyperspectral image analysis has been subjected to many improvements made in past decade . yet the accurate <task_4> is still a challenge . since <method_10> of the <material_12> is the first step in analysis of an image , the <metric_14> of analysis results highly depends on the <metric_14> of the <metric_0> . mostly , existing methods isolate the process of <method_10> and process of <task_13> which leads to an inaccurate estimation of constituent components in the signal . in this paper , the problem of estimating the dimensionality of <material_12> using the concept of '' noiseless code length '' is addressed . in our proposed method , nclm , a set of <otherscientificterm_7> including the <material_12> is generated first and then an <method_5> is utilized by estimating the <otherscientificterm_1> rather than <otherscientificterm_2> used by the existing methods to find the <otherscientificterm_6> . it has been shown that the estimated <otherscientificterm_11> has a minimum that represents the accurate estimation of the dimensionality of <material_9> . the comparison of nclm to other methods shows a substantial improvement in <task_4> in <material_8> .	15 -1 4 15 -1 10 12 14 0 17 15 -1 13 15 -1 15 -1 18 15 -1 7 5 1 2 6 15 -1 11 9 16 15 -1
Unsupervised modeling of user actions in a dialog corpus .	non-parametric bayesian hidden markov model ; data-driven spoken dialog system development ; modeling user actions ; automatically annotated corpus ; unsupervised approach ; dialog system ; semantic annotation ; labeling process ; user simulation ; human annotation ; dialog corpus	<method> <task> <task> <material> <method> <method> <method> <method> <method> <task> <material>	3 0 5 ; 0 0 4 ; 4 0 2 ; 6 2 10 ; 8 0 5	in <task_1> , developers should prepare a <material_10> with <method_6> . however , the <method_7> is a laborious and time consuming task . to reduce human efforts , we propose an <method_4> based on <method_0> to the problem of <task_2> . with the <method_0> , system designers do not need to determine the number and type of user actions . in the experiments , we evaluated the clustering results by comparing them to the <task_9> . we also tested a <method_5> that used models trained from the <material_3> with a <method_8> .	1 10 6 15 11 -1 7 11 -1 4 0 2 13 14 11 -1 11 -1 9 11 -1 5 3 8 12 16 11 -1
The czech speech and prosody database both for ASR and TTS purposes .	automatic speech recognition ; raw and stylized f0 values ; text-to-speech synthesis ; word-and phoneme-level time alignment ; frame level energy values ; automatic punctuation annotation ; czech high-quality synthesis ; czech prosodic database ; recorded speech ; prosodic data ; prosodic module ; linguistical annotation ; tagset ; stylization	<task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <task> <material> <material> <material> <method> <task> <method> <task>	0 0 0 ; 0 1 2 ; 4 1 3 ; 12 0 11 ; 0 0 10 ; 1 1 3 ; 8 1 1 ; 8 1 4 ; 0 0 5 ; 1 1 4 ; 10 0 6	this paper describes a preparation of the first large <material_7> which should be useful both in <task_0> and <task_2> . in the area of <task_0> we intend to use <task_0> for an <task_5> , in the area of <task_0> for building a <method_10> for the <task_6> . the database is based on the czech radio & tv broadcast news corpus -lrb- uwb b02 -rrb- recorded at the university of west bohemia . the configuration of the database includes <material_8> , <otherscientificterm_1> , <otherscientificterm_4> , a <otherscientificterm_3> , and a linguistically motivated description of the <material_9> . a technique of <material_9> acquisition and <task_13> is described . a new <method_12> for a <task_11> of the czech prosody is proposed and used .	7 0 2 16 14 -1 5 10 6 15 19 23 25 14 -1 14 -1 8 1 4 3 9 17 20 21 22 24 14 -1 14 -1 13 18 14 -1
I-vector based language modeling for query representation .	i-vector based language modeling framework ; tdt-2 -lrb- topic detection and tracking -rrb- collection ; spoken document retrieval ; indexing and modeling techniques ; multi-levels of index features ; word-and subword-level units ; language identification ; i-vector framework ; spoken documents ; query reformulation ; multimedia data ; speaker recognition ; query formulation	<method> <material> <task> <method> <otherscientificterm> <otherscientificterm> <task> <method> <material> <task> <material> <task> <task>	7 0 11 ; 5 6 4 ; 7 0 0 ; 0 0 12 ; 7 0 6 ; 10 0 2 ; 8 0 10 ; 6 1 11 ; 3 0 8 ; 0 0 6	since more and more <material_10> associated with <material_8> have been made available to the public , <task_2> has become an important research subject in the past two decades . following the research tendency , many efforts have been devoted towards developing <method_3> for representing <material_8> , but only few have been made on improving <task_12> for better representing users ' information needs . the <method_0> , stemming from the state-of-the-art <method_7> for <task_6> and <task_11> , has been proposed and formulated to represent documents in sdr with good promise recently . however , a major challenge of using <method_0> for <task_12> is that a query usually consists of only a few words ; thus , it is hard to learn a reliable representation accordingly . in this paper , we focus our attention on <task_9> and propose three novel methods on top of <method_0> to more accurately represent users ' information needs . in addition , we also explore the use of <otherscientificterm_4> , including <otherscientificterm_5> , to work in concert with the proposed methods . a series of empirical sdr experiments conducted on the <material_1> demonstrate the good effectiveness of our proposed methods as compared to existing state-of-the-art methods .	10 8 2 19 20 13 -1 3 12 22 13 -1 0 7 6 11 14 16 18 21 23 13 -1 17 13 -1 13 -1 9 15 13 -1 4 5 13 -1
Evaluation of a stereo audio data hiding method using inter-channel decorrelator polarity .	polarity of the echoes ; stereo audio signals ; mushra standard method ; raw embedded data ; sample rate conversion ; spread spectrum method ; data hiding algorithm ; random bit cropping ; mp3 coders ; hiding methods ; high-frequency channels ; embedded data ; spread spectrum	<otherscientificterm> <material> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm>	2 4 9 ; 6 0 1 ; 4 1 7 ; 0 0 6	we extensively evaluated a <method_6> for <material_1> which embeds data using the <otherscientificterm_0> added to the <otherscientificterm_10> , which we have previously proposed . its performance was also compared to conventional data hiding using <otherscientificterm_12> , and those using echoes with different delays . <material_3> was detected with little or no errors for added noise at 20 db snr and above , or with <otherscientificterm_8> , although the <method_5> showed almost no errors at all . however , <otherscientificterm_4> and <otherscientificterm_7> were shown not to affect the <material_11> with the proposed <method_6> , while other methods , including <otherscientificterm_12> , showed significant amount of errors . the embedded audio quality test using the <method_2> resulted in little noticeable degradation , far better quality compared to other <method_9> .	6 1 0 10 15 17 13 -1 12 3 13 -1 8 5 13 -1 4 7 11 16 13 -1 14 13 -1
An automatic face detection and recognition system for video indexing applications .	principal components analysis approach ; face detection and recognition rate ; mpeg-7 video content set ; video indexing applications ; mpeg-7 evaluation group ; face detection stage ; recognition system ; computational cost	<method> <metric> <material> <task> <material> <method> <method> <metric>	0 0 3 ; 0 0 5	the objective of this work is the integration and optimization of an automatic face detection and <method_6> for <task_3> . the system is composed of a <method_5> presented previously which provides good results maintaining a low <metric_7> . the <method_5> is based on the <method_0> which has been modified to cope with the <task_3> . after the integration of the two stages , several improvements are proposed which increase the <metric_1> and the overall performance of the system . good results have been obtained using the <material_2> used in the <material_4> .	6 3 8 -1 5 7 8 -1 0 9 10 8 -1 1 8 -1 2 4 8 -1
A Nonparametric Bayesian Method for Inferring Features From Similarity Judgments .	weighted linear function of common features ; fully bayesian formulation ; nonparametric bayesian statistics ; additive clustering model ; parameter estimation ; similarity judgments ; features ; similarity	<otherscientificterm> <method> <material> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 3 ; 1 0 5 ; 3 0 6	the <method_3> is widely used to infer the <otherscientificterm_6> of a set of stimuli from their similarities , on the assumption that <otherscientificterm_7> is a <otherscientificterm_0> . this paper develops a <method_1> of the <method_3> , using methods from <material_2> to allow the number of <otherscientificterm_6> to vary . we use this to explore several approaches to <task_4> , showing that the <method_1> provides a straightforward way to obtain estimates of both the number of <otherscientificterm_6> used in producing <otherscientificterm_5> and their importance .	3 6 7 0 11 8 -1 1 2 9 8 -1 4 5 10 8 -1
Incorporating Knowledge into Structural Equation Models Using Auxiliary Variables .	non-zero parameter values ; graph-based identification methods ; auxiliary variables ; single-door criterion ; linear systems ; identification technique ; instrumental variables ; identification method ; bootstrapping approach ; model testing ; external knowledge ; half-trek criterion ; background knowledge ; d-separation ; over-identification ; z-identification ; identification	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task>	14 6 9 ; 13 1 14 ; 12 0 1 ; 6 6 16 ; 8 0 1 ; 7 0 4 ; 13 1 13 ; 2 0 9 ; 11 6 16 ; 2 0 16 ; 9 1 15 ; 6 1 13 ; 3 1 6 ; 3 6 16 ; 13 6 9 ; 2 0 1 ; 6 1 11 ; 2 0 15 ; 3 1 11 ; 0 0 1	in this paper , we extend <method_1> by allowing <otherscientificterm_12> in the form of <otherscientificterm_0> . such <otherscientificterm_12> could be obtained , for example , from a previously conducted randomized experiment , from substantive understanding of the domain , or even an <method_5> . to incorporate such <otherscientificterm_12> systematically , we propose the addition of <otherscientificterm_2> to the <method_1> , which are constructed so that certain paths will be conveniently cancelled . this cancellation allows the <otherscientificterm_2> to help conventional methods of <task_16> -lrb- e.g. , <otherscientificterm_3> , <otherscientificterm_6> , <otherscientificterm_11> -rrb- , as well as <method_9> -lrb- e.g. , <otherscientificterm_13> , <otherscientificterm_14> -rrb- . moreover , by iteratively alternating steps of <task_16> and adding <otherscientificterm_2> , we can improve the power of existing <method_1> via a <method_8> that does not require <otherscientificterm_10> . we operationalize this <method_1> for simple instrumental sets -lrb- a generalization of <otherscientificterm_6> -rrb- and show that the resulting <method_1> is able to identify at least as many models as the most general <method_7> for <method_4> known to date . we further discuss the application of <otherscientificterm_2> to the tasks of <method_9> and <task_15> .	1 12 0 20 37 17 -1 5 17 -1 2 17 -1 16 3 6 11 9 18 19 21 24 26 27 29 30 31 32 34 36 17 -1 13 14 22 33 17 -1 8 10 23 17 -1 7 4 25 28 35 17 -1
Learning a Continuous Hidden Variable Model for Binary Data .	translationally invariant binary distribution ; directed generative model ; handwritten digit images ; principal components analysis ; continuous gaussian variables ; binary output variables ; hidden continuous units ; binary data ; clipping nonlinear-ity	<otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method>	1 0 7 ; 6 0 1 ; 3 0 1 ; 4 1 5 ; 8 0 1 ; 0 5 1	a <method_1> for <material_7> using a small number of <otherscientificterm_6> is investigated . a <method_8> distinguishes the <method_1> from conventional <method_3> . the relationships between the correlations of the underlying <otherscientificterm_4> and the <otherscientificterm_5> are utilized to learn the appropriate weights of the <method_1> . the advantages of this <method_1> are illustrated on a <otherscientificterm_0> and on <material_2> .	1 7 6 10 11 9 -1 8 3 12 14 9 -1 4 5 13 9 -1 0 2 15 9 -1
The case for automatic higher-level features in forensic speaker recognition .	automatic higher-level systems ; higher-level '' features ; automatic speaker recognition ; forensic context ; cepstral features ; forensic applications ; automatic systems	<method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <task>	4 0 2	approaches from standard <task_2> , which rely on <otherscientificterm_4> , suffer the problem of lack of interpretability for <task_5> . but the growing practice of using '' <otherscientificterm_1> in <task_6> offers promise in this regard . we provide an overview of <method_0> and discuss potential advantages , as well as issues , for their use in the <otherscientificterm_3> .	2 4 5 8 7 -1 1 6 7 -1 0 3 7 -1
Syntactic Topic Models .	syntactic topic model ; semantic insights of topic models ; approximate posterior inference method ; nonparametric bayesian model ; document-specific topic weights ; hierarchical dirichlet processes ; parse-tree-specific syntactic transitions ; parse trees ; synthetic data ; parse tree ; parsed documents ; syntactic information ; variational methods ; hand-parsed documents	<method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <method> <material>	12 0 5 ; 4 1 6 ; 7 1 11 ; 12 0 2 ; 8 1 13 ; 2 0 5	we develop the <method_0> , a <method_3> of <material_10> . the <method_0> generates words that are both thematically and syntactically constrained , which combines the <method_1> with the <otherscientificterm_11> available from <otherscientificterm_7> . each word of a sentence is generated by a distribution that combines <otherscientificterm_4> and <otherscientificterm_6> . words are assumed to be generated in an order that respects the <otherscientificterm_9> . we derive an <method_2> based on <method_12> for <method_5> , and we report qualitative and quantitative results on both <material_8> and <material_13> .	0 3 10 14 -1 1 11 7 17 14 -1 4 6 16 14 -1 9 14 -1 2 12 5 8 13 15 18 19 20 14 -1
System request detection in human conversation based on multi-resolution Gabor wavelet features .	voice activity detection systems ; power and prosody-based method ; detected speech section ; robot dialog corpus ; hands-free speech interface ; log-scale mel-frequency filter-bank ; prosodic articulation ; speech frames ; phoneme articulation ; gabor wavelet ; system requests ; system commands ; non-speech frames ; multi-resolution analysis ; spontaneous utterances ; command ; f-measure ; accuracy	<method> <method> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <metric> <metric>	16 5 1 ; 10 1 14 ; 11 1 14 ; 5 0 13 ; 12 0 0 ; 9 0 13	for a <otherscientificterm_4> , it is important to detect commands in <material_14> . usual <method_0> can only distinguish <otherscientificterm_7> from <otherscientificterm_12> , but they can not discriminate whether the <otherscientificterm_2> is a <otherscientificterm_15> for a system or not . in this paper , in order to analyze the difference between <otherscientificterm_10> and <material_14> , we focus on fluctuations in a long period , such as <otherscientificterm_6> , and fluctuations in a short period , such as <otherscientificterm_8> . the use of <method_13> using <otherscientificterm_9> on a <material_5> clarifies the different characteristics of <otherscientificterm_11> and <material_14> . experiments using our <material_3> show that the <metric_17> of the proposed method is 92.6 % in <metric_16> , while the conventional <method_1> is just 66.7 % .	4 14 18 -1 0 7 12 2 15 23 18 -1 10 6 8 20 18 -1 13 9 5 11 21 22 24 18 -1 3 19 18 -1
Approximate Solutions of Interactive Dynamic Influence Diagrams Using Model Clustering .	interactive dynamic influence diagrams ; transparent and semantically clear representation ; sequential decision-making problem ; approximation technique ; interacting agents	<method> <method> <task> <method> <method>	0 0 2 ; 1 0 2 ; 0 0 1	interactive dynamic influence diagrams -lrb- <method_0> -rrb- offer a <method_1> for the <task_2> over multiple time steps in the presence of other <method_4> . solving <method_0> exactly involves knowing the solutions of possible models of the other agents , which increase exponentially with the number of time steps . we present a method of solving <method_0> approximately by limiting the number of other agents ' candidate models at each time step to a constant . we do this by clustering the models and selecting a representative set from the clusters . we discuss the error bound of the <method_3> and demonstrate its empirical performance .	0 1 2 4 6 7 8 5 -1 5 -1 5 -1 5 -1 3 5 -1
ABSORB : Atlas building by Self-Organized Registration and Bundling .	relative distribution of subject images ; synthetic and real datasets ; hierarchical groupwise registration framework ; local data distribution ; representative subject images ; groupwise registration methods ; registration process ; global structure ; registration accuracy ; self-organized registration ; self-organized registration ; image bundling ; image population ; groupwise registration ; registration ; robustness	<otherscientificterm> <material> <method> <task> <material> <method> <method> <otherscientificterm> <metric> <method> <method> <task> <otherscientificterm> <task> <task> <metric>	8 1 15 ; 9 6 2 ; 1 5 2 ; 2 4 5	to achieve more accurate and consistent <task_14> in an <otherscientificterm_12> , a novel <method_2> , called atlas building by <method_9> and bundling -lrb- absorb -rrb- , is proposed in this paper . in this new <method_2> , the <otherscientificterm_7> , i.e. , the <otherscientificterm_0> is always preserved during the <method_6> by constraining each subject image to deform only locally with respect to its neighbors within the learned image manifold . to achieve this goal , two novel strategies , i.e. , the <method_10> by warping one image towards a set of its eligible neighbors and <task_11> to cluster similar images , are specially proposed . by using these two strategies , this new <method_2> can perform <task_13> in a hierarchical way . specifically , in the high level , <method_2> will perform on a much smaller dataset formed by the <material_4> of all subgroups that are generated in the previous levels of <task_14> . compared to the other <method_5> , our proposed <method_2> has several advantages : -lrb- 1 -rrb- <method_2> explores the <task_3> and uses the obtained distribution information to guide the <task_14> ; -lrb- 2 -rrb- the possible <task_14> error can be greatly reduced by requiring each individual subject to move only towards its nearby subjects with similar structures ; -lrb- 3 -rrb- <method_2> can produce a smoother <task_14> path , in general , from each subject image to the final built atlas than other <method_5> . experimental results on both <material_1> show that the proposed <method_2> can achieve substantial improvements , compared to the other two widely used <method_5> , in terms of both <metric_8> and <metric_15> .	14 12 2 9 18 16 -1 7 0 6 16 -1 10 11 16 -1 16 -1 13 16 -1 4 16 -1 5 3 17 19 20 16 -1
Effective Selectional Restrictions for Unsupervised Relation Extraction .	unsupervised relation extraction methods ; web-derived soft clustering of n-grams ; sparsity of the feature space ; selectional restrictions ; text corpora of unknown content ; fine-grained entity type system ; 7-class named entity types ; discriminative power of patterns ; modeling sr ; open domain ; fine-granular relations ; selectional restrictions ; semantic relations ; ambiguities ; setup	<method> <method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 7 ; 5 0 3 ; 0 0 13 ; 0 0 12	unsupervised relation extraction -lrb- <method_0> -rrb- methods automatically discover <otherscientificterm_12> in <material_4> and extract for each discovered relation a set of relation instances . due to the <otherscientificterm_2> , <method_0> is vulnerable to <otherscientificterm_13> and underspeci-fication in patterns . in this paper , we propose to increase the <otherscientificterm_7> in <method_0> using <otherscientificterm_3> . we propose a method that utilizes a <method_1> to model <otherscientificterm_11> in the <material_9> . we comparatively evaluate our method against a baseline without <otherscientificterm_3> , a <otherscientificterm_14> in which standard <otherscientificterm_6> are used as <otherscientificterm_3> and a <otherscientificterm_14> that models <otherscientificterm_3> using a <method_5> . our results indicate that <task_8> into patterns significantly improves the ability of <method_0> to discover relations and enables the discovery of more <otherscientificterm_10> .	0 12 4 19 15 -1 2 13 18 15 -1 7 3 16 15 -1 1 11 9 15 -1 14 6 5 17 15 -1 15 -1
FAB-MAP : Appearance-Based Place Recognition and Mapping using a Learned Visual Vocabulary Model .	mean filter update times ; infrastructure-free mobile robot navigation ; visually repetitive environments ; loop closure detection ; robot 's camera ; online appearance mapping ; system speed ; probabilis-tic framework ; visual elements ; tf-idf ranking ; place recognition ; multi-hypothesis testing ; joint distribution ; bail-out strategy ; fab-map	<metric> <task> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <task> <task> <otherscientificterm> <method> <method>	5 1 3 ; 5 5 14 ; 3 5 14 ; 11 0 6 ; 14 0 10 ; 13 0 11 ; 13 0 6 ; 14 0 3 ; 10 0 1	we present an overview of <method_14> , an algorithm for <task_10> and mapping developed for <task_1> in large environments . the <method_14> allows a robot to identify when it is revisiting a previously seen location , on the basis of imagery captured by the <otherscientificterm_4> . we outline a complete <method_7> for the task , which is applicable even in <otherscientificterm_2> where many locations may appear identical . our work introduces a number of technical innovations-notably we demonstrate that <task_10> performance can be improved by learning an approximation to the <otherscientificterm_12> over <otherscientificterm_8> . we also investigate several principled approaches to making the <method_14> robust in <otherscientificterm_2> , and define an efficient <method_13> for <task_11> to improve <otherscientificterm_6> . our model has been shown to substantially outperform standard <method_9> on our task of interest . we demonstrate the <method_14> performing reliable <task_5> and <task_3> over a 1,000 km trajectory , with <metric_0> of 14 ms.	14 10 1 20 24 15 -1 4 15 -1 7 2 15 -1 12 8 15 -1 19 21 22 15 -1 13 11 6 15 -1 9 16 17 18 23 15 -1
Statistical Analysis of Local 3D Structure in 2D Images .	homogeneous , edge-like , corner-like or texture-like structures ; edge-like or corner-like structures ; local image structures ; 3d range data ; homogeneous image patches ; computer vision applications ; local 3d structure ; analysis of images ; intrinsic structure ; 3d discontinuities ; continuous surfaces ; statistical analysis ; 2d images ; discontinuities	<otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm>	10 1 9 ; 11 0 12 ; 3 0 9	for the <task_7> , a deeper understanding of their <otherscientificterm_8> is required . this has been obtained for <material_12> by means of <method_11> -lsb- 15 , 18 -rsb- . here , we analyze the relation between <otherscientificterm_2> -lrb- i.e. , <otherscientificterm_0> -rrb- and the underlying <otherscientificterm_6> , represented in terms of <otherscientificterm_10> and different kinds of <otherscientificterm_9> , using <material_3> with the true color information . we find that <otherscientificterm_4> correspond to <otherscientificterm_10> , and <otherscientificterm_13> are mainly formed by <otherscientificterm_1> . the results are discussed with regard to existing and potential <task_5> and the assumptions made by these applications .	7 8 14 -1 12 11 16 14 -1 2 0 6 10 9 3 15 17 14 -1 4 13 1 14 -1 5 14 -1
Towards combining pitch and MFCC for speaker recognition systems .	voiced and unvoiced speech segments ; short -- term pitch information ; short -- term dependence ; speaker recognition systems ; voiced speech segments ; joint probability functions ; vocal tract ; pattern recognizers ; spidre corpus ; identification rates ; time duration ; vocal source ; feature vectors ; slp ; lvq ; gmm ; mfcc	<material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <metric> <otherscientificterm> <material> <otherscientificterm> <method> <method> <method> <method>	13 6 7 ; 13 1 15 ; 15 6 7 ; 14 1 15 ; 14 6 7	usually , <method_3> do not take into account the <otherscientificterm_2> between the <material_11> and the <otherscientificterm_6> . a feasibility study that retains this dependence is presented here . a model of <otherscientificterm_5> of the pitch and the <otherscientificterm_12> is proposed . three strategies are designed and compared for all female speakers taken from the <material_8> . the first operates on all <material_0> -lrb- baseline strategy -rrb- . the second strategy considers only the <otherscientificterm_4> and the last includes the <otherscientificterm_1> along with the standard <method_16> . we use two <method_7> : <method_14> -- <method_13> and <method_15> . in all cases , we observe an increase in the <metric_9> and more specifically when using a <otherscientificterm_10> of 500 ms -lrb- 6 % higher -rrb- .	3 2 11 6 17 -1 17 -1 5 12 17 -1 8 17 -1 0 17 -1 4 1 16 17 -1 7 14 13 15 18 19 20 21 22 17 -1 17 -1
Inducing Ontological Co-occurrence Vectors .	lexical co-occurrence vectors ; semantic information ; top-5 positions ; attachment accuracy ; unsupervised methodology ; lexical-semantic resources ; wordnet ; accuracy ; ontology	<otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method> <material> <material> <metric> <otherscientificterm>	4 0 0 ; 6 6 8	in this paper , we present an <method_4> for propagating <otherscientificterm_0> into an <otherscientificterm_8> such as <material_6> . we evaluate the <method_4> on the task of automatically attaching new concepts into the <otherscientificterm_8> . experimental results show 73.9 % <metric_3> in the first position and 81.3 % <metric_7> in the <otherscientificterm_2> . this <method_4> could potentially serve as a foundation for on-tologizing <material_5> and assist the development of other large-scale and internally consistent collections of <otherscientificterm_1> .	4 0 8 6 10 11 9 -1 9 -1 3 7 2 9 -1 5 1 9 -1
An Agent Architecture for Prognostic Reasoning Assistance .	user intention recognition ; user 's intention ; software assistant agent ; normative reasoning ; assistive actions ; nor-mative reasoning ; time-constrained environment ; prohibitions ; execution ; replanning ; planning	<task> <otherscientificterm> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <task> <method> <method>	0 1 1 ; 0 1 10 ; 3 1 8 ; 1 1 8 ; 10 1 3 ; 8 1 9 ; 0 1 8 ; 1 1 3 ; 9 0 4 ; 10 1 9 ; 0 1 3 ; 10 1 8 ; 2 0 5	in this paper we describe a <method_2> that can proactively assist human users situated in a <otherscientificterm_6> to perform <task_5> -- reasoning about <otherscientificterm_7> and obligations -- so that the user can focus on her <method_10> objectives . in order to provide proactive assistance , the <method_2> must be able to 1 -rrb- recognize the user 's planned activities , 2 -rrb- reason about potential needs of assistance associated with those predicted activities , and 3 -rrb- plan to provide appropriate assistance suitable for newly identified user needs . to address these specific requirements , we develop an <method_2> that integrates <task_0> , <method_3> over a <otherscientificterm_1> , and <method_10> , <task_8> and <method_9> for <task_4> . this paper presents the <method_2> and discusses practical applications of this <method_2> .	2 6 5 7 10 24 11 -1 11 -1 12 13 14 15 16 17 18 19 20 21 22 23 11 -1 0 3 1 8 9 4 11 -1
Affine Projection Algorithm with Selective Regressors .	affine projection algorithm ; affine projection algorithm ; selective regressors ; input vectors ; adaptive filter ; weight vector ; cost functions ; lms-type filter ; computational complexity ; minimum disturbance ; complexity	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <metric>	2 0 1 ; 0 0 5 ; 9 0 6 ; 8 5 0	affine projection algorithm , which updates the <otherscientificterm_5> based on several previous <otherscientificterm_3> , is an useful <method_4> to improve the convergence speed of <method_7> . however , the <metric_8> of <method_0> highly depends on the number of <otherscientificterm_3> used for update . in this paper , we propose <method_1> with <method_2> whose purpose is to reduce <metric_10> by selecting a subset of input regressors at every iteration . the optimal selection of input regressors is derived by comparing the <otherscientificterm_6> based on the principle of <otherscientificterm_9> . the new <method_1> show good convergence performance as attested to by various experimental results .	5 3 4 7 13 11 -1 8 0 15 11 -1 1 2 10 12 11 -1 6 9 14 11 -1 11 -1
Correlation Filters with Limited Boundaries .	inherent computational redundancies ; correlation filter estimation ; learning process ; fourier domain ; computational efficiency ; vision community ; correlation filters ; correlation filters ; frequency domain ; object tracking ; boundary effects ; mosse ; detection ; accuracy	<otherscientificterm> <task> <task> <material> <metric> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <task> <metric>	11 6 6 ; 13 1 4	correlation filters take advantage of specific properties in the <material_3> allowing them to be estimated efficiently : o -lrb- n d log d -rrb- in the <otherscientificterm_8> , versus o -lrb- d 3 + n d 2 -rrb- spatially where d is signal length , and n is the number of signals . recent extensions to <method_6> , such as <method_11> , have reignited interest of their use in the <method_5> due to their robustness and attractive computational properties . in this paper we demonstrate , however , that this <metric_4> comes at a cost . specifically , we demonstrate that only 1 d proportion of shifted examples are unaffected by <otherscientificterm_10> which has a dramatic effect on detection/tracking performance . in this paper , we propose a novel approach to <task_1> that : -lrb- i -rrb- takes advantage of <otherscientificterm_0> in the <otherscientificterm_8> , -lrb- ii -rrb- dramatically reduces <otherscientificterm_10> , and -lrb- iii -rrb- is able to implicitly exploit all possible patches densely extracted from training examples during <task_2> . impressive <task_9> and <task_12> results are presented in terms of both <metric_13> and <metric_4> .	3 8 14 -1 6 11 5 15 14 -1 4 14 -1 14 -1 10 14 -1 1 0 2 16 14 -1
Nonstationary Gaussian Process Regression for Evaluating Repeated Clinical Laboratory Tests .	cost-driven assessments of oversampling ; nonstationary latent function ; latent physio-logic function ; monitoring physiologic state ; retrospective analysis ; latent func-tion ; latent function ; gaussian process ; adaptive strategy ; undersampling ; oversampling ; sampling	<task> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <task>	9 4 10 ; 7 0 1	sampling repeated clinical laboratory tests with appropriate timing is challenging because the <otherscientificterm_2> being sampled is in general nonstation-ary . when ordering repeated tests , clinicians adopt various simple strategies that may or may not be well suited to the behavior of the function . previous research on this topic has been primarily focused on <task_0> . but for <task_3> or for <task_4> , <task_9> can be much more problematic than <method_10> . in this paper we analyze hundreds of observation sequences of four different clinical laboratory tests to provide princi-pled , data-driven estimates of <task_9> and over-sampling , and to assess whether the <task_11> adapts to changing volatility of the <otherscientificterm_6> . to do this , we developed a new method for fitting a <method_7> to samples of a <otherscientificterm_1> . our method includes an explicit estimate of the <otherscientificterm_5> 's volatility over time , which is deterministically related to its nonstationarity . we find on average that the degree of <task_9> is up to an order of magnitude greater than <method_10> , and that only a small minority are sampled with an <method_8> .	2 12 -1 12 -1 0 12 -1 3 4 9 10 13 12 -1 12 -1 11 6 14 12 -1 7 1 12 -1 5 12 -1
Covariance shrinkage for autocorrelated data .	real world data set ; high dimensional settings ; finite sample sizes ; pronounced estimation bias ; machine learning algorithms ; eeg-based brain-computer-interfacing experiment ; regularization strategies ; sancetta estimator ; high-dimensional limit ; i.i.d. data ; toy data ; analytic shrinkage ; sample covariance ; hyperparame-ter choice ; signal processing ; shrinkage framework ; covariance matrices	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm>	11 6 6 ; 14 1 4	the accurate estimation of <otherscientificterm_16> is essential for many <task_14> and <method_4> . in <otherscientificterm_1> the <otherscientificterm_12> is known to perform poorly , hence <method_6> such as <otherscientificterm_11> of ledoit/wolf are applied . in the standard setting , <material_9> is assumed , however , in practice , time series typically exhibit strong autocorrela-tion structure , which introduces a <otherscientificterm_3> . recent work by sancetta has extended the <method_15> beyond <material_9> . we contribute in this work by showing that the <method_7> , while being consistent in the <otherscientificterm_8> , suffers from a high bias in <otherscientificterm_2> . we propose an alternative estimator , which is -lrb- 1 -rrb- unbiased , -lrb- 2 -rrb- less sensitive to <otherscientificterm_13> and -lrb- 3 -rrb- yields superior performance in simulations on <material_10> and on a <material_0> from an <otherscientificterm_5> .	16 14 4 19 17 -1 1 12 6 11 18 17 -1 9 3 17 -1 15 17 -1 7 8 2 17 -1 17 -1
Intelligent Agent Supporting Human-Multi-Robot Team Collaboration .	myopic advice optimization problem ; search and rescue task ; operator 's satisfaction ; field applications ; multi-robot systems	<task> <task> <metric> <task> <method>	4 0 3	the number of <method_4> deployed in <task_3> has risen dramatically over the years . nevertheless , supervising and operating multiple robots at once is a difficult task for a single operator to execute . in this paper we propose a novel approach for utilizing advising automated agents when assisting an operator to better manage a team of multiple robots in complex environments . we introduce the <task_0> and exemplify its implementation using an agent for the <task_1> . our intelligent advising agent was evaluated through extensive field trials , with 44 non-expert human operators and 10 low-cost mobile robots , in simulation and physical deployment , and showed a significant improvement in both team performance and the <metric_2> .	4 3 6 5 -1 5 -1 5 -1 0 1 5 -1 5 -1
Detection of spread-spectrum signals in a multi-user environment .	direct-sequence spread-spectrum multiple access ; linear and non-linear structures ; impulsive channel noise ; spread digital signals ; stochastic multi-variate signal ; adaptive multiuser de-modulators ; locally optimum detector ; correlator based structures ; adaptive multiuser demodulators ; asymptotic normality ; hybrid detector ; spread-spectrum signals ; moderate complexity ; performance measure ; distribution-free detectors ; complexity	<task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <material> <metric> <metric> <method> <metric>	1 2 10 ; 2 2 4 ; 5 0 0 ; 6 0 4	motivated by a previous study of <method_5> for <task_0> , detectors for <material_11> are investigated . due to the prohibitive <metric_15> of the <method_6> for such a <otherscientificterm_4> in <otherscientificterm_2> , <metric_12> , <method_14> are pursued . in particular , the diierential snrs -lrb- processing gain -rrb- of <otherscientificterm_7> are determined . this <metric_13> is apt given the relatively low signal strength of <material_3> . the numerical results -lrb- in the context of the prior investigation of <method_8> -rrb- impel the development of a <method_10> which is composed of <otherscientificterm_1> . the <otherscientificterm_9> of the test statistics under study is also examined .	5 0 11 19 16 -1 15 6 4 2 12 14 18 20 16 -1 7 16 -1 13 3 16 -1 8 10 1 17 16 -1 9 16 -1
Automatic Error Recovery for Pronunciation Dictionaries .	multilingual wiki-based open content dictionary ; english wik-tionary word-pronunciation pairs ; globalphone hausa pronunciation dictionary ; mandarin-english seame code-switch dictionary ; word error rate ; pronunciation modeling ; automatic methods ; pronunciation dictionaries ; french ; asr ; german ; polish ; czech ; english	<material> <material> <material> <material> <metric> <task> <method> <material> <material> <task> <material> <material> <material> <material>	8 1 10 ; 13 1 10 ; 10 1 11 ; 12 1 13 ; 13 1 8 ; 12 1 8 ; 8 1 11 ; 10 1 0 ; 10 1 10 ; 11 1 2	in this paper , we present our latest investigations on <task_5> and its impact on <task_9> . we propose completely <method_6> to detect , remove , and substitute inconsistent or flawed entries in <material_7> . the experiments were conducted on different tasks , namely -lrb- 1 -rrb- word-pronunciation pairs from the <material_12> , <material_13> , <material_8> , <material_10> , <material_11> , and spanish wiktionary -lsb- 1 -rsb- , a <material_0> , -lrb- 2 -rrb- our <material_2> -lsb- 2 -rsb- , and -lrb- 3 -rrb- pronunciations to complement our <material_3> -lsb- 3 -rsb- . in the final results , we fairly observed on average an improvement of 2.0 % relative in terms of <metric_4> and even 27.3 % for the case of <material_1> .	5 9 14 -1 6 7 14 -1 12 13 8 10 11 0 2 3 15 16 17 18 19 20 21 22 23 24 14 -1 14 -1
Robust PCA neural networks for random noise reduction of the data .	principal component analysis approach ; 1-dimensional and 2-dimensional data ; realized compression ratio ; reduction of noise ; noise strength ; loss tolerance ; lossy compression ; noise ltering ; de-compressed signal ; compression/decompression ; noise ; de-compression	<method> <material> <metric> <otherscientificterm> <metric> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method>	0 0 3 ; 1 0 7 ; 6 1 11 ; 10 1 5	the paper presents <method_0> to the <otherscientificterm_3> contaminating the data . the <method_0> performs the role of <method_6> and <method_11> . the <method_9> provides the means of coding the data and then recovering <method_0> with some losses , dependent on the <metric_2> . in this process some part of information contained in the data is lost . when the <otherscientificterm_5> is equal to the <metric_4> , the <otherscientificterm_10> and the <otherscientificterm_5> are augmented and the <otherscientificterm_8> is deprived of <otherscientificterm_10> . this way of <task_7> has been checked on the examples of <material_1> and the results of numerical experiments have been included in the paper .	0 3 13 12 -1 6 11 15 12 -1 9 2 12 -1 12 -1 5 4 10 8 16 12 -1 7 1 14 12 -1
Stack-propagation : Improved Representation Learning for Syntax .	part-of-speech information ; reg-ularizer of learned representations ; dependency parsing and tagging ; predicted pos tags ; syntax models ; pos tags ; greedy model ; graph-based approach ; hand-tuned templates ; universal dependencies ; hidden layer ; tagger network ; features	<otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm>	7 4 6 ; 8 0 4 ; 8 0 12 ; 0 0 4 ; 5 0 1 ; 12 0 4 ; 12 0 0	traditional <method_4> typically leverage <otherscientificterm_0> by constructing <otherscientificterm_12> from <otherscientificterm_8> . we demonstrate that a better approach is to utilize <otherscientificterm_5> as a <method_1> . we propose a simple method for learning a stacked pipeline of <method_4> which we call '' stack-propagation '' . we apply this to <task_2> , where we use the <otherscientificterm_10> of the <method_11> as a representation of the input tokens for the parser . at test time , our parser does not require <otherscientificterm_3> . on 19 languages from the <material_9> , our method is 1.3 % -lrb- absolute -rrb- more accurate than a state-of-the-art <method_7> and 2.7 % more accurate than the most comparable <method_6> .	4 0 12 8 15 16 17 19 20 13 -1 5 1 18 13 -1 13 -1 2 10 11 13 -1 3 13 -1 9 14 13 -1
A Rote Extractor with Edit Distance-Based Generalisation and Multi-Corpora Precision Calculation .	pattern accuracy calculation procedure ; edit-distance-based pattern generalization algorithm ; named entity categories ; part-of-speech tags ; pattern generalization ; rote extrac-tor ; semantic relationships ; unrestricted text ; precision ; generalization	<method> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <material> <metric> <task>	3 0 9 ; 7 0 6 ; 8 5 5 ; 1 1 0 ; 5 0 6	in this paper , we describe a <method_5> that learns patterns for finding <otherscientificterm_6> in <material_7> , with new procedures for <task_4> and scoring . these include the use of <method_3> to guide the <task_9> , <otherscientificterm_2> inside the patterns , an <method_1> , and a <method_0> based on evaluating the patterns on several test corpora . in an evaluation with 14 entities , the <method_5> attains a <metric_8> higher than 50 % for half of the relationships considered .	5 6 7 4 12 15 10 -1 3 9 2 1 0 11 14 10 -1 8 13 10 -1
Robust Repositioning to Counter Unpredictable Demand in Bike Sharing Systems .	bike sharing systems ; online and robust repositioning approach ; iterative two player game ; real world data ; scenario generation approach ; myopic reasoning ; bsss operators ; repositioning solution	<method> <method> <method> <material> <method> <method> <method> <method>	2 0 4	bike sharing systems -lrb- bsss -rrb- experience a significant loss in customer demand due to starvation -lrb- empty base stations precluding bike pickup -rrb- or congestion -lrb- full base stations precluding bike return -rrb- . therefore , <method_6> reposition bikes between stations with the help of carrier vehicles . due to unpredictable and dynamically changing nature of the demand , <method_5> typically provides a below par performance . we propose an <method_1> to min-imise the loss in customer demand while considering the possible uncertainty in future demand . specifically , we develop a <method_4> based on an <method_2> to compute a strategy of repositioning by assuming that the environment can generate a worse demand scenario -lrb- out of the feasible demand scenarios -rrb- against the current <method_7> . extensive computational results from a simulation built on <material_3> set of bike sharing company demonstrate that our <method_1> can significantly reduce the expected lost demand over the existing benchmark approaches .	8 -1 6 8 -1 5 8 -1 1 8 -1 4 2 9 8 -1 7 8 -1
Does String-Based Neural MT Learn Source Syntax ? .	neural , encoder-decoder translation system ; local and global source syntax ; syntactic structure ; syntactic information ; encoder ; syntax	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 3	we investigate whether a <method_0> learns <otherscientificterm_3> on the source side as a by-product of training . we propose two methods to detect whether the <otherscientificterm_4> has learned <otherscientificterm_1> . a fine-grained analysis of the <otherscientificterm_2> learned by the <otherscientificterm_4> reveals which kinds of <otherscientificterm_5> are learned and which are missing .	0 3 7 6 -1 4 1 6 -1 2 5 6 -1
Nuclear Norm Minimization via Active Subspace Selection .	alternating least squares ; non-smooth and smooth optimization ; matrix completion problems ; nuclear norm regulariza-tion ; matrix completion problem ; second order methods ; nuclear norm solvers ; netflix dataset ; active sub-space ; proximal gradient ; non-convex solvers ; yahoo-music dataset	<method> <method> <task> <otherscientificterm> <task> <method> <method> <material> <otherscientificterm> <otherscientificterm> <method> <material>	0 6 10 ; 9 0 8	we describe a novel approach to optimizing <task_2> involving <otherscientificterm_3> and apply it to the <task_4> . we combine methods from <method_1> . at each step we use the <otherscientificterm_9> to select an <otherscientificterm_8> . we then find a smooth , convex relaxation of the smaller subspace problems and solve these using <method_5> . we apply our methods to <task_2> including <material_7> , and show that they are more than 6 times faster than state-of-the-art <method_6> . also , this is the first paper to scale <method_6> to the <material_11> , and the first time in the literature that the efficiency of <method_6> can be compared and even compete with <method_10> like <method_0> .	2 3 4 12 -1 1 12 -1 9 8 14 12 -1 5 12 -1 7 6 12 -1 11 13 12 -1
A Scalable Message-Passing Algorithm for Supply Chain Formation .	supply chain formation ; max-sum loopy belief propagation ; decentralized scf problem ; binary factor graph ; binary variables ; optimization problem ; decentralized scf ; local information ; scalability	<task> <method> <task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <metric>	5 0 2 ; 1 0 5	supply chain formation -lrb- scf -rrb- is the process of determining the participants in a supply chain , who will exchange what with whom , and the terms of the exchanges . <method_6> appears as a highly intricate task because agents only possess <otherscientificterm_7> and have limited knowledge about the capabilities of other agents . the <task_2> has been recently cast as an <task_5> that can be efficiently approximated using <method_1> . along this direction , in this paper we propose a novel encoding of the <task_2> into a <method_3> -lrb- containing only <otherscientificterm_4> -rrb- as well as an alternative algorithm . we empirically show that our approach allows to significantly increase <metric_8> , hence allowing to form supply chains in market scenarios with a large number of participants and high competition .	6 9 -1 7 9 -1 2 5 1 10 11 9 -1 3 4 9 -1 9 -1
Sudden noise reduction based on GMM with noise power estimation .	noise detection and classification methods ; estimation of noise power ; detection and classification results ; sudden noise detection ; recognition of utterances ; noise power estimation ; noise reduction method ; gmm-based noise reduction ; sudden noise ; noise ; classification	<method> <method> <metric> <task> <task> <task> <method> <task> <otherscientificterm> <otherscientificterm> <task>	1 0 7 ; 3 1 10 ; 1 1 6	this paper describes a method for reducing <otherscientificterm_8> using <method_0> , and <task_5> . <task_3> and <task_10> have been dealt with in our previous study . in this paper , <task_7> is performed using the <metric_2> . as a result of <task_10> , we can determine the kind of <otherscientificterm_9> we are dealing with , but the power is unknown . in this paper , this <task_7> is solved by combining an <method_1> with the <method_6> . in our experiments , the proposed method achieved good performance for <task_4> overlapped by sudden noises .	8 0 5 3 11 -1 10 13 11 -1 7 2 11 -1 9 11 -1 1 6 12 14 11 -1 4 11 -1
Gesture image sequence interpretation using the multi-PDM method and hidden Markov model .	hidden markov model ; multi-principal-distribution-model method ; gesture image sequence interpretation ; individual pdm shape model ; patterns of variability ; model transition sequence ; pdm shape model ; training hand shapes ; continuous gestures ; gesture recognition ; pdm model ; annotated images ; model transition ; hand-shape	<method> <method> <task> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <task> <method> <material> <otherscientificterm> <otherscientificterm>	1 0 2 ; 0 0 12 ; 1 0 8 ; 0 0 2 ; 1 1 0 ; 10 0 1 ; 0 0 6	this paper introduces a <method_1> and <method_0> for <task_2> . to track the <otherscientificterm_13> , <method_1> uses the <method_10> which is built by learning <otherscientificterm_4> from a training set of correctly <material_11> . for <task_9> , we need to deal with a large variety of <otherscientificterm_13> . therefore , we divide all the <otherscientificterm_7> into a number of similar groups , with each group trained for an <method_3> . finally , we use the <method_0> to determine <otherscientificterm_12> among these <method_6> . from the <material_5> , <method_1> can identify the <otherscientificterm_8> denoting one-digit or two-digit numbers .	1 0 2 15 18 19 14 -1 13 10 4 11 20 14 -1 9 14 -1 7 3 14 -1 12 6 16 21 14 -1 5 8 17 14 -1
The ester 2 evaluation campaign for the rich transcription of French radio broadcasts .	automatic radio broadcasts rich transcription systems ; ester 2 evaluation ; audio event detection ; french language ; evaluation protocols ; information extraction ; speaker tracking ; ortho-graphic transcription ; tracking	<task> <metric> <task> <material> <metric> <task> <task> <task> <task>	2 1 8 ; 2 1 6 ; 2 1 7 ; 6 1 7 ; 7 1 5 ; 6 1 8	this paper reports on the final results of the <metric_1> campaign held from 2007 to april 2009 . the aim of this campaign was to evaluate <task_0> for the <material_3> . the evaluation tasks were divided into three main categories : <task_2> and <task_8> -lrb- e.g. , speech vs. music , <task_6> -rrb- , <task_7> , and <task_5> . the paper describes the data provided for the campaign , the task definitions and <metric_4> as well as the results .	1 9 -1 0 3 9 -1 2 8 6 7 5 10 11 12 13 14 15 9 -1 4 9 -1
Factoring Synchronous Grammars by Sorting .	synchronous context-free grammars ; machine translation applications ; recognizing permutations ; translation models ; computational complexity ; rules ; parsing	<method> <task> <task> <method> <metric> <otherscientificterm> <task>	0 0 3 ; 3 0 1 ; 0 0 1 ; 0 0 6	synchronous context-free grammars -lrb- scfgs -rrb- have been successfully exploited as <method_3> in <task_1> . when <task_6> with an <method_0> , <metric_4> grows exponentially with the length of the <otherscientificterm_5> , in the worst case . in this paper we examine the problem of factorizing each rule of an input <method_0> to a generatively equivalent set of <otherscientificterm_5> , each having the smallest possible length . our algorithm works in time o -lrb- n log n -rrb- , for each rule of length n . this improves upon previous results and solves an open problem about <task_2> that can be factored .	3 1 8 9 10 7 -1 6 0 4 5 11 7 -1 7 -1 7 -1 2 7 -1
Improving deep neural networks for LVCSR using dropout and shrinking structure .	70-hour mandarin transcription task ; hidden markov models ; 309-hour switchboard task ; shrinking dnn structure ; greedy layer-wise pre-trained dnn ; hybrid deep neural networks ; relative recognition error reduction ; psc and swb tasks ; back-propagation ; gmm/hmms method ; computation time ; dnn prior ; test time ; swb task ; model size ; recognition accuracy ; hidden layers ; dropout ; dap	<task> <method> <material> <method> <method> <method> <metric> <task> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method>	6 5 7 ; 2 5 3 ; 1 4 9 ; 13 5 18 ; 5 1 1 ; 3 0 7 ; 0 5 3 ; 6 5 3	recently , the <method_5> and <method_1> have achieved dramatic gains over the conventional <method_9> on various large vocabulary continuous speech recognition -lrb- lvcsr -rrb- tasks . in this paper , we propose two new methods to further improve the <method_1> : i -rrb- use <otherscientificterm_17> as pre-conditioner -lrb- <method_18> -rrb- to initialize <otherscientificterm_11> to <method_8> for better <metric_15> ; ii -rrb- employ a <method_3> with <otherscientificterm_16> decreasing in size from bottom to top for the purpose of reducing <otherscientificterm_14> and expediting <otherscientificterm_10> . the proposed <method_3> is evaluated in a <task_0> and the <material_2> . compared with the traditional <method_4> , <method_3> can achieve about 10 % and 6.8 % <metric_6> for <task_7> respectively . in addition , we also evaluate <method_3> as well as its combination with <method_18> on the <task_13> . experimental results show that these methods can reduce <otherscientificterm_14> to 45 % of original size and accelerate training and <metric_12> by 55 % , without losing <metric_15> .	5 1 9 22 24 19 -1 17 18 11 8 15 3 16 14 10 19 -1 0 2 21 26 19 -1 4 20 25 27 19 -1 6 7 23 19 -1 13 19 -1
Using the GEMS System for Cancer Diagnosis and Biomarker Discovery from Microarray Gene Expression Data .	microarray gene expression data ; microarray datasets ; algorithmic evaluation ; gems system ; biomarker discovery ; human analysts	<material> <material> <method> <method> <task> <method>	1 0 2 ; 3 0 4 ; 1 5 3 ; 2 0 3 ; 0 0 3 ; 1 0 3	we will demonstrate the <method_3> for automated development and evaluation of high-quality cancer diagnostic models and <task_4> from <material_0> . the development of <method_3> was informed by the results of an extensive <method_2> using 11 <material_1> . the <method_3> was further evaluated in two cross-dataset applications and using 5 <material_1> . the performance of models produced by <method_3> is comparable or better than the results obtained by <method_5> , and these models generalize well to independent samples in cross-dataset applications . the <method_3> is freely available for download from http://www.gems-system.org for non-commercial use .	3 4 0 8 11 6 -1 2 1 7 10 12 6 -1 9 6 -1 5 6 -1 6 -1
Training structural SVMs when exact inference is intractable .	approximate trained structural svms ; theoretical and empirical analysis ; structural svm -rrb- ; approximate training methods ; approximate training algorithms ; relaxed trained models ; relaxations -rrb- algorithms ; image segmentation ; structural svms ; undergenerating methods ; overgenerating methods ; machine translation ; relaxed predictors ; discriminative training ; approximate training ; non-fractional predictions ; clustering	<method> <method> <method> <method> <method> <method> <method> <task> <method> <method> <method> <task> <otherscientificterm> <method> <task> <otherscientificterm> <task>	10 4 9 ; 2 0 11 ; 11 1 7 ; 13 0 11 ; 7 1 16 ; 12 0 15	while <method_13> -lrb- e.g. , crf , <method_2> holds much promise for <task_11> , <task_7> , and <task_16> , the complex inference these applications require make exact training intractable . this leads to a need for <method_3> . unfortunately , knowledge about how to perform efficient and effective <task_14> is limited . focusing on <method_8> , we provide and explore algorithms for two different classes of <method_4> , which we call undergenerating -lrb- e.g. , greedy -rrb- and overgenerating -lrb- e.g. , <method_6> . we provide a <method_1> of both types of <method_0> , focusing on fully connected pairwise markov random fields . we find that models trained with <method_10> have theoretic advantages over <method_9> , are empirically robust relative to their undergenerating brethren , and <method_5> favor <otherscientificterm_15> from <otherscientificterm_12> .	13 2 11 7 16 19 20 21 22 17 -1 3 17 -1 14 17 -1 8 4 6 17 -1 1 0 17 -1 18 23 17 -1
Multi-modal sensor localization using a mobile access point .	mobile access point ; doppler and time delay ; randomly deployed sensor network ; sensor node localization ; radio and acoustics ; angle of arrival ; sensor local-ization algorithms ; pre-established sensor network ; radio broadcasts timing ; acoustic propagation effects ; acoustic signal parameters ; location information ; acoustic emission ; multi-modal approach ; doppler stretch ; time delay ; broadcast mode ; sensor node ; turbulent atmosphere	<material> <task> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	11 1 10 ; 10 0 17 ; 14 1 15 ; 18 0 9 ; 4 0 13 ; 0 0 2 ; 8 1 11 ; 15 1 5	we consider the problem of <task_3> in a <method_2> , using a <material_0> . the <material_0> can be used to localize many sensors simultaneously in a <otherscientificterm_16> , without a <method_7> . we consider a <method_13> , combining <otherscientificterm_4> . the <task_8> , <otherscientificterm_11> , and <otherscientificterm_10> . the <otherscientificterm_12> may be used at the sensor to measure <otherscientificterm_14> , <otherscientificterm_15> , and <otherscientificterm_5> . these <otherscientificterm_10> are individually sufficient to localize a <otherscientificterm_17> , or they may be advantageously combined . we focus on the cases of <task_1> . <method_6> are developed , and performance analysis includes <otherscientificterm_9> caused by the <otherscientificterm_18> .	3 2 0 25 19 -1 16 7 19 -1 13 4 24 19 -1 8 11 10 20 26 19 -1 12 14 15 5 22 27 19 -1 17 21 19 -1 1 6 19 -1 9 23 19 -1
Tracking a hand manipulating an object .	pairwise markov random field ; anatomical hand structure ; individual local tracker ; classical anatomical constraints ; ground truth ; external forces ; articulated structure ; synthetic data ; partial occlusions ; belief propagation ; hand configuration ; soft constraints ; hand-tracking ; self-occlusions ; robustness	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric>	9 0 10	we present a method for tracking a hand while it is interacting with an object . this setting is arguably the one where <method_12> has most practical relevance , but poses significant additional challenges : strong occlusions by the object as well as <otherscientificterm_13> are the norm , and <otherscientificterm_3> need to be softened due to the <otherscientificterm_5> between hand and object . to achieve <metric_14> to <otherscientificterm_8> , we use an <method_2> for each segment of the <otherscientificterm_6> . the segments are connected in a <otherscientificterm_0> , which enforces the <otherscientificterm_1> through <otherscientificterm_11> on the joints between adjacent segments . the most likely <otherscientificterm_10> is found with <method_9> . both range and color data are used as input . experiments are presented for <material_7> with <material_4> and for real data of people manipulating objects .	15 -1 12 13 3 5 15 -1 14 8 2 6 15 -1 0 1 11 15 -1 16 15 -1 10 9 15 -1 15 -1
Optimal time-of-use electricity pricing using game theory .	demand-side management method ; game theory ; time-of-use pricing ; optimal tou pricing strategy ; fluctuating user demands ; user satisfaction measurement ; nash equilibrium ; user demand ; utility functions ; iterative methods ; user demands ; backward induction	<method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method>	1 0 3 ; 11 1 9 ; 9 0 6 ; 0 0 10	typical <otherscientificterm_10> of electricity vary throughout the day , which increases the cost to utility companies and decreases the stability of the power system . <method_2> has been proposed as a <method_0> to influence <otherscientificterm_10> . in this paper , we describe a new approach of <method_3> based on <method_1> . we propose models for costs due to the <otherscientificterm_4> to the utility companies , as well as the <method_5> because of the difference between the demand and actual load . we design <otherscientificterm_8> for the company and the user , and obtain the <otherscientificterm_6> using <method_11> and <method_9> . numerical example shows that our method is effective in lev-eling the <metric_7> by setting optimal tou prices , in potentially increasing the profit of the utility companies and ensuring overall user benefit .	10 2 12 -1 0 16 12 -1 3 1 13 12 -1 4 5 12 -1 8 6 11 9 14 15 12 -1 12 -1
Distance-Bounded Consistent Query Answering .	consistent query answering ; inconsistent data ; computational complexity ; reasoning ; ai	<task> <material> <metric> <task> <task>	1 0 3	the ability to perform <task_3> on <material_1> is a central problem both for <task_4> and database research . one approach to deal with this situation is <task_0> , where queries are answered over all possible repairs of the database . in general , the repair may be very distant from the original database . in this work we present a new approach where this distance is bounded and analyze its <metric_2> . our results show that in many -lrb- but not all -rrb- cases the complexity drops .	3 1 4 6 5 -1 0 5 -1 5 -1 2 5 -1 5 -1
Transform/subband representations for signals with arbitrarily shaped regions of support .	signal processing algorithms ; arbitrary-length 1-d signals ; transform/subband representations ; as signals ; as signal ; innite-length signals ; wavelet representations ; nite-length 1-d ; representations	<method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	6 0 1 ; 2 0 0 ; 8 0 5	transform/subband <method_8> form a basic building block for many <method_0> and applications . most of the eort has focused on developing <method_8> for <otherscientificterm_5> , with simple extensions to <otherscientificterm_7> and rectangular support 2-d signals . however , many signals may h a v e arbitrary length or arbitrarily shaped -lrb- as -rrb- regions of support -lrb- ros -rrb- . we present a novel framework for creating critically sampled perfect reconstruction transform/subband <method_8> for <otherscientificterm_3> . our method selects an appropriate subset of vectors from an -lrb- easily obtained -rrb- basis for a larger -lrb- superset -rrb- signal space , in order to form a basis for the <otherscientificterm_4> . in particular , we have developed a number of promising <method_6> for <material_1> and as 2-d/m-d signals that provide high performance with low complexity .	8 0 11 9 -1 5 7 12 9 -1 9 -1 3 9 -1 9 -1 4 10 9 -1
Learning a Distance Metric by Empirical Loss Minimization .	loss function based metric learning framework ; smoothed hinge loss function ; log loss function ; mild conditions ; instance distribution	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 1 1	in this paper , we study the problem of learning a metric and propose a <method_0> , in which the metric is estimated by minimizing an empirical risk over a training set . with <otherscientificterm_3> on the <otherscientificterm_4> and the used loss function , we prove that the empirical risk converges to its expected counterpart at rate of root-n . in addition , with the assumption that the best metric that minimizes the expected risk is bounded , we prove that the learned metric is consistent . two example algorithms are presented by using the proposed <method_0> , each of which uses a <otherscientificterm_2> and a <otherscientificterm_1> , respectively . experimental results suggest the effectiveness of the proposed algorithms .	0 5 -1 3 4 5 -1 5 -1 6 5 -1 2 1 5 -1
Word Representations : A Simple and General Method for Semi-Supervised Learning .	supervised nlp system ; unsupervised word representations ; nlp systems ; word features ; word representations ; supervised baselines ; brown clusters ; ner ; accuracy	<method> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <metric>	3 0 2 ; 1 0 0	if we take an existing <method_0> , a simple and general way to improve <metric_8> is to use <method_1> as extra <otherscientificterm_3> . we evaluate <method_6> , collobert and weston -lrb- 2008 -rrb- embeddings , and hlbl -lrb- mnih & hinton , 2009 -rrb- embeddings of words on both <otherscientificterm_7> and chunking . we use near state-of-the-art <method_5> , and find that each of the three <method_4> improves the <metric_8> of these baselines . we find further improvements by combining different <method_4> . you can download our <otherscientificterm_3> , for off-the-shelf use in existing <method_2> , as well as our <otherscientificterm_3> , here : http://metaoptimize . com/projects/wordreprs /	0 8 1 3 11 9 -1 6 7 9 -1 5 4 9 -1 9 -1 2 10 9 -1 9 -1
Using Text Reviews for Product Entity Completion .	real life data collection ; enterprise internal product descriptions ; external text data sources ; product data quality solutions ; domain specific rulesets ; composing attributes ; external data ; missing values ; brand name ; attribute-value pairs ; product descriptions ; structured information ; size ; color	<material> <material> <material> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	12 1 13 ; 1 1 6	in this paper we address the problem of obtaining <otherscientificterm_11> about products in the form of <otherscientificterm_9> by leveraging a combination of <material_1> and <material_6> . <material_10> are short text <material_10> used internally within enterprises to describe a product . these <material_10> usually comprise of the <otherscientificterm_8> , name of the product , and its attributes like <otherscientificterm_12> , <otherscientificterm_13> , etc. . existing <method_3> provide us the capability to standardize and segment these descriptions into their <otherscientificterm_5> using <otherscientificterm_4> . we provide techniques that can leverage the supervision provided by these existing rulesets for extracting <otherscientificterm_7> from other <material_2> accurately . we use a large <material_0> to demonstrate the effectiveness of our approach .	11 9 1 6 10 16 14 -1 14 -1 8 12 13 15 14 -1 3 5 4 14 -1 7 2 14 -1 14 -1
Ask , and Shall You Receive ? Understanding Desire Fulfillment in Natural Language Text .	unstructured and structured models ; narrative and discourse structure ; natural language understanding ; fulfillment cues	<method> <otherscientificterm> <task> <otherscientificterm>	0 0 3	the ability to comprehend wishes or desires and their fulfillment is important to <task_2> . this paper introduces the task of identifying if a desire expressed by a subject in a given short piece of text was fulfilled . we propose various <method_0> that capture <otherscientificterm_3> such as the subject 's emotional state and actions . our experiments with two different datasets demonstrate the importance of understanding the <otherscientificterm_1> to address this task .	2 4 -1 4 -1 0 3 5 4 -1 1 4 -1
Mel , linear , and antimel frequency cepstral coefficients in broad phonetic regions for telephone speaker recognition .	nasal and non-nasal consonant regions ; speaker discriminative power of mel ; physiological characteristics of speakers ; filterbank energy f-ratio analysis ; speaker discriminative power ; nasal , vowel ; vowel region ; cepstral coefficients ; filterbank energies ; telephone bandwidth ; non-telephone speech ; telephone speech ; a-mfccs ; speech	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material> <material> <otherscientificterm> <material>	12 4 12 ; 11 0 12	we 've examined the <method_1> - , antimel-and linear-frequency <otherscientificterm_7> -lrb- <otherscientificterm_12> , <otherscientificterm_12> and <otherscientificterm_12> -rrb- in the <otherscientificterm_5> , and non-nasal consonant <material_13> regions . our inspiration came from the work of lu and dang in 2007 , who showed that <material_8> at some frequencies mainly outside the <otherscientificterm_9> possess more <otherscientificterm_4> due to <otherscientificterm_2> , and derived a set of <otherscientificterm_7> that outperformed <otherscientificterm_12> in <material_10> . using <material_11> , we 've discovered that <otherscientificterm_12> gave 21.5 % and 15.0 % relative eer improvements over <otherscientificterm_12> in <otherscientificterm_0> , agreeing with our <method_3> . we 've also found that using only the <otherscientificterm_6> with <otherscientificterm_12> gives a 9.1 % relative improvement over using all <material_13> . last , we 've shown that <otherscientificterm_12> are valuable in combination , contributing to a system with 17.3 % relative improvement over our baseline .	1 7 12 5 13 14 -1 8 9 4 2 10 14 -1 11 0 3 15 16 14 -1 14 -1 6 14 -1
Performance costs for theoretical minimal-length equalizers .	impulse response duration ; governing design rules ; equalizer implementa-tional complexity ; linear equalizer filter ; complexity reduction ; minimal-length equalizer ; linear equalizer ; composite distortion ; intersymbol interference ; complexity	<otherscientificterm> <otherscientificterm> <metric> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	9 5 3 ; 6 0 8	the length and <metric_9> of a <method_3> is highly dependent on the nature of the channel effects it must mitigate . the <otherscientificterm_1> are typically stated in terms of the channel 's temporal characteristics , i.e. <otherscientificterm_0> . <metric_2> is a principal limiting factor for high bandwidth data communication applications , and consequently there is motivation for reexamining accepted design guidelines . recently , it was demonstrated in -lsb- 1 -rsb- that for relatively benign conditions on the effective channel and transmitter pulse shaping , there exists a <otherscientificterm_6> that perfectly mitigates <otherscientificterm_8> , and whose span matches that of the <otherscientificterm_7> . our paper examines the implications of the <otherscientificterm_5> in light of accepted design rules , and shows that a tangible loss in performance can be assigned to this <metric_4> . actual line-of-sight microwave radio channels are used to demonstrate the nature of the performance loss .	9 3 11 10 -1 1 0 2 10 -1 10 -1 6 8 12 10 -1 7 10 -1 5 4 10 -1
Polarization Multiplexing for Bidirectional Imaging .	diffuse and specular reflectance components ; multiple unknown light sources ; surface reflectance contributions ; light source direction ; overall surface reflectance ; polarization multiplexing ; appearance-based modeling ; intensity modulation ; phase his-tograms ; appearance modeling ; illumination direction ; bidirectional imaging ; intensity modulations ; scene properties ; polarization	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	12 0 8 ; 14 0 0 ; 3 1 7 ; 14 0 11 ; 14 0 2 ; 14 3 6 ; 8 0 13 ; 9 1 11	our goal is to incorporate <otherscientificterm_14> in <task_6> in an efficient and meaningful way . <otherscientificterm_14> has been used in numerous prior studies for separating <otherscientificterm_0> , but in this work we show that <otherscientificterm_14> also can be used to separate <otherscientificterm_2> from individual light sources . our approach is called <method_5> and <otherscientificterm_14> has significant impact in <task_9> and <task_11> where the image as a function of <otherscientificterm_10> is needed . <material_1> can illuminate the scene simultaneously , and the individual contributions to the <otherscientificterm_4> can be estimated . to develop the method of <method_5> , we use a relationship between <otherscientificterm_3> and <otherscientificterm_7> . inverting this transformation enables the individual intensity contributions to be estimated . in addition to <method_5> , we show that <otherscientificterm_8> from the <otherscientificterm_12> can be used to estimate <otherscientificterm_13> including the number of light sources .	14 6 21 15 -1 0 2 17 20 15 -1 5 9 11 10 1 19 23 15 -1 4 15 -1 18 15 -1 3 7 15 -1 16 22 15 -1
Regularization of Neural Networks using DropConnect .	regular-izing large fully-connected layers ; random subset of units ; image recognition benchmarks ; dropconnect-trained models ; neu-ral networks ; dropconnect ; dropout	<otherscientificterm> <otherscientificterm> <metric> <method> <method> <method> <method>	3 0 2 ; 6 1 5	we introduce <method_5> , a generalization of <method_6> -lrb- hinton et al. , 2012 -rrb- , for <otherscientificterm_0> within <method_4> . when training with <method_6> , a randomly selected subset of activations are set to zero within each layer . <method_5> instead sets a randomly selected subset of weights within the network to zero . each unit thus receives input from a <otherscientificterm_1> in the previous layer . we derive a bound on the generalization performance of both <method_6> and <method_5> . we then evaluate <method_5> on a range of datasets , comparing to <method_6> , and show state-of-the-art results on several <metric_2> by aggregating multiple <method_3> .	5 6 0 4 7 -1 7 -1 7 -1 1 7 -1 9 7 -1 8 7 -1
A Universal Catalyst for First-Order Optimization .	accelerated prox-imal point algorithm ; first-order optimization methods ; non-strongly convex objectives ; well-chosen auxiliary problems ; block coordinate descent ; convex objective ; proximal variants ; gradient descent ; ill-conditioned problems ; theoretical speed-up ; nesterov ; saga ; sag ; finito/miso ; svrg ; acceleration ; sdca	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	12 1 11 ; 4 1 12 ; 7 1 12 ; 4 1 11 ; 16 1 13 ; 11 1 16 ; 14 1 6 ; 11 1 14 ; 16 1 14 ; 14 1 13 ; 15 0 8 ; 7 1 4 ; 12 1 16 ; 13 1 6	we introduce a generic scheme for accelerating <method_1> in the sense of <method_10> , which builds upon a new analysis of the <method_0> . our approach consists of minimizing a <otherscientificterm_5> by approximately solving a sequence of <otherscientificterm_3> , leading to faster convergence . this strategy applies to a large class of algorithms , including <otherscientificterm_7> , <otherscientificterm_4> , <otherscientificterm_12> , <otherscientificterm_11> , <otherscientificterm_16> , <otherscientificterm_14> , <otherscientificterm_13> , and their <otherscientificterm_6> . for all of these methods , we provide <task_15> and explicit support for <otherscientificterm_2> . in addition to <otherscientificterm_9> , we also show that <task_15> is useful in practice , especially for <task_8> where we measure significant improvements .	1 10 0 17 -1 5 3 17 -1 7 4 12 11 16 14 13 6 18 19 20 21 22 23 24 25 26 27 29 30 31 17 -1 15 2 17 -1 9 28 17 -1
On simulation of first-order auto-regressive processes with near Laplace marginals .	stationary non-gaussian auto-regressive processes ; monte carlo rejection algorithms ; statistical signal processing ; time series model ; near-laplace marginal distributions ; complexity	<method> <method> <task> <method> <otherscientificterm> <metric>	0 0 2	the focus of this paper is the modeling of a class of <method_0> that often find applications in <task_2> . we propose a general simulation procedure for constructing a <method_3> with a <otherscientificterm_4> . our approach is based on a class of <method_1> . a theoretical analysis of the average <metric_5> of the proposed algorithms for simulating the <method_3> is included .	0 2 7 6 -1 3 4 6 -1 1 6 -1 5 6 -1
Collapsed Variational Inference for HDP .	collapsed variational latent dirichlet allocation ; dirichlet-multinomial ` topic ' models ; hyperparameters of dirichlet variables ; hierarchical dirichlet process ; model selection ; variational technique ; variational techniques ; variational algorithm ; marginal likelihood ; gibbs sampling ; inference ; hyperparameters ; accuracy	<otherscientificterm> <method> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <metric>	5 0 11 ; 0 6 5 ; 10 0 11 ; 7 0 3	a wide variety of <method_1> have found interesting applications in recent years . while <method_9> remains an important method of <task_10> in such <method_1> , <method_6> have certain advantages such as easy assessment of convergence , easy optimization without the need to maintain detailed balance , a bound on the <otherscientificterm_8> , and side-stepping of issues with topic-identifiability . the most accurate <method_5> thus far , namely <otherscientificterm_0> , did not deal with <method_4> nor did <method_5> include <task_10> for <otherscientificterm_11> . we address both issues by generalizing the technique , obtaining the first <method_7> to deal with the <method_3> and to deal with <method_2> . experiments show a significant improvement in <metric_12> .	1 13 -1 9 10 6 8 13 -1 5 0 4 11 14 15 16 13 -1 7 3 17 13 -1 2 13 -1
Organizational Issues Arising from the Integration of the Lexicon and Concept Network in a Text Understanding System .	lexical and encyclopaedic information ; knowledge bases arc ; text understanding system ; knowledge based system ; knowledge acquisition process ; text understanding ; conceptual information ; parsing process ; blackboard architecture ; target representation ; encyclopaedic information ; twig	<otherscientificterm> <otherscientificterm> <method> <method> <task> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method>	0 0 3 ; 3 0 5 ; 6 0 7 ; 11 6 2	a <method_3> for <task_5> will incorporate both <otherscientificterm_0> . the <otherscientificterm_0> is the basis of the <method_7> while the <otherscientificterm_10> forms the <method_9> and is used in the <task_4> . this paper describes <method_11> , a <method_2> where these two <otherscientificterm_1> integrated into one representation . there is some theoretical justification for this and <method_3> has the advantage of reducing duplication of information in the <method_3> . this integration also has the advantage of making <otherscientificterm_6> available during the <method_7> . most of all this integration of diverse information forms a natural basis for a <method_8> .	3 5 0 13 14 12 -1 7 10 9 4 12 -1 11 2 1 16 12 -1 12 -1 6 15 12 -1 8 12 -1
Global data association for multi-object tracking using network flows .	maximum-a-posteriori data association problem ; explicit occlusion model ; network flow based optimization method ; long-term inter-object occlu-sions ; termination of trajectories ; public pedestrian datasets ; min-cost flow algorithm ; multiple object tracking ; data association ; cost-flow network ; hypotheses pruning ; iterative approach ; non-overlap constraint	<task> <method> <method> <otherscientificterm> <otherscientificterm> <material> <method> <task> <task> <method> <method> <method> <otherscientificterm>	11 0 9 ; 2 0 7 ; 6 0 8 ; 6 4 11 ; 2 0 8 ; 8 0 7	we propose a <method_2> for <task_8> needed for <task_7> . the <task_0> is mapped into a <method_9> with a <otherscientificterm_12> on trajectories . the optimal <task_8> is found by a <method_6> in the <method_9> . the <method_9> is augmented to include an <method_1> to track with <otherscientificterm_3> . a solution to the <method_9> is found by an <method_11> built upon the original <method_6> . initialization and <otherscientificterm_4> and potential false observations are modeled by the formulation intrinsi-cally . the method is efficient and does not require <method_10> . performance is compared with previous results on two <material_5> to show its improvement .	2 8 7 15 18 19 13 -1 0 9 12 13 -1 6 16 13 -1 1 3 13 -1 11 14 17 13 -1 4 13 -1 10 13 -1 5 13 -1
Pronunciation variation in ASR : which variation to model ? .	within-word and crossword pronunciation variation ; continuous speech recognizer ; modeling pronunciation variation ; error rates ; error analysis ; wer ; recognition ; dutch	<otherscientificterm> <method> <otherscientificterm> <metric> <method> <metric> <task> <material>	5 0 2	this paper describes how the performance of a <method_1> for <material_7> has been improved by modeling <otherscientificterm_0> . a relative improvement of 8.8 % in <metric_5> was found compared to baseline system performance . however , as <metric_5> do not reveal the full effect of <otherscientificterm_2> , we performed a detailed analysis of the differences in <task_6> results that occur due to <otherscientificterm_2> and found that indeed a lot of the differences in <task_6> results are not reflected in the <metric_3> . furthermore , <method_4> revealed that testing sets of variants in isolation does not predict their behavior in combination . however , these results appeared to be corpus dependent .	1 7 0 8 -1 5 8 -1 2 6 3 9 8 -1 4 8 -1 8 -1
Hamming Distance Metric Learning .	loss-augmented inference algorithm ; sub-linear knn search ; triplet ranking loss ; latent structural svms ; high-dimensional data ; semantic similarity ; code length ; binary codes ; binary codes ; discrete mappings ; empirical loss ; large-scale applications ; cifar-10 ; mnist ; quadratic ; mappings ; knn ; retrieval	<method> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task>	4 0 15 ; 7 0 1 ; 7 0 11 ; 12 1 13 ; 4 0 8 ; 3 0 10 ; 8 0 5	motivated by large-scale multimedia applications we propose to learn <method_15> from <material_4> to <otherscientificterm_8> that preserve <otherscientificterm_5> . <otherscientificterm_7> are well suited to <task_11> as <otherscientificterm_7> are storage efficient and permit exact <task_1> . the framework is applicable to broad families of <method_15> , and uses a flexible form of <otherscientificterm_2> . we overcome discontinuous optimization of the <method_9> by minimizing a piecewise-smooth upper bound on <otherscientificterm_10> , inspired by <method_3> . we develop a new <method_0> that is <otherscientificterm_14> in the <otherscientificterm_6> . we show strong <task_17> performance on <method_12> and <method_13> , with promising classification results using no more than <otherscientificterm_16> on the <otherscientificterm_8> .	15 4 8 5 7 19 23 25 18 -1 11 1 20 21 18 -1 2 18 -1 9 10 3 24 18 -1 0 14 6 18 -1 17 12 13 22 18 -1
Speech Adaptation in Extended Ambient Intelligence Environments .	extended ambient intelligence ; mass-produced , one-size-fits-all software ; person 's preferences ; cognitive capability ; mobile devices ; personalized agents ; divergence detection ; speech patterns ; adaptive approach ; speech processing ; ambient intelligence ; conversational engagement	<task> <method> <otherscientificterm> <otherscientificterm> <material> <method> <task> <material> <method> <method> <task> <otherscientificterm>	6 0 7 ; 9 1 3	this blue sky presentation focuses on a major shift toward a notion of '' <task_10> '' that transcends general applications targeted at the general population . the focus is on highly <method_5> that accommodate individual differences and changes over time . this notion of <task_0> concerns adaptation to a <otherscientificterm_2> and experiences , as well as changing capabilities , most notably in an environment where <otherscientificterm_11> is central . an important step in moving this research forward is the accommodation of different degrees of <otherscientificterm_3> -lrb- including <method_9> -rrb- that may vary over time for a given user -- whether through improvement or through deterioration . we suggest that the application of <task_6> to <material_7> may enable adaptation to a speaker 's increasing or decreasing level of speech impairment over time . taking an <method_8> toward technology development in this arena may be a first step toward empowering those with special needs so that they may live with a high quality of life . it also represents an important step toward a notion of <task_10> that is personalized beyond what can be achieved by <method_1> currently in use on <material_4> .	10 12 -1 5 12 -1 0 2 11 12 -1 3 9 14 12 -1 13 12 -1 6 7 12 -1 8 12 -1
Bag-of-Audio-Words Approach for Multimedia Event Classification .	bag-of-audio words method ; text and image document retrieval ; audio document classification ; online video search ; acoustic event detection ; multimedia event classification ; online multimedia videos ; audio concept detectors ; multimedia videos ; unsupervised fashion ; audio component ; audio concepts ; supervised approaches ; low-level features ; annotated data	<method> <task> <task> <task> <task> <task> <material> <method> <material> <method> <method> <otherscientificterm> <method> <otherscientificterm> <material>	13 0 5 ; 14 0 12 ; 8 2 11 ; 10 0 5 ; 7 0 5 ; 0 0 11 ; 14 0 13 ; 2 0 1 ; 14 0 7	with the popularity of <material_6> , there has been much interest in recent years in <task_4> and classification for the improvement of <task_3> . the <method_10> of a video has the potential to contribute significantly to <task_5> . recent research in <task_2> has drawn parallels to <task_1> by employing what is referred to as the <method_0> . compared to <method_12> where <method_7> are trained using <material_14> and extracted labels are used as <otherscientificterm_13> for <task_5> . the <method_0> extracts <otherscientificterm_11> in an <method_9> . hence this <method_0> has the advantage that <method_0> can be employed easily for a new set of <otherscientificterm_11> in <material_8> without going through a laborious annotation effort . in this paper , we explore variations of the <method_0> and present results on nist 2011 multimedia event detection -lrb- med -rrb- dataset .	6 4 3 15 -1 10 5 19 15 -1 2 1 0 23 15 -1 12 7 14 13 16 17 20 22 24 15 -1 11 9 21 15 -1 18 15 -1 8 15 -1
Performance analysis of a recursive fractional super-exponential algorithm .	linear equalization of moderately distortive channels ; fractionally-sampled pam signals ; blind channel equalization ; speciic channel responses ; fast convergence rate ; convergence rate ; recursive propagation ; block-based technique ; pri-ori parameterization ; block length ; super-exponential algorithm ; sampling errors ; oversampling	<task> <material> <task> <otherscientificterm> <metric> <metric> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method>	3 0 5 ; 10 6 7 ; 10 0 2 ; 7 0 2 ; 10 0 1	the <method_10> is a <method_7> for <task_2> and system identii-cation . due to its <metric_4> , and no a <method_8> other than the <otherscientificterm_9> , it is a useful tool for <task_0> . this paper presents a recursive implementation of the <method_10> for <material_1> . although the resulting <method_10> is still block-based , <method_6> of several key variables allows the <otherscientificterm_9> to be signiicantly reduced without compromising the <method_10> 's accuracy or speed , thereby enhancing its ability t o t r a c k c hannel variations . the <metric_5> is only mildly innuenced by <otherscientificterm_3> , and <method_12> provides smaller output variance and almost perfect tolerance to <otherscientificterm_11> . simulation results demonstrate the eeectiveness of the proposed <method_10> .	10 7 2 15 16 17 13 -1 4 8 9 0 13 -1 1 18 13 -1 6 13 -1 5 3 12 14 13 -1 11 13 -1
Improving Regressors using Boosting Techniques .	bagging committee machines ; boston housing database ; boosting committee machines ; committee of regressors ; non-linear functions ; regression trees ; regression context ; prediction error ; boosting ; bagging	<task> <material> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method>	0 1 2 ; 8 1 9 ; 9 0 3 ; 8 4 9	in the <otherscientificterm_6> , <method_8> and <method_9> are techniques to build a <method_3> that may be superior to a single regressor . we use <method_5> as fundamental building blocks in <task_0> and <method_2> . performance is analyzed on three <otherscientificterm_4> and the <material_1> . in all cases , <method_8> is at least equivalent , and in most cases better than <method_9> in terms of <otherscientificterm_7> .	6 8 9 3 12 13 10 -1 5 0 2 11 10 -1 4 1 10 -1 7 14 10 -1
A Global Linear Method for Camera Pose Registration .	triangular relationship in camera triplets ; pairwise translation direction constraints ; global camera pose registration ; final bundle adjustment ; approximate geometric error ; pairwise relative poses ; collinear motion ; linear method ; system degeneracy ; point triangulation ; linear approximation ; trifocal tensor ; linear methods ; algebraic error ; robustness ; accuracy	<otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <metric>	5 0 7 ; 1 0 12 ; 15 5 7 ; 14 5 7 ; 6 0 8 ; 7 0 2 ; 13 6 1	we present a <method_7> for <task_2> from <otherscientificterm_5> encoded in essential matrices . our <method_7> minimizes an <otherscientificterm_4> to enforce the <otherscientificterm_0> . this <method_7> does not suffer from the typical ` unbalanced scale ' problem in <method_12> relying on <otherscientificterm_1> , i.e. an <otherscientificterm_13> ; nor the <method_8> from <otherscientificterm_6> . in the case of three cameras , our <method_7> provides a good <method_10> of the <otherscientificterm_11> . <method_7> can be directly scaled up to register multiple cameras . the results obtained are accurate for <task_9> and can serve as a good initialization for <task_3> . we evaluate the <method_7> performance with different types of data and demonstrate its effectiveness . our <method_7> produces good <metric_15> , <metric_14> , and outperforms some well-known systems on efficiency .	7 2 5 17 22 16 -1 4 0 16 -1 12 1 13 8 6 18 21 23 16 -1 10 11 16 -1 16 -1 9 3 16 -1 16 -1 19 20 16 -1
BFGUI : An interactive tool for the synthesis and analysis of microphone array beamformers .	multiple analytic microphone models ; microphone array beamformer ; number and geometry ; distant speech capture ; interactive graphical tool ; simulating microphone arrays ; performance metrics ; direc-tivity pattern ; design constraints ; microphone arrays ; derived metrics ; microphone types ; real-world data ; front-back ratio ; synthesizing beamformers ; directivity index ; bfgui ; reverberation ; regulariza-tion ; noise ; beamforming	<method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <metric> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	16 0 14 ; 7 1 15 ; 15 1 13 ; 4 0 14 ; 19 1 17 ; 16 6 4 ; 11 1 2 ; 18 6 8 ; 9 0 3 ; 20 0 19	microphone arrays are beneficial for <otherscientificterm_3> because the signals they capture can be exploited with <method_20> to suppress <otherscientificterm_19> and <otherscientificterm_17> . the theory for the design and analysis of microphone arrays is well established , however the performance of a <method_1> is often subject to conflicting criteria that need to be assessed manually . this paper describes <method_16> , a <method_4> for <method_16> , for <task_5> and <method_14> , and whose parameters can be modified and <metric_6> monitored in real-time . primarily aimed at teaching and research , this <method_16> provides the user with an intuitive insight into the effects of <otherscientificterm_11> , <otherscientificterm_2> , and the influence of <otherscientificterm_8> such as <otherscientificterm_18> and white <otherscientificterm_19> gain on <otherscientificterm_10> . the resulting <otherscientificterm_7> , <metric_15> and <metric_13> are examples of such metrics . <method_0> are supported and external measured microphone directivity patterns can also be loaded . the <method_0> can be then exported in a variety of formats for processing of <material_12> .	3 20 19 17 26 30 31 21 -1 1 21 -1 16 4 5 14 6 22 25 27 21 -1 28 29 21 -1 11 2 8 18 10 23 24 21 -1 7 15 13 0 21 -1 21 -1
Missing feature theory applied to robust speech recognition over IP network .	lost regions of speech data ; mean burst loss length ; reconstruction of missing frames ; mobile and ip networks ; gilbert loss models ; packet loss models ; speech data loss ; packet loss environment ; packet loss rate ; word accuracy ; speech recognition ; packet loss ; marginal distributions ; missing-feature-based approaches ; tacking method	<material> <metric> <task> <task> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <metric> <task> <otherscientificterm> <otherscientificterm> <method> <method>	13 0 0 ; 2 0 13 ; 5 0 13 ; 3 0 10 ; 12 0 13 ; 13 0 7	this paper addresses the problems involved in performing <task_10> over <task_3> . the main problem is <otherscientificterm_6> caused by <otherscientificterm_11> in the network . we present two <method_13> that recover <material_0> . these <method_13> are based on <task_2> or on <otherscientificterm_12> . for comparison , we also use a <method_14> , which recognizes only received data . we evaluate these <method_13> with <method_5> , i.e. , random loss and <method_4> . the results show that the <method_13> is most effective for a <otherscientificterm_7> ; the degradation of <metric_9> is only 5 % when the <metric_8> is 30 % and only 3 % when <metric_1> is 24 frames .	10 3 19 15 -1 6 11 15 -1 13 0 16 15 -1 2 12 17 20 15 -1 14 15 -1 5 4 18 15 -1 7 9 8 21 15 -1
Low-Complexity Fuzzy Video Rate Controller for Streaming .	video rate control algorithm ; low-complexity fuzzy video rate control algorithm ; quantization scale ; variable bitrate video ; variable bitrate benefits ; real-time streaming applications ; fuzzy controller ; buffer constraint ; constant bitrate ; encoded video ; streaming application ; average quality ; visual quality ; streaming constraints	<method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <material> <task> <metric> <metric> <otherscientificterm>	7 0 1 ; 1 0 5 ; 2 0 9 ; 6 0 2 ; 11 5 9 ; 0 0 3	in this paper we propose a <method_1> with <otherscientificterm_7> designed for <task_5> . while in low delay video communications bit streams with <otherscientificterm_8> are required , in <task_10> more delay and variation in bitrate is acceptable . the described <method_0> provides a <otherscientificterm_3> by control of the <method_2> on picture basis . the <method_2> is mainly controlled by a <method_6> such that it minimizes the variation of <method_2> to provide <material_9> with high <metric_12> so as to utilize the <otherscientificterm_4> as much as possible . the proposed rate control algorithm -lrb- rca -rrb- has been implemented in the mpeg-4 , h. 263 and h. 264/avc standard video codecs and the experimental results show that it provides high level <metric_11> for <material_9> while it strictly obeys <otherscientificterm_13> .	1 7 5 15 16 14 -1 8 10 14 -1 0 3 2 20 14 -1 6 9 12 4 17 18 14 -1 19 14 -1
A posterior approach for microphone array based speech recognition .	automatic speech recognition ; time-domain signal processing theory ; microphone array speech recognition ; adverse acoustic conditions ; tandem ann-hmm system ; posterior phone probabilities ; heterogeneous channels ; geometric analysis ; multiparty meetings ; background noise ; posterior-based approach ; microphone arrays ; beamforming techniques ; geometric properties ; speech signals ; asr accuracy ; beamforming ; reverberation ; cross-talk	<task> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <metric> <method> <otherscientificterm> <otherscientificterm>	9 1 17 ; 1 0 12 ; 17 6 3 ; 9 6 3 ; 5 0 4 ; 10 0 2 ; 17 1 18 ; 16 4 16 ; 18 6 3 ; 16 1 10 ; 10 4 16 ; 14 0 5 ; 11 0 15	automatic speech recognition -lrb- asr -rrb- is difficult in environments such as <otherscientificterm_8> because of <otherscientificterm_3> : <otherscientificterm_9> , <otherscientificterm_17> and <otherscientificterm_18> . <otherscientificterm_11> can increase <metric_15> dramatically in such situations . however , most existing <method_12> use <method_1> and are based on a <method_7> of the relationship between sources and microphones . this limits their application , and leads to performance degradation when the <otherscientificterm_13> are unavailable , or <otherscientificterm_6> are used . we present a new <method_10> for <task_2> . instead of enhancing <material_14> , we enhance <otherscientificterm_5> which are used in a <method_4> . significant improvements were achieved over a single channel baseline . combining <method_16> and our <method_10> is significantly better than <method_16> alone , especially in a moving speakers scenario .	8 3 9 17 18 11 20 22 23 26 28 19 -1 15 32 19 -1 12 1 7 21 19 -1 13 6 19 -1 10 2 25 19 -1 14 5 4 24 31 19 -1 19 -1 27 29 30 19 -1
Automated Dysarthria Severity Classification for Improved Objective Intelligibility Assessment of Spastic Dysarthric Speech .	ma-halanobis distance-based discriminant analysis classifier ; 9-dimensional intelligibility prediction mapping ; automatic dysarthria severity classification ; voice pathology assessment ; intelligibility prediction tasks ; spastic dysarthric speech ; subjective intelligibility ratings ; two-level severity classifier ; disorder severity classification ; salient features ; acoustic features ; root-mean-square error ; intelligibility accuracy ; intelligibility prediction ; classification errors ; feature selection	<method> <method> <task> <task> <task> <material> <metric> <method> <task> <otherscientificterm> <otherscientificterm> <metric> <metric> <task> <otherscientificterm> <method>	15 0 9 ; 10 0 0 ; 9 0 8 ; 15 0 8 ; 8 1 4 ; 15 0 4 ; 13 1 3	in this paper , <task_2> is explored as a tool to advance objective intelli-gibility prediction of <material_5> . a <method_0> is developed based on a set of <otherscientificterm_10> formerly proposed for <task_13> and <task_3> . <method_15> is used to sift <otherscientificterm_9> for both the <task_8> and <task_4> . experimental results show that a <method_7> combined with a <method_1> can achieve 0.92 correlation and 12.52 <metric_11> with <metric_6> . the effects of <otherscientificterm_14> on <metric_12> are also explored and shown to be insignificant .	2 5 16 -1 0 10 13 3 15 18 23 16 -1 9 8 4 17 19 20 21 22 16 -1 7 1 11 6 16 -1 14 12 16 -1
An improved parallel architecture for MPEG-4 motion estimation in 3G mobile applications .	full-search block matching algorithm ; preload and alignment cycles ; low clock rate requirements ; high-parallel vlsi core architecture ; 3g mobile applications ; mpeg-4 motion estimation ; one-dimensional tree architecture ; low memory bandwidth ; 16-pe array ; dual-register/buffer technique ; motion vectors	<method> <otherscientificterm> <otherscientificterm> <method> <task> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm>	9 0 1 ; 3 0 1 ; 7 1 2 ; 8 0 0 ; 9 0 3	a <method_3> for <task_5> is proposed in this paper . <method_3> possesses the characteristics of <otherscientificterm_7> and <otherscientificterm_2> , thus primarily aiming at <task_4> . based on a <method_6> , the <method_3> employs the <method_9> to reduce the <otherscientificterm_1> . as an example , <method_0> has been mapped onto this <method_3> using a <method_8> that has the ability to calculate the <otherscientificterm_10> of qcif video sequences in real time at 1 mhz clock rate and using 15.5 mbytes/s memory bandwidth .	3 5 11 -1 7 2 4 14 11 -1 6 9 1 12 13 16 11 -1 0 8 10 15 11 -1
Phase-only information loss .	complex sinusoid in white noise ; von mises distributional assumptions ; asymptotic distributional properties ; complex-valued random variables ; asymptotic variance ; statistical information ; system parameters ; complex distribution ; signal processing	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task>	5 1 4 ; 3 0 6	in many areas of <task_8> , the phases of <otherscientificterm_3> are used to estimate <otherscientificterm_6> , the magnitudes being discarded . in this paper , we consider the implications of doing this : the loss of <otherscientificterm_5> and subsequent increase in <otherscientificterm_4> . two particular cases , those of estimating the phase of the mean of a <task_7> , and estimating the frequency of a <otherscientificterm_0> , are considered . the estimators are motivated by estimation under <otherscientificterm_1> . the <otherscientificterm_2> are obtained under general assumptions , and are tested using a small number of simulations .	8 3 6 11 9 -1 5 4 10 9 -1 7 0 9 -1 1 9 -1 2 9 -1
Task Space Behavior Learning for Humanoid Robots using Gaussian Mixture Models .	robot behavior acquisition ; constrained reaching gestures ; gaussian mixture models ; kinesthetic demonstrations ; humanoid robot ; learning algorithm ; imitation trajectory	<task> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm>	4 0 1 ; 2 0 5	in this paper a system was developed for <task_0> using <method_3> . it enables a <method_4> to imitate <otherscientificterm_1> directed towards a target using a <method_5> based on <method_2> . the <otherscientificterm_6> can be reshaped in order to satisfy the constraints of the task and <otherscientificterm_6> can adapt to changes in the initial conditions and to target displacements occurring during movement execution . the potential of this method was evaluated using experiments with the nao , aldebaran 's <method_4> .	0 3 7 -1 4 1 5 2 8 9 7 -1 6 7 -1 7 -1
Empirical Study of Utilizing Morph-Syntactic Information in SMT .	morphological and relative positional information ; statistical machine translation framework ; class-based n-gram language model ; morphologically rich language pairs ; part-of-speech and base form ; local word orders ; relative positional features ; word-based language model ; word-based/class-based language models ; relative positional information ; data sparseness problem ; morph-syntactical information ; base form ; word group ; morpho-syntactical information ; morph-syntactical similarity ; multilingual translations ; log-linear model ; translation quality ; translation models ; part-of-speech	<otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <metric> <method> <otherscientificterm>	0 0 16 ; 12 1 20 ; 9 3 1 ; 20 1 9 ; 10 0 2 ; 9 6 14 ; 6 0 5 ; 0 0 3 ; 20 6 14 ; 12 6 14	in this paper , we present an empirical study that utilizes <otherscientificterm_11> to improve <metric_18> . with three kinds of language pairs matched according to <otherscientificterm_15> or difference , we investigate the effects of various <otherscientificterm_14> , such as <otherscientificterm_12> , <otherscientificterm_20> , and the <otherscientificterm_9> of a word in a <method_1> . we learn not only <method_19> but also <method_8> by manipulating <otherscientificterm_0> . and we integrate the models into a <method_17> . experiments on <material_16> showed that such <otherscientificterm_0> as <otherscientificterm_4> are effective for improving performance in <material_3> and that the <otherscientificterm_6> in a <otherscientificterm_13> are useful for reordering the <otherscientificterm_5> . moreover , the use of a <method_2> improves performance by alleviating the <task_10> in a <method_7> .	11 18 21 -1 15 14 12 20 9 1 23 24 25 27 30 31 21 -1 19 8 0 21 -1 17 21 -1 16 4 3 6 13 22 28 29 21 -1 5 26 21 -1
Lossless Compression of 4D Medical Images using H. 264/AVC .	dimensional medical data ; spatial and temporal redundancies ; lossless compression technique ; 4d compression methods ; 2d image slices ; 4d medical images ; 3d images ; diagnostic purposes ; image quality ; volumetric images ; compression	<material> <otherscientificterm> <method> <method> <material> <material> <material> <task> <metric> <material> <otherscientificterm>	4 1 1 ; 8 5 10 ; 4 1 6 ; 8 5 7 ; 2 4 3 ; 2 0 5	four <material_0> are sequences of <material_9> captured in time . these data sets are typically very large in size and demand a great amount of resources for storage and transmission . in this paper , we present a <method_2> for <material_5> which is based on the h. 264/avc video coding standard . our <method_2> efficiently exploits <otherscientificterm_1> between <material_4> and <material_6> in <material_5> and eliminates any concerns regarding the effects of <otherscientificterm_10> on <metric_8> for <task_7> . performance evaluations have shown that the proposed <method_2> outperforms current <method_3> by 70 % .	0 9 11 -1 11 -1 2 5 17 11 -1 1 4 6 10 8 7 12 13 14 15 11 -1 3 16 11 -1
Variational Mixture of Gaussian Process Experts .	mixture of gaussian processes models ; reduction of training complexity ; gaussian mixture model ; variational bayesian algorithm ; large-scale data sets ; gaussian components ; generative approaches ; experts model ; linear model ; inference algorithms ; gaussian process ; gibbs sampling	<method> <metric> <method> <method> <material> <method> <method> <method> <method> <method> <method> <method>	11 0 9 ; 10 0 0 ; 8 0 10 ; 9 0 0 ; 3 4 6	mixture of gaussian processes <method_0> extended a single <method_10> with ability of modeling multi-modal data and <metric_1> . previous <method_9> for these <method_0> are mostly based on <method_11> , which can be very slow , particularly for <material_4> . we present a new generative mixture of <method_7> . each expert is still a <method_10> but is reformulated by a <method_8> . this breaks the dependency among training outputs and enables us to use a much faster <method_3> for training . our <method_3> is more flexible than previous <method_6> as inputs for each expert are modeled by a <method_2> . the number of experts and number of <method_5> for an expert are inferred automatically . a variety of tests show the advantages of our method .	0 10 1 14 12 -1 9 11 4 13 16 12 -1 7 12 -1 8 15 12 -1 3 12 -1 6 2 17 12 -1 12 -1 5 12 -1
VMF-SNE : Embedding for spherical data .	von mises-fisher distribution ; simulation data set ; vmf-sne embedding algorithm ; data visualization ; local proximity ; spherical data ; iterative process ; euclidean space ; high-dimensional data ; gaussian distributions ; t-sne ; embeddings ; embedding	<otherscientificterm> <material> <method> <task> <otherscientificterm> <material> <method> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <method>	10 4 10 ; 0 0 4 ; 1 5 10 ; 10 0 5 ; 9 0 4 ; 8 0 3 ; 10 0 8 ; 6 0 12 ; 2 0 5	-- <method_10> is a well-known approach to embedding <material_8> and has been widely used in <task_3> . the basic assumption of <method_10> is that the data are non-constrained in the <otherscientificterm_7> and the <otherscientificterm_4> can be modelled by <otherscientificterm_9> . this assumption does not hold for a wide range of data types in practical applications , for instance <material_5> for which the <otherscientificterm_4> is better modelled by the <otherscientificterm_0> instead of the <otherscientificterm_9> . this paper presents a <method_2> to embed <material_5> . an <method_6> is derived to produce an efficient <method_12> . the results on a <material_1> demonstrated that <method_10> produces better <otherscientificterm_11> than <method_10> for <material_5> .	10 8 3 19 20 13 -1 7 4 9 18 13 -1 5 0 15 13 -1 2 22 13 -1 6 12 21 13 -1 1 14 16 17 13 -1
Bookmark Hierarchies and Collaborative Recommendation .	recommendation and search engine ; intelligent information retrieval techniques ; semantic similarity measure ; collaborative filtering ; bookmark files ; ranking algorithms ; novelty measures ; web pages ; hierarchical structure ; similarity-induced network ; bookmarks ; givealink.org ; urls ; tags	<method> <method> <metric> <method> <material> <method> <metric> <material> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	9 0 6 ; 5 0 0 ; 2 0 12 ; 6 0 5 ; 9 0 5 ; 6 0 0	givealink.org is a social bookmarking site where users may donate and view their personal <material_4> online securely . the <otherscientificterm_10> are analyzed to build a new generation of <method_1> to recommend , search , and personalize the web . <method_11> does not use <otherscientificterm_13> , content , or links in the submitted <material_7> . instead we present a <metric_2> for <otherscientificterm_12> that takes advantage both of the <otherscientificterm_8> in the <material_4> of individual users , and of <method_3> across users . in addition , we build a <method_0> from <method_5> based on popularity and <metric_6> extracted from the <method_9> . search results can be personalized using the <otherscientificterm_10> submitted by a user . we evaluate a subset of the proposed <metric_2> by conducting a study with human subjects .	4 14 -1 10 1 11 14 -1 13 7 14 -1 2 12 8 3 17 14 -1 0 5 6 9 15 16 18 19 20 14 -1 14 -1 14 -1
Automatic Generation of High-Level State Features for Generalized Planning .	diverse generalized planning problems ; computation of generalized plans ; high-level state features ; classical planning problems ; generalized planning problem ; computation of features ; generalized plans ; generalized planning ; classification tasks ; classical planning ; conjunctive queries ; features	<task> <task> <otherscientificterm> <task> <task> <otherscientificterm> <method> <task> <task> <task> <otherscientificterm> <otherscientificterm>	11 0 6 ; 11 0 0 ; 2 0 4	in many domains <method_6> can only be computed if certain <otherscientificterm_2> , i.e. <otherscientificterm_11> that capture key concepts to accurately distinguish between states and make good decisions , are available . in most applications of <task_7> such <otherscientificterm_11> are hand-coded by an expert . this paper presents a novel method to automatically generate <otherscientificterm_2> for solving a <task_4> . our method extends a compilation of <task_7> into <task_9> and integrates the <task_1> with the <otherscientificterm_5> , in the form of <otherscientificterm_10> . experiments show that we generate <otherscientificterm_11> for <task_0> and hence , compute <method_6> without providing a prior high-level representation of the states . we also bring a new landscape of challenging benchmarks to <task_9> since our compilation naturally models <task_8> as <task_3> .	6 2 11 12 -1 7 12 -1 4 15 12 -1 9 1 5 10 12 -1 0 13 14 12 -1 12 -1
Learning Partially Observable Deterministic Action Models .	partially observable strips domains ; reinforcement learning ; autonomous agent ; logical filtering ; conditional effects ; strips actions ; theoretical guarantees ; version spaces ; decision making ; deterministic domains ; hmms ; diagnosis	<material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <method> <task>	10 1 1 ; 7 1 3 ; 8 1 11 ; 4 6 9	we present the first tractable , exact solution for the problem of identifying actions ' effects in <material_0> . our algorithms resemble <method_7> and <method_3> , and they identify all the models that are consistent with observations . they apply in other <otherscientificterm_9> -lrb- e.g. , with <otherscientificterm_4> -rrb- , but are inexact -lrb- may return false positives -rrb- or inefficient -lrb- we could not bound the representation size -rrb- . our experiments verify the <otherscientificterm_6> , and show that we learn <otherscientificterm_5> efficiently , with time that is significantly better than approaches for <method_10> and <method_1> -lrb- which are inexact -rrb- . our results are especially surprising because of the inherent intractability of the general deterministic case . these results have been applied to an <method_2> in a virtual world , facilitating <task_8> , <task_11> , and exploration .	0 12 -1 7 3 14 12 -1 9 4 16 12 -1 6 5 10 1 13 12 -1 12 -1 15 12 -1
Optimal design of spectrum constrained signal sets with correlation analysis .	quadratic phase structure ; prescribed magnitude spectrum ; lowest maximum cross-correlation ; mathematical analysis ; analog signals ; analytic expression ; maximum cross-correlation	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm>	5 0 6 ; 1 1 0 ; 1 2 4	this paper is concerned with the design of an optimal set of <material_4> with <otherscientificterm_1> and <otherscientificterm_0> such that the <otherscientificterm_6> is minimized . an <otherscientificterm_5> for the <otherscientificterm_6> between two signals is derived through <method_3> . the optimal set of signals with the <otherscientificterm_2> is explicitly characterized under certain conditions .	4 1 0 6 9 10 7 -1 5 3 8 7 -1 2 7 -1
Learning to Solve QBF .	quantified boolean formulas ; dynamic , online approach ; search-based qbf solver ; machine learning techniques ; dynamic method variables ; unsolved problem instances ; variable assignment ; optimal heuristics ; heuristics ; classifier ; heuristic	<method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method>	2 1 3	we present a novel approach to solving <method_0> that combines a <method_2> with <method_3> . we show how classification methods can be used to predict run-times and to choose <method_7> both within a portfolio-based , and within a <method_1> . in the <otherscientificterm_4> are set to a truth value according to a scheme that tries to maximize the probability of successfully solving the remaining sub-problem efficiently . since each <otherscientificterm_6> can drastically change the problem-structure , new <method_8> are chosen dynamically , and a <method_9> is used online to predict the usefulness of each <method_10> . experimental results on a large corpus of example problems show the usefulness of our approach in terms of run-time as well as the ability to solve previously <otherscientificterm_5> .	0 2 3 12 11 -1 7 1 11 -1 4 11 -1 6 8 9 10 11 -1 11 -1
Can a Fully Unconstrained Imaging Model Be Applied Effectively to Central Cameras ? .	quasi-pinhole central cameras ; central camera settings ; ad hoc models ; image formation model ; parametric approaches ; unconstrained model ; imaging devices ; camera models ; free parameters ; precision calibration ; pinhole cameras ; calibration approach ; radial distortion ; estimation process ; non-linearities ; correction	<otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <method> <method> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	15 2 2 ; 5 4 2 ; 2 0 6 ; 9 5 11 ; 5 0 0 ; 2 0 12 ; 5 0 1 ; 5 0 8 ; 15 0 12	traditional <method_7> are often the result of a compromise between the ability to account for <otherscientificterm_14> in the <method_3> and the need for a feasible number of degrees of freedom in the <task_13> . these considerations led to the definition of several <method_2> that best adapt to different <method_6> , ranging from <method_10> with no <otherscientificterm_12> to the more complex catadioptric or polydioptric optics . in this paper we propose the use of an <method_5> even in standard <otherscientificterm_1> dominated by the <method_2> , and introduce a novel <method_11> that can deal effectively with the huge number of <otherscientificterm_8> associated with <method_5> , resulting in a higher <metric_9> than what is possible with the standard <method_2> with <otherscientificterm_15> for <otherscientificterm_12> . this effectively extends the use of general models to settings that traditionally have been ruled by <method_4> out of practical considerations . the benefit of such an <method_5> to <otherscientificterm_0> is supported by an extensive experimental validation .	7 14 3 13 16 -1 2 6 10 12 19 16 -1 5 1 11 8 17 18 20 22 23 24 25 16 -1 9 15 16 -1 4 21 16 -1
A Transcription Task for Crowdsourcing with Automatic Quality Control .	support vector machine classifier ; amazon mechanical turk ; two-stage transcription task design ; word level confidence scores ; automatic quality control mechanism ; academic lecture speech ; rover-based method ; baseline transcripts ; acoustic cues ; instantaneous feedback ; technical material ; transcription quality ; transcriber effort ; language patterns ; crowdsourcing ; mturk	<method> <method> <method> <metric> <method> <material> <method> <material> <otherscientificterm> <otherscientificterm> <material> <metric> <otherscientificterm> <otherscientificterm> <task> <material>	5 5 2 ; 1 0 2 ; 6 0 7 ; 3 0 11 ; 2 0 14 ; 8 1 13 ; 12 5 2	in this paper , we propose a <method_2> for <task_14> with an <method_4> embedded in each stage . for the first stage , a <method_0> is utilized to quickly filter poor quality transcripts based on <otherscientificterm_8> and <otherscientificterm_13> in the transcript . in the second stage , <metric_3> are used to estimate a <metric_11> and provide <otherscientificterm_9> to the transcriber . the proposed <method_2> was evaluated using <method_1> and tested on seven hours of <material_5> , which is typically conversational in nature and contains <material_10> . compared to <material_7> which were also collected from <material_15> using a <method_6> , we observed that the new <method_2> resulted in higher quality transcripts while requiring less <otherscientificterm_12> .	2 14 4 21 16 -1 0 8 13 22 16 -1 3 11 9 20 16 -1 1 5 10 17 18 16 -1 7 15 6 19 23 16 -1
Modeling tones in hakka on the basis of the command-response model .	subjective and relative nature ; f 0 contour generation ; 5-level notation of tones ; continuous f 0 contours ; quantitative approximations ; lexical tones ; command-response model ; tone type ; tone system ; phonological descriptions ; chinese dialects ; hakka	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <material>	9 0 3 ; 5 2 8 ; 6 0 1	as one of the major <material_10> , <material_11> typically has a <method_8> with six <otherscientificterm_5> . the traditional <otherscientificterm_2> in <material_11> varies in previous references due to its <otherscientificterm_0> . in order to overcome the limitations of the traditional approach , the <method_6> for the process of <task_1> is employed to analyze quantitatively the tones in continuous speech of two varieties of <material_11> , spoken in meixian and in shataukok , respectively . by providing both <otherscientificterm_9> to each <otherscientificterm_7> and <otherscientificterm_4> to <otherscientificterm_3> , the model-based approach provides an efficient connection between phonetics and phonology of <material_11> tones .	10 11 8 5 14 12 -1 2 0 12 -1 6 1 15 12 -1 9 7 4 3 13 12 -1
Matrix parametrization of compactly supported orthonormal wavelets .	orthogonal wavelet of compact support ; regular objective function ; nonlinear optimization problem ; arbitrary decision vector ; two-scale difference equation ; classical orthogonal wavelets ; customized orthonormal wavelets ; filter coefficients ; filter size ; decision vector ; filter design	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	8 2 3 ; 7 0 4 ; 1 2 10	we derive a new set of necessary and sufficient conditions for the <otherscientificterm_7> of the <otherscientificterm_4> to yield an <otherscientificterm_0> . the conditions constitute a linear set of equations of an <otherscientificterm_3> of half the <otherscientificterm_8> . the vector of the <otherscientificterm_7> is a differentiable function of the <otherscientificterm_9> . the formulation enables the optimization of the <method_10> under any <otherscientificterm_1> . the proposed parametrization is used to design <otherscientificterm_6> and to reproduce the <otherscientificterm_5> as a solution of a <task_2> .	7 4 0 13 11 -1 3 8 12 11 -1 9 11 -1 10 1 14 11 -1 6 5 2 11 -1
A theory of plenoptic multiplexing .	multiplex-ing the dimensions ; generic reconstruction algorithm ; plenoptic multiplexing schemes ; multiplexed imaging applications ; high-dimensional image data ; optical heterodyn-ing ; noise analysis ; plenoptic function ; fourier domain ; light fields ; image sensor ; spatial multiplexing ; color channels ; bayer patterns ; multiplexing	<otherscientificterm> <method> <method> <task> <material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <task>	14 0 4 ; 13 3 11 ; 6 6 2 ; 5 0 9	multiplexing is a common technique for encoding <material_4> into a single , two-dimensional image . examples of <task_11> include <otherscientificterm_13> to capture <material_12> , and integral images to encode <otherscientificterm_9> . in the <material_8> , <otherscientificterm_5> has been used to acquire <otherscientificterm_9> . in this paper , we develop a general theory of <otherscientificterm_0> of the <otherscientificterm_7> onto an <otherscientificterm_10> . our theory enables a principled comparison of <method_2> , including <method_6> , as well as the development of a <method_1> . the framework also aides in the identification and optimization of novel <task_3> .	4 16 15 -1 11 13 12 9 17 15 -1 8 5 19 15 -1 0 7 10 15 -1 2 6 1 18 15 -1 3 14 15 -1
Data spectroscopy : learning mixture models using eigenspaces of convolution operators .	kernel principal components analysis ; parametric distribution <i> p </i> ; gaussian mixture models ; identification of substances ; estimating mixture distributions ; gaussian mixture ; spectral techniques ; spectral clustering ; theoretical framework ; sampled data ; spectral framework ; mixture components ; spectroscopy	<method> <method> <method> <task> <task> <method> <method> <method> <method> <material> <method> <method> <method>	10 0 4 ; 7 6 6 ; 12 0 3 ; 0 6 6 ; 7 1 0	in this paper we develop a <method_10> for <task_4> , specifically <method_2> . in physics , <method_12> is often used for the <task_3> through their spectrum . treating a kernel function <i> k -lrb- x , y -rrb- </i> as `` light '' and the <material_9> as `` substance '' , the spectrum of their interaction -lrb- eigenvalues and eigenvectors of the kernel matrix <i> k </i> -rrb- unveils certain aspects of the underlying <method_1> , such as the parameters of a <method_5> . our <method_10> extends the intuitions and analyses underlying the existing <method_6> , such as <method_7> and <method_0> . we construct <method_10> to estimate parameters of <method_2> , including the number of <method_11> , their means and covariance matrices , which are important in many practical applications . we provide a <method_8> and show encouraging experimental results .	10 4 2 14 13 -1 12 3 16 13 -1 9 1 5 13 -1 6 7 15 17 18 13 -1 0 13 -1 11 13 -1
Gauss-Seidel based non-negative matrix factorization for gene expression clustering .	gene expression data ; cancer expression datasets ; representative nmf methods ; matrix inverse operators ; gene expression clustering ; genome-wide expression data ; projected data ; cluster centroids ; factor matrix ; raw data ; large-scale data ; linear system ; gauss-seidel method ; imbalance deficiency ; probed genes ; clustering methods ; features ; gsnmf ; clustering	<material> <material> <method> <method> <task> <material> <material> <method> <method> <material> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method>	17 0 0 ; 18 0 0 ; 11 0 8 ; 1 5 17 ; 6 0 7 ; 12 0 11 ; 17 0 4 ; 17 4 15 ; 2 1 15 ; 11 0 17 ; 15 0 4 ; 17 4 2	genome-wide expression data consists of millions of measurements towards large number of genes , and thus <material_0> is challenging for human beings to directly analyze such <material_10> . <method_18> provides a more convenient way to analyze <material_0> because <material_0> can subdivide <material_9> into comprehensive classes . however , the number of <otherscientificterm_14> is rather greater than the number of samples , and this makes conventional <method_15> perform unsatisfactorily . in this paper , we propose a gauss-seidel based non-negative matrix factorization -lrb- <method_17> -rrb- method to overcome such <otherscientificterm_13> between <otherscientificterm_16> and samples . in particular , <method_17> iteratively projects <material_0> onto the learned subspace followed by adaptively updating the <method_7> based on the <material_6> . since this <material_0> significantly reduces the influence of imbalance between the number of samples and the number of genes , <method_17> performs better than traditional <method_15> in <task_4> . since <method_17> updates each <method_8> by solution of a <method_11> obtained by the <method_12> , <material_0> converges rapidly without neither complex line search nor <method_3> . experimental results on several <material_1> confirm both efficiency and effectiveness of <method_17> comparing with the <method_2> and conventional <method_15> .	0 10 18 19 -1 9 21 19 -1 14 15 19 -1 17 13 16 19 -1 20 24 19 -1 7 6 26 30 19 -1 4 22 25 29 19 -1 8 11 12 3 23 27 28 31 19 -1
Automatic Term Ambiguity Detection .	information extraction systems ; resolution of term ambiguity ; term ambiguity detection problem ; ambiguous and unambigu-ous cases ; language models ; topic mod-eling ; baseline f-measure ; ambiguity detection ; entity ; ontologies	<task> <task> <task> <otherscientificterm> <method> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm>	9 1 5 ; 4 1 9	while the <task_1> is important for <task_0> , the cost of resolving each instance of an <otherscientificterm_8> can be prohibitively expensive on large datasets . to combat this , this work looks at <task_7> at the term , rather than the instance , level . by making a judgment about the general ambiguity of a term , a system is able to handle <otherscientificterm_3> differently , improving through-put and quality . to address the <task_2> , we employ a model that combines data from <method_4> , <otherscientificterm_9> , and <otherscientificterm_5> . results over a dataset of entities from four product domains show that the proposed approach achieves significantly above <metric_6> of 0.96 .	1 0 8 10 -1 7 10 -1 3 10 -1 2 4 9 5 11 12 10 -1 10 -1
Minimal local reconstruction error measure based discriminant feature extraction and classification .	geometric meaning of the minimal local reconstruction error ; mlre measure based discriminant feature extraction method ; minimal local reconstruction error ; mlre-based feature extraction and classification method ; within-class and between-class local scatters ; cenparmi handwritten numeral database ; feret face image database ; mlre-based classification method ; nearest neighbor classifier ; nearest neighbor line ; plane classifiers ; mlre-based classifier ; similarity measure	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <material> <material> <method> <method> <method> <method> <method> <metric>	5 1 6 ; 9 1 10 ; 2 0 4 ; 5 5 3 ; 6 5 3	this paper introduces the <otherscientificterm_2> as a <metric_12> and presents a <method_11> . from the <otherscientificterm_0> , we derive that the <method_11> is a generalization of the conventional <method_8> and the <method_9> and <method_10> . we further apply the <otherscientificterm_2> to characterize the <otherscientificterm_4> and then develop a <method_1> . the proposed <method_1> is in line with the <method_7> in spirit , thus the two methods can be seamlessly combined in applications . the experimental results on the <material_5> and the <material_6> show effectiveness of the proposed <method_3> .	2 12 11 13 -1 0 8 9 10 15 13 -1 4 1 16 13 -1 7 13 -1 5 6 3 14 17 18 13 -1
Spatial audio activity detection for hearing aids .	multi-microphone signal activity detection scheme ; hearing aid domain ; practical reverberant conditions ; hearing aids ; directional processing ; detection	<method> <material> <otherscientificterm> <otherscientificterm> <method> <task>	0 0 3 ; 0 0 5	we present a <method_0> for <otherscientificterm_3> to differentiate between the periods of activity of desired and interfering sources . the <method_0> is designed to provide robust performance in the presence of simultaneously active desired and interfering sources . we exploit knowledge from the <material_1> , and the <method_4> present in modern <otherscientificterm_3> , to present a <method_0> to design appropriate thresholds for the <task_5> . experiments confirm robust performance under <otherscientificterm_2> .	0 3 7 6 -1 6 -1 1 4 5 8 6 -1 2 6 -1
Hierarchical Part-Template Matching for Human Detection and Segmentation .	local part-based and global template-based schemes ; global shape template-based human detectors ; detecting and segmenting human shapes ; local part-based human detectors ; fine occlusion analysis ; bayesian map framework ; global likelihood re-evaluation ; background subtraction ; human shapes ; severe occlusion ; human detection ; detection hypotheses ; partial occlusions ; bayesian approach ; part-template tree ; images ; detection	<method> <otherscientificterm> <task> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <task>	3 0 12 ; 13 0 8 ; 4 0 5 ; 6 1 4 ; 14 0 11 ; 13 0 10 ; 5 0 13 ; 6 0 5 ; 15 5 13	local part-based human detectors are capable of handling <otherscientificterm_12> efficiently and modeling shape ar-ticulations flexibly , while <otherscientificterm_1> are capable of <task_2> simultaneously . we describe a <method_13> to <task_10> and segmentation combining <method_0> . the <method_13> relies on the key ideas of matching a <otherscientificterm_14> to <material_15> hierarchically to generate a reliable set of <otherscientificterm_11> and optimizing <method_13> under a <method_5> through <task_6> and <method_4> . in addition to <task_16> , our <method_13> is able to obtain <otherscientificterm_8> and poses simultaneously . we applied the <method_13> to <task_10> and segmentation in crowded scenes with and without <otherscientificterm_7> . experimental results show that our <method_13> achieves good performance on <material_15> and video sequences with <otherscientificterm_9> .	12 1 2 18 17 -1 13 10 0 17 -1 14 15 11 5 6 4 20 21 22 24 25 17 -1 16 8 19 17 -1 7 23 17 -1 26 17 -1
Modality and Component Aware Feature Fusion for RGB-D Scene Classification .	convolutional neural networks ; fv gmm components ; proposal-based fv features ; augmented pixel-wise representation ; exclusive group lasso ; global cn-n features ; full-image cnn features ; scene images ; sunrgbd dataset ; modal non-sparsity ; cnn features ; rgb-d data ; discriminative components ; gmm components ; group lasso ; scene discriminability ; scene classification ; regularization terms ; region proposals ; object recognition ; regres-sors ; modalities ; rgb ; hha	<method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm> <task> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	20 0 2 ; 6 0 16 ; 22 2 3 ; 3 0 10 ; 1 0 15 ; 13 1 4 ; 2 1 5 ; 21 2 3 ; 20 0 16 ; 22 1 23 ; 0 0 19 ; 14 0 13	while <method_0> have been excellent for <task_19> , the greater spatial variability in <material_7> typically meant that the standard <otherscientificterm_6> are suboptimal for <task_16> . in this paper , we investigate a framework allowing greater spatial flexibility , in which the fisher vector -lrb- fv -rrb- encoded distribution of local <otherscientificterm_10> , obtained from a multitude of <method_18> per image , is considered instead . the <otherscientificterm_10> are computed from an <method_3> comprising multiple <otherscientificterm_21> of <otherscientificterm_22> , <otherscientificterm_23> and surface normals , as extracted from <material_11> . more significantly , we make two postulates : -lrb- 1 -rrb- component sparsity -- that only a small variety of <method_18> and their corresponding <method_1> contribute to <otherscientificterm_15> , and -lrb- 2 -rrb- <otherscientificterm_9> -- within these <method_12> , all <otherscientificterm_21> have important contribution . in our framework , these are implemented through <method_17> applying <method_14> to <method_13> and <otherscientificterm_4> across <otherscientificterm_21> . by learning and combining <method_20> for both <otherscientificterm_2> and <otherscientificterm_5> , we were able to achieve state-of-the-art <task_16> performance on the <material_8> and nyu depth dataset v2 .	0 19 7 6 16 26 35 24 -1 10 18 24 -1 3 21 22 23 11 27 28 32 34 24 -1 29 24 -1 1 15 9 12 30 36 24 -1 17 14 13 4 25 31 33 24 -1
Efficient Kernel Machines Using the Improved Fast Gauss Transform .	moderate size problems ; approximation technique ; kernel machines ; uci datasets ; large datasets ; complexity	<otherscientificterm> <method> <method> <material> <material> <metric>	5 0 0	the computation and memory required for <method_2> with n training samples is at least o -lrb- n 2 -rrb- . such a <metric_5> is significant even for <otherscientificterm_0> and is prohibitive for <material_4> . we present an <method_1> based on the improved fast gauss transform to reduce the computation to o -lrb- n -rrb- . we also give an error bound for the approximation , and provide experimental results on the <material_3> .	2 6 -1 5 0 4 7 6 -1 1 6 -1 3 6 -1
Variance reduction by using separate genuine - impostor statistics in multimodal biometrics .	matching score level fusion methods ; biometric matching score level fusion ; genuine and impostor variances ; normalization and fusion techniques ; polycost and xm2vts databases ; genuine and impostor statistics ; global score statistics ; multimodal biometric ; monomodal scores ; person verification ; multimodal scores ; multimodal statistics ; weighting method	<method> <task> <otherscientificterm> <method> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <method>	3 0 1 ; 6 0 0	in this paper , we propose some novel <method_3> for <task_1> in <task_9> . while conventional <method_0> use <otherscientificterm_6> , we consider in this work both <material_5> separately . performing a joint mean normalization of the separate <otherscientificterm_8> , <otherscientificterm_10> with less separate variance than the monomodal ones are obtained . furthermore , a <method_12> has been designed in order to minimize the variance sum of the separate <material_11> . this <method_12> obtains a minor sum of <otherscientificterm_2> for the <otherscientificterm_7> than that of the monomodal ones . the results obtained in speech and face scores fusion upon <material_4> show that the proposed <method_3> provide better results than the conventional methods .	3 1 9 14 13 -1 0 6 5 15 13 -1 8 10 13 -1 12 11 13 -1 2 7 13 -1 4 13 -1
Modeling Interaction via the Principle of Maximum Causal Entropy .	sequentially revealed side information ; maximum causal entropy ; causally conditioned probabilities ; statistical models ; sequential data ; maximum entropy ; marginal distributions ; interaction ; feedback	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 0 1 ; 7 1 8	the principle of <method_5> provides a powerful framework for <method_3> of joint , conditional , and <otherscientificterm_6> . however , there are many important distributions with elements of <otherscientificterm_7> and <otherscientificterm_8> where its applicability has not been established . this work presents the principle of <otherscientificterm_1> -- an approach based on <otherscientificterm_2> that can appropriately model the availability and influence of <otherscientificterm_0> . using this principle , we derive models for <material_4> with revealed information , <otherscientificterm_7> , and <otherscientificterm_8> , and demonstrate their applicability for statistically framing inverse optimal control and decision prediction tasks .	5 3 6 9 -1 7 8 9 -1 1 2 0 10 9 -1 4 11 9 -1
A Novel Representation for Riemannian Analysis of Elastic Curves in Rn .	continuous , closed curves ; elastic shape metric ; shape analysis ; 3-d examples ; path-straightening methods ; computing geodesics ; fast algorithm ; step-by-step algorithms ; features ; geodesics ; path-straightening	<otherscientificterm> <otherscientificterm> <task> <material> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 1 4 ; 7 0 5	we propose a novel representation of <otherscientificterm_0> in ‚Ñù -lrb- n -rrb- that is quite efficient for analyzing their shapes . we combine the strengths of two important ideas - <otherscientificterm_1> and <method_4> - in <task_2> and present a <method_6> for finding <otherscientificterm_9> in shape spaces . the <method_6> allows for optimal matching of <otherscientificterm_8> while <otherscientificterm_10> provides <otherscientificterm_9> between curves . efficiency results from the fact that the <method_6> becomes the simple -lrb- 2 -rrb- metric in the proposed representation . we present <method_7> for <task_5> in this <method_6> , and demonstrate <method_7> with 2-d as well as <material_3> .	0 11 -1 1 4 2 6 9 12 11 -1 8 10 11 -1 11 -1 7 5 3 13 11 -1
Modelling activity global temporal dependencies using Time Delayed Probabilistic Graphical Model .	time delayed probabilistic graphical model ; globally optimised time-delayed dependencies ; global behaviour anomalies ; real-time anomaly detection ; semantically decomposed regions ; cumulative abnormality score ; multi-camera activities ; camera network ; disjoint cameras ; log-likelihood score	<method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <metric> <task> <method> <otherscientificterm> <otherscientificterm>	5 0 3 ; 5 4 9 ; 9 0 3 ; 0 0 6	we present a novel approach for detecting <otherscientificterm_2> in multiple <otherscientificterm_8> by learning time delayed dependencies between activities cross camera views . specifically , we propose to model <task_6> using a <method_0> with different nodes representing activities in different <otherscientificterm_4> from different camera views , and the directed links between nodes encoding causal relationships between the activities . a novel two-stage structure learning algorithm is formulated to learn <otherscientificterm_1> . a new <metric_5> is also introduced to replace the conventional <otherscientificterm_9> for gaining significantly more robust and reliable <task_3> . the effectiveness of the proposed approach is validated using a <method_7> installed at a busy underground station .	2 8 10 -1 6 0 4 14 10 -1 1 10 -1 5 9 3 11 12 13 10 -1 10 -1
A Bayesian framework for the multifractal analysis of images using data augmentation and a whittle approximation .	-lrb- linear regression based -rrb- estimation ; bayesian estimation of multifractal parameters ; regularity fluctuations of image intensity ; -lrb- wavelet -rrb- leaders ; fourier coefficients of log-leaders ; conditional posterior distributions ; nonstandard posterior distributions ; synthetic multifractal images ; image processing task ; data-augmented bayesian model ; texture analysis ; estimation quality ; inherent constraints ; bayesian model ; generative model ; mathematical framework ; computational cost ; numerical simulations ; statistical model ; reparametrization	<method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <task> <method> <task> <metric> <otherscientificterm> <method> <method> <method> <metric> <method> <method> <method>	14 0 4 ; 7 0 17 ; 14 0 12 ; 11 1 16 ; 5 0 9 ; 13 0 10 ; 9 0 5 ; 19 0 12 ; 10 6 8 ; 11 5 18 ; 16 5 18 ; 10 0 8 ; 7 0 18 ; 18 0 1 ; 18 4 0	texture analysis is an <task_8> that can be conducted using the <method_15> of <task_10> to study the <otherscientificterm_2> and the practical tools for their assessment , such as <otherscientificterm_3> . a recently introduced <method_18> for leaders enables the <task_1> . <method_18> significantly improves performance over standard <method_0> . however , the <metric_16> induced by the associated <otherscientificterm_6> limits its application . the present work proposes an alternative <method_13> for <task_10> that leads to more efficient algorithms . <method_18> relies on three original contributions : a novel <method_14> for the <method_4> ; an appropriate <method_19> for handling its <otherscientificterm_12> ; a <method_9> yielding standard <otherscientificterm_5> that can be sampled exactly . <method_17> using <material_7> demonstrate the excellent performance of the proposed <method_18> , both in terms of <metric_11> and <metric_16> .	8 15 10 2 3 29 32 20 -1 18 1 34 20 -1 0 35 20 -1 16 6 20 -1 13 26 20 -1 14 4 19 12 21 23 25 27 28 20 -1 9 5 17 22 24 30 31 33 20 -1
The Method of Quantum Clustering .	known data sets ; scale-space probability function ; support-vector clustering ; variable parameter ; probability function ; scale-space clustering ; schr√∂dinger equation ; cluster centers ; clustering method ; hilbert space ; gaussian kernel ; ideas	<material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm>	5 1 2	we propose a novel <method_8> that is an extension of <otherscientificterm_11> inherent to <task_5> and <task_2> . like the latter , <method_8> associates every data point with a vector in <otherscientificterm_9> , and like the former <method_8> puts emphasis on their total sum , that is equal to the <otherscientificterm_1> . the novelty of our <method_8> is the study of an operator in <otherscientificterm_9> , represented by the <otherscientificterm_6> of which the <otherscientificterm_4> is a solution . this <otherscientificterm_6> contains a potential function that can be derived analytically from the <otherscientificterm_4> . we associate minima of the potential with <method_7> . the <method_8> has one <otherscientificterm_3> , the scale of its <method_10> . we demonstrate its applicability on <material_0> . by limiting the evaluation of the schr√∂dinger potential to the locations of data points , we can apply this <method_8> to problems in high dimensions .	8 11 5 2 13 12 -1 9 1 12 -1 6 4 12 -1 12 -1 7 12 -1 12 -1 3 10 12 -1 0 12 -1
Linear interpolation of cepstral variance for noisy speech recognition .	pattern classification rate ; speech model combination ; cepstral variance ; recognition rate ; spectral statistics ; mapping process ; pattern classification ; noise variances ; background noise ; cepstral domain ; linear interpolation ; spectral domain ; noisy speech ; environmental adaptation ; speech feature ; speech recognition ; computation ; mapping	<metric> <task> <otherscientificterm> <metric> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <material> <method> <material> <material> <task> <otherscientificterm> <task> <otherscientificterm> <task>	14 0 6 ; 4 0 15 ; 4 0 1 ; 9 0 15 ; 8 0 1 ; 4 0 9	speech <task_1> with the <otherscientificterm_8> has been shown effective to improve the <metric_0> of <material_12> . the <task_1> can be performed by the addition of the <otherscientificterm_4> such as the means and the variances . since the <otherscientificterm_14> for <task_6> has to be expressed in the <material_9> , the combined <otherscientificterm_4> have to be transferred into the <material_9> for <task_15> . in our previous study , we have proposed a direct adaptation scheme of the <otherscientificterm_2> that is without the <task_17> from the <material_11> to the <material_9> . in this paper , an improved version to perform the adaptation is proposed . from the study , it is observed that the adapted variance can be expressed as a <method_10> of the speech and the <otherscientificterm_7> to obtain a comparable <metric_3> that is obtained with the <method_5> . due to the direct adaptation of the variances , a lot of <otherscientificterm_16> can be reduced to perform the <task_13> .	1 8 0 12 23 18 -1 4 21 18 -1 14 6 9 15 19 20 22 24 18 -1 2 17 11 18 -1 18 -1 18 -1 10 7 3 5 18 -1
An efficient fractional sample delayer for digital beam steering .	fractional sample delayer ; 35-tap finite impulse response filter ; digital fractional sample delayers ; flat magnitude response ; baseband sampling frequency ; baseband sampling time ; baseband width ; signal delay ; baseband rate ; 20-bit resolution ; tracking	<method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	9 0 1	in this paper we propose to use <method_2> to perform high precision beam steering at the <otherscientificterm_4> . the major advantages of the proposed technique are that the <method_0> used has a very <otherscientificterm_3> within the <otherscientificterm_6> allowing greater than <otherscientificterm_9> for a <method_1> . it also has a delay which is continuously variable providing resolutions greater than 220,000 ths of the <otherscientificterm_5> . owing to the <otherscientificterm_7> being performed at the <otherscientificterm_8> , elements with different delays may be placed in parallel , allowing for the formation of multiple beams -lrb- e.g. <task_10> and surveillance capability simultaneously -rrb- .	2 4 11 -1 0 3 6 9 1 12 11 -1 5 11 -1 7 8 10 11 -1
DFT domain subspace based noise tracking for speech enhancement .	noise power spectral density ; dft domain based speech enhancement methods ; eigenvalue decompositions of correlation matrices ; non-stationary noise sources ; noise tracking algorithms ; noisy dft coefficients ; estimation error ; enhancement system ; noise tracking ; spectral regions ; segmental snr ; noise psd	<metric> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm>	3 0 11	most <method_1> are dependent on an estimate of the <metric_0> . for <otherscientificterm_3> it is desirable to estimate the <otherscientificterm_11> also in <otherscientificterm_9> where speech is present . in this paper a new method for <task_8> is presented , based on <method_2> that are constructed from time series of <otherscientificterm_5> . the presented method can estimate the <otherscientificterm_11> at time-frequency points where both speech and noise are present . in comparison to state-of-the-art <method_4> the proposed algorithm reduces the <otherscientificterm_6> between the estimated and the true <otherscientificterm_11> and improves <method_10> when combined with an <method_7> with several db .	1 0 12 -1 3 11 9 13 12 -1 8 2 5 12 -1 12 -1 4 6 10 7 12 -1
Active Frame , Location , and Detector Selection for Automated and Manual Video Annotation .	semantic class label uncertainty ; information-driven active selection approach ; paragon '' algorithm ; uncertainty bound ; labeling mechanism ; noisy detectors ; computational cost ; pixel ; detectors	<otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <otherscientificterm>	1 0 4 ; 1 0 8	we describe an <method_1> to determine which <otherscientificterm_8> to deploy at which location in which frame of a video to minimize <otherscientificterm_0> at every <otherscientificterm_7> , with the smallest <metric_6> that ensures a given <otherscientificterm_3> . we show minimal performance reduction compared to a '' <method_2> running all <otherscientificterm_8> at all locations in all frames , at a small fraction of the <metric_6> . our <method_1> can handle uncertainty in the <method_4> , so <method_1> can handle both '' oracles '' -lrb- manual annotation -rrb- or <method_5> -lrb- automated annotation -rrb- .	1 8 0 7 6 3 11 9 -1 2 9 -1 4 5 10 9 -1
A Complete Epistemic Planner without the Epistemic Closed World Assumption .	epistemic closed-world assumption ; weak minimal epistemic cnf ; weak minimal epistemic dnf ; progression and entailment algorithms ; epistemic planning problems ; main planning algorithm ; single-agent epis-temic planner ; epistemic planning scenarios ; planning communities ; epistemic planner ; epistemic formulas ; epistemic goals ; contingent planning ; generic plan ; epistemic planning ; single-agent case	<method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <task> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <material>	6 0 4 ; 1 6 10 ; 6 6 9 ; 2 1 1 ; 2 6 10 ; 6 0 12 ; 0 0 6	planning with <otherscientificterm_11> has received attention from both the dynamic logic and <method_8> . in the <material_15> , under the <method_0> , <method_14> can be reduced to <task_12> . however , it is inappropriate to make the <method_0> in some <task_7> , for example , when the agent is not fully introspective , or when the agent wants to devise a <otherscientificterm_13> that applies to a wide range of situations . in this paper , we propose a complete <method_6> without the <method_0> . we identify two normal forms of <method_10> : <otherscientificterm_2> and <otherscientificterm_1> , and present the <method_3> based on these normal forms . we adapt the <method_6> for <task_12> from the literature as the <method_5> and develop a complete <method_9> called <method_6> . our experimental results show that <method_6> can generate solutions effectively for most of the <task_4> we have considered including those without the <method_0> .	11 8 16 -1 15 0 14 12 16 -1 7 13 16 -1 6 23 16 -1 10 2 1 3 18 20 21 16 -1 19 22 16 -1 5 9 17 16 -1
Rapid design of discrete orthonormal wavelet transforms using silicon IP components .	single and multi-stage wavelet analysis ; fpga and pld implementations ; orthonormal wavelet transform cores ; cascaded silicon cores ; wavelet based system ; data word length ; coefficient word length ; interface glue logic ; wavelet transform filters ; rapid design methodology ; wavelet family ; design time ; silicon layout ; hand-crafted designs ; time-interleaved coefficients ; control circuit ; wavelet type ; vhdl ; foundries	<task> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	5 1 6 ; 14 0 9 ; 9 0 1 ; 9 0 2 ; 10 1 16 ; 16 1 5 ; 14 0 8 ; 3 0 0 ; 11 0 12	a <method_9> for <otherscientificterm_2> has been developed . this <method_9> is based on a generic , scaleable <method_9> utilising <otherscientificterm_14> for the <method_8> . the <method_9> has been captured in <method_17> and parameterised in terms of <otherscientificterm_10> , <otherscientificterm_16> , <otherscientificterm_5> and <otherscientificterm_6> . the <otherscientificterm_15> is embedded within the cores and allows <otherscientificterm_15> to be cascaded without any <otherscientificterm_7> for any desired level of decomposition . case studies for stand alone and <material_3> for <task_0> respectively are reported . the <metric_11> to produce <otherscientificterm_12> of a <method_4> has been reduced to typically less than a day . the cores are comparable in area and performance to <otherscientificterm_13> . the <method_9> are portable across a range of <otherscientificterm_18> and are also applicable to <task_1> .	9 2 23 19 -1 14 8 21 26 19 -1 17 10 16 5 6 20 24 25 19 -1 15 7 19 -1 3 0 27 19 -1 11 12 4 28 19 -1 19 -1 13 22 19 -1
Detection of multipath random signals by multiresolution subspace design .	modied de blockinection sense ; multipath signal subspace s ; multipath signal set s ; multipath constrained environments ; random signal case ; representation subspace g ; gap metric sense ; modi-ed de blockinection ; linear subspace ; random process ; transmitted signal ; orthogonal projection ; subspaces	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	7 0 4 ; 11 0 1 ; 11 0 11 ; 5 0 2 ; 0 2 2	in our earlier work -lsb- 1 , 2 -rsb- , we developed a robust detector for <otherscientificterm_3> when the <material_10> is known . in this paper , we extend these results to the case where the <material_10> is a <otherscientificterm_9> . the approach i n -lsb- 1 , 2 -rsb- is to replace the <otherscientificterm_11> on the <otherscientificterm_1> by the <otherscientificterm_11> on a <otherscientificterm_5> , such that g and s are close in the <otherscientificterm_6> . when the signal is random , s is no longer a <otherscientificterm_8> but a set with a given structure . the gap metric applies only when s and g are <otherscientificterm_12> . in this paper , we introduce the <method_7> as the appropriate measure to be used in the <task_4> . we design the <otherscientificterm_5> to match the <otherscientificterm_2> in the <otherscientificterm_0> . wavelet multiresolution tools are used to facilitate the design .	3 10 13 -1 9 13 -1 11 1 5 6 15 16 13 -1 8 13 -1 13 -1 12 14 13 -1 7 4 17 18 13 -1 2 0 13 -1
Cyclic Causal Models with Discrete Variables : Markov Chain Equilibrium Semantics and Sample Ordering .	structural equation models ; equilibrium distribution ; markov chain equilibrium semantics ; cyclic structural equation models ; cyclic causal models ; discrete cyclic sems ; discrete variables ; causal graph ; markov chain ; sample order ; sample ordering ; independent noise ; noise ; semantics	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 0 6	we analyze the foundations of <method_4> for <otherscientificterm_6> , and compare <method_0> to an alternative <otherscientificterm_13> as the <otherscientificterm_1> of a <otherscientificterm_8> . we show under general conditions , <method_5> can not have <otherscientificterm_11> ; even in the simplest case , <method_3> imply constraints on the <otherscientificterm_12> . we give a formalization of an alternative <otherscientificterm_2> which requires not only the <otherscientificterm_7> , but also a <otherscientificterm_9> . we show how the resulting equilibrium is a function of the <otherscientificterm_10> , both theoretically and empirically .	4 6 0 13 1 8 15 14 -1 5 11 3 12 14 -1 2 7 9 14 -1 10 14 -1
The Shapley Value as a Function of the Quota in Weighted Voting Games .	player 's power ; weighted voting games ; shapley value-maximizing quota ; voter 's rank ; overall weight distribution ; quota manipulation ; algorithmic issues ; shapley value ; quota ; heuristic	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 0 5 ; 3 1 4	in <method_1> , each agent has a weight , and a coalition of players is deemed to be winning if its weight meets or exceeds the given <otherscientificterm_8> . an agent 's power in such games is usually measured by her <otherscientificterm_7> , which depends both on the agent 's weight and the <otherscientificterm_8> . -lsb- zuckerman et al. , 2008 -rsb- show that one can alter a <otherscientificterm_0> significantly by modifying the <otherscientificterm_8> , and investigate some of the related <otherscientificterm_6> . in this paper , we answer a number of questions that were left open by -lsb- zuckerman et al. , 2008 -rsb- : we show that , even though deciding whether a <otherscientificterm_8> maximizes or minimizes an agent 's <otherscientificterm_7> is conp-hard , finding a <otherscientificterm_2> is easy . minimizing a <otherscientificterm_0> appears to be more difficult . however , we propose and evaluate a <method_9> for this problem , which takes into account the <otherscientificterm_3> and the <metric_4> . we also explore a number of other <otherscientificterm_6> related to <task_5> .	1 8 10 -1 7 10 -1 0 6 10 -1 10 -1 2 10 -1 12 10 -1 9 3 4 11 10 -1
Speech analysis by rule extraction from trained artificial neural networks .	timit and ogi numbers95 speech corpora ; neural network feature extractors ; english fricative classes ; rule extraction technique ; transformed feature representation ; feature extraction ; input features ; pa-rameterization method ; if-then rules ; neural network ; class discrim-inability ; parameterized signal	<material> <method> <otherscientificterm> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	1 0 5	a recent development in <task_5> is the use of <method_1> , where the <otherscientificterm_11> is passed through a <method_9> trained to discriminate between targets representing e.g. different phone classes or speakers . while the <method_4> often enhances <otherscientificterm_10> and thereby overall performance , the transformation performed by the <method_9> can not directly be interpreted by human experts . however , explicit knowledge about this transformation could lead to the definition of a simpler function on the <otherscientificterm_6> which might eventually be incorporated into the basic <method_7> . in this paper we investigate a <method_3> for transforming the trained <method_9> into a set of <otherscientificterm_8> capable of representing the transformation in a more transparent way , and apply it to the problem of distinguishing between the <otherscientificterm_2> / f , v / and / s , z / from the <material_0> .	5 1 11 9 13 12 -1 4 10 12 -1 6 7 12 -1 3 12 -1
ARCH and GARCH parameter estimation in presence of additive noise using particle methods .	generalized autoregressive conditional heteroscedasticity models ; maximum likelihood estimation ; autoregressive conditional heteroscedasticity ; gradient based optimization algorithm ; gradient descend method ; active set method ; particle methods ; particle filters ; stationarity constraints ; gradient	<method> <task> <method> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm>	1 0 0 ; 4 1 5 ; 6 0 3 ; 7 0 1	in this paper , we propose a new method based on <method_7> for <task_1> of the parameters of <method_2> and <method_0> . our method is based on <method_4> and <method_5> for maximizing the likelihood function over parameters under <otherscientificterm_8> . the <otherscientificterm_9> of the likelihood function of observation given the parameters of the model , which is needed for <method_3> , is estimated using <method_6> . simulation results show the advantage of the proposed method over competing techniques .	7 1 2 0 11 14 10 -1 4 5 8 12 10 -1 9 3 6 13 10 -1 10 -1
Optimal dimensionality of metric space for classification .	discriminant adjacent matrix ; curse of dimensionality ; finite training samples ; high-dimensional patterns ; classification task ; metric space ; euclidean distance ; spectral analysis ; classification	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <task>	7 0 5 ; 5 0 8	in many real-world applications , <otherscientificterm_6> in the original space is not good due to the <otherscientificterm_1> . in this paper , we propose a new method , called discriminant neighborhood embedding -lrb- dne -rrb- , to learn an appropriate <otherscientificterm_5> for <task_8> given <material_2> . we define a <otherscientificterm_0> in favor of <task_4> , i.e. , neighboring samples in the same class are squeezed but those in different classes are separated as far as possible . the optimal dimensionality of the <otherscientificterm_5> can be estimated by <method_7> in the proposed method , which is of great significance for <otherscientificterm_3> . experiments with various datasets demonstrate the effectiveness of our method .	6 1 9 -1 5 8 2 11 9 -1 0 4 9 -1 7 3 10 9 -1 9 -1
Online Learning : Stochastic , Constrained , and Smoothed Adversaries .	stochastic and non-stochastic assumptions ; smoothed online learning scenario ; distribution-dependent rademacher complexity ; sequential symmetrization approach ; classical statistical setting ; infinite littlestone dimension ; fixed distribution ; adversarial scenario ; learning theory ; minimax value ; variation-type bounds ; function classes ; bounds	<otherscientificterm> <otherscientificterm> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 2 11	learning theory has largely focused on two main learning scenarios : the <method_4> where instances are drawn i.i.d. from a <otherscientificterm_6> , and the <otherscientificterm_7> wherein , at every time step , an adversarially chosen instance is revealed to the player . it can be argued that in the real world neither of these assumptions is reasonable . we define the <otherscientificterm_9> of a game where the adversary is restricted in his moves , capturing <otherscientificterm_0> on data . building on the <method_3> , we define a notion of <metric_2> for the spectrum of problems ranging from i.i.d. to worst-case . the <otherscientificterm_12> let us immediately deduce <otherscientificterm_10> . we study a <otherscientificterm_1> and show that exponentially small amount of noise can make <otherscientificterm_11> with <otherscientificterm_5> learnable .	4 6 7 13 -1 13 -1 9 0 13 -1 3 2 13 -1 13 -1 12 10 14 13 -1
One Permutation Hashing .	-lrb- k-permutation -rrb- minwise hashing ; sublinear time near-neighbor search ; binary data matrix ; b-bit minwise hashing ; massive binary data ; minwise hashing ; k-permutation scheme ; permutation hashing ; permutation scheme ; data vector ; permuted columns ; probability analysis ; large-scale learning ; pre-processing ; search	<method> <task> <otherscientificterm> <method> <material> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <task>	3 0 12 ; 8 4 0	minwise hashing is a standard procedure in the context of <task_14> , for efficiently estimating set similarities in <material_4> such as text . recently , <method_3> has been applied to <task_12> and <task_1> . the major drawback of <method_5> is the expensive <method_13> , as the method requires applying -lrb- e.g. , -rrb- k = 200 to 500 permutations on the data . this paper presents a simple solution called one <method_7> . conceptually , given a <otherscientificterm_2> , we permute the columns once and divide the <otherscientificterm_10> evenly into k bins ; and we store , for each <otherscientificterm_9> , the smallest nonzero location in each bin . the <method_11> illustrates that this one <method_8> should perform similarly to the original <method_0> . our experiments with training svm and logistic regression confirm that one <method_7> can achieve similar -lrb- or even better -rrb- accuracies compared to the <method_6> . see more details in arxiv :1208.1259 .	14 4 15 -1 3 12 1 16 15 -1 5 13 15 -1 7 15 -1 2 10 9 15 -1 17 15 -1 11 8 0 15 -1 6 15 -1
Automatic Depiction of Spatial Descriptions .	wip -lrb- words into pictures -rrb- system ; natural language spatial predications ; conceptual representation of objects ; deictic/intrinsic reference frame ambiguity ; spatial occupancy models ; qualitative layer ; field model ; quantitative layer ; projective prepositions	<method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	5 0 2	a novel combination of ideas from cognitive linguistics and <method_4> in robotics has led to the <method_0> . <method_0> automatically generates depictions of natural language descriptions of indoor scenes . a <otherscientificterm_5> in the <otherscientificterm_2> underlies a mechanism by which alternative depictions arise for qualitatively distinct interpretations , as often occurs as a result of <otherscientificterm_3> . at the same time , a <otherscientificterm_7> , in conjunction with a potential <method_6> of the semantics of <otherscientificterm_8> , is used in the process of capturing the inherently fuzzy character of the meaning of <task_1> .	4 0 9 -1 9 -1 5 2 3 10 9 -1 7 6 8 1 9 -1
AER Building Blocks for Multi-Layer Multi-Chip Neuromorphic Vision Systems .	event-based hardware vision system ; data-driven adaptive real time vision systems ; event-based hardware vision system ; spatio-temporal trajectories ; rotating disk ; aer system ; object chip	<method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	0 0 3 ; 0 6 5	we describe the construction and characterization of an <method_0> that learns to classify <otherscientificterm_3> . our characterization so far showed that stimuli of two different shapes on a <otherscientificterm_4> could simultaneously be discriminated and their position extracted at level of the <otherscientificterm_6> . <method_0> is the largest <method_5> yet assembled . <method_0> is a step towards efficient architectures for <task_1> .	0 3 8 7 -1 4 6 7 -1 5 9 7 -1 1 2 7 -1
Combining multi-party speech and text exchanges over the internet .	fully situated human-human spoken conversation ; spoken and text chat records ; spoken information representation ; meeting history tools ; on-line multi-speaker conversation ; video conferencing ; magic lounge ; spoken conversation ; on-line communication ; text chat ; internet ; speech	<material> <material> <method> <method> <material> <material> <method> <material> <task> <material> <material> <material>	0 6 8 ; 9 1 8 ; 0 1 5 ; 9 1 11 ; 9 1 7 ; 4 0 9	bilateral or group text chatting over the <material_10> has become a favoured pastime for many people across the world . yet it would seem that , in general , <material_9> is a severely impoverished mode of <task_8> compared to , e.g. , <material_0> , <material_5> , or even speaking over the telephone . this paper explores what happens when <material_4> over the <material_10> is added to <material_9> , creating what may become a widespread mode of communication in the near future . the system used is called the <method_6> . <method_6> offers a multimodal combination of <material_9> and <material_7> for meetings and other encounters among ubiquitous users who may join the communication from workstations , pdas and wap phones . in addition , the system has a series of <method_3> which provide various forms of structure to the <material_1> of the meeting as it unfolds and after the meeting . the paper presents rather clear-cut results on the respective communicative roles of <material_11> and <material_9> from a series of user tests with the system in which different groups of users performed scenarios designed to explore the combined use of <material_9> and <material_11> . the results reported may generalise to a wide range of applications which combine text and <method_2> .	10 12 -1 9 8 0 5 13 14 15 12 -1 4 18 12 -1 6 12 -1 7 17 12 -1 12 -1 3 1 16 12 -1 11 12 -1
Visual tracking via geometric particle filtering on the affine group with optimal importance functions .	geometrically defined optimal importance function ; 2-d affine motion ; principal component analysis ; coordinate-invariant particle filtering ; object template ; geometric method ; visual tracking ; video sequence	<otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <task> <material>	5 0 6 ; 3 0 1 ; 0 0 6	we propose a <method_5> for <task_6> , in which the <otherscientificterm_1> of a given <otherscientificterm_4> is estimated in a <material_7> by means of <method_3> on the 2-d affine group aff -lrb- 2 -rrb- . <task_6> performance is further enhanced through a <otherscientificterm_0> , obtained explicitly via taylor expansion of a <method_2> based measurement function on aff -lrb- 2 -rrb- . the efficiency of our <method_5> to <task_6> is demonstrated via comparative experiments .	5 6 1 4 7 3 10 8 -1 0 2 11 8 -1 9 8 -1
Language identification on code-switching utterances using multiple cues .	acoustic , prosodic and phonetic features ; asr -rrb- error rate reduction ; switching linguistic unit ; posteriori decision rule ; mandarin-taiwanese code-switching utterance ; stage lvcsr-based system ; language identifier ; language model ; acoustic model ; code-switching speech ; duration model ; speech recognizer ; two-stage framework	<otherscientificterm> <metric> <method> <otherscientificterm> <material> <method> <method> <method> <method> <material> <method> <method> <method>	10 1 7 ; 6 1 11 ; 1 5 5 ; 6 3 12	code-switching speech is an utterance containing two or more languages . usually , the <method_2> is in clause or word levels . in this paper , a <method_12> is proposed , containing a <method_6> and then a <method_11> , to evaluate on a <material_4> . in the <method_6> , we use multiple cues including <otherscientificterm_0> . in order to integrate the cues to distinguish one language from another , we used a maximum a <otherscientificterm_3> to connect an <method_8> , a <method_10> and a <method_7> . in the experiments , we have achieved 34.5 % -lrb- lid -rrb- and 17.7 % -lrb- <metric_1> comparing with one <method_5> .	13 -1 2 13 -1 12 6 11 4 15 17 13 -1 0 13 -1 3 8 10 7 14 13 -1 16 13 -1
Physical models of the human vocal tract with gel-type material .	default low tongue height ; articulatory training ; ultra-malleable model ; gel-type tongue ; speech science ; speech pathology ; language learning ; talking heads	<otherscientificterm> <task> <method> <otherscientificterm> <task> <task> <task> <otherscientificterm>	5 1 6 ; 1 0 6 ; 5 1 1	beginning in 2001 , we have been developing models of the vocal tract to promote a more intuitive understanding of the theories for <task_4> for technical and non-technical students . in this paper , we compared and contrasted four newer models of the <otherscientificterm_7> : our original model with a <otherscientificterm_3> , a similar model including teeth and palate , a third model with teeth and palate having a <otherscientificterm_0> , and a fourth <method_2> made completely of gel material . results are discussed regarding their strengths and weaknesses for educational purposes and <task_1> in <task_5> and <task_6> .	4 8 -1 7 3 0 2 8 -1 1 5 6 9 10 11 8 -1
Theory and design of a class of cosine-modulated non-uniform filter banks .	pr cosine-modulated nonuniform filter bank ; pr nonuniform filter banks ; high stopband attenuation ; uniform filter bank ; filter representations ; merging techniques ; synthesis section ; design procedure ; filter quality ; spectrum inversion ; design examples ; arithmetic complexity ; protrusion cancellation ; filter bank ; implementation complexities ; decimation ; cox ; cmfb ; simplifications	<task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <metric> <method> <material> <metric> <otherscientificterm> <method> <metric> <otherscientificterm> <method> <method> <otherscientificterm>	9 1 4 ; 12 6 5 ; 8 1 14 ; 4 1 12 ; 9 6 5	in this paper , the theory and design of a class of <task_0> is proposed . <task_0> is based on a structure previously proposed by <method_16> , where the outputs of a <otherscientificterm_3> is combined or merged by means of the <method_6> of another <method_13> with smaller channel number . <otherscientificterm_18> are imposed on this structure so that the <method_7> can be considerably simplified . due to the use of <method_17> as the original and recombination filter banks , excellent <metric_8> and low design and <metric_14> can be achieved . problems with these <method_5> such as <method_9> , equivalent <method_4> and <otherscientificterm_12> are also addressed . as the merging is performed after the <otherscientificterm_15> , the <metric_11> is lower than other conventional approaches . <material_10> show that <method_1> with <otherscientificterm_2> and low design and <metric_14> can be obtained by the proposed <task_0> .	0 19 -1 16 3 6 13 18 19 -1 7 19 -1 17 8 14 22 19 -1 5 9 4 20 21 23 24 19 -1 12 19 -1 15 11 10 19 -1
An Analysis of Inference with the Universum .	positive and negative data ; pattern classification algorithm ; data-dependent reduced kernel ; fisher discriminant analysis ; inductive principle ; projected subspace ; universum ; pca	<material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <method>	4 0 1 ; 3 1 7	we study a <method_1> which has recently been proposed by vapnik and coworkers . <method_1> builds on a new <method_4> which assumes that in addition to <material_0> , a third class of data is available , termed the <material_6> . we assay the behavior of the <method_1> by establishing links with <method_3> and oriented <method_7> , as well as with an <method_7> in a <otherscientificterm_5> -lrb- or , equivalently , with a <otherscientificterm_2> -rrb- . we also provide experimental results .	1 8 -1 4 0 6 9 8 -1 3 7 5 2 10 8 -1 8 -1
Approximate eigenvalue decomposition of para-Hermitian systems through successive FIR paraunitary transformations .	zeroth order diagonal energy ; signal-adapted pu filter bank ; para-hermitian system ; approximate evd ; eigenvalue decomposition ; unitary matrices ; approximate diag-onalization ; hermitian matrix	<method> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 2 ; 4 3 7 ; 5 2 7	the <task_4> of a <otherscientificterm_7> in terms of <otherscientificterm_5> is well known . in this paper , we present an algorithm for the <method_3> of a <method_2> . here , the <otherscientificterm_6> is carried out successively by applying degree-1 finite impulse response -lrb- fir -rrb- paraunitary -lrb- pu -rrb- transformations . the system parameters are chosen to make the <method_0> nondecreasing at each stage . simulation results presented for the design of a <method_1> show close agreement with the behavior of the infinite order principal component fb -lrb- pcfb -rrb- .	4 7 5 10 11 8 -1 3 2 9 8 -1 6 8 -1 0 8 -1 1 8 -1
Segmentation and relevance measure for speaker verification .	nist 2003 speaker evaluation database ; speaker recognition systems ; non speech frames ; decision score ; likelihood ratio ; segment position ; automatic segmentation	<material> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method>	3 5 1	in all the efficient <method_1> , the <metric_3> is based on the average of the <otherscientificterm_4> computed on each frame of the sentence . except for the <otherscientificterm_2> which are rejected , each one has the same weight in this summation . this paper deals with the study of the speaker relevance of each frame . an <method_6> provides quasi stationary segments of variable length ; a weight is allocated to each frame in function of its <otherscientificterm_5> and a weighted mean of the <otherscientificterm_4> is then computed . experiments are performed with <material_0> . they show that the frames near segment frontiers , that is to say the transient ones , are more speaker relevant than the middle frames of long segments which correspond to the steady parts of the phones .	1 3 4 8 7 -1 2 7 -1 7 -1 6 5 7 -1 0 7 -1 7 -1
Detection of Concentric Circles for Camera Calibration .	patterns of pairs of concentric circles ; image of the circle center ; fully automatic calibration system ; plane-based calibration methods ; feature detection ; pattern features ; user interaction ; geometric method ; construction method ; homolog-ical constraints ; features ; accuracy	<otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <metric>	6 0 4 ; 9 0 2 ; 11 5 2 ; 0 0 2 ; 8 0 5	the geometry of <method_3> is well understood , but some <otherscientificterm_6> is often needed in practice for <task_4> . this paper presents a <method_2> that uses <otherscientificterm_0> . the key observation is to introduce a <method_7> that constructs a sequence of points strictly convergent to the <otherscientificterm_1> from an arbitrary point . the <method_2> automatically detects the points of the <otherscientificterm_5> by the <method_8> , and identify them by invariants . <method_2> then takes advantage of <otherscientificterm_9> to consistently and optimally estimate the <otherscientificterm_10> in the image . the experiments demonstrate the ro-bustness and the <metric_11> of the new <method_2> .	3 6 4 13 12 -1 2 0 16 12 -1 7 1 12 -1 5 8 17 12 -1 9 10 14 12 -1 11 15 12 -1
Optimal VLC sequence decoding exploiting additional video stream properties .	maximum likelihood decoder ; image and video streaming transmission ; vlc sequence unit ; prefix-based decoder ; awgn channels ; vlc codeword ; vlc codewords ; video decoding ; unreliable links ; vlc decoders ; wireless networks	<method> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method>	10 6 8	codes -lrb- vlc -rrb- for <task_1> over <otherscientificterm_8> , such as <method_10> , is a subject of increasing interest . this paper proposes an optimum <method_0> of vlc sequences which exploits additional inherent redundancy in the source information , namely -lrb- i -rrb- the correlation between bits inside a <otherscientificterm_5> as well as -lrb- ii -rrb- the correlation between <otherscientificterm_6> of a <otherscientificterm_2> -lrb- e.g. corresponding to one image block -rrb- . performance results for improving <task_7> over <material_4> are then presented and compared to the <method_3> as well as the recently proposed <method_9> .	1 8 10 12 11 -1 0 5 6 2 11 -1 7 4 3 9 11 -1
A Joint Model for Discovery of Aspects in Utterances .	natural language utterance understanding model ; unstructured web search query logs ; supervised joint learning model ; labeled and unlabeled utterances ; multi-layer generative approach ; natural language utterances ; generative process ; semantic component ; semantic units ; cascaded approach	<method> <material> <method> <material> <method> <material> <method> <method> <otherscientificterm> <method>	3 0 4 ; 1 0 0 ; 4 4 9	we describe a <method_4> for understanding user actions in <material_5> . our <method_4> uses both <material_3> to jointly learn aspects regarding utterance 's target domain -lrb- e.g. movies -rrb- , intention -lrb- e.g. , finding a movie -rrb- along with other <otherscientificterm_8> -lrb- e.g. , movie name -rrb- . we inject information extracted from <material_1> as prior information to enhance the <method_6> of the <method_0> . using utterances from five domains , our <method_4> shows up to 4.5 % improvement on domain and dialog act performance over <method_9> in which each <method_7> is learned sequentially and a <method_2> -lrb- which requires fully labeled data -rrb- .	4 5 10 -1 3 8 11 10 -1 1 6 0 12 10 -1 9 7 2 13 10 -1
Haar filter banks for I-D space signals .	notions of signal and filter spaces ; 1-d space signal processing ; symmetric space shift operation ; directed time shift operation ; 1-d space signals ; haar filter bank ; space signal processing ; filters ; subspaces ; fourier	<otherscientificterm> <task> <method> <method> <material> <method> <task> <otherscientificterm> <otherscientificterm> <method>	5 0 1 ; 5 0 4 ; 5 0 6 ; 2 0 5	we derive the <method_5> for <material_4> , based on our recently introduced framework for <task_1> , termed this way since <method_5> is built on a <method_2> in contrast to the <method_3> . the framework includes the proper <otherscientificterm_0> , '' z-transform , '' convo-lution , and <method_9> transform , each of which is different from their time equivalents . in this paper , we extend this framework by deriving the proper notions of a <method_5> for <task_6> , and show that <method_5> has a similar yet different form compared to the time case . our derivation also sheds light on the nature of filter banks and makes a case for viewing them as projections on <otherscientificterm_8> rather than as based on <otherscientificterm_7> .	5 4 1 2 3 11 12 14 10 -1 0 9 10 -1 6 13 10 -1 10 -1
Analogy-preserving Semantic Embedding for Visual Object Categorization .	analogy-preserving semantic embedding ; discriminatively learned label embedding ; higher-order geometric constraints ; attribute-based class descriptions ; multi-class categorization tasks ; visual recognition datasets ; semantic analogies ; analogy completion ; inter-class confusion ; visual recognition ; semantic distances ; object taxonomy ; semantic relationships ; convex regularizer ; recognition accuracy ; analogical parallelograms ; pairwise structures	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm>	11 0 9 ; 13 0 1 ; 6 3 2 ; 6 0 1 ; 15 6 2 ; 6 0 13 ; 5 5 0 ; 14 1 7 ; 15 0 6	in <task_4> , knowledge about the classes ' <otherscientificterm_12> can provide valuable information beyond the class labels themselves . however , existing techniques focus on preserving the <otherscientificterm_10> between classes -lrb- e.g. , according to a given <method_11> for <task_9> -rrb- , limiting the influence to <otherscientificterm_16> . we propose to model analogies that reflect the relationships between multiple pairs of classes simultaneously , in the form '' p is to q , as r is to s '' . we translate <otherscientificterm_6> into <otherscientificterm_2> called <otherscientificterm_15> , and use <otherscientificterm_6> in a novel <method_13> for a <otherscientificterm_1> . furthermore , we show how to discover analogies from <otherscientificterm_3> , and how to prioritize those likely to reduce <otherscientificterm_8> . evaluating our <method_0> on two <material_5> , we demonstrate clear improvements over existing approaches , both in terms of <metric_14> and <task_7> .	4 12 17 -1 10 11 9 16 18 17 -1 17 -1 6 2 15 13 1 19 20 21 22 23 26 17 -1 17 -1 3 8 24 25 17 -1
A General Framework for Generating Multivariate Explanations in Bayesian Networks .	maximum a posteriori assignment ; most relevant explanation ; most probable explanation ; reversible jump mcmc ; generalized bayes factor ; relevance measure ; generating explanations ; approximate algorithm ; explanation methods ; simulated annealing ; bayesian networks ; pri-ori	<method> <method> <method> <method> <method> <metric> <task> <method> <method> <task> <method> <method>	0 6 10 ; 8 3 10 ; 7 0 1 ; 9 0 7 ; 3 1 9 ; 0 6 8 ; 0 1 2 ; 3 0 7 ; 2 6 10	many existing <method_8> in <method_10> , such as <method_0> and <method_2> , generate complete assignments for target variables . a <method_11> , the set of target variables is often large , but only a few of them may be most relevant in explaining given evidence . <task_6> with all the target variables is hence not always desirable . this paper addresses the problem by proposing a new framework called <method_1> , which aims to automatically identify the most relevant target variables . we will also discuss in detail a specific instance of the framework that uses <method_4> as the <metric_5> . finally we will propose an <method_7> based on <method_3> and <task_9> to solve <method_1> . empirical results show that the new <method_7> typically finds much more concise explanations than existing methods .	8 10 0 2 13 14 18 19 21 12 -1 11 6 12 -1 12 -1 1 12 -1 4 5 12 -1 15 16 17 20 12 -1 7 3 9 12 -1
The robustness of an almost-parsing language model given errorful training data .	word error rate ; inconsistent and flawed training data ; almost-parsing 1 language model ; uniform linguistic structure ; parser-based language models ; syntactic constraints ; lvcsr tasks ; lexical features	<metric> <material> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm>	7 3 3 ; 7 1 5 ; 5 3 3	an <method_2> has been developed -lsb- 1 -rsb- that provides a framework for tightly integrating multiple knowledge sources . <otherscientificterm_7> and <otherscientificterm_5> are integrated into a <otherscientificterm_3> -lrb- called a superarv -rrb- that is associated with words in the lexicon . the <method_2> has been found able to reduce perplexity and <metric_0> compared to trigram , part-of-speech-based , and <method_4> on the darpa wall street journal -lrb- wsj -rrb- csr task . in this paper we further investigate the robustness of the <method_2> to possibly <material_1> , as well as its ability to scale up to sophisticated <task_6> by comparing performance on the darpa wsj and hub4 -lrb- broadcast news -rrb- csr tasks .	2 7 8 -1 5 3 9 10 11 8 -1 0 4 8 -1 1 6 8 -1
Finite-State Controllers Based on Mealy Machines for Centralized and Decentralized POMDPs .	centralized and decentralized pomdps ; existing controller-based approaches ; solution methods ; mealy machine ; controller-based algorithms ; controller-based approaches ; mealy machines ; moore machines ; automata	<method> <method> <method> <method> <method> <method> <method> <method> <method>	6 0 4 ; 4 4 1 ; 1 0 0 ; 3 6 8 ; 7 6 8 ; 6 4 7 ; 8 0 1 ; 1 4 1	existing <method_5> for <method_0> are based on <method_8> with output known as <method_7> . in this paper , we show that several advantages can be gained by utilizing another type of <method_8> , the <method_3> . <method_6> are more powerful than <method_7> , provide a richer structure that can be exploited by <method_2> , and can be easily incorporated into current <method_5> . to demonstrate this , we adapted some existing <method_4> to use <method_6> and obtained results on a set of benchmark domains . the <method_1> always outperformed the <method_1> and often out-performed the state-of-the-art <method_4> for both <method_0> . these findings provide fresh and general insights for the improvement of existing <method_4> and the development of new <method_1> .	5 0 8 7 12 14 16 9 -1 3 6 13 9 -1 2 15 9 -1 4 10 9 -1 1 17 9 -1 11 9 -1
The Parameterized Complexity of Global Constraints .	constraint programming ; value symmetry ; symmetry breaking ; constraint propagation ; dynamic program ; natural parameters ; cycle cutset ; global constraints ; parameterized complexity ; decomposition ; backdoor ; symmetries	<method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	8 0 0 ; 2 6 0 ; 8 0 7	we argue that <otherscientificterm_8> is a useful tool with which to study <otherscientificterm_7> . in particular , we show that many <otherscientificterm_7> which are intractable to propagate completely have <otherscientificterm_5> which make them fixed-parameter tractable and which are easy to compute . this tractability tends either to be the result of a simple <method_4> or of a <method_9> which has a strong <otherscientificterm_10> of bounded size . this strong <otherscientificterm_10> is often a <otherscientificterm_6> . we also show that <otherscientificterm_8> can be used to study other aspects of <method_0> like <task_2> . for instance , we prove that <otherscientificterm_1> is fixed-parameter tractable to break in the number of <otherscientificterm_11> . finally , we argue that <otherscientificterm_8> can be used to derive results about the approximability of <method_3> .	8 7 15 12 -1 5 12 -1 4 9 10 12 -1 6 12 -1 0 2 13 14 12 -1 1 12 -1 11 12 -1
Memory efficient JPEG2000 architecture with stripe pipeline scheme .	level switch discrete wavelet transform ; code-block switch embedded block coding ; jpeg 2000 architectures ; stripe pipeline scheme ; memory issue ; inter-leaved scheme ; code-blocks ; ls-dwt	<method> <method> <method> <method> <task> <method> <otherscientificterm> <method>	0 1 1 ; 0 3 3 ; 1 0 6 ; 4 3 2	memory issue is the most critical problem for a high performance jpeg 2000 <method_3> . the <task_4> occupies more than 50 % of area in conventional <method_2> . to solve this problem , we propose a <method_3> . for this <method_3> , a <method_0> and a <method_1> are proposed . with small additional memory , the <method_7> and the <method_1> can process multiple levels and <otherscientificterm_6> in parallel by an <method_5> . as a result of above techniques , the overall memory requirements of the proposed <method_3> can be reduced to only 8.5 % comparing with conventional architectures .	3 8 -1 4 2 12 8 -1 8 -1 0 1 9 10 8 -1 7 6 5 11 8 -1 8 -1
On the consistency of l1-norm based ar parameters estimation in a sparse multipath environment .	symmetric finite impulse response filter ; autoregressive process ; sparse multipath environment ; ar process ; ar parameters ; 0-norm minimization ; 1-norm minimization ; reflection gains ; multipath reflections ; sparsity ; poles ; consistency ; zeros	<method> <method> <otherscientificterm> <task> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm>	2 0 1 ; 4 1 7	when an <method_1> is observed through a <otherscientificterm_2> , its <otherscientificterm_4> may be estimated by searching for a <method_0> , which , when convolved with the observed signal 's autocorrelation sequence , yields the sparsest output . the <otherscientificterm_12> of that filter would then correspond to the <otherscientificterm_10> of the <task_3> . when the 0-norm of the output is used as a measure of its <metric_9> , <metric_11> of the resulting estimate -lrb- under some simple conditions -rrb- is readily obtained . however , due to problematic aspects of <task_5> , it is often more convenient to resort to <method_6> . a question of major interest in this context is whether -lrb- and if so , under what conditions -rrb- <metric_11> of the resulting estimate is maintained . by analyzing the perturbations of the 1-norm about the desired solution , we derive -lrb- and illustrate -rrb- specific conditions for <metric_11> . we show that when the <otherscientificterm_8> are sufficiently sparse , <metric_11> is guaranteed for a very wide range of <otherscientificterm_4> and <otherscientificterm_7> .	1 2 4 0 14 13 -1 12 10 3 13 -1 9 11 13 -1 5 6 13 -1 13 -1 13 -1 15 13 -1
Keeping Flexible Active Contours on Track using Metropolis Updates .	computationally burdensome number of particles ; active contour '' framework ; likelihood-weighted particle filtering ; flexible contours ; video sequences ; metropolis algorithm ; condensation algorithm ; contour distribution ; video sequence ; condensation ; contours ; shape-subspace ; condensation	<otherscientificterm> <method> <method> <otherscientificterm> <material> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 7 ; 5 4 6 ; 8 0 12 ; 5 0 12 ; 9 6 2 ; 8 0 5	condensation , a form of <method_2> , has been successfully used to infer the shapes of highly constrained '' active '' <otherscientificterm_10> in <material_4> . however , when the <otherscientificterm_10> are highly flexible -lrb- e.g. for tracking fingers of a hand -rrb- , a <otherscientificterm_0> is needed to successfully approximate the <otherscientificterm_7> . we show how the <method_5> can be used to update a particle set representing a distribution over <otherscientificterm_10> at each frame in a <material_8> . we compare this <method_5> to <otherscientificterm_12> using a <material_8> that requires highly <otherscientificterm_3> , and show that the new <method_5> performs dramatically better that the <method_6> . we discuss the incorporation of this <method_5> into the '' <method_1> where a <otherscientificterm_11> is used constrain shape variation .	2 10 4 18 13 -1 0 7 14 13 -1 5 8 13 -1 12 3 15 16 17 19 13 -1 6 13 -1
Pliable Rejection Sampling .	pliable rejection sampling ; adaptive rejection sampling methods ; kernel estimator ; rejection rate ; sampling proposal ; rejection sampling ; sampling	<method> <method> <method> <metric> <method> <method> <task>	2 0 4	rejection <task_6> is a technique for <task_6> from difficult distributions . however , its use is limited due to a high <metric_3> . common <method_1> either work only for very specific distributions or without performance guarantees . in this paper , we present <method_0> , a new approach to <method_5> , where we learn the <method_4> using a <method_2> . since our method builds on <method_5> , the samples obtained are with high probability i.i.d. and distributed according to f. moreover , <method_0> comes with a guarantee on the number of accepted samples .	6 7 -1 3 7 -1 1 7 -1 0 5 4 2 8 7 -1 7 -1
Product Sparse Coding .	codebook size k ; sparse coding problem ; image retrieval ; computer vision ; sparse coding ; time complexity ; computational cost ; codebook size ; image classification ; sparse coding	<otherscientificterm> <task> <task> <task> <method> <metric> <metric> <otherscientificterm> <task> <task>	4 3 3 ; 8 1 2	sparse coding is a widely involved technique in <task_3> . however , the expensive <metric_6> can hamper its applications , typically when the <otherscientificterm_7> must be limited due to concerns on running time . in this paper , we study a special case of <task_9> in which the codebook is a cartesian product of two subcodebooks . we present algorithms to decompose this <task_1> into smaller subproblems , which can be separately solved . our solution , named as product sparse coding -lrb- psc -rrb- , reduces the <metric_5> from o -lrb- k -rrb- to o -lrb- ‚àö k -rrb- in the <otherscientificterm_0> . in practice , this can be 20-100 √ó faster than standard <task_9> . in experiments we demonstrate the efficiency and quality of this method on the applications of <task_8> and <task_2> .	3 11 10 -1 6 7 10 -1 9 10 -1 1 10 -1 5 10 -1 0 10 -1 12 10 -1
Automatic Language Identification in music videos with low level audio and visual features .	automatic language identification ; corpus of 25000 music videos ; linear svm classifiers ; bag-of-words '' approach ; automatic lid ; music videos ; accuracy	<task> <material> <method> <method> <task> <material> <metric>	2 0 4 ; 1 5 3 ; 6 5 3	automatic language identification -lrb- lid -rrb- in music has received significantly less attention than lid in speech . here , we study the problem of lid in <material_5> uploaded on youtube . we use a '' <method_3> based on state-of-the-art content based audiovisual features and <method_2> for <task_4> . our <method_3> obtains 48 % <metric_6> for a <material_1> and 25 different languages .	7 -1 5 7 -1 3 2 4 8 7 -1 6 1 0 9 10 7 -1
A hybrid method for deconvolution of Bernoulli-Gaussian processes .	stochastic inference methods ; parameter estimation methods ; bernoulli-gaussian prior model ; state inference ; deterministic inference ; student-t model ; hybrid method ; bernoulli-gaussian process ; simulation studies ; sem ; signal ; filter	<method> <method> <method> <task> <method> <method> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm>	10 1 11 ; 5 0 2 ; 9 6 0 ; 4 0 2	we investigate a <method_6> which improves the quality of <task_3> and parameter estimation in blind decon-volution of a sparse source modeled by a <material_7> . in this problem , when both the <otherscientificterm_10> and the <otherscientificterm_11> are jointly estimated , the true posterior is typically highly multimodal . therefore , when not properly initialized , standard <method_0> , -lrb- mcem , <method_9> or saem -rrb- , tend to get stuck and suffer from poor convergence . in our <method_6> , we first relax the <method_2> by a <method_5> . our simulations suggest that <method_4> in the <method_2> is not only efficient , but also provides a very good initialization for the <method_2> . we provide <method_8> that compare the results obtained with and without our <method_2> for several combinations of <task_3> and <method_1> used for the <method_2> .	6 3 7 12 -1 10 11 13 12 -1 0 9 15 12 -1 2 5 14 12 -1 4 16 12 -1 12 -1
An HMM/n-gram-based linguistic processing approach for Mandarin spoken document retrieval .	minimum classification error training algorithms ; vector space model approach ; mandarin spoken document retrieval ; hmm/n-gram-based linguistic processing approach ; spoken document retrieval ; retrieval capabilities ; word-and syllable-levels ; discrimination capabilities ; hmms	<method> <method> <task> <method> <task> <metric> <otherscientificterm> <metric> <method>	3 0 2	in this paper an <method_3> for <task_2> is presented . the underlying characteristics and different structures of this <method_3> were extensively investigated . the <metric_5> were verified by tests with indexing features of word-and syllable -lrb- subword -rrb- - levels and comparison with the conventional <method_1> . to further improve the <metric_7> of the <method_8> , both the expectation-maximization -lrb- em -rrb- and <method_0> were introduced in training . the information fusion of indexing features of <otherscientificterm_6> was also investigated . the <task_4> experiments were performed on the topic detection and tracking corpora -lrb- tdt-2 and tdt-3 -rrb- . very encouraging retrieval performance was obtained .	3 2 10 9 -1 9 -1 5 1 9 -1 7 8 0 9 -1 6 9 -1 4 9 -1 9 -1
Adaptive step-size parameter control for real-world blind source separation .	blind source separation ; complex gradient theory ; newton 's method ; adaptive step-size control ; robot audition systems ; fixed step-size parameter ; simultaneous speeches ; separation matrix ; honda asimo ; step-size parameter ; environmental changes ; real-world applications	<task> <method> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task>	0 0 11 ; 1 0 2 ; 4 6 11 ; 9 0 7	this paper describes a method to adaptively control a <otherscientificterm_9> which is used for updating a <otherscientificterm_7> to extract a target sound source accurately in <task_0> . the design of the <otherscientificterm_9> is essential when we apply <task_0> to <task_11> such as <method_4> , because the surrounding environment dynamically changes in the real world . it is common to use a <otherscientificterm_5> that is obtained empirically . however , due to <otherscientificterm_10> and noises , the performance of <task_0> with the <otherscientificterm_5> deteriorates and the <otherscientificterm_7> sometimes diverges . we propose a general method that allows <method_3> . the proposed method is an extension of <method_2> utilizing a <method_1> and is applicable to any <task_0> . actually , we applied it to six types of <task_0> for an 8 ch microphone array embedded in <material_8> . experimental results show that the proposed method improves the performance of these six <task_0> through experiments of separation and recognition for two <material_6> .	9 7 0 16 12 -1 11 4 13 15 12 -1 5 12 -1 10 12 -1 3 12 -1 14 12 -1 2 1 12 -1 8 12 -1
GPU-accelerated scene categorization under multiscale category-specific visual word strategy .	bag of word models ; calculation of euclidean distance ; multimedia information retrieval ; visual word quantization ; scene categorization ; computer vision ; multimedia analysis ; feature clustering ; gpu implementations	<method> <otherscientificterm> <task> <otherscientificterm> <task> <task> <task> <method> <method>	7 1 3 ; 8 0 6 ; 6 5 8 ; 8 0 2 ; 5 1 2 ; 8 0 5	we utilize <method_8> to accelerate an essential component for <task_5> and <task_2> , i.e. <task_4> . to construct <method_0> , we modify <otherscientificterm_1> so that <method_7> and <otherscientificterm_3> can be processed in a parallel manner . we provide details of <method_8> and conduct comprehensive experiments to verify the efficiency of <method_8> on <task_6> .	8 5 2 4 13 14 15 9 -1 0 1 7 3 10 9 -1 6 11 12 9 -1
Learning semantic hierarchy with distributed representations for unsupervised spoken language understanding .	frame-semantic based unsupervised slot induction approach ; unsupervised ontology learning ; hierarchical semantic structure ; high-level semantic estimation ; spoken dialogue systems ; hierarchical agglomerative clustering ; coherent semantic hierarchy ; high-level semantic information ; slot induction ; topically-related slots ; slot importance ; location-related information ; semantic decoder ; semantic understanding ; cross-slot relations ; hand-crafted grammars ; unlabelled conversations ; f-measure	<method> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <metric>	0 0 9 ; 1 0 13 ; 5 0 0 ; 4 0 13 ; 1 0 4 ; 17 5 12 ; 15 0 12	we study the problem of <method_1> for <task_13> in <method_4> , in particular , learning the <otherscientificterm_2> from the data . given <otherscientificterm_16> , we augment a <method_0> with <method_5> to merge <otherscientificterm_9> -lrb- e.g. , both slots '' direction '' and '' locale '' convey <otherscientificterm_11> -rrb- for building a <otherscientificterm_6> , and then estimate the <otherscientificterm_10> at different levels . the <task_3> involves not only within-slot but also <otherscientificterm_14> . the experiments show that <otherscientificterm_7> can accurately estimate the prominence of slots , significantly improving the <task_8> performance ; furthermore , a <method_12> trained on the data with automatically extracted slots achieves about 68 % <metric_17> , which is close to the one from <method_15> .	1 13 4 2 20 22 23 18 -1 16 0 5 9 11 6 10 19 21 18 -1 3 14 18 -1 7 8 12 24 25 18 -1
Quantization Noise Shaping for Information Maximizing ADCs .	common time and frequency interleaved multi channel structures ; wireline and wireless style channels ; analog and digital worlds ; non constant information ; fixed power budget ; quantization noise shaping ; loop filter design ; con-figurable adc ; digital domain ; quantization noise ; adcs	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <material> <otherscientificterm> <material>	6 0 5 ; 3 2 7	adcs sit at the interface of the <otherscientificterm_2> and fundamentally determine what information is available in the <material_8> for processing . this paper shows that a <method_7> can be designed for signals with <otherscientificterm_3> as a function of frequency such that within a <otherscientificterm_4> the <material_10> maximizes the information in the converted signal by frequency shaping the <otherscientificterm_9> . <task_5> can be realized via <method_6> for a single channel delta sigma <material_10> and extended to <otherscientificterm_0> . results are presented for example <material_1> .	2 8 11 -1 7 3 4 10 9 5 13 11 -1 6 0 12 11 -1 1 11 -1
The relevance of feature type for the automatic classification of emotional user states : low level descriptors and functionals .	low level descriptor types ; support vector machines ; information gain ratio ; german database ; random forests ; features ; classification	<otherscientificterm> <method> <metric> <material> <material> <otherscientificterm> <task>	1 1 4	in this paper , we report on <task_6> results for emotional user states -lrb- 4 classes , <material_3> of children interacting with a pet robot -rrb- . six sites computed acoustic and linguistic <otherscientificterm_5> independently from each other , following in part different strategies . a total of 4244 <otherscientificterm_5> were pooled together and grouped into 12 <otherscientificterm_0> and 6 functional types . for each of these groups , <task_6> results using <method_1> and <material_4> are reported for the full set of <otherscientificterm_5> , and for 150 <otherscientificterm_5> each with the highest individual <metric_2> . the performance for the different groups varies mostly between ‚âà 50 % and ‚âà 60 % .	6 3 7 -1 5 7 -1 0 7 -1 1 4 2 8 7 -1 7 -1
Multi-Relational Latent Semantic Analysis .	multi-relational latent semantic analysis ; latent semantic analysis ; homogeneous and heterogeneous information sources ; latent semantic space ; latent square matrix ; linear algebraic operations ; 3-way tensor ; low-rank approximation ; tensor decomposition ; antonymy	<method> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm>	0 0 1	we present <method_0> which generalizes <method_1> . <method_0> provides an elegant approach to combining multiple relations between words by constructing a <otherscientificterm_6> . similar to <method_0> , a <method_7> of the tensor is derived using a <method_8> . each word in the vocabulary is thus represented by a vector in the <otherscientificterm_3> and each relation is captured by a <otherscientificterm_4> . the degree of two words having a specific relation can then be measured through simple <method_5> . we demonstrate that by integrating multiple relations from both <material_2> , <method_0> achieves state-of-the-art performance on existing benchmark datasets for two relations , <otherscientificterm_9> and is-a .	0 1 11 10 -1 6 10 -1 7 8 10 -1 3 4 10 -1 5 10 -1 2 10 -1
Automatic Construction of Polarity-Tagged Corpus from HTML Documents .	html documents ; linguistic pattern ; layout structures ; polarity-tagged corpus	<material> <otherscientificterm> <otherscientificterm> <material>	2 1 1	this paper proposes a novel method of building <material_3> from <material_0> . the characteristics of this method is that it is fully automatic and can be applied to arbitrary <material_0> . the idea behind our method is to utilize certain <otherscientificterm_2> and <otherscientificterm_1> . by using them , we can automatically extract such sentences that express opinion . in our experiment , the method could construct a corpus consisting of 126,610 sentences .	3 0 4 -1 4 -1 2 1 5 4 -1 4 -1 4 -1
A non-Gaussian LCMV beamformer for MEG source reconstruction .	linearly constraint minimum variance beamformer ; source probability density function ; non-gaussian source estimation of stationary signals ; magnetoencephalo-gram data ; real meg measurements ; localising brain activity ; lcmv beamformer ; bayesian formulation ; non-gaussian distribution ; source localisation ; gaussian behaviour ; non-gaussian signal ; meg data ; spatial estimates ; gaussian	<method> <method> <task> <material> <otherscientificterm> <task> <method> <method> <otherscientificterm> <task> <otherscientificterm> <material> <material> <otherscientificterm> <method>	8 2 3 ; 11 1 4 ; 7 0 0 ; 1 4 6 ; 13 5 1 ; 10 0 9 ; 13 5 6 ; 2 0 5	-- evidence suggests that <material_3> have characteristics with <otherscientificterm_8> , however , standard methods for <task_9> assume <otherscientificterm_10> . we present a new general method for <task_2> for <task_5> in the <material_12> . by providing a <method_7> for <method_0> , we extend this <method_7> and show that how the <method_1> , which is not necessarily <method_14> , can be estimated . the proposed <method_1> is shown to give better <otherscientificterm_13> than the <method_6> , in both simulations incorporating <material_11> and in <otherscientificterm_4> .	3 8 9 10 16 21 15 -1 2 5 12 23 15 -1 7 0 1 14 18 15 -1 13 6 11 4 17 19 20 22 15 -1
Automatic prominence identification and prosodic typology .	fundamental frequency movements ; automatic detection of prosodic prominence ; typological point of view ; overall syllable energy ; syllable nuclei duration ; acoustic parameters ; continuous speech ; pitch accent ; prosodic prominence ; prosodic parameters ; prominence phenomenon ; prosodic features ; mid-to-high-frequency emphasis ; stress-accented languages ; automatic system ; inter-human agreement ; stress	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <metric> <otherscientificterm>	12 6 5 ; 11 3 8 ; 4 1 12 ; 3 1 12 ; 3 6 5 ; 3 1 16 ; 7 1 3 ; 7 0 8 ; 7 1 16 ; 7 1 4 ; 4 6 5 ; 5 1 10 ; 3 1 4	this paper presents a follow up of a study on the <task_1> in <material_6> . <otherscientificterm_8> involves two different <otherscientificterm_11> , <otherscientificterm_7> and <otherscientificterm_16> , that are typically based on four <otherscientificterm_5> : <otherscientificterm_0> , <otherscientificterm_3> , <otherscientificterm_4> and <otherscientificterm_12> . a careful measurement of these <otherscientificterm_5> , as well as the identification of their connection to <otherscientificterm_9> , makes it possible to build an <method_14> capable of identifying prominent syllables in utterances with performance comparable with the <metric_15> reported in the literature . this <method_14> has been used to cast light on the actual correlation among the <otherscientificterm_5> and the <otherscientificterm_10> from an <otherscientificterm_2> , by examining data derived from some <material_13> .	1 6 8 17 -1 11 7 16 5 0 3 4 12 18 19 20 21 22 23 24 25 26 27 28 30 17 -1 9 14 15 17 -1 29 17 -1
Modulation spectrogram features for improved speaker diarization .	nist rich transcription 2007 task ; icsi speaker diarization system ; mfcc only system ; modulation spectrogram features ; relative der ; speaker diarization ; mfccs	<material> <method> <method> <method> <metric> <task> <method>	4 5 1 ; 3 4 6 ; 0 5 1 ; 3 0 5	we propose the use of <method_3> in <task_5> . these <method_3> carry longer term characteristics of the acoustic signals than the widely used <method_6> , thus providing potential improvement by using both <method_3> in combination . using the state-of-the-art <method_1> , an improvement of 20.77 % <metric_4> is obtained on the <material_0> with respect to the <method_2> .	3 5 11 7 -1 6 9 7 -1 1 4 0 2 8 10 7 -1
Image interpolation using across-scale pixel correlation .	available image data ; unknown pixel values ; priori similarity ; high-resolution image ; pixel correlation ; local regions ; image interpolation ; evaluation	<material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <task>	0 0 2 ; 1 3 3	in this paper , a novel method is proposed for <task_6> . it is assumed that the <otherscientificterm_4> between <otherscientificterm_5> across scales would remain similar . in addition , this a <otherscientificterm_2> could be extracted from a set of <material_0> that have the same content but different resolutions . a simple architecture is devised to estimate the correlation efficiently , which is then used to predict the <otherscientificterm_1> in a <material_3> . <task_7> shows a promising performance of the proposed algorithm .	6 8 -1 4 5 8 -1 2 0 9 8 -1 1 3 7 10 8 -1 8 -1
Learning to Freestyle : Hip Hop Challenge-Response Induction via Transduction Rule Segmentation .	token based and rule segmentation induction method ; under-explored natural language genre of music lyrics ; strictly unsupervised transduction grammar induction approach ; out-of-the-box phrase based smt system ; bottom-up token based rule induction ; maghrebi french hip hop lyrics ; pri-ori linguistic or phonetic information ; dedicated rhyme scheme detection module ; top-down rule segmentation strategies ; rhyming and fluent responses ; stochas-tic transduction grammar ; hip hop lyrics ; rhyming criteria ; unsupervised learning ; human evaluators	<method> <material> <method> <method> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <method> <material> <metric> <method> <otherscientificterm>	4 1 8 ; 13 0 2 ; 8 0 10 ; 7 0 2 ; 13 0 7	we present a novel model , freestyle , that learns to improvise <otherscientificterm_9> upon being challenged with a line of <material_11> , by combining both <method_4> and <method_8> to learn a <method_10> that simultaneously learns both phrasing and rhyming associations . in this attack on the woefully <material_1> , we exploit a <method_2> . our <method_2> is particularly ambitious in that no use of any a <otherscientificterm_6> is allowed , even though the domain of <material_11> is particularly noisy and unstructured . we evaluate the performance of the learned model against a model learned only using the more conventional <method_4> , and demonstrate the superiority of our combined <method_0> toward generating higher quality improvised responses , measured on fluency and <metric_12> as judged by <otherscientificterm_14> . to highlight some of the inherent challenges in adapting other algorithms to this novel <method_2> , we also compare the quality of the responses generated by our model to those generated by an <method_3> . we tackle the challenge of selecting appropriate training data for our <method_2> via a <method_7> , which is also acquired via <method_13> and report improved quality of the generated responses . finally , we report results with <material_5> indicating that our model performs surprisingly well with no special adaptation to other languages .	9 11 4 8 10 16 18 15 -1 1 2 15 -1 6 15 -1 15 -1 0 12 14 15 -1 3 17 19 20 15 -1 7 13 15 -1
A Risk Minimization Principle for a Class of Parzen Estimators .	maximal average margin optimality principle ; o algorithm ; classical parzen window classifier ; risk minimization principle ; ordinal regression tasks ; learning algorithms ; margin transformation ; facilitating analysis ; learning machines ; rademacher complexities	<method> <method> <method> <method> <task> <method> <method> <method> <method> <otherscientificterm>	0 0 5 ; 0 0 4	this paper 1 explores the use of a <method_0> for the design of <method_5> . it is shown that the application of this <method_3> results in a class of -lrb- computationally -rrb- simple <method_8> similar to the <method_2> . a direct relation with the <otherscientificterm_9> is established , as such <method_7> and providing a notion of certainty of prediction . this analysis is related to support vector machines by means of a <method_6> . the power of the <method_0> is illustrated further by application to <task_4> , resulting in an <method_1> able to process large datasets in reasonable time .	0 5 11 10 -1 3 8 2 10 -1 9 7 10 -1 6 10 -1 4 1 12 10 -1
Phoneme recognition based on fisher weight map to higher-order local auto-correlation .	fisher weight map ; higher-order local auto-correlation ; feature extraction method ; local auto-correlation features ; two-dimensional local regions ; total phoneme recognition ; fisher weight map ; discriminative areas ; global regions ; vowel recognition ; score map ; temporal dynamics ; features	<method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 2 ; 11 2 1 ; 9 1 0 ; 9 1 5 ; 0 0 2 ; 7 0 3 ; 1 1 0 ; 0 1 0 ; 4 2 3	in this paper , we propose a new <method_2> based on <method_1> and <method_0> . widely used <method_1> lack <otherscientificterm_11> . to solve this problem , 35 types of <otherscientificterm_3> are computed within <otherscientificterm_4> . these <otherscientificterm_3> are accumulated over more <otherscientificterm_8> by weight-ing high scores on the <otherscientificterm_7> where the typical <otherscientificterm_12> among all phonemes are well expressed . this <otherscientificterm_10> is called <method_6> . we verified the effectiveness of the <method_0> and <method_0> through <task_9> and <task_5> .	2 1 0 14 18 20 13 -1 11 15 13 -1 3 4 22 13 -1 8 7 12 19 13 -1 10 6 13 -1 9 5 16 17 21 13 -1
Estimating the spectral envelope of voiced speech using multi-frame analysis .	multi-frame analysis ; spectral envelope of voiced speech ; vocal-tract transfer function ; transfer characteristics ; harmonic structure ; spectral envelope ; vocal-tract shape ; voiced speech ; speech	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material>	0 0 5 ; 4 2 1	this paper proposes a novel approach for estimating the <otherscientificterm_1> independently of its <otherscientificterm_4> . because of the quasi-periodicity of <material_7> , its spectrum indicates <otherscientificterm_4> and only has energy at frequencies corresponding to integral multiples of 1/4 . it is hence impossible to identify <otherscientificterm_3> between the adjacent harmonics . in order to resolve this problem , <task_0> is introduced . the mfa estimates a <otherscientificterm_5> using many portions of <material_8> which are vo-calised using the same <otherscientificterm_6> . since each of the portions usually has a different 1/4 and ensuing different <otherscientificterm_4> , a number of harmonics can be obtained at various frequencies to form a <otherscientificterm_5> . the method thereby gives a closer approximation to the <otherscientificterm_2> .	1 4 11 9 -1 7 9 -1 3 9 -1 0 9 -1 5 8 6 10 9 -1 9 -1 9 -1
Stereo reconstruction with mixed pixels using adaptive over-segmentation .	over-segmentation based , dense stereo algorithm ; middlebury stereo evaluation ; fronto-parallel planar segments ; segmentation based methods ; depth estimates ; shape constraints ; depth estimation ; generative model ; map estimation ; segment boundaries ; image formation ; belief propagation ; reference view ; mixed pixels ; segmentation ; color ; depth ; opacity	<method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <metric>	1 5 0 ; 7 0 10 ; 5 0 0 ; 7 0 13 ; 11 0 4 ; 0 0 14 ; 0 4 3 ; 7 0 2 ; 0 0 13 ; 8 0 0	we present an <method_0> that jointly estimates <otherscientificterm_14> and <metric_16> . for <otherscientificterm_13> on <otherscientificterm_9> , the <method_0> computes foreground <metric_17> -lrb- alpha -rrb- , as well as <otherscientificterm_15> and <metric_16> for the foreground and background . we model the scene as a collection of <otherscientificterm_2> in a <otherscientificterm_12> , and use a <method_7> for <task_10> that handles <otherscientificterm_13> at <otherscientificterm_9> . our <method_0> iteratively updates the <otherscientificterm_14> based on <otherscientificterm_15> , <metric_16> and <otherscientificterm_5> using <method_8> . given a <otherscientificterm_14> , the <method_4> are updated using <method_11> . we show that our <method_0> is competitive with the state-of-the-art based on the new <method_1> , and that <method_0> overcomes limitations of traditional <method_3> while properly handling <otherscientificterm_13> . z-keying results show the advantages of combining <metric_17> and <method_6> .	0 14 16 18 -1 13 9 17 15 18 -1 2 12 7 10 20 22 26 18 -1 5 8 21 24 28 18 -1 4 11 23 18 -1 19 25 27 18 -1 1 3 18 -1
Color Constancy , Intrinsic Images , and Shape Estimation .	mit intrinsic images dataset ; modified problem formulation ; intrinsic image decomposition ; sirfs -lrb- shape ; chromatic illumination ; unified model ; optimization scheme ; inference problem ; priors ; illumination ; reflectance	<material> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 1 10 ; 9 1 10 ; 3 1 9 ; 5 0 4 ; 6 0 7 ; 10 1 9 ; 10 1 8	we present <otherscientificterm_3> , <otherscientificterm_9> , and <otherscientificterm_10> from shading -rrb- , the first <method_5> for recovering shape , <otherscientificterm_4> , and <otherscientificterm_10> from a single image . our model is an extension of our previous work -lsb- 1 -rsb- , which addressed the achromatic version of this problem . dealing with color requires a <method_1> , novel <otherscientificterm_8> on <otherscientificterm_10> and <otherscientificterm_9> , and a new <method_6> for dealing with the resulting <task_7> . our approach outperforms all previously published algorithms for <task_2> and shape-from-shading on the <material_0> -lsb- 1 , 2 -rsb- and on our own '' naturally '' illuminated version of that dataset .	3 9 10 5 4 12 13 14 15 11 -1 11 -1 1 8 6 7 16 17 18 11 -1 2 0 11 -1
The Infinite Hierarchical Factor Regression Model .	nonparametric bayesian factor regression model ; gene-expression data analysis ; indian buffet process ; kingman 's coalescent ; hierarchical model ; factor regression ; factor analysis	<method> <task> <method> <otherscientificterm> <method> <method> <method>	3 0 4 ; 5 2 1	we propose a <method_0> that accounts for uncertainty in the number of factors , and the relationship between factors . to accomplish <method_0> , we propose a sparse variant of the <method_2> and couple <method_0> with a <method_4> over factors , based on <otherscientificterm_3> . we apply <method_0> model to two problems -lrb- <method_6> and <method_5> -rrb- in <task_1> .	0 7 -1 2 4 3 8 7 -1 6 5 1 9 7 -1
A Confidence Measure for Boundary Detection and Object Selection .	detection of object boundaries ; user-guided image segmentation environment ; object boundary definition ; object houndury ; graph arc ; confidence measure ; conjidence measure ; fixed-length paths ; edge	<task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm>	5 0 0	we introduce a <method_6> that estimates the assurance that a <otherscientificterm_4> -lrb- or <otherscientificterm_8> -rrb- corresponds to an <otherscientificterm_3> in an image . a weighted , planar graph is imposed onto the watershed lines of a gradient magnitude image and the <method_6> is afunction of the cost of <otherscientificterm_7> emanating from and extending to each end of a <otherscientificterm_4> . the <metric_5> is applied to automate the <task_0> and thereby reduces -lrb- often greatly -rrb- the time and effort required for <task_2> within a <otherscientificterm_1> .	6 4 8 3 9 -1 7 9 -1 5 0 2 1 10 9 -1
Ritel : an open-domain , human-computer dialog system .	open-domain question answering system ; spoken language dialog system ; human-computer dialog corpus ; ritel platform ; qa system ; collected corpus	<method> <method> <material> <method> <method> <material>	3 0 2 ; 1 1 0 ; 3 0 1 ; 1 3 4	the project <method_3> aims at integrating a <method_1> and an <method_0> to allow a human to ask general questions -lrb- '' who is currently presiding the senate ? '' -rrb- and refine the search interactively . as this point in time the <method_3> is being used to collect a <material_2> . the user can receive factual answers to some questions -lrb- q : who is the president of france , r : jacques chirac is the president for france since may 1995 -rrb- . this paper briefly presents the current system , the <material_5> , the problems encountered by such a system and our first answers to these problems . when the system is more advance , it will allow measuring the net worth of integrating a <method_1> into a <method_4> . does allowing such a <method_1> really enables to reach faster and more precisely the '' right '' answer to a question ?	3 1 0 8 9 6 -1 2 6 -1 7 6 -1 5 6 -1 6 -1 4 10 6 -1 6 -1
SMT-Based Validation of Timed Failure Propagation Graphs .	satisfiability modulo theories engines ; timed failure propagation graphs ; dynamic partially observable system ; model-based diagnosis approach ; model-checking techniques ; model-based diagnosis ; failure propagation	<method> <method> <method> <method> <method> <task> <otherscientificterm>	4 0 1 ; 6 3 2 ; 0 0 1 ; 1 0 5	timed failure propagation graphs -lrb- <method_1> -rrb- are a formalism used in industry to describe <otherscientificterm_6> in a <method_2> . <method_1> are commonly used to perform <task_5> . as in any <method_3> , however , the quality of the diagnosis strongly depends on the quality of the <method_1> . approaches to certify the quality of the <method_1> are limited and mainly rely on testing . in this work we address this problem by leverag-ing efficient <method_0> to perform exhaustive reasoning on <method_1> . we apply <method_4> to certify that a given <method_1> satisfies -lrb- or not -rrb- a property of interest . moreover , we discuss the problem of refinement and diagnosability testing and empirically show that our <method_4> can be used to efficiently solve them .	1 6 2 9 7 -1 5 11 7 -1 3 7 -1 7 -1 0 10 7 -1 4 8 7 -1 7 -1
Apply n-best list re-ranking to acoustic model combinations of boosting training .	utterance level error rate ; frame level decoding ; word error rate ; improvement of system ; n-best list re-ranking ; boosting training method ; word level ; object function ; re-ranked hypotheses ; performance metric ; speech recognition ; top-1 hypotheses ; confidence feature ; acoustic modeling ; rover	<metric> <task> <metric> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <otherscientificterm> <method> <task> <method>	4 1 14 ; 13 0 8 ; 12 0 1 ; 0 5 13 ; 7 0 5 ; 8 4 11 ; 0 5 5 ; 13 4 11	the <otherscientificterm_7> for <method_5> in <task_13> aims to reduce <metric_0> . this is different from the most commonly used <metric_9> in <task_10> , <metric_2> . this paper proposes that the combination of <method_4> and <method_14> can partly address this problem . in particular , <task_13> is applied to <otherscientificterm_8> rather than to the original <otherscientificterm_11> and carried on <otherscientificterm_6> . <method_3> performance is observed in our experiments . in addition , we describe and evaluate a new <method_12> that measures the correctness of <task_1> result .	7 5 13 0 19 20 22 15 -1 9 10 2 15 -1 4 14 16 15 -1 8 11 6 3 17 21 23 15 -1 15 -1 12 1 18 15 -1
Efficient Processing of Underspecified Discourse Representations .	processing partially disambiguated discourse structure ; underspecified discourse description ; rst discourse treebank ; weighted tree grammars ; dominance graphs ; discourse representation ; underspecification-based algorithms	<task> <task> <material> <method> <otherscientificterm> <method> <method>	4 1 3 ; 6 0 0	underspecification-based algorithms for <task_0> must cope with extremely high numbers of readings . based on previous work on <otherscientificterm_4> and <method_3> , we provide the first possibility for computing an <task_1> and a best <method_5> efficiently enough to process even the longest discourses in the <material_2> .	0 9 7 -1 4 3 1 5 2 6 8 7 -1
Facial Contour Labeling via Congealing .	histogram of oriented gradient ; automatic or semi-supervised fashion ; manual landmark labels ; dual-curve congealing manner ; parametric curve representation ; non-rigid shape deformation ; semi-supervised approach ; inter-person database ; labeling accuracy ; object class ; congealing framework ; closed contour ; appearance information ; 300-image ensemble ; image ensemble ; vision problem ; congealing-like process ; features ; curve ; congealing	<method> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <method> <material> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <task> <task> <method> <otherscientificterm> <otherscientificterm> <task>	0 6 17 ; 17 3 10 ; 5 0 14 ; 16 0 6 ; 6 0 2 ; 0 0 10 ; 15 0 5 ; 16 0 2	it is a challenging <task_15> to discover <otherscientificterm_5> for an <task_14> belonging to a single <otherscientificterm_9> , in an <otherscientificterm_1> . the conventional <method_6> -lsb- 1 -rsb- uses a <method_16> to propagate <material_2> from a few images to a large ensemble . although effective on an <material_7> with a large population , there is potential for increased <metric_8> . with the goal of providing highly accurate labels , in this paper we present a <method_4> for each of the seven major facial contours . the <otherscientificterm_12> along the <otherscientificterm_18> , named <otherscientificterm_18> descriptor , is extracted and used for <task_19> . furthermore , we demonstrate that advanced <otherscientificterm_17> such as <method_0> can be utilized in the proposed <method_10> , which operates in a <otherscientificterm_3> for the case of a <otherscientificterm_11> . with extensive experiments on a <material_13> that exhibits moderate variation in facial pose and shape , we show that substantial progress has been achieved in the <metric_8> compared to the previous state-of-the-art approach .	15 5 14 9 1 23 27 20 -1 6 16 2 24 25 28 20 -1 7 8 20 -1 4 20 -1 12 18 19 20 -1 21 22 26 20 -1 17 0 10 3 11 20 -1
Fast polygonal integration and its application in extending haar-like features to improve object detection .	viola and jones ' object detection framework ; mars ' surface terrain assessment ; fixed-pose hand detection ; polyg-onal haar-like features ; classical haar-like features ; frontal face detection ; image resolution ; object detection ; rectangular region ; rock detection ; integration time ; rectilinear ; polygon ; function	<method> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <task> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 0 1 ; 5 1 2 ; 2 1 9	the integral image is typically used for fast integrating a <otherscientificterm_13> over a <otherscientificterm_8> in an image . we propose a method that extends the integral image to do fast integration over the interior of any <otherscientificterm_12> that is not necessarily <otherscientificterm_11> . the <metric_10> of the method is fast , independent of the <otherscientificterm_6> , and only linear to the <otherscientificterm_12> 's number of vertices . we apply the method to <method_0> , in which we propose to improve <otherscientificterm_4> with <otherscientificterm_3> . we show that the extended feature set improves <task_7> 's performance . the experiments are conducted in three domains : <task_5> , <task_2> , and <task_9> for <task_1> .	13 8 14 -1 12 11 14 -1 10 6 14 -1 0 4 3 14 -1 7 14 -1 15 16 17 14 -1
Computation as estimation : Estimation-theoretic IC design improves robustness and reduces power consumption .	modern integrated circuits ; massively parallel systems ; silicon feature sizes ; design optimization formalization ; moore 's law ; viewing hardware errors ; estimation-theoretic framework ; estimation theory ; power savings ; particle hits ; power/reliability trade-off ; system reliability ; measurement	<method> <method> <otherscientificterm> <method> <method> <task> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <metric> <task>	6 0 10 ; 8 1 11 ; 6 0 3	modern integrated circuits -lrb- ics -rrb- are designed as <method_1> as a consequence of diminishing <otherscientificterm_2> . this has adversely impacted reliability because of increased errors due to process and environmental variations , and <otherscientificterm_9> . <task_5> as analogous to <task_12> or system noise allows us to borrow results from <method_7> and extend <method_4> . the <method_6> provides a <method_3> that enables <otherscientificterm_10> in broad classes of applications . two applications described here show that specific instantiations of the <method_6> yield significant <metric_8> and <metric_11> .	1 2 13 -1 9 5 13 -1 12 7 4 13 -1 6 3 10 14 16 13 -1 8 11 0 15 13 -1
Snapshot spectral imaging via compressive random convolution .	random convolution snapshot spectral imaging ; coded aperture spectral snapshot imaging ; focal plane array measurement ; psnr spectral image cube reconstructions ; compressive sensing reconstruction algorithm ; 3d spectral cube ; spatial light modulator ; wide-area airborne surveillance ; shot 2d measurement ; remote sensing ; cassi systems ; random convolutions ; fpa measurements ; tissue spectroscopy ; compres-sive sensing ; spectral imaging	<method> <method> <method> <task> <method> <otherscientificterm> <method> <task> <method> <task> <method> <otherscientificterm> <method> <task> <task> <method>	7 1 9 ; 1 0 5 ; 3 5 10 ; 4 0 5 ; 2 0 1 ; 9 1 13	spectral imaging is of interest in many applications , including <task_7> , <task_9> , and <task_13> . <method_1> provides an efficient mechanism to capture a <otherscientificterm_5> with a single <method_8> . <method_1> uses a <method_2> of a spectrally dispersed , aperture coded , source . the <otherscientificterm_5> is then attained using a <method_4> . in this paper , we explore a new approach referred to as <method_0> . it is based on <method_12> of spectrally dispersed coherent sources that have been randomly convoluted by a <method_6> . the new method , based on the theory of <task_14> via <otherscientificterm_11> , is shown to outperform traditional <method_10> in terms of <task_3> .	7 9 13 1 17 22 16 -1 5 8 18 16 -1 2 21 16 -1 4 20 16 -1 0 16 -1 12 6 16 -1 14 11 19 16 -1
Neural CRF Parsing .	rich nonlinear fea-turization of neural net approaches ; baseline crf model ; anchored rule productions ; linear potential functions ; feedforward neu-ral network ; dense features ; crf parsing ; penn tree-bank ; sparse features ; computing gradients ; error signal ; anchored rules ; nonlinear potentials ; parsing model ; parser	<method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	13 4 1 ; 7 5 13 ; 8 0 3 ; 12 0 3 ; 4 0 12	this paper describes a <method_13> that combines the exact dynamic programming of <method_6> with the <method_0> . our <method_13> is structurally a <method_6> that factors over <otherscientificterm_2> , but instead of <otherscientificterm_3> based on <otherscientificterm_8> , we use <otherscientificterm_12> computed via a <method_4> . because potentials are still local to <otherscientificterm_11> , structured inference -lrb- cky -rrb- is unchanged from the sparse case . <otherscientificterm_9> during learning involves backpropagating an <otherscientificterm_10> formed from standard <method_6> sufficient statistics -lrb- expected rule counts -rrb- . using only <otherscientificterm_5> , our <method_13> already exceeds a strong <method_1> -lrb- hall et al. , 2014 -rrb- . in combination with <otherscientificterm_8> , our <method_13> 1 achieves 91.1 f 1 on section 23 of the <material_7> , and more generally outperforms the best prior single <method_14> results on a range of languages .	13 6 0 15 -1 2 3 8 12 4 18 19 20 15 -1 11 9 15 -1 10 15 -1 5 1 16 15 -1 17 15 -1
Packetized video transmission for OFDM wireless systems with dynamic ordered subcarrier selection algorithm .	dynamic ordered subcarrier selection algorithm ; bit error rate ; unequal error protection ; ofdm based video transmission system ; highest channel gain ; ossa	<method> <metric> <method> <task> <otherscientificterm> <method>	0 0 3 ; 0 4 5 ; 1 5 0 ; 5 0 2	in this paper , we proposed a <method_0> for <task_3> . the proposed <method_0> is shown to achieve lower <metric_1> than the previously proposed <method_5> by ≈ørst selecting a fraction of the subcarriers with <otherscientificterm_4> . the content information is then exploited in order to extend the <method_5> to achieve <method_2> for packets of different importance . simulation results show that <method_0> that utilizes the proposed <method_0> can achieve higher <metric_1> , especially at low snr , compared to those that use the equal error protection -lrb- eep -rrb- <method_5> .	0 3 7 6 -1 1 5 4 8 9 6 -1 2 10 6 -1 6 -1
Novel approach to AM-FM decomposition with applications to speech and music analysis .	k-nearest neighbour -lrb- ` k-nn ' -rrb- framework ; freqeuency modulation components ; discrete-energy separation algorithm ; amplitude modulation ; envelope and frequency estimates ; zero-crossing instant information ; bandpass filtered speech ; time-varying lowpass filter ; teager energy operator ; zero-crossing based algorithm ; fine-structured modulations ; analysis frame ; bandpass signal ; micro-time scale ; fm component ; instantaneous frequency ; coherent demodulation	<method> <method> <method> <method> <metric> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	16 0 14 ; 4 5 2 ; 7 0 16 ; 5 0 14 ; 9 4 2 ; 5 0 9 ; 9 0 12 ; 8 0 2 ; 3 1 1 ; 9 0 10 ; 7 0 14	we present a new <method_9> for decomposing a <otherscientificterm_12> into the <method_3> and <method_1> . in this <method_9> , the <method_14> is first estimated using <otherscientificterm_5> in a <method_0> . the <method_14> is estimated by <method_16> using a <method_7> that uses the estimated <otherscientificterm_15> . simulation results show that the proposed <method_9> gives more accurate <metric_4> compared to the <method_2> which uses the <method_8> . using the proposed <method_9> on <material_6> and music we can extract the <otherscientificterm_10> that occur on a <otherscientificterm_13> , within an <otherscientificterm_11> .	9 12 3 1 24 26 17 -1 14 5 0 21 23 17 -1 16 7 15 18 20 28 17 -1 4 2 8 19 22 25 17 -1 6 10 13 11 27 17 -1
Robust Matched Filters for Target Detection in Hyperspectral Imaging Data .	uncertainty and/or variability of target signatures ; robust matched ¬ø lter ; hyperspectral imaging data ; hyperspectral imaging applications ; spectral space ; spectral variability ; target mismatch ; hydice sensor ; spectral signature ; target signature ; detection algorithms ; ellipsoid ; spectra	<otherscientificterm> <method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	1 0 5 ; 10 0 3 ; 1 0 6 ; 6 1 5 ; 4 2 11	most <method_10> for <task_3> assume a target with a perfectly known <otherscientificterm_8> . in practice , the <otherscientificterm_9> is either imperfectly measured -lrb- <otherscientificterm_6> -rrb- and/or it exhibits <otherscientificterm_5> . the objective of this paper is to introduce a <method_1> that takes the <otherscientificterm_0> into account . it is shown that , if we describe this uncertainty with an <otherscientificterm_11> in the <otherscientificterm_4> , we can design a matched ¬ø lter that provides a response of the same magnitude for all <otherscientificterm_12> within this <otherscientificterm_11> . thus , by changing the size of this <otherscientificterm_11> , we can control the '' spectral selectivity '' of the matched ¬ø lter . the ability of the <method_1> to deal effectively with <otherscientificterm_6> and <otherscientificterm_5> is demonstrated with <material_2> from the <method_7> .	10 3 8 15 13 -1 9 6 5 13 -1 1 0 13 -1 11 4 12 18 13 -1 13 -1 14 16 17 13 -1
The Parameterized Complexity of Abduction .	parameterized complexity analysis of abduction ; fundamental reasoning methods ; propositional logic ; logic-based abduction ; reverse inference ; proposi-tional formulas ; computational complexity ; abduction	<task> <method> <otherscientificterm> <task> <task> <otherscientificterm> <metric> <task>	6 5 3	abduction belongs to the most <method_1> . it is a method for <task_4> , this means one is interested in explaining observed behavior by finding appropriate causes . we study <task_3> , where knowledge is represented by <otherscientificterm_5> . the <metric_6> of this <task_3> is highly intractable in many interesting settings . in this work we therefore present an extensive <task_0> within various fragments of <otherscientificterm_2> together with -lrb- combinations of -rrb- natural parameters .	1 8 -1 4 8 -1 3 5 8 -1 6 9 8 -1 0 2 7 8 -1
Interpolatory Mercer kernel construction for kernel direct LDA on face recognition .	self-constructed interpolatory mercer kernel ; rbf kernel based kdda method ; im kernel based kdda approach ; feret and cmu pie databases ; lagrange interpolatory basis functions ; mercer kernel function ; cmu pie database ; mercer kernel construction ; nonlinear mapping œÜ ; gram matrix ; interpolatory strategy ; face recognition ; kernel function ; face databases ; cholesky decomposition	<method> <method> <method> <material> <otherscientificterm> <method> <material> <task> <method> <otherscientificterm> <method> <task> <otherscientificterm> <material> <method>	0 0 9 ; 5 0 12 ; 3 5 2 ; 6 5 2 ; 13 5 1 ; 3 6 13 ; 10 0 7 ; 4 0 8	this paper proposes a novel methodology on <task_7> using <method_10> . based on a given symmetric and positive semi-definite matrix -lrb- <otherscientificterm_9> -rrb- and <method_14> , it first constructs a <method_8> , which is well-defined on the training data . this <method_8> is then extended to the whole input feature space by utilizing <otherscientificterm_4> . the <otherscientificterm_12> constructed by inner product is proven to be a <method_5> . the <method_0> keeps the <otherscientificterm_9> unchanged on the training samples . to evaluate the performance of the proposed <method_0> , a popular kernel direct linear discriminant analysis -lrb- kdda -rrb- method for <task_11> is selected . comparing with <method_1> on two <material_13> , namely <material_3> , the <method_2> could increase the performance by around 20 % on <material_6> .	7 10 22 15 -1 9 14 8 15 -1 4 23 15 -1 12 5 17 15 -1 0 16 15 -1 15 -1 11 18 19 20 21 15 -1
The Use of DBN-HMMs for Mispronunciation Detection and Diagnosis in L2 English to Support Computer-Aided Pronunciation Training .	word pronunciation error rate ; unannotated l2 data ; hybrid dbn-hmm framework ; supervised manner ; asr engine ; unsupervised manner ; unsupervised pre-training ; annotated data ; acoustic modeling ; mispronunciation detection ; features ; gmm-hmm ; dbn-hmm ; ml	<metric> <material> <method> <method> <task> <method> <method> <material> <task> <task> <otherscientificterm> <method> <method> <method>	7 0 4 ; 9 0 8 ; 13 1 11 ; 1 0 5 ; 5 0 4 ; 3 0 4 ; 2 0 9 ; 1 0 4 ; 6 0 12 ; 2 0 8	this paper investigates <task_8> using the <method_2> in <task_9> and diagnosis of l2 english . this is one of the first efforts that compare the performance of <method_12> with that of the best-tuned <method_11> trained in <method_13> and mwe on the same set of <otherscientificterm_10> . previous work in <task_4> has also shown the necessity of <method_6> for <method_12> to work well . we explore further the effect of training our <task_4> in an <method_5> with additional <material_1> from the test speakers . this is compared with the original <task_4> that has been trained with <material_7> in a <method_3> . experiments show that <method_12> can give significant improvement -lrb- between 13-18 % relative in <metric_0> -rrb- but is computationally more expensive .	8 2 9 16 21 24 14 -1 12 11 13 10 17 14 -1 4 6 23 14 -1 5 1 18 19 22 14 -1 7 3 15 20 14 -1 14 -1
Generalization in Decision Trees and DNF : Does Size Matter ? .	class of node decision functions ; decision tree of depth ; two-layer neural networks ; thresh-olded real-valued functions ; support vector machines ; misclassiication probability ; boolean functions ; vc theory ; pattern classiication ; dnf formulae ; sig-moid networks ; distribution	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm>	4 6 3 ; 10 6 3 ; 3 2 8 ; 4 1 10	recent theoretical results for <task_8> with <otherscientificterm_3> -lrb- such as <method_4> , <method_10> , and boosting -rrb- give bounds on <otherscientificterm_5> that do not depend on the size of the classiier , and hence can be considerably smaller than the bounds that follow from the <method_7> . in this paper , we show that these techniques can be more widely applied , by representing other <otherscientificterm_6> as <method_2> -lrb- thresholded convex combinations of <otherscientificterm_6> -rrb- . for example , we show that with high probability any <otherscientificterm_1> no more than d that is consistent with m training examples has <otherscientificterm_5> no more than o ? 1 m ? n ee vcdim -lrb- u -rrb- log 2 m log d 1 = 2 , where u is the <otherscientificterm_0> , and n ee n can be thought of as the eeective number of leaves -lrb- it becomes small as the <otherscientificterm_11> on the leaves induced by the training data gets far from uniform -rrb- . this bound is qualitatively diierent from the vc bound and can be considerably smaller . we use the same technique to give similar results for <method_9> .	8 3 4 10 5 7 13 14 15 16 12 -1 6 2 12 -1 1 12 -1 0 11 12 -1 12 -1 9 12 -1 12 -1
Salient Color Names for Person Re-identification .	semantic analysis of images ; user 's feedback optimization ; computer vision applications ; metric learning method ; salient color names ; color name ; color distributions ; background information ; person re-identification ; color naming ; color names ; color spaces ; feature representation ; scncd	<task> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <method>	0 0 2 ; 6 0 12 ; 7 0 8 ; 4 0 13	color naming , which relates colors with <otherscientificterm_10> , can help people with a <task_0> in many <task_2> . in this paper , we propose a novel <otherscientificterm_4> based color descriptor -lrb- <method_13> -rrb- to describe colors . <method_13> utilizes <otherscientificterm_4> to guarantee that a higher probability will be assigned to the <otherscientificterm_5> which is nearer to the color . based on <method_13> , <otherscientificterm_6> over <otherscientificterm_10> in different <otherscientificterm_11> are then obtained and fused to generate a <method_12> . moreover , the effect of <otherscientificterm_7> is employed and analyzed for <task_8> . with a simple <method_3> , the proposed <method_13> outperforms the state-of-the-art performance -lrb- without <method_1> -rrb- on two challenging datasets -lrb- viper and prid 450s -rrb- . more importantly , the proposed <method_3> can be obtained very fast if we compute <method_13> of each color in advance .	10 0 2 15 14 -1 4 13 14 -1 5 18 14 -1 6 11 12 16 14 -1 7 8 17 14 -1 3 14 -1 1 14 -1
Implementation of parallel cosine and sine modulated filter banks for equalized transmultiplexer systems .	reconstruction cosine modulated transmultiplexer systems ; filter bank based transmultiplexer systems ; parallel filter bank system ; sine modulated filter banks ; frequency selective channels ; dft-based multicarrier systems ; channel equalization idea ; realization structures ; receiver end ; parallel cosine ; data transmission ; equalizer	<method> <method> <method> <otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	1 4 5 ; 9 0 11 ; 1 0 10 ; 9 1 3 ; 3 0 11 ; 7 0 2 ; 4 0 10	filter bank based transmultiplexer systems have certain advantages compared with existing <method_5> and <method_1> are promising candidates for <task_10> in <material_4> . we have recently proposed a novel and efficient <method_6> to be used with critically decimated perfect <method_0> . the <otherscientificterm_11> utilizes <otherscientificterm_9> and <otherscientificterm_3> in the <otherscientificterm_8> . this paper explores efficient <otherscientificterm_7> for the needed <method_2> , which finds applications also in other areas .	5 1 10 4 13 15 19 12 -1 6 0 12 -1 11 9 3 8 14 16 17 12 -1 7 2 18 12 -1
Zero resource spoken audio corpus analysis .	segmental dynamic time warping algorithm ; expectation-maximization algorithm ; zero-resource speech processing ; acoustic pattern discovery ; audio document collection ; latent probability distributions ; acoustic summaries ; zero-resource system ; probabilistic model ; automatic analysis ; topical themes ; audio corpus ; hidden variables ; speech data ; pseudo-words	<method> <method> <task> <task> <task> <otherscientificterm> <material> <method> <method> <task> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm>	0 0 7 ; 7 0 10 ; 7 0 5 ; 7 0 3 ; 0 0 3 ; 10 3 11	zero-resource speech processing involves the <task_9> of a collection of <material_13> in a completely unsupervised fashion without the benefit of any transcriptions or annotations of the data . in this paper , our <method_7> seeks to automatically discover important words , phrases and <otherscientificterm_10> present in an <material_11> . this <method_7> employs a <method_0> for <task_3> in conjunction with a <method_8> which treats the topic and pseudo-word identity of each discovered pattern as <otherscientificterm_12> . by applying an <method_1> , our <method_7> estimates the <otherscientificterm_5> over the <otherscientificterm_14> and topics associated with the discovered patterns . using this information , we produce <material_6> of the dominant <otherscientificterm_10> of the <task_4> .	9 13 15 -1 7 10 11 17 21 15 -1 0 3 8 12 16 19 20 15 -1 1 5 14 18 15 -1 15 -1
Manifold alignment using Procrustes analysis .	`` semi-supervised alignment '' ; dimensionality reduction method ; cross-lingual information retrieval ; markov decision processes ; manifold alignment ; procrustes analysis ; transfer learning ; mapping	<method> <method> <task> <method> <task> <method> <task> <method>	2 1 6 ; 6 3 3	in this paper we introduce a novel approach to <task_4> , based on <method_5> . our approach differs from <method_0> in that it results in a <method_7> that is defined everywhere - when used with a suitable <method_1> - rather than just on the training data points . we describe and evaluate our approach both theoretically and experimentally , providing results showing useful knowledge transfer from one domain to another . novel applications of our method including <task_2> and <task_6> in <method_3> are presented .	4 5 8 -1 0 7 1 8 -1 8 -1 2 6 3 9 10 8 -1
An EM Algorithm for Video SummarizationGenerative Model Approach .	visual video summarization problem ; linear dynamical system theory ; evolution of appearance ; temporal transformation symmetries ; image-like data structures ; time correlated frames ; time evolution models ; probabilistic approach ; bayesian framework ; generative model ; temporal information ; perceptual similarity ; video sequence ; sequence evolution ; invariance	<task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	8 0 0 ; 1 0 0 ; 7 0 0	in this paper , we address the <task_0> in a <method_8> in order to detect and describe the underlying <otherscientificterm_3> in a <material_12> . given a set of <otherscientificterm_5> , we attempt to extract a reduced number of <otherscientificterm_4> which are semantically meaningful and that have the ability of representing the <otherscientificterm_13> . to this end , we present a <method_9> which involves jointly the representation and the <otherscientificterm_2> . applying <method_1> to this <task_0> , we discuss how the <otherscientificterm_10> is encoded yielding a manner of grouping the iconic representations of the <material_12> in terms of <otherscientificterm_14> . the formulation of this <task_0> is driven in terms of a <method_7> , which affords a measure of <otherscientificterm_11> taking both learned appearance and <method_6> into account .	0 8 3 12 16 15 -1 5 4 13 15 -1 9 2 15 -1 1 10 14 17 15 -1 18 15 -1
Hybrid weak-perspective and full-perspective matching .	t h e weak-perspective algorithm ; 3d model-based robot navigation ; probabilistic combinatorial optimization algorithm ; w eak-perspective algorithm ; h ybrid algorithm ; 2d images ; full-perspective algorithm ; 2d projection ; 3d landmark ; weak-perspective mappings ; full-perspective mappings ; landmark ; rotation ; scaling ; translation ; robot	<method> <task> <method> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm>	14 1 13 ; 12 1 14	full-perspective mappings between 3d objects and <material_5> are more complicated than <method_9> , which consider only <otherscientificterm_12> , <task_14> and <task_13> . therefore , in <task_1> , it is important to understand how and when full-perspective m ust be taken into account . in this paper we use a <method_2> to search for an optimal match between <otherscientificterm_8> and 2d image features . three variations are considered : a <method_3> rotates , translates and scales an initial <otherscientificterm_7> of the <otherscientificterm_8> . a <method_6> always recomputes the <otherscientificterm_15> 's pose and repro-jects the <otherscientificterm_11> when testing alternative matches . finally , a <method_4> uses weak-perspective t o select a most promising alternative , but then updates the pose and reprojects the <otherscientificterm_11> . the <method_6> appears to combine the best attributes of the other two . like the <method_6> , it reliably recovers the true pose of the <otherscientificterm_15> , and like <method_0> , it runs 5 to 10 faster than the <method_6> .	5 9 12 14 13 17 18 16 -1 1 16 -1 2 8 16 -1 3 7 16 -1 6 15 11 16 -1 16 -1 4 16 -1 16 -1
Fast Newton-type Methods for Total Variation Regularization .	anisotropic -lrb- ‚Ñì 1-based -rrb- tv ; total variation penalties ; newton-type methods ; machine learning ; 1d-tv algorithms ; optimization problems ; image de-noising ; tv solvers ; signal processing ; fused-lasso	<method> <otherscientificterm> <method> <task> <method> <task> <task> <method> <task> <otherscientificterm>	8 1 3 ; 1 0 3	numerous applications in statistics , <task_8> , and <task_3> regularize using <otherscientificterm_1> . we study <method_0> and also a related ‚Ñì 2-norm variant . we consider for both variants associated -lrb- 1d -rrb- proximity operators , which lead to challenging <task_5> . we solve these problems by developing <method_2> that outperform the state-of-the-art algorithms . more importantly , our <method_4> serve as building blocks for solving the harder task of computing 2 - -lrb- and higher -rrb- - dimensional tv proximity . we illustrate the computational benefits of our <method_4> by applying <method_4> to several applications : -lrb- i -rrb- <task_6> ; -lrb- ii -rrb- image deconvolution -lrb- by plugging in our <method_7> into publicly available software -rrb- ; and -lrb- iii -rrb- four variants of <otherscientificterm_9> . the results show large speedups -- and to support our claims , we provide software accompanying this paper .	8 3 1 11 12 10 -1 0 10 -1 5 10 -1 2 10 -1 4 10 -1 10 -1 6 7 9 10 -1
Resampling auxiliary data for language model adaptation in machine translation for speech .	speech to speech translation system ; n-gram language models ; sparse in-domain resources ; in-domain conversational data ; language modeling community ; domain textual data ; resampled language models ; auxiliary textual material ; language models ; n-gram ratios ; newswire text ; s2s system ; cen-troid similarity ; bleu score	<task> <method> <material> <material> <method> <material> <method> <material> <method> <otherscientificterm> <material> <task> <otherscientificterm> <metric>	7 0 4 ; 9 1 6 ; 5 0 11 ; 10 6 5 ; 7 0 2 ; 12 1 9 ; 8 0 0	performance of <method_1> depends to a large extent on the amount of training text material available for building the <method_1> and the degree to which this text matches the domain of interest . the <method_4> is showing a growing interest in using large collections of <material_7> to supplement <material_2> . one of the problems in using such <method_1> is that <method_1> may differ significantly from the specific nature of the domain of interest . in this paper , we propose three different methods for adapting <method_8> for a <task_0> when <method_1> are of different genre and domain . the proposed methods are based on <otherscientificterm_12> , <otherscientificterm_9> and <method_6> . we show how these methods can be used to select out of <material_5> such as <material_10> to improve a <task_11> . we were able to achieve an overall relative improvement of 3.8 % in <metric_13> over a baseline system that uses only <material_3> .	1 14 -1 4 7 2 15 19 14 -1 14 -1 8 0 21 14 -1 16 20 14 -1 12 9 6 17 18 14 -1 5 10 11 14 -1
Learning Taxonomies by Dependence Maximization .	image and text data ; numerical taxonomy clustering ; dependence maximization approach ; spectral clustering ; unsupervised algorithms ; taxonomy ; clustering	<material> <method> <method> <method> <method> <method> <method>	3 1 2	we introduce a family of <method_4> , <method_1> , to simultaneously cluster data , and to learn a <method_5> that encodes the relationship between the clusters . the <method_4> work by maximizing the dependence between the <method_5> and the original data . the resulting <method_5> is a more informative visualization of complex data than simple <method_6> ; in addition , taking into account the relations between different clusters is shown to substantially improve the quality of the <method_6> , when compared with state-of-the-art <method_4> in the literature -lrb- both <method_3> and a previous <method_2> -rrb- . we demonstrate our algorithm on <material_0> .	4 1 5 7 -1 7 -1 6 3 2 8 7 -1 7 -1
On Kernel Methods for Relational Learning .	high dimensional implicit space ; structured and relational data ; machine learning community ; restricted feature space ; natural language processing ; high-dimensional feature spaces ; description language ; limited expressivity ; relational domains ; kernel operations ; time complexity ; relational kernels ; relational learning ; kernel methods ; kernel learning ; kernel functions ; feature space ; generalization ability ; kernels	<otherscientificterm> <material> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 9 ; 13 3 2 ; 8 2 14	kernel methods have gained a great deal of popularity in the <task_2> as a method to learn indirectly in <otherscientificterm_5> . those interested in <method_12> have recently begun to cast learning from <material_1> in terms of <task_9> . we describe a general family of <otherscientificterm_15> built up from a <otherscientificterm_6> of <otherscientificterm_7> and use it to study the benefits and drawbacks of <task_14> in <material_8> . learning with <otherscientificterm_18> in this family directly models learning over an expanded <otherscientificterm_16> constructed using the same <otherscientificterm_6> . this allows us to examine issues of <otherscientificterm_10> in terms of learning with these and other <otherscientificterm_11> , and how these relate to <otherscientificterm_17> . the tradeoffs between using <otherscientificterm_18> in a very <otherscientificterm_0> versus a <otherscientificterm_3> , is highlighted through two experiments , in bioinformatics and in <task_4> .	2 5 21 19 -1 12 1 9 20 19 -1 15 6 7 14 8 22 19 -1 18 16 19 -1 10 19 -1 11 17 19 -1
Convolution Kernels on Constituent , Dependency and Sequential Structures for Relation Extraction .	constituent and dependency parse trees ; target relation extraction task ; syntactic and semantic structures ; automated relation extraction ; support vector machines ; word sequence kernels ; ace 2004 corpus ; lexical sequences ; syntactic tree ; partial tree ; entity types ; semantics concerns ; syntax	<otherscientificterm> <task> <otherscientificterm> <task> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	9 1 5 ; 8 1 9 ; 0 0 12	this paper explores the use of innovative kernels based on <otherscientificterm_2> for a <task_1> . <material_12> is derived from <otherscientificterm_0> whereas <otherscientificterm_11> to <otherscientificterm_10> and <material_7> . we investigate the effectiveness of such representations in the <task_3> from text . we process the above data by means of <method_4> along with the <otherscientificterm_8> , the <otherscientificterm_9> and the <otherscientificterm_5> . our study on the <material_6> illustrates that the combination of the above kernels achieves high effectiveness and significantly improves the current state-of-the-art .	2 1 12 13 -1 0 11 10 7 16 13 -1 3 13 -1 4 8 9 5 14 15 13 -1 6 13 -1
Situation Testing-Based Discrimination Discovery : A Causal Inference Approach .	legally grounded situation testing methodology ; causal bayesian networks ; discrimination discovery ; real dataset ; protected-by-law group ; causal inference ; historical dataset ; causal structure ; similarity measurement ; discrimination ; eciency ; accuracy	<method> <method> <task> <material> <otherscientificterm> <method> <material> <otherscientificterm> <method> <otherscientificterm> <metric> <metric>	11 1 10	discrimination discovery is to unveil <otherscientificterm_9> against a specific individual by analyzing the <material_6> . in this paper , we develop a general technique to capture <otherscientificterm_9> based on the <method_0> . for any individual , we find pairs of tuples from the dataset with similar characteristics apart from belonging or not to the <otherscientificterm_4> and assign them in two groups . the individual is considered as discriminated if significant di ‚Üµ erence is observed between the decisions from the two groups . to find similar tuples , we make use of the <method_1> and the associated <method_5> as a guideline . the <otherscientificterm_7> of the dataset and the causal e ‚Üµ ect of each attribute on the decision are used to facilitate the <method_8> . through empirical assessments on a <material_3> , our approach shows good ecacy both in <metric_11> and <metric_10> .	9 6 12 -1 0 12 -1 4 12 -1 12 -1 1 5 12 -1 12 -1 7 8 13 12 -1
A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate .	variance-reduced stochastic gradient technique ; principal component analysis ; singular value decomposition ; slow convergence ; runtime scales ; non-convex problem ; stochastic iterations ; data size	<method> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm>	1 1 2	we describe and analyze a simple algorithm for <task_1> and <task_2> , vr-pca , which uses computa-tionally cheap <otherscientificterm_6> , yet converges exponentially fast to the optimal solution . in contrast , existing algorithms suffer either from <otherscientificterm_3> , or computationally intensive iterations whose <otherscientificterm_4> with the <otherscientificterm_7> . the algorithm builds on a recent <method_0> , which was previously analyzed for strongly convex optimization , whereas here we apply it to an inherently <task_5> , using a very different analysis .	1 2 6 9 8 -1 3 4 7 8 -1 0 5 8 -1
Information-bearing components of speech intelligibility under babble-noise and bandlimiting distortions .	spectro-temporal modulation index ; spectral and temporal modulations ; additive babble noise ; intelligibility of speech ; representation of sound ; biological model ; adverse conditions ; information-bearing features ; psychoacoustic tests ; low-pass filtering ; speech intelligibility ; noisy speech ; continuous speech ; features ; noise ; babble	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <metric> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 3 ; 1 2 3 ; 9 1 2 ; 6 2 3	performance of speech technologies can benefit greatly from a deeper appreciation of the nature of the <otherscientificterm_7> in <material_12> . to explore these <otherscientificterm_13> , we focus here on the role of the <otherscientificterm_1> in maintaining the <otherscientificterm_3> as it becomes severely degraded by <method_9> and <otherscientificterm_2> . these <otherscientificterm_1> are estimated using a <method_5> of auditory processing which approximates the <otherscientificterm_4> in the cortex . intelligibility of the <material_11> is computed directly from this model via the <method_0> -lsb- 1 -rsb- , and the validity of this metric is confirmed by a detailed comparison with results of <material_8> . our analysis reveals quantitatively why certain types of <otherscientificterm_14> are more disruptive to <metric_10> than others -lrb- e.g. , <otherscientificterm_15> vs. white <otherscientificterm_14> -rrb- . it also highlights the important contribution of both <otherscientificterm_1> in accurately predicting the <otherscientificterm_3> under <otherscientificterm_6> .	7 12 16 -1 13 1 3 9 2 17 19 16 -1 5 4 16 -1 11 0 8 16 -1 16 -1 14 10 15 18 20 16 -1
Temporal Planning with Semantic Attachment of Non-Linear Monotonic Continuous Behaviours .	existent temporal planning techniques ; non-linear continuous monotonic functions ; non-linear continuous change ; semantic attachment mechanism ; external libraries ; physical systems ; planning problems ; native pddl ; planning system ; linear programming ; real-world problems ; planning process	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <material> <method> <method> <task> <task>	8 0 6	non-linear continuous change is common in <task_10> , especially those that model <method_5> . we present an algorithm which builds upon <method_0> based on <method_9> to approximate <otherscientificterm_1> . these are integrated through a <method_3> , allowing <otherscientificterm_4> or functions that are difficult to model in <material_7> to be evaluated during the <task_11> . a new <method_8> implementing this algorithm was developed and evaluated . results show that the addition of this algorithm to the <task_11> can enable <method_8> to solve a broader set of <task_6> .	10 5 12 -1 0 9 1 12 -1 3 4 7 11 12 -1 8 12 -1 6 2 13 12 -1
Comparing Agents ' Success against People in Security Domains .	peer designed agents ; computer agents ; autonomous agents ; human subjects ; security domains	<method> <method> <method> <otherscientificterm> <material>	4 2 2	the interaction of people with <method_2> has become increasingly prevalent . some of these settings include <material_4> , where people can be characterized as uncooperative , hostile , manipulative , and tending to take advantage of the situation for their own needs . this makes it challenging to design proficient agents to interact with people in such environments . evaluating the success of the agents automatically before evaluating them with people or deploying them could alleviate this challenge and result in better designed agents . in this paper we show how <method_0> -- <method_1> developed by <otherscientificterm_3> -- can be used as a method for evaluating <method_2> in <material_4> . such evaluation can reduce the effort and costs involved in evaluating <method_2> interacting with people to validate their efficacy . our experiments included more than 70 <otherscientificterm_3> and 40 <method_0> developed by students . the study provides empirical support that <method_0> can be used to compare the proficiency of <method_2> when matched with people in <material_4> .	2 5 -1 4 5 -1 5 -1 5 -1 0 1 3 6 5 -1 5 -1 5 -1 5 -1
Symmetry Breaking via LexLeader Feasibility Checkers .	lexleader feasibility checkers ; partial assignments ; partial assignment ; value symmetries ; variable orderings ; matrix models ; canonical solution ; snakelex ; doublelex	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method>	1 1 4 ; 4 1 3 ; 8 1 7	this paper considers <method_5> , a class of <method_5> which generally exhibit significant symmetries . it proposed the idea of <method_0> that verify , during search , whether the current <otherscientificterm_2> can be extended into a <method_6> . the <method_0> are based on a novel result by -lsb- katsirelos et al. , 2010 -rsb- on how to check efficiently whether a solution is canonical . the paper generalizes this result to <otherscientificterm_1> , various <otherscientificterm_4> , and <otherscientificterm_3> . empirical results on 5 standard benchmarks shows that <method_0> may bring significant performance gains , when jointly used with <method_8> or <method_7> .	5 9 -1 0 2 6 9 -1 9 -1 1 4 3 10 11 9 -1 8 12 9 -1
Complex Newton algorithm for blind signal extraction of speech in diffuse noise .	frequency domain blind signal extraction method ; frequency domain blind signal separation ; blind signal separation approach ; diffuse background noise ; nonlin-ear post filter ; cost function ; speech enhancement ; diffuse noise ; gradient descent ; newton algorithm ; newton method ; minimization	<method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method>	0 0 7 ; 11 0 0 ; 7 1 4 ; 8 1 2 ; 3 0 6	several recent methods for <task_6> in presence of <otherscientificterm_3> use <task_1> to estimate the <otherscientificterm_7> and a <method_4> to suppress this estimated noise . this paper presents a <method_0> for estimating the <otherscientificterm_7> in place of the <task_1> . the <method_0> is based on the <method_11> by means of a complex <method_9> of a <otherscientificterm_5> depending of the modulus of the extracted component . the proposed complex <method_10> is compared to the <otherscientificterm_8> on the same <otherscientificterm_5> and to the <method_2> .	6 3 1 7 4 15 17 12 -1 0 13 12 -1 11 9 5 14 12 -1 10 8 2 16 12 -1
Stereophonic acoustic echo canceller without pre-processing .	stereophonic acoustic echo canceller ; filter coefficients ; echo-path identification ; convergence analysis ; stable adaptation ; adaptive step-size ; filter coefficient ; convergence detection ; pre-processing ; echo-paths ; step-size	<method> <otherscientificterm> <task> <method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm>	7 1 5	this paper proposes a <method_0> without <method_8> which can identify the correct <otherscientificterm_9> . by dividing the <otherscientificterm_1> into two portions and update one part at a time , the <otherscientificterm_6> have an unique solution . <method_3> clarifies the condition for correct <task_2> . for fast convergence and <task_4> , a <method_7> and an <method_5> are also introduced . the modification amount of the <otherscientificterm_1> detects the convergence and also determines the <otherscientificterm_10> . computer simulations show 10db smaller coefficient error than those of the conventional algorithms .	0 8 9 11 -1 1 6 3 11 -1 2 11 -1 4 7 5 12 11 -1 10 11 -1 11 -1
Convex Subspace Representation Learning from Multi-View Data .	convex subspace representation learning method ; convex min-max dual formulation ; common subspace representation matrix ; group sparsity inducing norm ; sparsity inducing trace norm ; proximal bundle optimization algorithm ; joint optimization problem ; multi-view clustering methods ; unsuper-vised multi-view clustering ; sub-space learning ; multi-view clustering ; dual norms ; multi-view data	<method> <method> <method> <method> <otherscientificterm> <method> <task> <method> <task> <method> <method> <otherscientificterm> <material>	0 4 7 ; 0 0 10 ; 6 0 9 ; 0 0 8 ; 5 0 6 ; 4 2 1	learning from <material_12> is important in many applications . in this paper , we propose a novel <method_0> for <task_8> . we first formulate the <method_9> with multiple views as a <task_6> with a <method_2> and a <method_3> . by exploiting the properties of <otherscientificterm_11> , we then show a <method_1> with a <otherscientificterm_4> can be obtained . we develop a <method_5> to globally solve the <task_6> . our empirical study shows the proposed <method_0> can effectively facilitate <method_10> and induce superior clustering results than alternative <method_7> .	12 13 -1 0 8 17 13 -1 9 6 2 3 16 13 -1 11 1 4 19 13 -1 5 18 13 -1 10 7 14 15 13 -1
Unsupervised Feature Learning through Divergent Discriminative Feature Accumulation .	hidden layer size ; unsupervised feature learning ; mnist dataset ; classification problem ; ddfa features ; unsupervised approaches ; features ; autoencoders	<otherscientificterm> <method> <material> <task> <otherscientificterm> <method> <otherscientificterm> <method>	4 0 6 ; 7 6 5	unlike <method_5> such as <method_7> that learn to reconstruct their inputs , this paper introduces an alternative approach to <method_1> called divergent discriminative feature accumulation -lrb- <otherscientificterm_4> -rrb- that instead continually accumulates <otherscientificterm_6> that make novel discriminations among the training set . thus <otherscientificterm_4> are inherently discriminative from the start even though <otherscientificterm_4> are trained without knowledge of the ultimate <task_3> . interestingly , <otherscientificterm_4> also continues to add new <otherscientificterm_6> indefinitely -lrb- so <otherscientificterm_6> does not depend on a <otherscientificterm_0> -rrb- , is not based on minimizing error , and is inherently divergent instead of convergent , thereby providing a unique direction of research for <method_1> . in this paper the quality of its learned <otherscientificterm_6> is demonstrated on the <material_2> , where its performance confirms that indeed <otherscientificterm_4> is a viable technique for learning useful <otherscientificterm_6> .	5 7 1 4 6 10 8 -1 3 8 -1 0 8 -1 9 8 -1
Decision tree based frame mode selection for AMR-WB + .	decision tree based coding mode selection method ; open loop mode selection module ; closed loop mode selection ; speech and music materials ; amr-wb + audio coder ; mode selection accuracy ; decision tree classifier ; amr-wb + ; pruning	<method> <method> <method> <material> <method> <metric> <method> <method> <otherscientificterm>	1 0 7 ; 2 0 6 ; 0 0 4 ; 5 5 0 ; 5 5 1	in this paper , we propose a <method_0> for the <method_4> . in order to obtain improved performance with reduced computation , <method_6> is adopted with the <method_2> results as the target classification labels . to secure the practical feasibility of this <method_0> , the size of the <method_6> is controlled by <otherscientificterm_8> . through an evaluation on a database covering both <material_3> , the proposed <method_0> is found to increase the <metric_5> compared with the <method_1> in the <method_7> .	0 4 12 9 -1 6 2 11 9 -1 8 9 -1 3 5 1 7 10 13 14 9 -1
Sparse Finite Elements for Geodesic Contours with Level-Sets .	automatic detection of nested contours ; signed distance constraint ; geodesic contour problem ; finite difference representations ; numerical scheme ; level-set function ; flexible topology ; manual initialisation ; banded computation ; closed curves ; computational complexity ; banded algorithms ; level-set methods ; re-initialisation procedures ; maximum sparsity ; finite elements ; optimisation problems ; images ; re-initialisation	<task> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm>	12 0 16 ; 15 0 8 ; 11 0 10 ; 1 3 4	level-set methods have been shown to be an effective way to solve <task_16> that involve <otherscientificterm_9> . they are well known for their capacity to deal with <otherscientificterm_6> and do not require <otherscientificterm_7> . <metric_10> has previously been addressed by using <method_11> which restrict computation to the vicinity of the zero set of the <otherscientificterm_5> . so far , such schemes have used <method_3> which suffer from limited accuracy and require <method_13> to stabilise the evolution . this paper shows how <method_8> can be achieved using <otherscientificterm_15> . we give details of the novel representation and show how to build the <otherscientificterm_1> into the presented <method_4> . we apply the algorithm to the <task_2> -lrb- including the <task_0> -rrb- and demonstrate its performance on a variety of <material_17> . the resulting algorithm has several advantages which are demonstrated in the paper : it is inherently stable and avoids <otherscientificterm_18> ; it is convergent and more accurate because of the capabilities of <otherscientificterm_15> ; it achieves <otherscientificterm_14> because with <otherscientificterm_15> the band can be effectively of width 1 .	16 9 20 19 -1 6 7 10 19 -1 11 5 22 19 -1 3 13 19 -1 8 15 21 19 -1 23 19 -1 1 4 19 -1 2 0 17 19 -1
The Complexity of Subsumption in Fuzzy EL .	fuzzy description logics ; finitely valued fuzzy dls ; vague and imprecise knowledge ; ≈Çukasiewicz extensions of el ; lightweight dl el ; truth value ; classical dl ; application domains ; ≈Çukasiewicz semantics ; biomedical ontologies ; reasoning ; exptime	<method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <task> <method>	0 4 11	fuzzy description logics -lrb- dls -rrb- are used to represent and reason about <otherscientificterm_2> that is inherent to many <material_7> . it was recently shown that the complexity of <task_10> in <material_1> is often not higher than that of the underlying <material_6> . we show that this does not hold for fuzzy extensions of the <method_4> , which is used in many <otherscientificterm_9> , under the <otherscientificterm_8> . the complexity of <task_10> increases from <method_0> to <method_11> , even if only one additional <otherscientificterm_5> is introduced . the same lower bound holds also for infinitely valued <method_3> .	2 7 12 -1 10 1 6 12 -1 4 9 8 12 -1 0 11 5 13 12 -1 3 12 -1
Analysis of HMM temporal evolution for automatic speech recognition and utterance verification .	temporal evolution of hmm 's state scores ; viterbi grammar-free decoding step ; hmm-based acoustic modeling ; utterance verification system ; baseline verification algorithm ; acoustic parameters ; state scores ; utterance verification ; speech recognition ; acoustic models ; decoding ; hmms	<metric> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <method> <method> <method>	9 0 10 ; 11 0 8	this paper proposes a double layer <task_8> and <method_3> based on the analysis of the <metric_0> . for the lower layer , it uses standard <method_2> , followed by a <method_1> which provides us with the <otherscientificterm_6> of the <method_9> . in the second layer , these <otherscientificterm_6> are added to the regular set of <otherscientificterm_5> , building a new set of expanded <method_11> . using this expanded set of <method_11> for <task_8> a significant improvement in performance is achieved . next , we will use this new architecture for <task_7> in a '' second opinion '' framework . we will consign to the second layer evaluating the reliability of <method_10> using the <method_9> from the first layer . an outstanding improvement in performance versus a <method_4> has been achieved .	8 3 0 12 -1 2 1 6 9 12 -1 5 11 12 -1 14 12 -1 7 12 -1 13 12 -1 10 12 -1
Residual Algorithms : Reinforcement Learning with Function Approximation .	direct and residual gradient algorithms ; mean squared bellman residual ; reinforcement learning algorithms ; residual gradient algorithms ; general function-approximation system ; sigmoidal multilayer perceptron ; memory-based learning system ; linear function-approximation system ; theoretical analysis ; lookup tables ; gradient descent ; direct algorithms ; value iteration ; radial-basis-function system ; residual gradient ; advantage learning ; q-learning	<method> <otherscientificterm> <method> <method> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <method>	9 0 2 ; 5 1 13 ; 2 0 10 ; 14 1 16 ; 13 1 7 ; 16 1 15 ; 13 1 6 ; 0 0 3 ; 3 0 10 ; 6 1 7	a number of <method_2> have been developed that are guaranteed to converge to the optimal solution when used with <otherscientificterm_9> . it is shown , however , that these <method_2> can easily become unstable when implemented directly with a <method_4> , such as a <method_5> , a <method_13> , a <method_6> , or even a <method_7> . a new class of <method_2> , <method_3> , is proposed , which perform <otherscientificterm_10> on the <otherscientificterm_1> , guaranteeing convergence . i shown , however , that they may learn very slowly in some cases . a larger class of <method_2> , <method_3> , is proposed that has the guaranteed convergence of the <method_3> , yet can retain the fast learning speed of <method_11> . in fact , both <method_0> are shown to be special cases of <method_3> , and it is shown that <method_3> can combine the advantages of each approach . the direct , <otherscientificterm_14> , and residual forms of <method_12> , <method_16> , and <method_15> are all presented . <method_8> is given explaining the properties these <method_2> have , and simulation results are given that demonstrate these properties .	2 9 18 17 -1 4 5 13 6 7 19 22 24 27 17 -1 3 10 1 20 26 17 -1 17 -1 17 -1 11 25 17 -1 0 21 23 17 -1 14 12 16 15 8 17 -1
A local intensity adaptive structural similarity index .	structural similarity index ; ssim index ; local intensities ; weighting factors ; luminance comparison ; ssim index	<otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	3 0 5 ; 5 0 2	existing <otherscientificterm_0> comprises of one term on <otherscientificterm_4> and the other term on contrast and structure comparison . in this paper , the <material_5> is first improved by introducing three <otherscientificterm_3> to the second term such that <material_5> is adaptive to <otherscientificterm_2> of two images to be compared . the improved <metric_1> is further extended for two images with possibly different exposures . experimental results show that the proposed indices are more robust to large intensity changes of two images from the same scene and more sensitive to two images from different scenes than the existing <material_5> .	0 4 6 -1 5 3 2 7 8 6 -1 1 6 -1 6 -1
A sliding-window online fast variational sparse Bayesian learning algorithm .	variational sparse bayesian learning method ; automatic relevance determination ; inclusion or deletion of basis functions ; sliding window estimator ; online learning algorithm ; adaptive non-linear filtering ; sequential decision rule ; basis functions ; online fashion ; noise variance	<method> <method> <task> <method> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm>	3 0 4 ; 1 0 4 ; 4 0 9	in this work a new <method_4> that uses <method_1> is proposed for fast <task_5> . a <method_6> for <task_2> is obtained by applying a recently proposed fast <method_0> . the proposed <method_4> uses a <method_3> to process the data in an <material_8> . the <otherscientificterm_9> can be implicitly estimated by the <method_4> . it is shown that the described <method_4> has better mean square error -lrb- mse -rrb- performance than a state of the art kernel re-cursive least squares -lrb- kernel-rls -rrb- <method_4> when using the same number of <otherscientificterm_7> .	4 1 5 12 10 -1 6 2 0 10 -1 3 8 11 10 -1 9 13 10 -1 7 10 -1
Multi-resolution motion estimation .	fine-to-coarse motion estimation ; spatial multi-resolution video sequences ; multi-resolution video coding ; coding schemes ; visual quality ; coarsest resolution	<method> <material> <task> <method> <metric> <otherscientificterm>	0 0 3 ; 0 0 2 ; 0 0 5	spatial multi-resolution video sequences provide video at multiple frame sizes , allowing extraction of only the resolution or bit rate required by the user . this paper proposes <method_0> for <task_2> . while <method_0> , used in previously proposed <method_3> , can provide a better estimate at the <otherscientificterm_5> , <method_0> is outperformed by <method_0> at finer resolutions due to the inability of <method_0> to accurately track motion at finer resolutions . at the finest resolution , <method_0> provides a psnr improvement of up to 1 db , for the sequences tested , and better <metric_4> at all resolutions . in addition , <method_0> provides more accurate and thus more compressible motion estimates .	6 -1 0 2 8 6 -1 3 5 7 9 6 -1 4 6 -1 6 -1
Using Multiple Sources to Construct a Sentiment Sensitive Thesaurus for Cross-Domain Sentiment Classification .	cross-domain sentiment classification methods ; labeled and unlabeled data ; sentiment classification method ; multiple source domains ; sentiment sensitive thesaurus ; amazon user reviews ; binary classifier ; feature vectors	<method> <material> <method> <material> <otherscientificterm> <material> <method> <otherscientificterm>	2 4 0 ; 4 0 6 ; 7 0 6 ; 4 0 7	we describe a <method_2> that is applicable when we do not have any labeled data for a target domain but have some labeled data for multiple other domains , designated as the source domains . we automatically create a <otherscientificterm_4> using both <material_1> from <material_3> to find the association between words that express similar sentiments in different domains . the created thesaurus is then used to expand <otherscientificterm_7> to train a <method_6> . unlike previous <method_0> , our <method_2> can efficiently learn from <material_3> . our <method_2> significantly outperforms numerous baselines and returns results that are better than or comparable to previous <method_0> on a benchmark dataset containing <material_5> for different types of products .	2 8 -1 4 1 3 8 -1 7 6 10 11 12 8 -1 0 8 -1 9 8 -1
Recovering dropped pronouns from Chinese text messages .	lexical , contextual and syntactic information ; machine learning algorithms ; chinese text messages ; sms data ; text messages ; dropped pronouns ; sms files ; chi-nese sentences ; informal data ; features ; pronouns	<otherscientificterm> <method> <material> <material> <material> <otherscientificterm> <material> <material> <material> <otherscientificterm> <otherscientificterm>	0 0 9 ; 5 3 3 ; 4 6 8 ; 0 0 1	pronouns are frequently dropped in <material_7> , especially in <material_8> such as <material_4> . in this work we propose a solution to recover <otherscientificterm_5> in <material_3> . we manually annotate <otherscientificterm_5> in 684 <material_6> and apply <method_1> to recover them , leveraging <otherscientificterm_0> as <otherscientificterm_9> . we believe this is the first work on recovering <otherscientificterm_5> in <material_2> .	7 8 4 14 11 -1 5 3 13 11 -1 6 1 0 9 12 15 11 -1 2 10 11 -1
Pre-steering derivative constraints for robust broadband antenna arrays .	lcmv -lrb- linearly constrained minimum variance -rrb- problem ; pre-steered front end ; pre-steering derivative constraints ; look direction ; lcmv processor ; processor robustness ; broadband processor ; linear equations ; objective function ; positional errors ; quantization errors ; constraints space ; mismatches ; constraints	<task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 6 13	the weights of an optimum pb -lrb- pre-steered broadband -rrb- antenna array processor are often obtained by solving a <task_0> . the <otherscientificterm_8> is the mean output power -lrb- variance -rrb- and the <otherscientificterm_11> is a set of <otherscientificterm_7> which ensure a constant gain in a fixed direction known as the <otherscientificterm_3> . however , errors in a practical scenario could degrade the performance of the <method_4> significantly , namely , <otherscientificterm_12> between the <otherscientificterm_3> and the actual doa -lrb- direction of arrival -rrb- of the desired signal , <otherscientificterm_9> in the sensors and <otherscientificterm_10> in the <otherscientificterm_1> of the <method_6> . the main contribution of this paper is the derivation of a new set of <otherscientificterm_13> , referred to as the <otherscientificterm_2> , which is able to maintain the <metric_5> in the general 3d -lrb- three dimensional -rrb- space scenario with all the errors mentioned above .	0 14 -1 8 11 7 3 14 -1 4 12 9 10 1 14 -1 6 15 14 -1
Learning to Branch in Mixed Integer Programming .	machine learning framework ; mixed integer programming ; strong branching ; small search trees ; variable branching ; ranking function ; branch-and-bound search ; surrogate function ; benchmark instances ; parameter settings ; learning-to-rank problem ; commercial solver ; parameter tuning ; heterogeneous testbed ; time-consuming strategy ; search trees ; offline experimentation ; heuristics ; ml ; learning ; features ; branching	<method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <task> <otherscientificterm> <task>	5 0 21 ; 14 0 3 ; 17 4 11 ; 0 4 11 ; 0 4 17 ; 12 1 16 ; 8 5 0	the design of strategies for <task_21> in <task_1> is guided by cycles of <method_12> and <otherscientificterm_16> on an extremely <otherscientificterm_13> , using the average performance . once devised , these strategies -lrb- and their <otherscientificterm_9> -rrb- are essentially input-agnostic . to address these issues , we propose a <method_0> for <task_4> in mip . our <method_0> observes the decisions made by <method_2> , a <method_14> that produces <otherscientificterm_3> , collecting <otherscientificterm_20> that characterize the candidate <task_21> variables at each node of the tree . based on the collected data , we learn an easy-to-evaluate <otherscientificterm_7> that mimics the <method_2> , by means of solving a <task_10> , common in <task_18> . the learned <otherscientificterm_5> is then used for <task_21> . the <task_19> is instance-specific , and is performed on-the-fly while executing a <method_6> to solve the instance . experiments on <material_8> indicate that our <method_0> produces significantly smaller <otherscientificterm_15> than existing <method_17> , and is competitive with a state-of-the-art <method_11> .	21 1 12 16 13 28 22 -1 9 22 -1 0 4 22 -1 2 14 3 20 24 22 -1 7 22 -1 10 18 23 22 -1 5 22 -1 19 6 25 26 27 29 22 -1
Improved Chinese broadcast news transcription by language modeling with temporally consistent training corpora and iterative phrase extraction .	iterative chinese new phrase extraction method ; chinese language model enhancement framework ; chinese broadcast news transcription ; adaptation corpora ; lexicon expansion ; temporal consistency	<method> <method> <material> <material> <task> <metric>	4 3 1	in this paper an <method_0> based on the intra-phrase association and context variation statistics is proposed . a <method_1> including <task_4> is then developed . extensive experiments for <material_2> were then performed to explore the achievable improvements with respect to the degree of <metric_5> for the <material_3> . very encouraging results were obtained and detailed analysis discussed .	0 6 -1 1 4 7 6 -1 2 5 3 6 -1 6 -1
Exploiting the baseband phase structure of the voiced speech for speech enhancement .	noise dominant frequency bins ; baseband stft domain ; speech enhancement techniques ; babble noise ; voiced frames ; voiced segment ; phase spectra ; log-mmse stsa ; spectral subtraction ; pitch estimation ; noisy speech ; voiced speech	<otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <material> <material>	10 0 9 ; 8 1 7 ; 11 3 1 ; 8 6 2 ; 1 2 11	performance of traditional <method_2> like <otherscientificterm_8> and log-minimum mean squared error short time spectral amplitude -lrb- <metric_7> -rrb- estimation degrades in presence of highly non-stationary noises like <otherscientificterm_3> . this is mainly due to inaccurate noise estimation during the <otherscientificterm_5> of the speech signal . in this paper , we propose to exploit the fine structure of the <otherscientificterm_6> of the <material_11> in the <material_1> . this phase structure is used to detect the <otherscientificterm_0> in the <otherscientificterm_4> . this information is used to achieve better non-stationary noise power spectral density -lrb- psd -rrb- estimation . using this estimation , performance of <otherscientificterm_8> and <metric_7> is improved overall by 0.3 and 0.2 , respectively , in terms of perceptual evaluation of speech quality -lrb- pesq -rrb- measure over the original algorithms when <material_10> is used for <task_9> . we also present the combination of these two algorithms -lrb- <otherscientificterm_8> and <metric_7> -rrb- to achieve the overall pesq improvement of 0.5 over standard <metric_7> when accurate <task_9> is available .	2 8 7 3 16 12 -1 5 12 -1 6 11 1 15 17 12 -1 0 4 12 -1 12 -1 13 14 12 -1 10 9 12 -1
Dialogue act compression via pitch contour preservation .	automatically compressing dialogue acts ; random baseline approach ; text compression method ; pitch contour ; human-authored gold-standard ; human an-notators ; prosodic approach ; meeting speech ; edit distance ; prosody	<task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method>	6 4 2 ; 6 4 1 ; 1 4 2 ; 4 0 8	this paper explores the usefulness of <method_9> in <task_0> from <material_7> . specifically , this work attempts to compress utterances by preserving the <otherscientificterm_3> of the original whole utterance . two methods of doing this are described in detail and are evaluated subjectively using <otherscientificterm_5> and objectively using <otherscientificterm_8> with a <otherscientificterm_4> . both metrics show that such a <method_6> is much better than the <method_1> and significantly better than a simple <method_2> .	9 0 7 10 -1 3 10 -1 5 8 4 14 10 -1 6 1 2 11 12 13 10 -1
Prediction of Pronunciation Variations for Speech Synthesis : A Data-Driven Approach .	full and reduced pronunciations ; unit selection speech synthesis ; pronunciation variation prediction model ; speaker 's pronunciation distribution ; automatically categorized data ; machine learning techniques ; human labeled data ; acoustic modeling techniques ; automatic pronunciation labels ; utterance text ; speech recognition	<otherscientificterm> <task> <method> <otherscientificterm> <material> <method> <material> <method> <material> <material> <task>	5 0 4 ; 7 0 0 ; 3 0 1 ; 5 0 2 ; 10 0 7	the fact that speakers vary pronunciations of the same word within their own speech is well known , but little has been done to automatically categorize and predict a <otherscientificterm_3> for <task_1> . recent work demonstrated how to automatically identify a speaker 's choice between <otherscientificterm_0> using <method_7> from <task_10> . here , we extend this approach and show how its results can be used to predict a speaker 's choice of pronunciations for synthesis . we apply <method_5> to the <material_4> to produce a <method_2> given only the <material_9> -- allowing the system to synthesize novel phrases with variations like those the speaker would make . empirical studies emphasize that we can improve <material_8> and successfully utilize the results for prediction of future synthesized examples . the prediction results based on these <material_8> are very similar to those trained from <material_6> -- allowing us to reduce manual effort while still achieving comparable results .	3 1 14 11 -1 0 7 10 13 16 11 -1 11 -1 5 4 2 9 12 15 11 -1 11 -1 8 11 -1
Item Bidding for Combinatorial Public Projects .	combina-torial public project problem ; coordinated deviations of subsets of agents ; combi-natorial preferences -lrb- valuation functions ; truthful approximation mechanisms ; optimum social welfare ; tight worst-case bounds ; vcg-based payment rule ; item bidding interface ; multi-agent environments ; autonomous agents ; social welfare ; abstract model ; computational hardness ; valuation functions ; decision making ; natural simplicity	<task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric>	11 0 9 ; 0 0 14 ; 10 0 9 ; 11 0 14	we present and analyze a mechanism for the <task_0> . the problem asks to select k out of m available items , so as to maximize the <otherscientificterm_10> for <method_9> with <otherscientificterm_2> -rrb- over subsets of items . the <task_0> constitutes an <method_11> for <task_14> by <method_9> and has been shown to present severe <otherscientificterm_12> , in the design of <method_3> . we study a non-truthful mechanism that is , however , practically relevant to <otherscientificterm_8> , by virtue of its <metric_15> . <task_0> employs an <method_7> , wherein every agent issues a separate bid for the inclusion of each distinct item in the outcome ; the k items with the highest sums of bids are chosen and agents are charged according to a <otherscientificterm_6> . for fairly expressive classes of the agents ' <otherscientificterm_13> , we establish existence of socially optimal pure nash and strong equilibria , that are resilient to <otherscientificterm_1> . subsequently we derive <otherscientificterm_5> on the approximation of the <otherscientificterm_4> achieved in equilibrium . we show that the mechanism 's performance improves with the number of agents that can coordinate , and reaches half of the optimum welfare at strong equilibrium .	0 16 -1 10 9 2 19 16 -1 11 14 12 3 17 18 20 16 -1 8 15 16 -1 7 16 -1 6 16 -1 13 1 16 -1 5 4 16 -1
Harmonic phase estimation in single-channel speech enhancement using von mises distribution and prior SNR .	single-channel speech enhancement ; noisy spectral phase ; speech enhancement ; signal reconstruction ; bayesian estimator ; noisy signal ; noisy speech ; spectral amplitude ; signal-to-noise ratio ; upper-bound ; intelligibility ; snrs ; quality	<task> <otherscientificterm> <task> <task> <method> <otherscientificterm> <material> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <metric>	7 2 0 ; 8 5 4 ; 10 5 4 ; 7 2 5 ; 1 0 3	in <task_0> the <otherscientificterm_7> of the <otherscientificterm_5> is often modified while the <otherscientificterm_1> is directly employed for <task_3> . recently , additional improvement in <task_2> performance has been reported when the <otherscientificterm_1> is modified . in this work , we propose a <method_4> for phase of harmonics given the <material_6> . the proposed <method_4> relies on the fundamental frequency and the <metric_8> at harmonics . throughout our experiments , we evaluate the performance of the proposed <task_0> in comparison with the <otherscientificterm_1> , a benchmark and the clean phase as the <otherscientificterm_9> . the proposed <method_4> leads to joint improvement in <metric_12> and <metric_10> at different <otherscientificterm_11> and noise types .	0 7 5 1 3 14 17 18 13 -1 2 13 -1 4 6 13 -1 8 15 13 -1 9 13 -1 16 13 -1
Preference Elicitation and Interview Minimization in Stable Matchings .	knowledge of agent preferences ; pure interview minimization algorithm ; stable matching problems ; coarse preference queries ; agent preferences ; stable matching	<otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method>	3 0 0	while <task_2> are widely studied , little work has investigated schemes for effectively eliciting <otherscientificterm_4> using either preference -lrb- e.g. , comparison -rrb- queries or interviews -lrb- to form such comparisons -rrb- ; and no work has addressed how to combine both . we develop a new model for representing and assessing <otherscientificterm_4> that accommodates both forms of information and -lrb- heuristically -rrb- minimizes the number of queries and interviews required to determine a <method_5> . our refine-then-interview -lrb- rti -rrb- scheme uses <otherscientificterm_3> to refine <otherscientificterm_0> and relies on interviews only to assess comparisons of relatively '' close '' options . empirical results show that rti compares favorably to a recent <method_1> , and that the number of interviews it requires is generally independent of the size of the market .	2 4 6 -1 5 6 -1 3 0 7 6 -1 6 -1
Supervaluation Semantics for an Inland Water Feature Ontology .	snapshots of river networks ; formal concept analysis ; inland water features ; threshold parameters ; supervaluation semantics ; su-pervaluation semantics	<method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 1 5	this paper describes an ontology for <task_2> built using <method_1> and <otherscientificterm_5> . the first is used to generate a complete lattice of the water domain , whereas <otherscientificterm_4> is used to model the variability of the concepts in terms of <otherscientificterm_3> . we also present an algorithm for a mechanism of individuation and classification of water features , from <method_0> , according to the proposed ontology .	2 1 5 7 6 -1 4 3 6 -1 0 6 -1
An application of system theory to stochastic models for first order chemical reactions .	closed and open reaction environments ; coupled first-order chemical reactions ; computation of probability distributions ; first-order reaction chain ; enzyme catalyst reaction ; complicated reaction system ; chemical species ; block diagrams ; coupled reactions ; transfer functions ; chemical reactions ; system theory ; reaction topology ; analytic solution ; molecule species ; molecule population ; vice versa	<otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 0 8 ; 7 0 5 ; 8 0 0 ; 2 0 1 ; 3 6 12	a new approach for the <task_2> for <otherscientificterm_1> is introduced . the approach is based on <method_11> , where the <method_11> states are <otherscientificterm_6> and the signals are probabilities . the <otherscientificterm_9> of the so defined systems for <otherscientificterm_8> can be applied to both <otherscientificterm_0> . the use of <method_7> offers a clear , visual , and convenient way to decompose a <method_5> into simpler subsystems and <otherscientificterm_16> . since the state of the <method_11> is defined as a <otherscientificterm_14> instead of <otherscientificterm_15> , with this method one can study <otherscientificterm_10> involving any number of molecules . such analysis is shown on an <otherscientificterm_4> . in addition , a special form of <otherscientificterm_12> , the <method_3> , is studied , and the <method_13> for its distribution is derived .	2 1 21 17 -1 11 6 17 -1 9 8 0 18 20 17 -1 7 5 16 19 17 -1 14 15 10 17 -1 17 -1 4 22 17 -1
Rescaling , thinning or complementing ? On goodness-of-fit procedures for point process models and Generalized Linear Models .	checking model adequacy of point processes ; generalized linear models ; stochastic point processes ; neural spike trains ; neural firing rates ; surrogate point processes ; complementing point processes ; time-rescaling theorem ; coarse discretization ; time-series observations ; discretized models ; point-process theory ; thinning	<task> <method> <method> <task> <metric> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	7 6 11 ; 4 1 8 ; 9 0 5 ; 11 0 1	generalized linear models -lrb- <method_1> -rrb- are an increasingly popular framework for modeling <task_3> . they have been linked to the theory of <method_2> and researchers have used this relation to assess goodness-of-fit using methods from <method_11> , e.g. the <method_7> . however , high <metric_4> or <otherscientificterm_8> lead to a breakdown of the assumptions necessary for this connection . here , we show how goodness-of-fit tests from <method_11> can still be applied to <method_1> by constructing equivalent <method_5> out of <otherscientificterm_9> . furthermore , two additional tests based on <otherscientificterm_12> and <method_6> are introduced . they augment the instruments available for <task_0> as well as <method_10> .	1 3 13 -1 2 11 7 14 13 -1 4 8 15 13 -1 5 9 16 17 13 -1 12 6 13 -1 13 -1
A Topographic Support Vector Machine : Classification Using Local Label Configurations .	cell image segmentation task ; measured vectorial feature information ; 2d regular rectangular grid ; classification of objects ; recurrent neural network ; topo-graphical relationship ; image segmentation ; to-pographic neighborhood ; classification method ; label configuration ; topographic kernel ; label assignment ; collective classification ; self-consistent solution ; topography ; svm	<task> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <method>	10 1 13 ; 1 0 8 ; 0 5 15	the standard approach to the <task_3> is to consider the examples as independent and identically distributed -lrb- iid -rrb- . in many real world settings , however , this assumption is not valid , because a <otherscientificterm_5> exists between the objects . in this contribution we consider the special case of <task_6> , where the objects are pixels and where the underlying <otherscientificterm_14> is a <otherscientificterm_2> . we introduce a <method_8> which not only uses <otherscientificterm_1> but also the <otherscientificterm_9> within a <otherscientificterm_7> . due to the resulting dependence between the labels of neighboring pixels , a <method_12> of a set of pixels becomes necessary . we propose a new method called ` topographic support vector machine ' -lrb- tsvm -rrb- , which is based on a <method_10> and a <method_13> to the <task_11> shown to be equivalent to a <method_4> . the performance of the algorithm is compared to a conventional <method_15> on a <task_0> .	3 16 -1 5 16 -1 6 14 2 16 -1 8 1 9 7 18 16 -1 12 16 -1 17 16 -1 10 13 11 4 19 16 -1
Signal Independent Wideband Activity Detection Features for Microphone Arrays .	tolerable detection errors ; direction of arrival ; detection of activity ; detection methods ; time delays ; array system ; activity features ; loudspeaker experiment ; spatial data ; microphone arrays	<otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm>	4 1 1 ; 2 0 9 ; 8 0 6 ; 7 0 6	detection of activity is a key capability for <otherscientificterm_9> . an <method_5> should tell when a source of interest is present and evaluate the usability of the computed spatial estimates . this work proposes <otherscientificterm_6> that are computed from <material_8> only , using <otherscientificterm_4> and <otherscientificterm_1> . the <otherscientificterm_6> are validated with a <method_7> . results show that the <otherscientificterm_6> are effective : <otherscientificterm_0> are achievable with simple <method_3> . in addition , <otherscientificterm_1> estimation error is reduced down to one third when unreliable estimates are discarded .	9 12 10 -1 5 10 -1 6 8 4 1 11 13 10 -1 7 14 10 -1 0 3 10 -1 2 10 -1
Meta-Learning with Memory-Augmented Neural Networks .	neural turing machines ; memory location-based focusing mechanisms ; memory-augmented neu-ral network ; augmented memory capacities ; deep neural networks ; one-shot learning ; external memory ; iterative training ; memory content ; gradient-based networks ; catastrophic interference ; architec-tures	<method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <material> <method> <otherscientificterm> <method>	0 6 3	despite recent breakthroughs in the applications of <method_4> , one setting that presents a persistent challenge is that of '' <task_5> . '' traditional <method_9> require a lot of data to learn , often through extensive <method_7> . when new data is encountered , the models must inefficiently relearn their parameters to adequately incorporate the new information without <otherscientificterm_10> . <method_11> with <otherscientificterm_3> , such as <method_0> , offer the ability to quickly encode and retrieve new information , and hence can potentially obviate the down-sides of conventional models . here , we demonstrate the ability of a <method_2> to rapidly assimilate new data , and leverage this data to make accurate predictions after only a few samples . we also introduce a new method for accessing an <otherscientificterm_6> that focuses on <material_8> , unlike previous methods that additionally use <method_1> .	4 5 12 -1 9 7 12 -1 10 11 12 -1 3 0 13 12 -1 2 12 -1 12 -1
Mining Parallel Documents Using Low Bandwidth and High Precision CLIR from the Heterogeneous Web .	search query relevance score ; cross lingual information retrieval ; mined parallel material ; pure clir approach ; parallel documents ; mined documents ; parallel resources ; content-based approach ; mining recall ; url matching ; batch mode ; computational cost ; non-parallel sites ; local machines ; smt performance ; bleu score ; mining precision ; search engines ; web	<method> <method> <material> <method> <material> <material> <material> <method> <task> <method> <otherscientificterm> <metric> <material> <otherscientificterm> <metric> <metric> <metric> <method> <material>	1 0 7 ; 7 0 4 ; 17 0 7 ; 7 0 8 ; 7 0 6 ; 9 0 4 ; 11 1 13	we propose a <method_7> to mine <material_6> from the entire <material_18> using <method_1> with <method_0> . our <method_7> improves <task_8> by going beyond <method_9> to find <material_4> from <material_12> . we introduce <method_0> to improve the precision of mining . our <method_7> makes use of <method_17> to query for target document given each source document and therefore does not require downloading target language documents in <otherscientificterm_10> , reducing <metric_11> on the <otherscientificterm_13> and bandwidth consumption . we obtained a very high <metric_16> -lrb- 88 % -rrb- on the <material_4> by the <method_3> . after extracting parallel sentences from the <material_5> and using them to train an <method_1> , we found that the <metric_14> , with 29.88 <metric_15> , is comparable to that obtained with high quality manually translated parallel sentences with 29.54 <metric_15> , illustrating the excellent quality of the <material_2> .	7 6 18 1 0 20 24 19 -1 8 9 4 12 21 23 25 19 -1 19 -1 17 10 11 13 22 26 19 -1 16 3 19 -1 5 19 -1
Influence of temporal discretization schemes on formant frequencies and bandwidths in time domain simulations of the vocal tract system .	piece-wise constant area function ; temporal finite-difference approximation ; frequency domain simulations ; transmission line model ; trapezoid rule ; finite-difference scheme ; acoustic propagation ; differential equations ; finite-difference schemes ; parameter Œ∏ ; formant frequencies ; sampling rates ; lumped elements ; sampling rate ; vocal tract ; simulated vowels ; spatial discretization ; Œ∏	<otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <method>	0 0 16 ; 4 3 5 ; 13 5 17 ; 12 2 14 ; 9 0 5 ; 6 3 14	a time domain simulation of <task_6> in the <otherscientificterm_14> requires the spatial and temporal discretization of the equations of motion and continuity . in the classic <method_3> of the <otherscientificterm_14> with <otherscientificterm_12> , the <otherscientificterm_16> is provided by the <otherscientificterm_0> . the <method_1> of the <otherscientificterm_7> can , however , vary from one implementation to the other -lrb- e.g. , -lsb- 4 -rsb- vs. -lsb- 5 -rsb- -rrb- . in this study , we have adopted a general <method_5> that depends on a <method_9> where 0 ‚â§ <method_17> ‚â§ 1 . as special cases , this general <method_5> includes the <otherscientificterm_4> -lrb- <method_17> = 0.5 -rrb- as well as the implicit -lrb- <method_17> = 1 -rrb- and explicit -lrb- <method_17> = 0 -rrb- <otherscientificterm_8> . we have examined how <otherscientificterm_10> and bandwidths of <material_15> are effected by the choice of <method_17> . the experiments were conducted for the <metric_11> of 44.1 khz and 88.2 khz and compared with the accurate and thus desirable frequencies and bandwidths measured in <method_2> of the <otherscientificterm_14> . it can be shown that optimal values for <method_17> are slightly above 0.5 depending on the <metric_13> .	6 14 24 18 -1 3 12 16 0 19 22 18 -1 1 7 18 -1 5 9 17 23 18 -1 20 18 -1 4 8 18 -1 10 15 18 -1 11 2 21 18 -1
Algorithms for Non-negative Matrix Factorization .	non-negative matrix factorization ; diagonally rescaled gradient descent ; generalized kullback-leibler divergence ; rescaling factor ; multi-plicative algorithms ; expectation-maximization algorithm ; multivariate data ; auxiliary function ; update rules ; multiplicative factor ; monotonic convergence ; decomposition	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	9 0 8 ; 7 0 10 ; 4 0 0	non-negative matrix factorization -lrb- <method_0> -rrb- has previously been shown to be a useful <method_11> for <material_6> . two different <method_4> for <method_0> are analyzed . <method_0> differ only slightly in the <otherscientificterm_9> used in the <otherscientificterm_8> . one algorithm can be shown to minimize the conventional least squares error while the other minimizes the <otherscientificterm_2> . the <otherscientificterm_10> of both algorithms can be proven using an <otherscientificterm_7> analogous to that used for proving convergence of the <method_5> . the algorithms can also be interpreted as <otherscientificterm_1> , where the <method_3> is optimally chosen to ensure convergence .	0 11 6 12 -1 4 15 12 -1 9 8 13 12 -1 2 12 -1 10 7 5 14 12 -1 1 3 12 -1
Human Re-identification by Matching Compositional Template with Cluster Sampling .	markov chain monte carlo mechanism ; large human appearance variability ; matching solution ; cluster sampling ; visual surveillance ; candidacy graph ; partial matches ; public databases ; body information ; reference template ; re-identifying people ; matching algorithm ; surrounding clutters ; poses/views ; occlusions ; illumination	<method> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	13 1 15	this paper aims at a newly raising task in <task_4> : <task_10> at a distance by matching <otherscientificterm_8> , given several reference examples . most of existing works solve this task by matching a <otherscientificterm_9> with the target individual , but often suffer from <otherscientificterm_1> -lrb- e.g. different <otherscientificterm_13> , <otherscientificterm_15> -rrb- and high false positives in matching caused by conjunctions , <otherscientificterm_14> or <otherscientificterm_12> . addressing these problems , we construct a simple yet expressive template from a few reference images of a certain individual , which represents the body as an articulated assembly of compositional and alternative parts , and propose an effective <method_11> with <method_3> . this algorithm is designed within a <method_5> whose vertices are matching candidates -lrb- i.e. a pair of source and target body parts -rrb- , and iterates in two steps for convergence . -lrb- i -rrb- it generates possible <otherscientificterm_6> based on compatible and competitive relations among body parts . -lrb- ii -rrb- it confirms the <otherscientificterm_6> to generate a new <method_2> , which is accepted by the <method_0> . in the experiments , we demonstrate the superior performance of our approach on three <material_7> compared to existing methods .	4 10 8 16 -1 9 1 13 15 14 12 17 16 -1 16 -1 11 3 16 -1 5 16 -1 6 16 -1 2 0 16 -1
On the Hardness of Approximate Reasoning .	counting satisfying assignments of propositional languages ; restricted classes of propositional formulae ; linear time satissability algorithms ; horn and monotone formulae ; bayesian belief networks ; counting satisfying assignments ; knowledge compilation ; approximate reasoning ; ai problems ; constraint satisfaction ; propositional domain ; propo-sitional expression ; eecient algorithms ; deductive reasoning ; model-counting problems ; reasoning techniques ; horn theories ; binary clauses ; computational diiculties ; approximation	<task> <method> <method> <otherscientificterm> <method> <task> <task> <method> <task> <method> <material> <otherscientificterm> <method> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method>	9 1 4 ; 4 6 7 ; 9 1 6 ; 12 0 5 ; 6 1 4 ; 6 6 15 ; 6 6 7 ; 9 6 15 ; 9 6 7	many <task_8> , when formalized , reduce to evaluating the probability that a <otherscientificterm_11> is true . in this paper we show that this problem is computationally intractable even in surprisingly restricted cases and even if we settle for an <method_19> to this probability . we consider various methods used in <method_7> such as computing degree of belief and <method_4> , as well as <method_15> such as <method_9> and <task_6> , that use <method_19> to avoid <otherscientificterm_18> , and reduce them to <task_14> over a <material_10> . we prove that <task_0> is intractable even for <otherscientificterm_3> , and even when the size of clauses and number of occurrences of the variables are extremely limited . this should be contrasted with the case of <method_13> , where <method_16> and theories with <otherscientificterm_17> are distinguished by the existence of <method_2> . what is even more surprising is that , as we show , even approximating the number of satisfying assignments -lrb- i.e. , \ approximating '' <method_7> -rrb- , is intractable for most of these restricted theories . we also identify some <method_1> for which <method_12> for <task_5> can be given .	8 11 20 -1 19 20 -1 7 4 15 9 6 18 14 10 21 22 23 25 26 27 28 29 20 -1 0 3 20 -1 20 -1 13 16 17 2 20 -1 24 20 -1
Learning attentional policies for tracking and recognition in video with deep networks .	simultaneous object tracking and recognition ; dorsal pathway models ; human perceptual system ; ventral and dorsal ; restricted boltzmann machines ; particle filtering ; posterior distribution ; attentional mechanism ; video sequences ; retinal images ; dorsal pathway ; tracking uncertainty ; gaze data ; attentional model ; decaying resolution ; orientation ; scale ; location	<task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <material> <material> <otherscientificterm> <task> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	17 1 16 ; 17 1 15 ; 13 0 0 ; 7 0 11 ; 15 1 16 ; 5 0 6	we propose a novel <method_13> for <task_0> that is driven by <material_12> . motivated by theories of the <method_2> , the <method_13> consists of two interacting pathways : <otherscientificterm_3> . the ventral pathway models object appearance and classification using deep -lrb- factored -rrb- - <otherscientificterm_4> . at each point in time , the observations consist of <material_9> , with <otherscientificterm_14> toward the periphery of the gaze . the <method_1> the <otherscientificterm_17> , <otherscientificterm_15> , <otherscientificterm_16> and speed of the attended object . the <otherscientificterm_6> of these states is estimated with <method_5> . deeper in the <otherscientificterm_10> , we encounter an <method_7> that learns to control gazes so as to minimize <task_11> . the <method_13> is modular -lrb- with each module easily replaceable with more sophisticated algorithms -rrb- , straightforward to implement , practically efficient , and works well in simple <material_8> .	13 0 12 21 18 -1 2 3 18 -1 4 18 -1 9 14 18 -1 1 17 15 16 19 20 23 18 -1 6 5 24 18 -1 10 22 18 -1 7 11 18 -1
Common Pattern Discovery Using Earth Mover 's Distance and Local Flow Maximization .	earth movers distance framework ; unary and adaptive neighborhood color similarity ; local flow maximization approach ; reduced spatial space ; common pattern discovery ; iterative optimization ; segmentation-insensitive approach ; search space ; location	<method> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm>	3 0 4 ; 0 1 1 ; 0 0 6	in this paper , we present a novel <method_6> for mining common patterns from 2 images . we develop an <method_6> using the <method_0> , <otherscientificterm_1> . we then propose a novel <method_2> to provide the best estimation of <otherscientificterm_8> and scale of the common pattern . this is achieved by performing an <method_5> in search of the most stable flows ' centroid . common pattern discovery is difficult owing to the huge <otherscientificterm_7> and problem domain . we intend to solve this problem by reducing the <otherscientificterm_7> through identifying the <otherscientificterm_8> and a <otherscientificterm_3> for <task_4> . experimental results justify the effectiveness and the potential of the <method_2> .	6 9 -1 0 1 11 12 9 -1 2 8 9 -1 5 9 -1 7 9 -1 3 4 10 9 -1 9 -1
A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining .	interpolation of translitera-tion and non-transliteration sub-models ; news 2010 shared task data ; unsupervised and semi-supervised settings ; transliteration pairs ; transliter-ation mining ; parallel corpora	<method> <material> <otherscientificterm> <otherscientificterm> <task> <material>	5 0 3 ; 0 0 4	we propose a novel model to automatically extract <otherscientificterm_3> from <material_5> . our model is efficient , language pair independent and mines <otherscientificterm_3> in a consistent fashion in both <otherscientificterm_2> . we model <task_4> as an <method_0> . we evaluate on <material_1> and on <material_5> with competitive results .	3 5 7 6 -1 2 6 -1 4 0 8 6 -1 1 6 -1
Extending Decidable Cases for Rules with Existential Variables .	map of known decidable cases ; tgd -lrb- tuple-generating dependencies -rrb- ; backward and forward chaining schemes ; existen-tially quantified variables ; conceptual graph rules ; reasoning tasks ; logical form ; deduction ; graph	<task> <material> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 5	in ‚àÄ ‚àÉ - rules , the conclusion may contain <otherscientificterm_3> , which makes <task_5> -lrb- as <otherscientificterm_7> -rrb- non-decidable . these rules have the same <otherscientificterm_6> as <material_1> in databases and as <otherscientificterm_4> . we extend known decidable cases by combining <method_2> , in association with a <otherscientificterm_8> that captures exactly the notion of dependency between rules . finally , we draw a <task_0> , including an extension obtained by combining our approach with very recent results on <material_1> .	3 5 7 10 9 -1 6 1 4 9 -1 2 8 9 -1 0 9 -1
Efficient Large-Scale Similarity Search Using Matrix Factorization .	high-dimensional global image descriptors ; group testing formulation ; locality sensitive hashing ; image search benchmarks ; small-to-medium sized problems ; image retrieval problem ; search complexity ; decoding architecture ; large-scale scenarios ; global descriptors ; dictionary learning ; -rrb- accuracy ; ya-hoo100m dataset ; dimen-sionality reduction ; vector operations ; query image ; memory ; images ; eigendecomposition ; accuracy	<otherscientificterm> <method> <method> <material> <task> <task> <metric> <method> <task> <otherscientificterm> <method> <metric> <material> <method> <task> <material> <otherscientificterm> <material> <method> <metric>	1 0 7 ; 10 1 18 ; 18 0 7 ; 13 1 2 ; 1 0 4 ; 10 3 8 ; 12 6 3 ; 10 0 7	we consider the <task_5> of finding the <material_17> in a dataset that are most similar to a <material_15> . our goal is to reduce the number of <task_14> and <otherscientificterm_16> for performing a search without sacrificing <metric_19> of the returned <material_17> . we adopt a <method_1> and design the <method_7> using either <method_10> or <method_18> . the latter is a plausible option for <task_4> with <otherscientificterm_0> , whereas <method_10> is applicable in <task_8> . we evaluate our approach for <otherscientificterm_9> obtained from both sift and cnn features . experiments with standard <material_3> , including the <material_12> comprising 100 million <material_17> , show that our method gives comparable -lrb- and sometimes superior <metric_11> compared to exhaustive search while requiring only 10 % of the <task_14> and <otherscientificterm_16> . moreover , for the same <metric_6> , our method gives significantly better <metric_19> compared to approaches based on <method_13> or <method_2> .	5 17 15 20 -1 14 16 19 20 -1 1 7 10 18 21 22 23 28 20 -1 4 0 8 25 26 20 -1 9 20 -1 3 12 27 20 -1 11 24 20 -1
Finite data record performance analysis of rapid synchronization and combined demodulation algorithms .	wireless direct-sequence code-division-multiple-access communication environments ; short-data-record sample-matrix-inversion implementations ; self-synchronized receivers -lrb- integrated synchronizers/demodulators -rrb- ; minimum-variance-distortionless-response-type linear self-synchronized receivers ; computationally demanding performance evaluation ; asynchronous direct-sequence code-division-multiple-access communications ; finite data record adaptation ; filter order p ; adaptive short-data-record designs ; coarse synchronization error ; short data records ; system adaptivity ; matured discipline ; communication environments ; coarse synchronization ; computational complexity ; analytic expressions ; introduction	<task> <method> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm> <method>	10 0 11 ; 1 0 14 ; 3 0 5	we investigate the <task_14> performance of matched-filter-type -lrb- mf -rrb- and <method_3> for <task_5> under <otherscientificterm_6> . <otherscientificterm_16> are derived that approximate closely the probability of <otherscientificterm_9> and provide low-cost highly-accurate alternatives to the <task_4> through simulations . the expressions are explicit functions of the data record size n and the <otherscientificterm_7> and reveal the effect of <method_1> on the <task_14> performance . 1 . <method_17> the effectiveness of a receiver designed for rapidly changing <task_0> depends on establishing a successful tradeoff among the following three design objectives : -lrb- z -rrb- low <metric_15> , -lrb- 22 -rrb- multiple-access-interference -lrb- mai -rrb- near-far resistance , and -lrb- iii -rrb- system adaptivity with superior performance under limited data support . <method_8> appear as the natural next step -lsb- l -rsb- to a <otherscientificterm_12> that has extensively addressed the first two design objectives in ideal setups -lrb- perfectly known or asymptotically estimated statistical properties -rrb- -lsb- 2 -rsb- . <task_11> based on <material_10> is necessary for the development of receivers that exhibit superior bit-error-rate performance when <task_11> operate in rapidly changing <otherscientificterm_13> that limit substantially the available data support . in -lsb- 3 -rsb- , we considered <method_2> and we presented	14 3 5 6 16 21 18 -1 9 4 18 -1 7 1 20 18 -1 17 18 -1 0 15 18 -1 8 18 -1 12 11 19 18 -1 10 13 18 -1
Active Face Tracking and Pose Estimation in an Interactive Room .	spatial location of a user 's head ; foveated images of the face ; closed loop feedback ; unconstrained ooce environment ; active foveated camera ; real-time face tracking ; pose estimation ; vision routines ; interactive environment ; foveated view ; eigenspaces ; faces	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 2 3 ; 7 0 8	we demonstrate <task_5> and <task_6> in an <otherscientificterm_3> with an <otherscientificterm_4> . using <method_7> previously implemented for an <otherscientificterm_8> , we determine the <otherscientificterm_0> and guide an active camera to obtain <material_1> . <otherscientificterm_11> are analyzed using a set of <otherscientificterm_10> indexed over both pose and world location . <otherscientificterm_2> from the estimated facial location is used to guide the camera when a face is present in the <otherscientificterm_9> . our system can detect the head pose of an unconstrained user in real-time as he or she moves about an open room .	5 6 3 4 13 12 -1 7 8 0 1 11 14 12 -1 10 2 12 -1 9 12 -1 12 -1
Third-Order Edge Statistics : Contour Continuation , Curvature , and Cortical Connections .	pairwise statistics of edges ; suf-ficiency of pairwise statistics ; human contour grouping ; probabilistic spectral embedding ; association field models ; curvature-dependent components ; association fields ; natural scenes ; order structure ; v1	<otherscientificterm> <otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	4 0 2	association field models have attempted to explain <task_2> performance , and to explain the mean frequency of long-range horizontal connections across cortical columns in <otherscientificterm_9> . however , <otherscientificterm_6> only depend on the <otherscientificterm_0> in <material_7> . we develop a spectral test of the <otherscientificterm_1> and show there is significant higher <otherscientificterm_8> . an analysis using a <method_3> reveals <method_5> .	2 9 11 10 -1 6 0 7 10 -1 1 8 10 -1 3 5 4 10 -1
Combining recurrent neural networks and factored language models during decoding of code-Switching speech .	recurrent neu-ral network language models ; syntactic and semantic features ; unconverted recurrent neural network ; mixed error rate reduction ; backoff language models ; seame evaluation set ; factored language models ; language modeling process ; brown word clusters ; language models ; part-of-speech tags ; language modeling ; text material ; language identifiers ; error analysis ; code-switching speech ; perplexity ; decoding ; code-switching	<method> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <material> <otherscientificterm> <method> <material> <metric> <task> <task>	10 1 13 ; 0 3 4 ; 9 0 17 ; 1 3 7 ; 13 1 8 ; 4 0 17 ; 14 5 9 ; 12 0 15 ; 11 0 18	in this paper , we present our latest investigations of <task_11> for <task_18> . since there is only little <material_12> for <material_15> available , we integrate <otherscientificterm_1> into the <method_7> . in particular , we use <otherscientificterm_10> , <otherscientificterm_13> , <otherscientificterm_8> and clusters of open class words . we develop <method_6> and convert <method_0> into <method_4> for an efficient usage during <task_17> . a detailed <method_14> reveals the strengths and weaknesses of the different <method_9> . when we interpolate the <method_4> linearly , we reduce the <metric_16> by 15.6 % relative on the <otherscientificterm_5> . this is even slightly better than the result of the <method_2> . we also combine the <method_9> during <task_17> and obtain a <metric_3> of 4.4 % relative on the <otherscientificterm_5> .	11 18 28 19 -1 12 15 1 7 23 27 19 -1 10 13 8 20 24 19 -1 6 0 4 17 21 25 19 -1 14 9 26 19 -1 16 5 19 -1 19 -1 2 22 19 -1
A Color-based Particle Filter for Joint Detection and Tracking of Multiple Objects .	hybrid valued sequential state estimation algorithm ; external target detection algorithm ; particle filter-based solution ; real-world video sequences ; color particle filter ; tracking deformable objects ; observation feature ; image sequences ; complex backgrounds ; color description ; track initialization ; particle filter ; color	<method> <method> <method> <material> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm>	10 0 11 ; 12 0 11 ; 11 0 5 ; 2 0 4 ; 6 0 11 ; 8 2 7 ; 3 5 0	recent works have shown that the <method_11> using <otherscientificterm_12> as <otherscientificterm_6> is a powerful technique for <task_5> in <material_7> with <otherscientificterm_8> . this paper presents a <method_0> , and its <method_2> , that extends the standard <method_4> in two ways . firstly , <task_10> is embedded in the <method_11> without relying on an <method_1> . secondly , the <method_0> is able to track multiple objects sharing the same <otherscientificterm_9> . we evaluate the performance of the proposed <method_0> on various <material_3> with appearing and disappearing targets .	11 12 6 5 7 8 15 16 18 19 13 -1 0 2 4 17 13 -1 10 1 14 13 -1 9 13 -1 3 20 13 -1
A constrained optimal data association for multiple target tracking .	heuris-tic adjustments of the parameters ; multiple target tracking ; false alarm errors ; map estimation method ; optimal data association ; adaptive mechanism ; natural constraints ; energy function ; parameter updation ; missed detection ; position errors ; clutter environment ; noisy measurements ; nnf ; pda	<otherscientificterm> <task> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	3 0 4 ; 7 0 3 ; 14 1 13 ; 5 0 8 ; 9 1 2	one of the major problems in <task_1> is to obtain an accurate association between targets and <otherscientificterm_12> . we introduce a new scheme , called constrained optimal data association -lrb- coda -rrb- , that finds the <task_4> by a <method_3> and uses a new <method_7> . in this scheme , the <otherscientificterm_6> between targets and measurements are defined so that <otherscientificterm_6> may contain <otherscientificterm_9> and <otherscientificterm_2> . most current algorithms involve many <otherscientificterm_0> . instead , this paper suggests an <method_5> for such <task_8> . in this manner , the system automatically adapts to the <otherscientificterm_11> as it continuously changes in time and space , resulting in better association . experimental results , using <method_14> , <method_13> , and coda , show that the new approach reduces <otherscientificterm_10> in crossing trajecto-ries by 13.9 % on average compared to <method_13> .	1 12 15 -1 4 3 7 16 17 15 -1 6 9 2 20 15 -1 0 15 -1 5 8 19 15 -1 11 15 -1 18 15 -1
Unit fusion for concatenative speech synthesis .	sinusoidal + all-pole analysis of speech ; spectral trajectories of the concatenation units ; inventory of diphones ; modified speech units ; sonorant speech units ; initial spectral trajectories ; fusion units ; dynamic constraints ; residual-excited lpc ; concatenative synthesis ; synthesis algorithm ; concatenated units ; concatenation mismatch ; fusion units ; con-catenation units ; spectral information ; concatenation artifacts ; spectral discontinuities	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 3 ; 1 0 7 ; 7 0 14 ; 0 0 10	an important problem in <task_9> is the occurence of <otherscientificterm_17> or '' <task_12> '' between <otherscientificterm_4> . in this paper , we present an approach to reduce <task_12> by combining <otherscientificterm_15> from two sequences of speech units selected in parallel . <method_14> , on one hand , define <otherscientificterm_5> for a target utterance . <method_6> , on the other hand , define the desired transitions between <otherscientificterm_11> . the two <method_14> are '' fused '' by imposing <otherscientificterm_7> defined by the <otherscientificterm_13> on the <otherscientificterm_1> . to regenerate the <otherscientificterm_3> , we use a <method_10> based on <material_0> , which overcomes the limitations of <method_8> . results from a perceptual test show that our method is highly successful at removing <otherscientificterm_16> in speech generated from an <otherscientificterm_2> .	9 17 12 4 18 -1 15 14 18 -1 5 6 18 -1 11 18 -1 7 13 1 20 21 18 -1 3 10 0 19 22 18 -1 8 18 -1
Unsupervised speaker diarization using riemannian manifold clustering .	rieman-nian locally linear embedding algorithm ; nist 2010 speaker recognition evaluation set ; riemannian property of gaussian pdfs ; robust un-supervised speaker diarization ; riemannian manifold clustering problem ; speaker-homogeneous segment ; single-gaussian modeling ; speaker clustering ; der	<method> <material> <method> <task> <task> <method> <method> <task> <metric>	7 0 3	we address the problem of <task_7> for <task_3> . we model each <method_5> as one single full multivariate gaussian probability density function -lrb- pdf -rrb- and take into consideration the <method_2> . by assuming that segments from different speakers lie on different -lrb- possibly intersected -rrb- sub-manifolds of the manifold of gaussian pdfs , we formulate the original problem as a <task_4> . to apply the computationally simple <method_0> , we impose a constraint on the length of each segment so as to ensure the fitness of <method_6> and to increase the chance that all k-nearest neighbors of a pdf are from the same sub-manifold -lrb- speaker -rrb- . experiments on the microphone-recorded conversational interviews from <material_1> demonstrate promising results of less than 1 % <metric_8> .	7 3 10 9 -1 5 2 9 -1 4 9 -1 0 6 9 -1 9 -1
Variational Inference for Stick-Breaking Beta Process Priors .	variational bayesian inference algorithm ; matrix factorization problems ; non-negative factorization model ; truncated beta process ; variational inference ; linear-gaussian model ; beta process ; infinite counterpart	<method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm>	2 1 5 ; 0 0 6	we present a <method_0> for the stick-breaking construction of the <task_6> . we derive an alternate representation of the <task_6> that is amenable to <otherscientificterm_4> , and present a bound relating the <otherscientificterm_3> to its <otherscientificterm_7> . we assess performance on two <task_1> , using a <method_2> and a <method_5> .	0 6 10 8 -1 4 3 7 8 -1 1 2 5 9 8 -1
Music algorithm to localize sources with unknown directivity in acoustic imaging .	multiple signal classification algorithm ; pure monopolar , dipolar and quadrupolar sources ; fixed functional form ; arbitrary directional characteristics ; undirectional radiation pattern ; acoustic imaging ; hamiltonian matrix ; mathematical problem	<method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task>	0 0 5	the <method_0> for <task_5> most commonly assumes that all sources have <otherscientificterm_4> . we here propose a modification of this <method_0> such that the concept is applicable for <otherscientificterm_3> of the sources . this is accomplished by fitting for each frequency the real valued amplitudes of the <task_5> rather than assuming a <otherscientificterm_2> . the <task_7> can be solved analytically resulting in an eigenvalue problem of a real valued <otherscientificterm_6> . the performance is illustrated in simulations using <material_1> .	0 5 4 9 8 -1 3 8 -1 2 8 -1 7 6 8 -1 1 8 -1
On the Convergence of Stochastic Gradient MCMC Algorithms with High-Order Integrators .	stochastic gradient mcmc algorithms ; stochas-tic gradient langevin dynamics ; stochastic gradient hamiltonian mcmc ; mean square error ; synthetic and real datasets ; 2nd-order symmetric splitting integrator ; 1st-order euler integrators ; stochastic gradient thermostat ; 1st-order euler integrator ; finite-time convergence properties ; asymptotic invariant measures ; high-order integrators ; higher-order integrators ; convergence rates ; bayesian learning ; posterior average ; large-scale data ; convergence rate ; fixed-step-size counterparts ; invariant measures	<method> <method> <method> <metric> <material> <method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <metric> <task> <otherscientificterm> <material> <metric> <otherscientificterm> <metric>	16 0 14 ; 0 1 1 ; 9 1 10 ; 2 1 7 ; 19 0 0 ; 16 0 0 ; 1 1 2 ; 8 0 9 ; 1 6 0	recent advances in <task_14> with <material_16> have witnessed emergence of <method_0> , such as <method_1> , <method_2> , and the <method_7> . while <otherscientificterm_9> of the <method_1> with a <method_8> have recently been studied , corresponding theory for general <method_0> has not been explored . in this paper we consider general <method_0> with <method_11> , and develop theory to analyze <otherscientificterm_9> and their <method_10> . our theoretical results show faster <metric_13> and more accurate <metric_19> for <method_0> with <method_12> . for example , with the proposed efficient <method_5> , the <metric_3> of the <otherscientificterm_15> for the <method_0> achieves an optimal <metric_17> of l ‚àí 4/5 at l iterations , compared to l ‚àí 2/3 for the <method_0> and <method_1> with <method_6> . furthermore , convergence results of <method_0> are also developed , with the same <metric_13> as their <otherscientificterm_18> for a specific decreasing sequence . experiments on both <material_4> verify our theory , and show advantages of the proposed method in two large-scale real applications .	14 16 0 1 2 7 21 24 26 27 29 20 -1 9 8 28 20 -1 11 10 23 20 -1 13 19 12 25 20 -1 5 3 15 22 20 -1 17 6 20 -1 18 20 -1
Flexible Guidance Generation Using User Model in Spoken Dialogue Systems .	kyoto city bus information system ; real dialogue data ; spoken dialogue systems ; user 's knowledge ; decision tree learning ; classification accuracy ; cooperative responses ; user modeling ; dialogue strategies ; dialogue duration	<method> <material> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <method> <method> <otherscientificterm>	7 3 2 ; 7 0 6 ; 4 0 7 ; 7 0 8 ; 1 0 4 ; 8 0 0	we address appropriate <method_7> in order to generate <otherscientificterm_6> to each user in <method_2> . unlike previous studies that focus on <otherscientificterm_3> or typical kinds of users , the <method_7> we propose is more comprehensive . specifically , we set up three dimensions of <method_7> : skill level to the system , knowledge level on the target domain and the degree of hastiness . moreover , the <method_7> are automatically derived by <method_4> using <material_1> collected by the system . we obtained reasonable <metric_5> for all dimensions . <method_8> based on the <method_7> are implemented in <method_0> that has been developed at our laboratory . experimental evaluation shows that the <otherscientificterm_6> adaptive to individual users serve as good guidance for novice users without increasing the <otherscientificterm_9> for skilled users .	7 6 2 11 12 10 -1 3 10 -1 10 -1 4 1 13 15 10 -1 5 8 10 -1 0 14 16 10 -1 10 -1
Two-Sided Exponential Concentration Bounds for Bayes Error Rate and Shannon Entropy .	unknown probability distributions ; bayes error rate ; shannon entropy approximation ; unbounded variables ; continuous variables ; shannon entropy ; bayesian networks ; clas-sifier	<otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method>	1 1 5	we provide a method that approximates the <metric_1> and the <method_5> with high probability . the <metric_1> approximation makes possible to build a <method_7> that polynomially approaches <metric_1> . the <method_2> provides provable performance guarantees for learning trees and <method_6> from <otherscientificterm_4> . our results rely on some reasonable regularity conditions of the <otherscientificterm_0> , and apply to bounded as well as <otherscientificterm_3> .	1 5 9 8 -1 7 8 -1 2 6 4 8 -1 0 3 8 -1
Using cross-decoder co-occurrences of phone n-grams in SVM-based phonotactic language recognition .	cross-decoder co-occurrences of phone n-grams ; cross-decoder co-occurrences of phones ; nist lre2007 database ; phonotactic language recognition ; baseline phonotactic recognizers ; time alignment ; phone n-grams ; frame level ; fused system ; phone decoders ; language modeling ; cross-decoder dependencies ; co-occurrence statistics ; decodings ; eer	<method> <otherscientificterm> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <metric>	8 4 4 ; 14 5 8 ; 14 5 4 ; 11 0 10 ; 12 0 4	most common approaches to <task_3> deal with several independent <method_9> . <method_13> are processed and scored in a fully uncoupled way , their <otherscientificterm_5> -lrb- and the information that may be extracted from it -rrb- being completely lost . recently , we have presented a new approach to <task_3> which takes into account <otherscientificterm_5> information , by considering <otherscientificterm_1> or <otherscientificterm_6> at the <otherscientificterm_7> . experiments on the <material_2> demonstrated that using <otherscientificterm_12> could improve the performance of <method_4> . in this work , the approach based on <method_0> is further developed and evaluated . systems were built by means of open software -lrb- brno university of technology phone de-coders , liblinear and focal -rrb- and experiments were carried out on the <material_2> . a system based on co-occurrences of <otherscientificterm_6> -lrb- up to 4-grams -rrb- outperformed the <method_4> , yielding around 8 % relative improvement in terms of <metric_14> . the best <method_8> attained 1,90 % <metric_14> -lrb- a 16 % improvement with regard to the <method_4> -rrb- , which supports the use of <otherscientificterm_11> for improved <task_10> .	3 9 13 15 -1 5 15 -1 1 6 7 15 -1 2 12 4 20 15 -1 0 15 -1 15 -1 18 15 -1 14 16 17 19 15 -1
Improving the suitability of imperfect transcriptions for information retrieval from spoken documents .	speech recognition engines ; word error probability ; word transcription error ; retrieval effectiveness ; multimedia databases ; hypothesized texts ; multimedia indexing ; transcriber error ; spoken documents ; reference texts ; information retrieval ; word graphs ; speech	<method> <otherscientificterm> <otherscientificterm> <metric> <material> <material> <task> <otherscientificterm> <material> <material> <task> <otherscientificterm> <material>	11 0 0 ; 12 0 6 ; 9 1 5 ; 10 0 4 ; 8 0 10	recently there has been a considerable focus on <task_10> for <material_4> . when <material_12> is used as the source material for <task_6> , the effect of <otherscientificterm_7> on <metric_3> must be considered . this paper describes a method for measuring the relevance of documents to queries when information about the probability of <otherscientificterm_2> is available . to support the use of this technique , a method is presented for estimating <otherscientificterm_1> in <method_0> that use <otherscientificterm_11> -lrb- lattices -rrb- . an <task_10> experiment using this technique on a large corpus of <material_8> is discussed . the method was able to reduce the difference in <metric_3> between <material_9> and <material_5> by 13 % -38 % depending on the size of the document set .	10 4 17 13 -1 12 6 7 3 15 13 -1 2 13 -1 1 0 11 14 13 -1 8 18 13 -1 16 13 -1
Polarization and Phase-Shifting for 3D Scanning of Translucent Objects .	structured light 3d scanning techniques ; polarization direction of the illumination ; optical 3d scanning techniques ; scanning real-world translucent objects ; polarization direction of light ; descattering methods ; descattered reflectance ; 3d coordinates ; polarization-difference imaging ; descattering technique ; subsurface scattering ; subsurface scattering ; range estimation ; surface reflectance ; translucent objects ; translucent objects ; structured light ; signal-to-noise ratio ; phase-shifting	<method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	13 0 1 ; 2 0 6 ; 18 0 3 ; 10 0 12 ; 6 0 7 ; 2 0 7 ; 16 6 2 ; 5 0 7 ; 7 0 15	translucent objects pose a difficult problem for traditional <method_0> . <task_10> corrupts the <task_12> in two ways : by drastically reducing the <otherscientificterm_17> and by shifting the intensity peak beneath the surface to a point which does not coincide with the point of incidence . in this paper we analyze and compare two <method_5> in order to obtain reliable <otherscientificterm_7> for <otherscientificterm_15> . by using <method_8> , <method_11> can be filtered out because multiple scattering ran-domizes the <otherscientificterm_4> while the <otherscientificterm_13> partially keeps the <otherscientificterm_1> . the <otherscientificterm_6> can be used for reliable <otherscientificterm_7> using traditional <method_2> , such as <otherscientificterm_16> . <method_18> is another effective <method_9> if the frequency of the projected pattern is sufficiently high . we demonstrate the performance of these two techniques and the combination of <method_18> on <task_3> .	0 10 19 -1 12 17 23 19 -1 5 7 15 27 28 19 -1 8 11 4 13 1 20 19 -1 6 2 21 24 25 26 19 -1 16 18 19 -1 9 22 19 -1
Discriminative template learning in group-convolutional networks for invariant speech representations .	perturbations of the vocal tract length ; invariant sensory signal representations ; wall street journal datasets ; filter weight sharing ; densely connected layers ; convolutional neural networks ; theoretical invariance guarantees ; discriminative template selection ; locally compact groups ; max pooling ; discrimina-tive approach ; deep network ; speech variability ; frame classification ; convolution-pooling layers ; speech sounds ; local translations ; convolutional networks ; frequency transpositions ; template signals ; data-specific templates ; group-generalized convolutions ; signature ; dnns ; templates ; translation-cnns	<otherscientificterm> <task> <material> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	21 3 17 ; 11 0 20 ; 3 2 5 ; 17 0 20 ; 22 0 15 ; 7 1 25 ; 3 1 9 ; 25 1 23 ; 6 1 25 ; 21 1 7 ; 4 2 11 ; 18 1 0 ; 6 1 7 ; 14 1 4 ; 14 2 11 ; 21 1 6	in the framework of a theory for <task_1> , a <otherscientificterm_22> which is invariant and selective for <material_15> can be obtained through projections in <material_19> and pooling over their transformations under a group . for <otherscientificterm_8> , e.g. , translations , the theory explains the resilience of <method_5> with <method_3> and <method_9> across their <otherscientificterm_16> in frequency or time . in this paper we propose a <method_10> for learning an optimum set of <otherscientificterm_24> , under a family of transformations , namely <otherscientificterm_18> and <otherscientificterm_0> , which are among the primary sources of <otherscientificterm_12> . implicitly , we generalize <method_17> to transformations other than translations , and derive <otherscientificterm_20> by training a <method_11> with <otherscientificterm_14> and <otherscientificterm_4> . we demonstrate that such a <method_17> , combining <otherscientificterm_21> , <otherscientificterm_6> and <method_7> , improves <task_13> performance over standard <method_25> and <method_23> on timit and <material_2> .	1 22 15 19 31 26 -1 8 5 3 9 16 29 33 26 -1 10 24 18 0 12 38 26 -1 17 28 30 37 40 41 26 -1 20 11 14 4 27 32 34 35 36 39 42 26 -1
Noise estimation for efficient speech enhancement and robust speech recognition .	distributed speech recognition ; minima tracking based noise estimation algorithms ; aurora 2 evaluation databases ; noise suppression algorithm ; speech recognition system ; noise estimation techniques ; estimated noise ; algorithmic delay	<task> <method> <material> <method> <method> <method> <otherscientificterm> <otherscientificterm>	3 0 4 ; 2 5 3	different approaches of <method_1> are compared and modifications increasing their efficiency are proposed . <otherscientificterm_6> is used by <method_3> that is a part of <method_4> . moreover , the <method_3> are developed to be applied in feature extraction of <task_0> . therefore we propose such modifications to the <method_5> that are quickly adaptable on varying noise and do not need so much information from past segments . we also minimized the <otherscientificterm_7> . the robustness of proposed <method_3> were tested under several noisy conditions on five speech-dat car -lrb- sdc -rrb- and <material_2> .	1 6 8 -1 3 4 9 8 -1 0 8 -1 5 8 -1 7 8 -1 2 10 8 -1
Perception of disfluency : language differences and listener bias .	non-recognition of the acoustic material ; crosslinguistic disfluency perception experiment ; recognizability of pause fillers ; phonetic crosslinguistic cues ; german accuracy rates ; fluent utterances ; pause fillers ; partial words ; accuracy rates ; dis-fluent speech ; conservative bias ; english ; german ; mandarin	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <metric> <material> <otherscientificterm> <otherscientificterm> <metric> <material> <otherscientificterm> <material> <material> <material>	12 1 13 ; 11 1 12 ; 2 1 7 ; 6 4 7	this paper describes a <otherscientificterm_1> . we tested the <task_2> and <otherscientificterm_7> in <material_11> , <material_12> and <material_13> . subjects were speakers of <material_11> with no knowledge of <material_13> or ger-man . we found that subjects could identify disfluent from <material_5> at a level above chance . <otherscientificterm_6> were easier to identify than <otherscientificterm_7> . <metric_8> were highest for <material_11> , followed by <material_12> and then <material_13> . although <metric_4> were higher than those for <material_13> , discriminability analysis suggests that this is due to <otherscientificterm_10> towards false negatives rather than <otherscientificterm_0> . the fact that subjects could identify <material_9> in languages they did not know shows that there are real <otherscientificterm_3> to disfluency .	1 14 -1 2 7 11 12 13 15 16 17 14 -1 14 -1 5 6 14 -1 8 18 14 -1 14 -1 4 10 0 14 -1 9 14 -1
LOCUS : Learning Object Classes with Unsupervised Segmentation .	locus -lrb- learning object classes ; bottom-up cues of color ; top-down cues of shape ; unsupervised segmentation -rrb- ; object class models ; generative probabilistic model ; object class model ; unsupervised object discovery ; object appearance ; supervised methods ; unannotated images ; object segmentations ; within-class variation ; unlabeled images ; object classes ; segmentation accuracies ; simultaneous recognition ; size ; segmentation ; edge	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <task> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 11 ; 4 1 11 ; 5 0 0 ; 13 0 6 ; 17 1 18 ; 7 6 14 ; 0 0 6	we address the problem of learning <method_4> and <otherscientificterm_11> from <material_10> . we introduce <method_0> with <method_3> which uses a <method_5> to combine <otherscientificterm_1> and <otherscientificterm_19> with <otherscientificterm_2> and pose . a key aspect of this <method_5> is that the <otherscientificterm_8> is allowed to vary from image to image , allowing for significant <otherscientificterm_12> . by iteratively updating the belief in the object 's position , <otherscientificterm_17> , <otherscientificterm_18> and pose , <method_0> avoids making hard decisions about any of these quantities and so allows for each to be refined at any stage . we show that <method_0> successfully learns an <method_6> from <material_13> , whilst also giving <method_15> that rival existing <method_9> . finally , we demonstrate <task_16> and <otherscientificterm_18> in novel images using the learned models for a number of <otherscientificterm_14> , as well as <task_7> and tracking in video .	4 11 10 21 22 20 -1 0 3 5 1 19 2 23 20 -1 8 12 20 -1 17 18 25 20 -1 24 27 20 -1 6 13 15 9 26 20 -1
A fixed dimension and perceptually based dynamic sinusoidal model of speech .	fixed-and low-dimensional , perceptually based dynamic sinusoidal model ; pdm -lrb- perceptual dynamic model -rrb- ; maximum spectral amplitude ; modulated noise component ; dynamic sinusoidal component ; sinusoidal components ; listening test ; sinusoidal model ; sinu-soids	<method> <method> <otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm>	5 0 7	this paper presents a <method_0> of speech referred to as <method_1> . to decrease and fix the number of <method_5> typically used in the standard <method_7> , we propose to use only one <method_4> per critical band . for each band , the si-nusoid with the <otherscientificterm_2> is selected and associated with the centre frequency of that critical band . the model is expanded at low frequencies by incorporating <otherscientificterm_8> at the boundaries of the corresponding bands while at the higher frequencies a <method_3> is used . a <method_6> is conducted to compare speech reconstructed with <method_1> and state-of-the-art models of speech , where all models are constrained to use an equal number of parameters . the results show that <method_1> is clearly preferred in terms of quality over the other systems .	0 1 9 -1 5 7 4 10 9 -1 2 9 -1 8 3 9 -1 6 9 -1 9 -1
A comparison of supervised and unsupervised cross-lingual speaker adaptation approaches for HMM-based speech synthesis .	objective and subjective evaluations ; unsupervised and cross-lingual cases ; unsupervised cross-lingual speaker adaptation ; phoneme error rate ; hmm state mapping ; decision tree marginalization ; speaker adaptation systems ; personalized speech-to-speech translator ; emime scenario ; spoken input ; spoken output ; spectrum adaptation ; supervised case	<otherscientificterm> <otherscientificterm> <task> <metric> <method> <task> <method> <method> <otherscientificterm> <material> <material> <task> <task>	12 0 8 ; 2 4 12 ; 11 3 8 ; 0 5 6 ; 5 1 4 ; 9 0 10	the emime project aims to build a <method_7> , such that <material_9> of a user in one language is used to produce <material_10> that still sounds like the user 's voice however in another language . this distinctiveness makes <task_2> one key to the project 's success . so far , research has been conducted into <otherscientificterm_1> separately by means of <task_5> and <method_4> respectively . in this paper we combine the two techniques to perform <task_2> . the performance of eight <method_6> -lrb- supervised vs. unsupervised , intra-lingual vs. cross-lingual -rrb- is compared using <otherscientificterm_0> . experimental results show the performance of <task_2> is comparable to that of the <task_12> in terms of <task_11> in the <otherscientificterm_8> , even though automatically obtained transcriptions have a very high <metric_3> .	7 9 10 19 13 -1 2 13 -1 1 5 4 18 13 -1 13 -1 6 0 17 13 -1 14 15 16 13 -1
Competence Driven Case-Base Mining .	smyth and keane 's case-deletion policy ; nonlin-ear transformation of the data set ; high-quality case base ; statistical distribution ; case-based reasoning ; case-base sizes ; data sets ; case base ; raw data ; case-base competence ; deletion-based algorithm ; features	<method> <otherscientificterm> <material> <method> <method> <otherscientificterm> <material> <material> <material> <otherscientificterm> <method> <otherscientificterm>	3 0 7	we present a novel algorithm for extracting a <material_2> from <material_8> while preserving and sometimes improving the competence of <method_4> . we extend the framework of <method_0> with two additional <otherscientificterm_11> . first , we build a <material_7> using a <method_3> that is mined from the input data so that the <otherscientificterm_9> can be preserved or even increased for future problems . second , we introduce a <otherscientificterm_1> so that the <otherscientificterm_5> can be further reduced while ensuring that the competence be preserved and even increased . we show that smyth and keane 's <method_10> is sensitive to noisy cases , and that our <method_10> solves this problem more satisfactorily . we show the theoretical foundation and empirical evaluation on several <material_6> .	2 8 4 12 -1 0 11 12 -1 7 3 9 13 12 -1 1 5 12 -1 10 12 -1 12 -1
What Do You Do ? Occupation Recognition in a Photo via Social Context .	well-labeled occupation database ; spatial configuration model ; computer vision ; structure svm ; representative occupations ; arbitrary poses ; occupation recognition ; co-occurrence	<material> <method> <task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	7 1 1 ; 4 2 0 ; 6 0 2	in this paper , we investigate the problem of recognizing occupations of multiple people with <otherscientificterm_5> in a photo . previous work utilizing single person 's nearly frontal clothing information and fore/background context preliminarily proves that <task_6> is com-putationally feasible in <task_2> . however , in practice , multiple people with <otherscientificterm_5> are common in a photo , and recognizing their occupations is even more challenging . we argue that with appropriately built visual attributes , <otherscientificterm_7> , and <method_1> that is learned through <method_3> , we can recognize multiple people 's occupations in a photo simultaneously . to evaluate our method 's performance , we conduct extensive experiments on a new <material_0> with 14 <otherscientificterm_4> and over 7k images . results on this database validate our method 's effectiveness and show that <task_6> is solv-able in a more general case .	5 8 -1 6 2 11 8 -1 8 -1 7 1 3 9 8 -1 10 8 -1 0 4 8 -1
The Use of Dynamic Writing Information in a Connectionist On-Line Cursive Handwriting Recognition System .	multi-state time delay neural network ; curvature or writing direction ; npen + + ; word recognition rates ; neural network architecture ; dynamic writing information ; robust input representation ; language models ; temporal sequences ; local features ; vocabulary sizes ; coordinate sequence ; ms-tdnn architecture ; connectionist system ; preprocessing ; segmen-tation ; rec.ognition	<method> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm>	2 6 13 ; 11 3 14 ; 0 6 4 ; 12 0 8 ; 6 0 5 ; 4 3 2 ; 2 0 5	in this paper we present <method_2> , a <method_13> for writer independent , large vocabulary on-line cursive handwriting recognition . this <method_2> combines a <method_6> , which preserves the <otherscientificterm_5> , with a <method_4> , a so called <method_0> , which integrates <otherscientificterm_16> and <otherscientificterm_15> in a single framework . our <method_14> transforms the original <otherscientificterm_11> into a -lrb- still temporal -rrb- sequence offea-ture vectors , which combine strictly <otherscientificterm_9> , like <otherscientificterm_1> , with a bitmap-like representation of the co-ordinate 's proximity . the <method_12> is well suited for handling <material_8> as provided by this <method_6> . our <method_2> is tested both on writer dependent and writer independent tasks with <otherscientificterm_10> ranging from 400 up to 20,000 words . for example , on a 20,000 word vocabulary we achieve <metric_3> up to 88.9 % -lrb- writer dependent -rrb- and 84.1 % -lrb- writer independent -rrb- without using any <method_7> .	2 13 18 17 -1 6 5 4 0 16 15 20 22 23 24 17 -1 14 11 9 1 19 17 -1 12 8 21 17 -1 17 -1 10 17 -1
Lexical embedding in spoken dutch .	corpora of spoken dutch ; polysyllabic word tokens ; dictionary of dutch ; monosyllabic word tokens ; speech processing ; temporary ambiguity ; word-initial embedding ; lexical embedding	<material> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 2 1	a stretch of speech is often consistent with multiple words , e.g. , the sequence / haem / is consistent with ` ham ' but also with the first syllable of ` hamster ' , resulting in <otherscientificterm_5> . however , to what degree does this <otherscientificterm_7> occur ? analyses on two <material_0> showed that 11.9 % -19.5 % of <otherscientificterm_1> have <otherscientificterm_6> , while 4.1 % -7.5 % of <otherscientificterm_3> can appear word-initially embedded . this is much lower than suggested by an analysis of a large <material_2> . <task_4> thus appears to be simpler than one might expect on the basis of statistics on a dictionary .	5 8 -1 7 0 1 6 3 8 -1 2 4 9 8 -1 8 -1 8 -1
Decoding of Neuronal Signals in Visual Pattern Recognition .	inferior temporal cortex ; spatial patterns of the stimuli ; pattern matching task ; temporally encoded information ; measured neuronal signal ; neuronal response waveforms ; back-propagation networks ; behavioral context ; stimulus conditions	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	6 0 5	we have investigated the properties of neurons in <otherscientificterm_0> in monkeys performing a <task_2> . simple <method_6> were trained to discriminate the various <otherscientificterm_8> on the basis of the <otherscientificterm_4> . we also trained <method_6> to predict the <otherscientificterm_5> from the <otherscientificterm_1> . the results indicate t.hat it neurons convey <otherscientificterm_3> about both current and remembered patterns , as well as about their <otherscientificterm_7> .	0 2 9 -1 6 8 4 9 -1 5 1 10 9 -1 3 7 9 -1
A Simple Additive Re-weighting Strategy for Improving Margins .	state of the art algorithms ; vector quantization algorithm ; tangent distance models ; sample re-weighting scheme ; tangent models ; margin theory ; input distribution ; generalization power ; 1-nn classifier ; svm	<method> <method> <method> <method> <method> <method> <otherscientificterm> <metric> <method> <method>	1 0 8 ; 1 0 2	we present a <method_3> inspired by recent results in <method_5> . the basic idea is to add to the training set replicas of samples which are not classified with a sufficient margin . we prove the convergence of the <otherscientificterm_6> obtained in this way . as study case , we consider an instance of the <method_3> involving a <method_8> implementing a <method_1> that accommodates <method_2> . the <method_2> created in this way have shown a significant improvement in <metric_7> with respect to the standard <method_4> . moreover , the obtained models were able to outperform <method_0> , such as <method_9> .	3 5 10 -1 10 -1 6 10 -1 8 1 2 11 12 10 -1 7 4 10 -1 0 9 10 -1
Optimizing bottle-neck features for lvcsr .	phoneme mlp training targets ; english conversational telephone speech ; neural net input representations ; arabic broadcast news ; probabilistic mlp features ; mlp training targets ; arbitrary feature size ; bottleneck feature extraction ; bottleneck features ; mlp topology ; lvcsr tasks ; dimensionality reduction ; delta features ; optimized features ; english meetings ; cepstral features ; five-layers mlp ; asr	<task> <material> <method> <material> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <task>	14 6 10 ; 1 1 14 ; 1 6 10 ; 16 0 7 ; 4 0 2 ; 3 1 1 ; 3 6 10 ; 15 1 4 ; 8 0 17	this work continues in development of the recently proposed <method_8> for <task_17> . a <method_16> used in <task_7> allows to obtain <otherscientificterm_6> without <otherscientificterm_11> by transforms , independently on the <otherscientificterm_5> . the <otherscientificterm_9> -- number and sizes of layers , suitable training targets , the impact of output feature transforms , the need of <otherscientificterm_12> , and the dimensionality of the final feature vector are studied with respect to the best <task_17> result . <otherscientificterm_13> are employed in three <task_10> : <material_3> , <material_1> and <material_14> . improvements over standard <otherscientificterm_15> and <method_4> are shown for different tasks and different <method_2> . a significant improvement is observed when <task_0> are replaced by phoneme states and when <otherscientificterm_12> are added .	8 17 27 18 -1 16 7 6 11 5 22 18 -1 9 12 13 18 -1 10 3 1 14 19 20 21 24 25 18 -1 15 4 23 26 18 -1 2 18 -1
Multi-channel high resolution blind image restoration .	mutually referen-ced equalizers algorithm ; blind multi-input multi-output deconvolution ; artificial and photographics images ; blind source separation algorithms ; mixed polyphase components ; digital communications ; polyphase components ; unknown response ; fir filters ; blind equalization ; bandlimited signal ; fir channels ; undersampled measurements	<method> <method> <material> <method> <method> <task> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <material>	7 2 12 ; 0 0 9 ; 6 3 10 ; 4 3 10 ; 5 0 9 ; 7 2 11	we address the reconstruction problem of a high resolution image from its <material_12> accross multiple <otherscientificterm_11> with <otherscientificterm_7> . our method consists of two stages : <method_1> using <method_8> and blind separation of <method_4> . the proposed deconvolution method is based on the <method_0> previously developed for <task_9> in <task_5> . for sources separation , a method is proposed for separating <method_4> of a <otherscientificterm_10> . the existing <method_3> assume that the source signals are either independent or uncorrelated , which is not the case when the sources are <method_6> of a <otherscientificterm_10> . simulation results on <material_2> are given .	12 11 7 14 19 13 -1 1 8 4 13 -1 0 9 5 15 18 13 -1 10 17 13 -1 3 6 16 13 -1 2 13 -1
Stop-probability estimates computed on a large corpus improve Unsupervised Dependency Parsing .	average attachment score ; unsupervised dependency parsers ; dependency model ; reducibility principle ; stop-probabilities ; valence	<metric> <method> <method> <method> <method> <method>	0 5 2 ; 0 5 5	even though the quality of <method_1> grows , <method_1> often fail in recognition of very basic dependencies . in this paper , we exploit a prior knowledge of <method_4> -lrb- whether a given word has any children in a given direction -rrb- , which is obtained from a large raw corpus using the <method_3> . by incorporating this knowledge into <method_2> with <method_5> , we managed to considerably outperform the state-of-the-art results in terms of <metric_0> over 20 treebanks from conll 2006 and 2007 shared tasks .	1 6 -1 4 3 6 -1 2 5 0 7 8 6 -1
Generalizing Image Captions for Image-Text Parallel Corpus .	image-text parallel corpus ; visually-guided sentence compression ; dynamic beam search ; image caption generalization ; natural language processing ; image caption transfer ; generalized captions ; computer vision ; image content ; integrative models ; web images ; image-caption pairs ; dependency-based constraints ; extrinsic utility ; intrinsic quality ; complexity ; noise	<material> <task> <method> <task> <task> <task> <otherscientificterm> <task> <material> <method> <material> <otherscientificterm> <otherscientificterm> <metric> <metric> <metric> <otherscientificterm>	9 0 7 ; 9 0 4 ; 11 2 0 ; 4 1 7 ; 15 1 16 ; 1 0 3 ; 12 2 2	the ever growing amount of <material_10> and their associated texts offers new opportunities for <method_9> bridging <task_4> and <task_7> . however , the potential benefits of such data are yet to be fully realized due to the <metric_15> and <otherscientificterm_16> in the alignment between <material_8> and text . we address this challenge with contributions in two folds : first , we introduce the new task of <task_3> , formulated as <task_1> , and present an efficient algorithm based on <method_2> with <otherscientificterm_12> . second , we release a new <material_0> with 1 million <otherscientificterm_11> achieving tighter content alignment between images and text . evaluation results show the <metric_14> of the <otherscientificterm_6> and the <metric_13> of the new <material_0> with respect to a concrete application of <task_5> .	10 9 4 7 18 19 21 17 -1 15 16 8 22 17 -1 3 1 2 12 23 24 17 -1 0 11 20 17 -1 17 -1
Discriminative learning for differing training and test distributions .	kernel logistic regression classifier ; integrated optimization problem ; covariate shift ; test distribution ; classification problems ; distribution ; classification	<method> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task>	1 0 2	we address <task_4> for which the training instances are governed by a <otherscientificterm_5> that is allowed to differ arbitrarily from the <otherscientificterm_3> -- problems also referred to as <task_6> under <otherscientificterm_2> . we derive a solution that is purely discriminative : neither training nor <otherscientificterm_3> are modeled explicitly . we formulate the general problem of learning under <otherscientificterm_2> as an <task_1> . we derive a <method_0> for differing training and test distributions .	4 5 3 6 2 7 -1 7 -1 1 8 7 -1 0 7 -1
Non-intrusive Iris Image Capturing System Using Light Stripe Projection and Pan-Tilt-Zoom Camera .	non-intrusive iris image capturing system ; exact zoom and focus position ; light stripe projection ; user 's position ; 2d face search ; narrow search range ; user 's position ; adaboost-based face detection ; 1d face search ; pan-tilt-zoom camera ; tilt angle ; iris image ; zoom ; panning	<method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method>	8 0 4 ; 0 0 11 ; 3 4 4 ; 7 0 10	this paper proposes <method_0> , which consists of <otherscientificterm_9> and light stripe projection . <task_2> provides the position of user . after <method_13> according to <otherscientificterm_6> , <task_7> finds <otherscientificterm_10> . with <otherscientificterm_6> and <otherscientificterm_10> , <otherscientificterm_12> and focus position are initialized . <otherscientificterm_3> replaces <method_4> with <method_8> . <otherscientificterm_1> enable fast control and <otherscientificterm_5> . consequently , experimental results show that proposed <method_0> can capture <material_11> within acceptable time .	0 9 2 14 -1 14 -1 13 6 7 10 18 14 -1 12 3 14 -1 4 8 1 15 17 14 -1 5 14 -1 11 16 14 -1
Exponentially Decaying Bag-of-Words Input Features for Feed-Forward Neural Network in Statistical Machine Translation .	one-hot encoded input vectors of words ; feed-forward neural network translation models ; neural network translation model ; bidirectional lstm translation model ; phrase-based state-of-the-art system ; neural network models ; statistical machine translation ; decay rates ; translation tasks ; bag-of-words model ; weight parameters ; ter ; bleu	<otherscientificterm> <method> <method> <method> <method> <method> <task> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <metric>	2 5 4 ; 12 1 11 ; 8 5 4 ; 9 0 4 ; 0 0 5 ; 5 0 6	recently , <method_5> have achieved consistent improvements in <task_6> . however , most <method_5> only use <otherscientificterm_0> as their input . in this work , we investigated the exponentially decaying bag-of-words input features for <method_1> and proposed to train the <otherscientificterm_7> along with other <otherscientificterm_10> . this novel <method_9> improved our <method_4> , which already includes a <method_2> , by up to 0.5 % <metric_12> and 0.6 % <metric_11> on three different <task_8> and even achieved a similar performance to the <method_3> .	5 6 19 13 -1 0 18 13 -1 1 7 10 13 -1 9 4 2 12 11 8 3 14 15 16 17 13 -1
Non-Ideal Sampling and Adapted Reconstruction Using the Stochastic Matern Model .	mmse reconstruction of stochastic mat√©rn signals ; generalized , anisotropic version ; lter-based reconstruction method ; riesz basis ; correlation structure ; natural images ; mat√©rn function ; reconstruction space ; multi-integer shifts ; autocorrelation functions ; mat√©rn class ; measured data ; geostatistics	<task> <method> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	3 2 6 ; 9 0 12	the <otherscientificterm_10> is a parametric family of <otherscientificterm_9> that is commonly used in <otherscientificterm_12> . we argue that a <method_1> of this model is suitable for capturing the <otherscientificterm_4> of a variety of <material_5> . we specify the optimal space for the <task_0> from their uniformly-sampled noisy measurements -lrb- generalized sampling problem -rrb- . we prove that the optimal <otherscientificterm_7> is generated by the <otherscientificterm_8> of a <otherscientificterm_6> which form a <otherscientificterm_3> . based on this representation , we propose a practical <method_2> that relies on the prior identi cation of the mat√©rn parameters from the <material_11> . we present experimental results to justify the use of the mat√©rn model and to demonstrate the performance of our <method_2> .	10 9 12 15 13 -1 1 4 5 13 -1 0 13 -1 7 8 6 3 14 13 -1 2 11 13 -1 13 -1
BIG & QUIC : Sparse Inverse Covariance Estimation for a Million Variables .	1-regularized gaussian maximum likelihood estimator ; super-linear or even quadratic convergence rates ; sparse inverse covari-ance matrix ; non-smooth log-determinant program ; block-coordinate descent method ; clustering scheme ; statistical guarantees ; bounded memory ; high-dimensional settings ; gaussian variables ; repeated computations	<method> <metric> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 2 ; 5 0 4	the <method_0> has been shown to have strong <otherscientificterm_6> in recovering a <otherscientificterm_2> even under <otherscientificterm_8> . however , it requires solving a difficult <method_3> with number of parameters scaling quadratically with the number of <otherscientificterm_9> . state-of-the-art methods thus do not scale to problems with more than 20 , 000 variables . in this paper , we develop an algorithm bigquic , which can solve 1 million dimensional 1-regularized gaussian mle problems -lrb- which would thus have 1000 billion parameters -rrb- using a single machine , with <otherscientificterm_7> . in order to do so , we carefully exploit the underlying structure of the problem . our innovations include a novel <method_4> with the blocks chosen via a <method_5> to minimize <otherscientificterm_10> ; and allowing for inexact computation of specific components . in spite of these modifications , we are able to theoretically analyze our <method_4> and show that bigquic can achieve <metric_1> .	0 6 2 8 12 11 -1 3 9 11 -1 11 -1 7 11 -1 11 -1 13 11 -1 4 5 10 11 -1
Better Synchronous Binarization for Machine Translation .	scfg parsing based machine translation systems ; string-to-tree statistical machine translations system ; nist machine translation evaluation tasks ; left-heavy binary scfg ; synchronous bina-rization method ; polynomial time complexity ; binary scfgs ; decoding	<task> <method> <task> <method> <method> <metric> <method> <task>	7 0 0 ; 4 0 2 ; 2 5 1	binarization of synchronous context free grammars -lrb- scfg -rrb- is essential for achieving <metric_5> of <task_7> for <task_0> . in this paper , we first investigate the excess edge competition issue caused by a <method_3> derived with the method of zhang et al. -lrb- 2006 -rrb- . then we propose a new binarization method to mitigate the problem by exploring other alternative equivalent <method_6> . we present an algorithm that iteratively improves the resulting <method_6> , and empirically show that our method can improve a <method_1> based on the <method_4> in zhang et al. -lrb- 2006 -rrb- on the <task_2> .	5 7 0 9 8 -1 3 8 -1 6 8 -1 1 4 2 10 11 8 -1
Finite Sample Convergence Rates of Zero-Order Stochastic Optimization Methods .	stochastic gradient methods ; noisy function values ; information-theoretic lower bounds ; finite-sample convergence rates ; minimax convergence rate ; stochastic optimization problems ; random perturbations ; function values ; convergence rate ; gradient estimates ; problem-dependent quantities ; algorithmic development ; derivative-free algorithms ; gradients	<method> <otherscientificterm> <otherscientificterm> <metric> <metric> <task> <otherscientificterm> <otherscientificterm> <metric> <method> <otherscientificterm> <method> <method> <otherscientificterm>	12 0 5 ; 1 0 12 ; 2 0 11 ; 6 0 9	we consider <method_12> for <task_5> that use only <otherscientificterm_1> rather than <otherscientificterm_13> , analyzing their <metric_3> . we show that if pairs of <otherscientificterm_7> are available , algorithms that use <method_9> based on <otherscientificterm_6> suffer a factor of at most ‚àö d in <metric_8> over traditional <method_0> , where d is the problem dimension . we complement our <method_11> with <otherscientificterm_2> on the <metric_4> of such problems , which show that our bounds are sharp with respect to all <otherscientificterm_10> : they can not be improved by more than constant factors .	12 5 1 13 3 15 16 14 -1 7 9 6 8 0 18 14 -1 11 2 4 10 17 14 -1
Learning Hybrid Representations to Retrieve Semantically Equivalent Questions .	convolutional neural network ; bow based information retrieval methods ; bag-of-words representation ; semantically equivalent question retrieval ; online q&a community sites ; distributed vector representation ; neural network architecture ; long texts ; bow-cnn ; tfidf	<method> <method> <method> <task> <material> <method> <method> <material> <method> <method>	2 1 5 ; 0 0 5 ; 6 0 3 ; 8 4 1	retrieving similar questions in <material_4> is a difficult task because different users may formulate the same question in a variety of ways , using different vocabulary and structure . in this work , we propose a new <method_6> to perform the task of <task_3> . the proposed <method_6> , which we call <method_8> , combines a <method_2> with a <method_5> created by a <method_0> . we perform experiments using data collected from two stack exchange communities . our experimental results evidence that : -lrb- 1 -rrb- <method_8> is more effective than <method_1> such as <method_9> ; -lrb- 2 -rrb- <method_8> is more robust than the pure cnn for <material_7> .	4 10 -1 6 3 13 10 -1 8 2 5 0 11 12 10 -1 10 -1 1 9 14 10 -1
NF-Features - No-Feature-Features for Representing Non-textured Regions .	description of non-textured areas ; regular interest point detectors ; correspondences of regular features ; nf recall rates ; regular feature detection ; local image statistics ; recall rates ; image description ; nf descriptors ; textured regions ; non-textured regions ; regular features ; unchanged precision ; once-detected nf-features ; nf descriptor ; affine transformations ; image perturbation ; description approaches ; precision ; recall ; sift ; nf-features ; points ; blobs ; surf ; illumination	<task> <otherscientificterm> <otherscientificterm> <metric> <task> <material> <metric> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <metric> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	23 6 9 ; 14 0 10 ; 21 0 17 ; 21 0 4 ; 22 1 23 ; 22 6 9 ; 4 1 17	in order to achieve a complete <task_7> , we introduce no-feature-features -lrb- <method_21> -rrb- representing object regions where <otherscientificterm_1> do not detect features . as these regions are usually non-textured , stable re-localization in different images with conventional methods is not possible . therefore , a technique is presented which re-localizes <otherscientificterm_13> using <otherscientificterm_2> . furthermore , a distinctive <otherscientificterm_14> for <otherscientificterm_10> is derived which has invariance towards <otherscientificterm_15> and changes in <otherscientificterm_25> . for the matching of <method_8> , an approach is introduced that is based on <material_5> . <method_21> can be used complementary to all kinds of <task_4> and <method_17> that focus on <otherscientificterm_9> , i.e. <otherscientificterm_22> , <otherscientificterm_23> or contours . using <method_20> , mser , hessian-affine or <method_24> as regular detectors , we demonstrate that our approach is not only suitable for the <task_0> but that <metric_18> and <metric_19> of the <method_21> is significantly superior to those of <otherscientificterm_11> . in experiments with high variation of the perspective or <otherscientificterm_16> , at <metric_12> we achieve <metric_3> which are better by more than a factor of two compared to <metric_6> of <otherscientificterm_11> .	7 21 1 26 -1 26 -1 13 2 26 -1 14 10 15 25 28 26 -1 8 5 26 -1 4 27 29 30 31 32 33 26 -1 17 9 22 23 26 -1 20 24 0 18 19 11 26 -1
Relighting objects from image collections .	distant , unknown illumination ; all-frequency relighting framework ; synthetic test cases ; per-surface point reflectance ; per-image incident illumination ; multi-view stereo reconstruction ; reflection models ; laboratory conditions ; known geometry ; geometry ; images ; illumination	<otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm>	4 1 3	we present an approach for recovering the reflectance of a static scene with <otherscientificterm_8> from a collection of <material_10> taken under <otherscientificterm_0> . in contrast to previous work , we allow the <otherscientificterm_11> to vary between the <material_10> , which greatly increases the applicability of the approach . using an <method_1> based on wavelets , we are able to simultaneously estimate the <otherscientificterm_4> and the <otherscientificterm_3> . the wavelet framework allows for incorporating various <method_6> . we demonstrate the quality of our results for <task_2> as well as for several datasets captured under <otherscientificterm_7> . combined with <method_5> , we are even able to recover the <otherscientificterm_9> and reflectance of a scene solely using <material_10> collected from the internet .	8 10 0 12 -1 11 12 -1 1 4 3 13 12 -1 6 12 -1 2 7 12 -1 5 12 -1
Automated Variational Inference for Gaussian Process Models .	gaus-sian process models ; automated variational method ; model-specific inference algorithms ; mcmc sampling approaches ; univari-ate gaussian distributions ; variational distribution ; gradient-based optimization ; black-box manner ; approximate inference ; gp hyperparameters ; model likelihood ; variational objective ; covariance matrices ; gaussians ; posteriors ; sampling	<method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	12 2 5 ; 1 0 8	we develop an <method_1> for <task_8> in <method_0> whose <otherscientificterm_14> are often intractable . using a mixture of <method_13> as the <otherscientificterm_5> , we show that -lrb- i -rrb- the <otherscientificterm_11> and its gradients can be approximated efficiently via <method_15> from <otherscientificterm_4> and -lrb- ii -rrb- the gradients wrt the <method_9> can be obtained analytically regardless of the <otherscientificterm_10> . we further propose two instances of the <otherscientificterm_5> whose <otherscientificterm_12> can be parametrized linearly in the number of observations . these results allow <method_6> to be done efficiently in a <method_7> . our <method_1> is thoroughly verified on five models using six benchmark datasets , performing as well as the exact or hard-coded implementations while running orders of magnitude faster than the alternative <method_3> . our <method_1> can be a valuable <method_1> for practitioners and researchers to investigate new models with minimal effort in deriving <method_2> .	1 8 0 14 18 16 -1 13 5 11 15 4 9 10 16 -1 12 17 16 -1 6 7 16 -1 16 -1 3 16 -1
Automatically learning speaker-independent acoustic subword units .	unsupervised learning of sub-word acoustic units ; maximum likelihood successive state splitting algorithm ; speaker-dependent and cross-speaker correspondence ; hidden markov model ; viterbi state sequence ; unsupervised adaptation ; mllr ; accuracy ; speech	<task> <method> <otherscientificterm> <method> <material> <method> <method> <metric> <material>	1 0 3 ; 6 0 5 ; 7 5 5	we investigate methods for <task_0> of a language directly from <material_8> . we demonstrate that states of a <method_3> '' grown '' using a novel modification of the <method_1> correspond very well with the phones of the language . in particular , the correspondence between the <material_4> for unseen <material_8> from the training speaker and the phone transcription of the <material_8> is over 85 % , and generalizes to a large extent -lrb- ‚àº 63 % -rrb- to <material_8> from a different speaker . furthermore , we are able to bridge more than half the gap between the <otherscientificterm_2> of the automatically learned units to phones -lrb- ‚àº 75 % <metric_7> -rrb- by <method_5> via <method_6> .	0 8 9 -1 3 1 10 9 -1 4 9 -1 2 11 12 9 -1
Pixel Recurrent Neural Networks .	fast two-dimensional recurrent layers ; deep recurrent networks ; deep neural network ; raw pixel values ; residual connections ; spatial dimensions ; natural images ; architectural novelties ; unsupervised learning ; image model ; log-likelihood scores ; imagenet dataset ; image ; pixels	<otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	4 3 1 ; 2 0 13 ; 0 6 7 ; 4 0 7 ; 0 1 4	modeling the distribution of <material_6> is a landmark problem in <task_8> . this task requires an <method_9> that is at once expressive , tractable and scalable . we present a <method_2> that sequentially predicts the <otherscientificterm_13> in an <otherscientificterm_12> along the two <otherscientificterm_5> . our <method_2> models the discrete probability of the <otherscientificterm_3> and encodes the complete set of dependencies in the <otherscientificterm_12> . <otherscientificterm_7> include <otherscientificterm_0> and an effective use of <otherscientificterm_4> in <method_1> . we achieve <otherscientificterm_10> on <material_6> that are considerably better than the previous state of the art . our main results also provide benchmarks on the diverse <material_11> . samples generated from the <method_2> appear crisp , varied and globally coherent .	6 8 14 -1 9 14 -1 2 13 12 5 16 14 -1 3 7 14 -1 0 4 1 15 17 18 19 14 -1 10 14 -1 14 -1 11 14 -1
Analytical Assessment of Capacity Vs. Robustness Trade-Offs in Systems with Selective Multi-User Diversity .	spatial vs. multiuser diversity tradeoffs ; siso and stbc transmission schemes ; short-term snr fluctuations ; cellular system ; feedback channel ; design trade-offs ; bandwidth restrictions ; transmission schemes ; closed-form expressions ; selective feedback ; robustness ; terminals	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm>	9 3 3 ; 0 3 3	in this paper , we explore <otherscientificterm_0> in a <method_3> with <otherscientificterm_9> . we first derive <otherscientificterm_8> of the average system capacity for both <otherscientificterm_1> in order to analytically assess the impact of the number of <otherscientificterm_11> and <otherscientificterm_6> in the <otherscientificterm_4> . next , we analyze several <otherscientificterm_5> in terms of increased average -lrb- long term -rrb- system capacity vs. <metric_10> to <otherscientificterm_2> for both <method_7> under consideration .	0 3 9 13 14 12 -1 8 1 11 6 4 12 -1 5 10 2 7 12 -1
Context-based error recovery technique for GSM AMR speech codec .	internet and mobile networks ; context-based error recovery technique ; gsm amr speech codec ; recovery of erased frames ; random bit errors ; output speech quality ; segmental itakura-saito measure ; error concealment techniques ; celp-based speech codec ; contextual information ; mos scores ; frame erasures ; erasure spells ; parameter estimation ; codec parameters ; robustness	<method> <method> <method> <task> <otherscientificterm> <metric> <metric> <method> <task> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <metric>	9 0 1 ; 11 1 4 ; 1 0 8 ; 2 0 0 ; 6 1 10 ; 1 0 3	gsm amr speech codec being used for both <method_0> , <metric_15> to both <otherscientificterm_11> and <otherscientificterm_4> assumes significance . this paper proposes a new <method_1> for the <task_8> accomplishing <task_3> , updating decoder state during <otherscientificterm_12> and reliable estimation of <otherscientificterm_14> in case of bit errors . previous <method_7> do not adequately make use of the context in which concealment is being done . the proposed <method_1> is intended to retrieve and use <otherscientificterm_9> for better performance . the <method_1> is solely receiver based , uses no look ahead , makes use of implicitly available <otherscientificterm_14> and buffers for <task_13> and is hence computationally efficient . <metric_6> and <metric_10> are used to compare the <metric_5> of the proposed technique with those of the basic techniques as recommended by the standard .	0 15 11 4 18 20 16 -1 1 8 3 12 14 19 22 16 -1 7 16 -1 9 17 16 -1 13 16 -1 6 21 16 -1
Antenna selection for space time coding over frequency-selective fading channels .	space-time code ; signal-to-noise-ratio ; frequency-selective fading channel -rrb- ; frequency-selective fading channels ; space-time coded systems ; receiver side ; antenna selection	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	6 0 5 ; 5 2 4 ; 1 0 6	in this paper , we deal with <task_6> at the <otherscientificterm_5> for <method_4> over <otherscientificterm_3> . we reveal that introducing <task_6> based on the <method_1> observed can still achieve the full diversity available , if the underlying <otherscientificterm_0> is full-rank -lrb- i.e. , if <otherscientificterm_0> achieves full diversity without <task_6> over the <otherscientificterm_2> . we also argue that if the <otherscientificterm_0> is not full-rank , <task_6> results in a loss in the diversity of the system .	6 5 4 3 8 9 7 -1 1 0 2 10 7 -1 7 -1
Lateen EM : Unsupervised Training with Multiple Objectives , Applied to Dependency Grammar Induction .	expectation max-imization algorithms ; unsu-pervised dependency parsing tasks ; en-glish dependency grammar induction ; lateen em ; switching objectives ; local optima ; training methods ; unsupervised training ; em ; disagreements ; accuracy	<method> <task> <task> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <metric>	6 4 0 ; 6 0 5	we present new <method_6> that aim to mitigate <otherscientificterm_5> and slow convergence in <method_7> by using additional imperfect objectives . in its simplest form , <method_3> alternates between the two objectives of ordinary '' soft '' and '' hard '' <method_0> . <otherscientificterm_4> when stuck can help escape <otherscientificterm_5> . we find that applying a single such alternation already yields state-of-the-art results for <task_2> . more elaborate <method_6> track both objectives , with each validating the moves proposed by the other . <otherscientificterm_9> can signal earlier opportunities to switch or terminate , saving iterations . de-emphasizing fixed points in these ways eliminates some guesswork from tuning <method_8> . an evaluation against a suite of <task_1> , for a variety of languages , showed that <method_6> significantly speed up training of both <method_0> , and improve <metric_10> for <otherscientificterm_5> .	6 5 7 11 -1 3 0 4 11 -1 11 -1 2 11 -1 9 11 -1 11 -1 11 -1 8 12 13 11 -1
Fast Parameter Sensitivity Analysis of PDE-Based Image Processing Methods .	discontinuity-preserving optical flow computation ; fast parameter sensitivity analysis ; pde-based image processing operators ; stochastic finite elements ; image processing operators ; full sensitivity analysis ; parameter sensitivity analysis ; polynomial chaos expansion ; perona-malik diffusion ; ambrosio-tortorelli segmentation ; uncertainty quantification ; sampling strategy	<task> <method> <method> <otherscientificterm> <method> <task> <method> <method> <task> <task> <method> <method>	11 0 1 ; 7 1 3 ; 6 0 8 ; 7 1 2 ; 10 0 1 ; 10 1 4	we present a <method_1> by combining recent developments from <method_10> with <method_4> . the <method_1> is not based on a <method_11> , instead we combine the <method_7> and <otherscientificterm_3> with <method_2> . with our <method_1> and a moderate number of parameters in the models the <task_5> is obtained at the cost of a few monte carlo runs . to demonstrate the efficiency and simplicity of the <method_1> we show a <method_6> for <task_8> , random walker and <task_9> , and <task_0> .	1 10 4 17 18 12 -1 11 7 3 2 13 14 16 12 -1 5 12 -1 6 8 9 0 15 12 -1
Revisiting probabilistic models for clustering with pair-wise constraints .	undesirable local behaviors ; chunklet model ; constraint violation ; probabilistic clustering ; learning technique ; pair-wise constraints ; soft constraints ; misspecified constraints ; robustness	<otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	8 2 7 ; 1 0 6	we revisit recently proposed algorithms for <task_3> with <otherscientificterm_5> between data points . we evaluate and compare existing techniques in terms of <metric_8> to <otherscientificterm_7> . we show that the technique that strictly enforces the given constraints , namely the <method_1> , produces poor results even under a small number of <otherscientificterm_7> . we further show that methods that penalize <otherscientificterm_2> are more robust to <otherscientificterm_7> but have <otherscientificterm_0> . based on this evaluation , we propose a new <method_4> , extending the <method_1> to allow <otherscientificterm_6> represented by an intuitive measure of confidence in the constraint .	3 5 9 -1 8 7 10 9 -1 1 9 -1 2 0 9 -1 4 6 11 9 -1
Impact of an Energy Normalization Transform on the Performance of the LF-ASD Brain Computer Interface .	active and idle eeg data ; lf-asd brain-computer interface ; energy normalization transform ; signal amplitude variability ; class separation ; system errors ; non-normalized accuracy ; lf-asd	<material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <method>	0 0 4	this paper presents an <method_2> as a method to reduce <otherscientificterm_5> in the <task_1> . the <method_2> has two major benefits to the system performance . first , it can increase <otherscientificterm_4> between the <material_0> . second , it can desensitize the system to the <otherscientificterm_3> . for four subjects in the study , the benefits resulted in the performance improvement of the <method_7> in the range from 7.7 % to 18.9 % , while for the fifth subject , who had the highest <metric_6> of 90.5 % , the performance did not change notably with normalization .	2 5 1 8 -1 8 -1 4 0 9 8 -1 3 8 -1 7 6 8 -1
A study on domain recognition of spoken dialogue systems .	parallel computation of speech-recognition engines ; multi-domain spoken dialogue system ; information retrieval nature ; human-machine interaction ; scoring method ; weather report ; news query ; in-car usage ; recognition accuracy ; speech recognizer	<method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <metric> <method>	5 1 6	in this paper , we present a <method_1> equipped with the capability of <method_0> that are assigned to each domain . the experimental <method_1> is set up to handle three different domains -lrb- restaurant information , <material_5> , and <otherscientificterm_6> -rrb- in an <otherscientificterm_7> . all of these tasks are of <otherscientificterm_2> . the domain of a particular utterance is determined based on the likelihood of each <method_9> . in addition to the <otherscientificterm_3> , synthesized voice of the route subsystem interrupts the dialogue frequently . experimental evaluation has yielded 95 percent <metric_8> in selecting the task domain based on a specially designed <method_4> .	1 0 10 -1 5 6 7 11 10 -1 2 10 -1 9 10 -1 3 10 -1 8 10 -1
Repulsive Mixtures .	markov chain monte carlo sampling algorithm ; fully supervised multi-task learning ; iris data set ; infinite mixtures ; redundant components ; low separation ; dirichlet processes ; finite mixtures ; bayesian approach ; posterior computation ; discrete mixtures ; computational problems ; discrete mixtures ; supervised settings ; unsupervised learning ; synthetic examples ; repulsive process ; unsupervised settings ; repulsive prior ; redundancy ; redundancy ; clusters ; penalty	<method> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <material> <method> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 9 ; 15 1 2 ; 7 1 3	discrete mixtures are used routinely in broad sweeping applications ranging from <method_17> to <task_1> . indeed , <otherscientificterm_7> and <otherscientificterm_3> , relying on <method_6> and modifications , have become a standard tool . one important issue that arises in using <otherscientificterm_12> is <otherscientificterm_5> in the components ; in particular , different components can be introduced that are very similar and hence redundant . such <otherscientificterm_20> leads to too many <otherscientificterm_21> that are too similar , degrading performance in <method_14> and leading to <task_11> and an unnecessarily complex model in <material_13> . <otherscientificterm_19> can arise in the absence of a <otherscientificterm_22> on components placed close together even when a <method_8> is used to learn the number of components . to solve this problem , we propose a novel prior that generates components from a <otherscientificterm_16> , automatically penalizing <otherscientificterm_4> . we characterize this <otherscientificterm_18> theoretically and propose a <method_0> for <task_9> . the methods are illustrated using <material_15> and an <material_2> .	17 1 23 -1 7 3 6 26 23 -1 12 5 23 -1 20 21 14 11 13 19 23 -1 22 23 -1 8 23 -1 16 4 24 23 -1 18 0 9 25 23 -1
Estimation of cortical connectivity from E/MEG using nonlinear state-space models .	radial basis function kernels ; nonlinear multivariate au-toregressive model ; maximum likelihood estimates ; nonlinear dynamics of the cortical signals ; magnetoencephalographic data ; expectation-maximization algorithm ; spatially extended cortical sources ; nonlinear state-space model parameters ; nonlinear state-space model ; parsimonious spatial bases ; estimating cortical connectivity ; measuring cortical connectivity ; e/meg data ; observation equation ; system identification ; granger causality ; cortical signals ; decoupled approach ; inverse problem ; mvar model ; state equation ; observed data ; roi	<otherscientificterm> <method> <method> <otherscientificterm> <material> <method> <material> <otherscientificterm> <method> <otherscientificterm> <task> <task> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm>	1 0 20 ; 0 0 1 ; 14 0 10 ; 16 0 13 ; 9 0 6 ; 4 0 14 ; 9 0 12 ; 8 0 14 ; 5 0 2 ; 16 4 17 ; 9 0 16 ; 0 0 3 ; 4 0 10 ; 16 2 12	we present the problem of <task_10> between different regions of the cortex from scalp electroen-cephalographic -lrb- eeg -rrb- or <material_4> as <task_14> of a <method_8> . the <otherscientificterm_20> is based on a <method_1> with <otherscientificterm_0> . the <otherscientificterm_0> capture the <otherscientificterm_3> and provide a framework for measuring interactions between cortical regions of interest -lrb- rois -rrb- based on the definition of <otherscientificterm_15> . the <otherscientificterm_13> relates the <otherscientificterm_16> associated with each <otherscientificterm_22> to the observed <material_12> using a set of <otherscientificterm_9> to represent <material_6> . an <method_5> is derived to obtain <method_2> of the <otherscientificterm_7> directly from the <material_21> . we show that this integrated approach for <task_11> performs significantly better than the conventional <method_17> in which <otherscientificterm_16> are first estimated by solving the <task_18> followed by fitting a <method_19> .	10 4 14 8 26 29 31 36 23 -1 20 1 0 24 25 23 -1 3 15 35 23 -1 13 16 22 12 9 6 27 28 30 34 37 23 -1 5 2 7 21 32 23 -1 33 23 -1
Prediction error based feedback for downlink transmit beamforming .	joint maximum-likelihood and set-membership filtering algorithm ; downlink transmit beamforming scheme ; adaptive channel estimation ; uplink capacity analysis ; mobile decision errors ; adaptive channel estimator ; prediction error ; incorrect feedback ; robustness ; base-station ; power	<method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	0 0 2 ; 3 0 0	this paper examines a <method_1> recently proposed in -lsb- 1 -rsb- . the idea is based on the use of an <method_5> at the <otherscientificterm_9> and requires the mobile to selectively feed back the value of the <otherscientificterm_6> . this paper proposes a <method_0> for <task_2> that provides <metric_8> against <otherscientificterm_7> due to <otherscientificterm_4> . the amount of <otherscientificterm_10> and bandwidth-saving possible with this <method_0> is quantified via an <method_3> .	1 11 -1 5 9 6 11 -1 0 2 8 7 4 12 11 -1 10 3 13 11 -1
Sparse variable reduced rank regression via Stiefel optimization .	sparse variable reduced rank regression ; reduced rank regression ; rank regression ; vector l1 penalty ; estimation algorithm ; stiefel manifold ; signal processing ; optimization	<otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <method>	5 0 4 ; 7 0 4 ; 2 0 6	reduced <method_2> has found application in various fields of <task_6> . in this paper we propose a novel extension of the <method_2> which we call <otherscientificterm_0> . by using a <otherscientificterm_3> we remove variables completely from the <method_2> . the proposed <method_4> involves <method_7> on the <otherscientificterm_5> and we illustrate <method_4> both on a simulated and a real functional magnetic resonance imaging -lrb- fmri -rrb- data set .	2 6 11 8 -1 0 8 -1 3 8 -1 4 7 5 1 9 10 8 -1
Enhanced multidimensional spatial functions for unambiguous localization of multiple sparse acoustic sources .	global coherence field ; detection of multiple competing sources ; spatial and multidimensional tdoa domains ; single source localiza-tion case ; discrete time-frequency domain ; acoustic source localization ; multiple source case ; steered response power ; spatial function ; simulated data ; computational inexpensiveness ; cross-power spectrum ; multidimensional metric ; ambiguous locations ; mid-high reverberation ; higher norms ; source sparseness ; partitioned representation ; multidimensional kernel ; l1 norm ; phat ; robustness	<method> <task> <material> <task> <otherscientificterm> <task> <material> <method> <otherscientificterm> <material> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <metric>	12 0 7 ; 11 0 18 ; 7 0 5 ; 10 1 14 ; 9 5 8 ; 8 0 2 ; 17 0 18 ; 0 0 5 ; 10 1 21 ; 7 1 0	the <method_7> with <method_20> transform -lrb- srp-phat -rrb- or <method_0> , has become a standard method for <task_5> , thanks to their simplicity , <metric_10> and <metric_21> against <otherscientificterm_14> . however , originally formulated for the <task_3> , <method_7> does not apply satisfactorily to the <material_6> . in this paper , we analyze the structure of the <otherscientificterm_8> and reshape <method_7> according to a generic <method_12> . we show that traditional functions are based on the <otherscientificterm_19> which is prone to generate <otherscientificterm_13> with high likelihood -lrb- i.e. ghosts -rrb- . a more generic <method_18> based on <otherscientificterm_15> and on a <method_17> of the <otherscientificterm_11> is introduced , which better exploits the <otherscientificterm_16> in the <otherscientificterm_4> . evaluation results over <material_9> show that the new <otherscientificterm_8> considerably improve the <task_1> in both <material_2> .	7 20 0 5 10 21 14 25 26 30 31 32 22 -1 3 6 22 -1 8 12 23 22 -1 19 13 22 -1 18 15 24 29 22 -1 17 11 16 4 27 28 22 -1
Convex Relaxations for Learning Bounded Treewidth Decomposable Graphs .	forest and hyperforest polytopes ; convex optimization problem ; combi-natorial optimization problem ; undirected graphical models ; local search techniques ; maximum likelihood framework ; run-time complexity ; synthetic datasets ; classical benchmarks ; convex approach ; supergradient method ; bounded treewidth ; np-hard problem	<otherscientificterm> <task> <task> <method> <method> <method> <metric> <material> <material> <method> <method> <otherscientificterm> <task>	7 5 10 ; 1 0 0 ; 11 2 3	we consider the problem of learning the structure of <method_3> with <otherscientificterm_11> , within the <method_5> . this is an <task_12> and most approaches consider <method_4> . in this paper , we pose <task_12> as a <task_2> , which is then relaxed to a <task_1> that involves searching over the <otherscientificterm_0> with special structures , independently . a <method_10> is used to solve the dual problem , with a <metric_6> of o -lrb- k 3 n k +2 log n -rrb- for each iteration , where n is the number of variables and k is a bound on the treewidth . we compare our <method_10> to state-of-the-art methods on <material_7> and <material_8> , showing the gains of the novel <method_9> .	3 11 5 16 13 -1 12 4 13 -1 2 1 0 15 13 -1 10 6 13 -1 14 13 -1
Bayesian MCMC nonlinear time series prediction .	mcmc -lrb- markov chain monte carlo -rrb- algorithm ; nonlinear time series prediction ; hierarchical bayesian framework ; predictive distributions ; quadratic approximations ; time series	<method> <task> <method> <otherscientificterm> <method> <otherscientificterm>	0 0 1 ; 0 4 4	an <method_0> is proposed for <task_1> with <method_2> . the <method_0> computes predictive mean and error bar by drawing samples from <otherscientificterm_3> . the <method_0> is tested against <otherscientificterm_5> generated by -lrb- chaotic -rrb- r√∂ssler system and <method_0> outperforms <method_4> previously proposed by the authors .	0 1 2 7 6 -1 3 6 -1 5 4 8 6 -1
Activity-Based Scheduling of Science Campaigns for the Rosetta Orbiter .	science ground segment ; automated and semi-automated scheduling software ; science planning and scheduling system ; incremental planning process ; medium term planning ; automated scheduling capability ; pre-landing operations phase ; long term planning ; short term planning ; science mission plan ; rosetta orbiter ; skeleton planning ; comet nucleus ; rosetta orbiter ; philae lander	<method> <method> <method> <method> <method> <method> <task> <method> <method> <method> <task> <method> <otherscientificterm> <method> <method>	4 1 8 ; 9 0 13 ; 7 1 4	rosetta is an esa cornerstone mission that will reach the comet 67p/churyumov-gerasimenko in august 2014 and will escort the comet for a 1.5 year nominal mission offering the most detailed study of a comet ever undertaken by humankind . the <method_13> has 11 scientific instruments -lrb- 4 remote sensing -rrb- and the <method_14> to make complementary measurements of the <otherscientificterm_12> , coma -lrb- gas and dust -rrb- , and surrounding environment . the esa rosetta science ground segment has developed a <method_2> that includes an <method_5> to assist in developing science plans for the <task_10> . while <method_5> is a small portion of the overall <method_0> as well as the overall scheduling system , this paper focuses on the <method_1> -lrb- called aspen-rssc -rrb- and how this software is used . specifically , the <method_13> uses an <method_3> of successive refinement of the <method_9> beginning with <method_11> , <method_7> , <method_4> , and <method_8> . these phases represent the evolution of the <method_9> from one year before execution running through just before execution . we also report on aspen-rssc experience and usage during the <task_6> thus far .	15 -1 13 14 12 15 -1 2 5 10 15 -1 15 -1 0 1 16 17 18 15 -1 3 9 11 7 4 8 15 -1 15 -1
Bounded Gaussian fingerprints and the gradient collusion attack -LSB- multimedia fingerprinting applications -RSB- .	direct-sequence and uniformly distributed spread spectrum fingerprints ; analog hole '' problem ; audio or video signals ; digital rights management system ; bounded gaussian fingerprints ; multimedia file sharing ; analog hole ; object size ; cryptographic primitives ; gradient attack ; spread-spectrum fingerprints ; collusion procedure ; multimedia fingerprinting ; robustness ; encryption ; scrambling	<otherscientificterm> <task> <material> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <metric> <method> <method>	13 2 9 ; 14 1 15 ; 14 6 8 ; 11 0 10 ; 15 6 8 ; 4 0 9	the difficulty of building an effective <method_3> stems from the fact that traditional <otherscientificterm_8> such as <method_14> or <method_15> do not protect <material_2> once they are played in plain-text . this fact , commonly referred to as '' the <otherscientificterm_6> , '' has been responsible for the popularity of <task_5> which can not be controlled , at least technically , by content 's copyright owners . in this paper , we explore a specific issue in <task_12> as an answer to '' the <task_1> . we analyze the collusion resistance of three large classes of <otherscientificterm_10> using a recently introduced <method_11> , the <method_9> . surprisingly , we show that the collusion resistance of <otherscientificterm_0> is a small constant that does not depend on the <otherscientificterm_7> , whereas <otherscientificterm_4> demonstrate significantly better <metric_13> to the <method_9> .	3 8 14 15 2 18 19 21 16 -1 6 5 16 -1 12 1 16 -1 10 20 16 -1 11 9 17 22 16 -1
Full Diversity Detection in MIMO Systems with a Fixed-Complexity Sphere Decoder .	≈øxed-complexity sphere decoder ; maximum likelihood detector ; noise ratio regime ; sphere decoder ; signi≈øcantly lower complexity ; hardware implementation ; sequential structure ; coding loss ; variable complexity ; diversity order ; mld	<method> <method> <metric> <method> <metric> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method>	8 1 6 ; 0 0 5	the <method_0> has been previously proposed for multiple input-multiple output -lrb- mimo -rrb- detection to overcome the two main drawbacks of the original <method_3> , namely its <metric_8> and <otherscientificterm_6> . as such , the <method_0> is highly suitable for <task_5> and has shown remarkable performance through simulations . herein , we explore the theoretical aspects of the algorithm and prove that the <method_0> achieves the same <otherscientificterm_9> as the <method_1> . further , we show that the <otherscientificterm_7> can be made negligible in the high signal to <metric_2> with a <metric_4> than that of the <method_10> .	0 3 8 6 12 11 -1 5 13 11 -1 9 1 11 -1 7 2 4 10 11 -1
Sparse covariance estimation under Kronecker product structure .	sparse kronecker-decomposable covariance matrix ; sparse covariance estimation method ; large-sample statistical consistency ; 1-penalized log-likelihood function ; block coordinate-descent approach ; high dimensional setting ; penalized maximum-likelihood approach ; iterative algorithm ; glasso algorithm ; local maximum ; covariance matrix ; mild assumptions ; objective function ; convergence bound ; kronecker product ; ffp ; gaussian	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	8 0 0 ; 15 4 8 ; 7 0 1 ; 1 0 5	we introduce a <method_1> for the <otherscientificterm_5> when the <otherscientificterm_10> decomposes as a <otherscientificterm_14> , i.e. , œÉ 0 = a 0 ‚äó b 0 , and the observations are <method_16> . we propose an 1 <method_6> to solve this problem . the <method_1> motivates an <method_7> -lrb- penalized flip-flop ; <method_15> -rrb- based on a <method_4> . although the <otherscientificterm_3> -lrb- <otherscientificterm_12> -rrb- is non-convex in general and non-smooth , we show that <method_15> converges to a <otherscientificterm_9> under relatively <otherscientificterm_11> . for the fixed dimension case , <otherscientificterm_2> is proved and a rate of <otherscientificterm_13> is derived . simulations show that <method_15> outperforms its non-penalized counterpart and the naive <method_8> for <otherscientificterm_0> .	1 5 10 14 16 21 17 -1 6 17 -1 7 15 4 20 17 -1 3 12 9 11 17 -1 2 13 17 -1 18 19 17 -1
Learning feed-forward one-shot learners .	visual object tracking benchmark ; feed-forward one-shot learner ; tracking visual objects ; one-shot classification objective ; deep network ; one-shot learning ; pupil network ; learning scenarios ; generative models ; deep model ; one-shot learning ; discriminative methods ; discriminative embeddings ; deep learning ; omniglot	<task> <method> <task> <otherscientificterm> <method> <task> <method> <task> <method> <method> <task> <method> <method> <method> <material>	11 0 7 ; 8 1 12 ; 12 0 10 ; 13 0 11 ; 0 0 2 ; 8 0 10	one-shot learning is usually tackled by using <method_8> or <method_12> . <method_11> based on <method_13> , which are very effective in other <task_7> , are ill-suited for <task_5> as <method_11> need large amounts of training data . in this paper , we propose a method to learn the parameters of a <method_9> in one shot . we construct the learner as a second <method_4> , called a learnet , which predicts the parameters of a <method_6> from a single exemplar . in this manner we obtain an efficient <method_1> , trained end-to-end by minimizing a <otherscientificterm_3> in a learning to learn formulation . in order to make the construction feasible , we propose a number of factorizations of the parameters of the <method_6> . we demonstrate encouraging results by learning characters from single exemplars in <material_14> , and by <task_2> from a single initial exemplar in the <task_0> .	8 12 11 17 18 21 15 -1 13 7 5 16 19 15 -1 9 15 -1 4 6 15 -1 1 3 15 -1 15 -1 20 15 -1
On-demand new word learning using world wide web .	out-of-vocabulary words ; global semantic features ; oov word retrieval ; local decoding pass ; locally-augmented lexicons ; hypothesis words ; lexicon augmenting ; local context ; transcription process ; oov words ; web-based methods ; part-of-speech models ; accuracy	<otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <metric>	10 0 6 ; 4 0 3 ; 11 0 8	most of the <method_10> for <task_6> consist in capturing <otherscientificterm_1> of the targeted domain in order to collect relevant documents from the web . we suggest that the <otherscientificterm_7> of the <otherscientificterm_0> contains relevant information on the <otherscientificterm_9> . with this information , we propose to use the web to build <otherscientificterm_4> which are used in a final <method_3> . we first demonstrate the relevance of the web for the <task_2> . then , different methods are proposed to retrieve the <otherscientificterm_5> . finally we present the integration of new words in the <method_8> based on <method_11> . this technique allows to recover 7.7 % of the significant <otherscientificterm_9> and the <metric_12> of the system is slightly improved .	10 6 1 14 13 -1 7 0 9 13 -1 4 3 15 13 -1 2 13 -1 5 13 -1 8 11 16 13 -1 13 -1
Scalable Semantic Retrieval through Summarization and Refinement .	processing of instance retrieval queries ; expressive description logic shin ; querying of ontologies ; secondary storage ; query processing ; owl-dl ontologies ; instance retrieval ; summarization ; owl-dl ; abox ; datatypes	<task> <method> <task> <otherscientificterm> <task> <material> <task> <method> <method> <otherscientificterm> <method>	6 3 9 ; 7 0 6	query processing of <material_5> is intractable in the worst case , but we present a novel technique that in practice allows for efficient <task_2> with large aboxes in <otherscientificterm_3> . we focus on the <task_0> , i.e. , queries that retrieve individuals in the <otherscientificterm_9> which are instances of a given concept c . our technique uses <method_7> and refinement to reduce <task_6> to a small relevant subset of the original <otherscientificterm_9> . we demonstrate the effectiveness of this technique in aboxes with up to 7 million assertions . our results are applicable to the very <method_1> , which corresponds to <method_8> minus nominals and <method_10> .	5 2 3 11 -1 0 9 11 -1 7 6 12 13 11 -1 11 -1 1 11 -1
Adaptive Singleton-Based Consistencies .	singleton arc consistency ; adaptive partition-one-ac ; adaptive variants ; singleton-based consistency ; singleton tests ; arc consistency ; singleton-based consistencies ; constraint solvers ; fixpoint ; partition-one-ac ; pruning	<otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <task>	6 0 7 ; 5 1 9	singleton-based consistencies have been shown to dramatically improve the performance of <method_7> on some difficult instances . however , they are in general too expensive to be applied exhaustively during the whole search . in this paper , we focus on <method_9> , a <otherscientificterm_3> which , as opposed to <otherscientificterm_0> , is able to prune values on all variables when <method_9> performs <otherscientificterm_4> on one of them . we propose <method_2> of <method_9> that do not necessarily run until having proved the <otherscientificterm_8> . the <task_10> can be weaker than the full version but the computational effort can be significantly reduced . our experiments show that <method_1> can obtain significant speed-ups over <metric_5> and over the full version of <method_9> .	7 12 11 -1 11 -1 9 3 0 4 11 -1 2 8 11 -1 10 11 -1 13 11 -1
K-SVD dictionary-learning for the analysis sparse model .	greedy tailored pursuit algorithms ; synthesis-based sparse representation model ; signal of interest ; dictionary update stage ; synthesis model ; analysis dictionary ; signal examples ; analysis dictionary ; analysis-based model ; k-svd algorithm ; penalty function ; linear combination	<method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <method> <method> <method> <otherscientificterm> <method>	0 1 10 ; 10 0 3 ; 0 6 8 ; 6 0 5 ; 10 3 8	the <method_1> for signals has drawn a considerable interest in the past decade . such a <method_1> assumes that the <otherscientificterm_2> can be decomposed as a <method_11> of a few atoms from a given dictionary . in this paper we concentrate on an alternative , <method_8> , where an <method_7> multiplies the signal , leading to a sparse outcome . our goal is to learn the <method_5> from a set of <material_6> , and the <method_8> taken is parallel and similar to the one adopted by the <method_9> that serves the corresponding problem in the <method_4> . we present the development of the <method_8> , which include two <method_0> and a <otherscientificterm_10> for the <otherscientificterm_3> . we demonstrate its effectiveness in several experiments , showing a successful and meaningful recovery of the <method_5> .	1 12 -1 2 11 12 -1 8 7 12 -1 5 6 9 4 16 12 -1 13 14 15 17 12 -1 0 10 3 12 -1
Frequency-domain single-channel inverse filtering for speech dereverberation : Theory and practice .	approximate time-domain inverse filtering techniques ; single-channel least-squares ; single-channel speech enhancement scheme ; frequency-domain inverse filtering technique ; acoustic transfer function ; single-channel inverse filtering ; rir inaccuracies ; theoretical analysis ; inverse filter ; scls technique ; computational complexity ; frequency-domain ; dereverberation ; estimate ; regularization	<method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <metric> <otherscientificterm> <task> <task> <otherscientificterm>	4 3 11 ; 10 5 3 ; 3 4 9 ; 5 0 8 ; 10 5 9 ; 1 6 0 ; 14 1 2	the objective of <method_5> is to design an <method_8> that achieves <task_12> while being robust to an inaccurate room impulse response -lrb- rir -rrb- measurement or <task_13> . since a stable and causal <method_8> typically does not exist , <method_0> such as <otherscientificterm_1> have been proposed . however , besides being computationally expensive and often infeasible , <otherscientificterm_1> generally leads to distortions in the output signal in the presence of <otherscientificterm_6> . in this paper , a <method_7> is initially provided , showing that the direct inversion of the <otherscientificterm_4> in the <otherscientificterm_11> generally yields instability and acausality issues . in order to resolve these issues , a novel <method_3> is proposed that incorporates <otherscientificterm_14> and uses a <method_2> . experimental results demonstrate that the proposed <method_3> yields a higher dere-verberation performance and has a significantly lower <metric_10> compared to the <method_9> .	5 8 12 13 19 15 -1 0 1 21 15 -1 6 15 -1 7 4 11 16 15 -1 22 15 -1 3 14 2 17 18 20 15 -1
ReNoun : Fact Extraction for Nominal Attributes .	open information extraction system ; open information extraction ; renoun 's approach ; noun-based relations ; verb phrases ; search engines ; nominal attributes ; text corpus ; verb-based techniques ; knowledge bases ; user queries ; precision ; renoun	<method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <method> <otherscientificterm> <material> <metric> <method>	7 1 10 ; 12 6 0	search engines are increasingly relying on large <otherscientificterm_9> of facts to provide direct answers to users ' queries . however , the construction of these <otherscientificterm_9> is largely manual and does not scale to the long and heavy tail of facts . <task_1> tries to address this challenge , but typically assumes that facts are expressed with <otherscientificterm_4> , and therefore has had difficulty extracting facts for <otherscientificterm_3> . we describe <method_12> , an <method_0> that complements previous efforts by focusing on <otherscientificterm_6> and on the long tail . <method_2> is based on leveraging a large on-tology of noun attributes mined from a <material_7> and from <material_10> . <method_12> creates a seed set of training data by using specialized patterns and requiring that the facts mention an attribute in the ontol-ogy . <method_12> then generalizes from this seed set to produce a much larger set of extractions that are then scored . we describe experiments that show that we extract facts with high <metric_11> and for attributes that can not be extracted with <method_8> .	9 13 -1 1 13 -1 4 3 13 -1 12 0 6 2 15 13 -1 14 13 -1 7 10 13 -1 13 -1 13 -1
Incremental Learning in SwiftFile .	user 's mail-filing habits ; swiftfile 's classifier ; incremental learning algorithms ; learning systems ; intelligent assistant ; text classifier ; incremen-tal learning ; shortcut buttons ; swiftfile	<otherscientificterm> <method> <method> <method> <method> <method> <task> <otherscientificterm> <method>	2 0 1 ; 6 0 8 ; 5 0 8	swiftfile is an <method_4> that helps users organize their e-mail into folders . <method_8> uses a <method_5> to predict where each new message is likely to be filed by the user and provides <otherscientificterm_7> to quickly file messages into one of its predicted folders . one of the challenges faced by <method_8> is that the <otherscientificterm_0> are constantly changing -- users are frequently creating , deleting and rearranging folders to meet their current filing needs . in this paper , we discuss the importance of <task_6> in <method_8> . we present several criteria for judging how well <method_2> adapt to quickly changing data and evaluate <method_1> using these criteria . we find that <method_1> is surprisingly responsive and does not require the extensive training that is often assumed in most <method_3> .	4 8 9 -1 5 7 12 9 -1 0 9 -1 6 11 9 -1 2 10 9 -1 1 9 -1
AOSO-LogitBoost : Adaptive One-Vs-One LogitBoost for Multi-Class Problem .	tractable model learning algorithm ; adaptive block coordinate descent ; node value fittings ; dense hessian matrices ; additive tree regression ; public data sets ; classification accuracy ; node values ; convergence rates ; node value ; log-itboost setting ; sum-to-zero constraint ; vector tree ; statistical view ; multi-class logitboost ; model learning ; abc-logitboost implementations ; dense hessian ; logitboost ; lat-ter ; classification	<method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <metric> <otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <method> <task>	1 0 17 ; 14 0 15 ; 12 0 10 ; 14 0 20	this paper presents an improvement to <task_15> when using <method_14> for <task_20> . motivated by the <otherscientificterm_13> , <method_18> can be seen as <method_4> . two important factors in this setting are : 1 -rrb- coupled classifier output due to a <otherscientificterm_11> , and 2 -rrb- the <otherscientificterm_3> that arise when computing tree node split gain and <otherscientificterm_2> . in general , this setting is too complicated for a <method_0> . however , too aggressive simplification of the setting may lead to degraded performance . for example , the original <method_18> is outper-formed by <method_18> due to the <method_19> 's more careful treatment of the above two factors . in this paper we propose techniques to address the two main difficulties of the <method_10> : 1 -rrb- we adopt a <method_12> -lrb- i.e. , each <otherscientificterm_9> is vector -rrb- that enforces a <otherscientificterm_11> , and 2 -rrb- we use an <method_1> that exploits the <otherscientificterm_17> when computing tree split gain and <otherscientificterm_7> . higher <metric_6> and faster <metric_8> are observed for a range of <material_5> when compared to both the original and the <method_16> .	15 14 20 23 25 21 -1 13 18 4 21 -1 11 3 2 21 -1 0 21 -1 21 -1 19 21 -1 22 24 21 -1 10 12 9 1 17 7 21 -1
Automatic Non-rigid 3D Modeling from Video .	estimating non-rigid 3d shape and motion ; rigid and non-rigid shape reconstruction ; input video sequence ; 3d time-varying shape ; video sequences ; user-tuned parameters ; non-rigid deformations ; system parameters ; user-specified region ; variable illumination ; image stream ; pdf ; initialization ; outliers ; occlusion	<task> <task> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	14 1 9 ; 6 3 7	we present a robust framework for <task_0> in <material_4> . given an <material_2> , and a <otherscientificterm_8> to reconstruct , the algorithm automatically solves for the <otherscientificterm_3> and motion of the object , and estimates which pixels are <otherscientificterm_13> , while learning all <otherscientificterm_7> , including a <otherscientificterm_11> over <otherscientificterm_6> . there are no <otherscientificterm_5> -lrb- other than <otherscientificterm_12> -rrb- ; all parameters are learned by maximizing the likelihood of the entire <otherscientificterm_10> . we apply our method to both <task_1> , and demonstrate it in challenging cases of <otherscientificterm_14> and <otherscientificterm_9> .	0 4 15 -1 2 8 3 13 7 11 6 17 15 -1 5 12 10 15 -1 1 14 9 16 15 -1
Joint Acoustic-Video Fingerprinting of Vehicles , Part I.	envelope shape components ; intuitive discriminatory feature space ; acoustic and video sensors ; passive acoustic sensor ; vehicle speed estimation ; vehicle profile vector ; silhouette extraction ; vehicle classification ; field data ; mensuration problems ; video sensor ; wheel detection ; acoustic wave-pattern ; shape ; mensuration ; classification	<method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <task> <material> <task> <method> <task> <otherscientificterm> <otherscientificterm> <task> <task>	3 0 12 ; 6 1 11 ; 0 0 12 ; 7 1 14	we address <task_7> and <task_9> using <otherscientificterm_2> . in this paper , we show how to estimate a vehicle 's speed , width , and length by jointly estimating its <otherscientificterm_12> using a single <method_3> that records the vehicle 's drive-by noise . the <otherscientificterm_12> is approximated using three <method_0> , which approximate the <otherscientificterm_13> of the received signal 's power envelope . we incorporate the parameters of the <method_0> along with estimates of the vehicle engine rpm and number of cylinders to create a <otherscientificterm_5> that forms an <otherscientificterm_1> . in the companion paper , we discuss <task_7> and <task_14> based on <task_6> and <task_11> , using a <method_10> . <task_4> and <task_15> results are provided using <material_8> .	7 9 2 16 -1 12 3 17 16 -1 0 13 19 16 -1 5 1 16 -1 18 20 16 -1 14 6 11 10 4 16 -1
Coupled dictionary training for exemplar-based speech enhancement .	signal-to-distortion ratio ; speech and noise estimates ; exemplar-based speech enhancement systems ; lower dimensional features ; exemplar-based speech enhancement ; full-scale dft features ; noisy dft enhancement ; modulation envelope features ; activations of exemplars ; wiener-like filter ; mel resolution ; wiener filter ; dft space ; sub-optimal filter ; feature space ; computational complexity	<metric> <material> <method> <otherscientificterm> <task> <otherscientificterm> <task> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	8 0 11 ; 14 1 12 ; 7 0 4 ; 14 2 1 ; 9 0 6 ; 10 0 8	in <method_2> , <otherscientificterm_3> are preferred over the <otherscientificterm_5> for their reduced <metric_15> and the ability to better generalize for the unseen cases . but in order to obtain the <method_9> for <task_6> , the <material_1> obtained in the <otherscientificterm_14> need to be mapped to the <otherscientificterm_12> , which yield a low-rank approximation of the estimates resulting in a <otherscientificterm_13> . this paper proposes a novel method using coupled dictionaries where the exemplars for the required <otherscientificterm_14> and the <otherscientificterm_12> are jointly extracted and the estimates are directly obtained in the <otherscientificterm_12> following the decomposition in the chosen <otherscientificterm_14> . simulation experiments revealed that the proposed approach , where the <otherscientificterm_8> calculated using the <task_10> are directly used to obtain the <method_11> in the <otherscientificterm_12> , results in improved <metric_0> when compared to the system without coupled dictionaries . to further motivate the use of coupled dictionaries , the paper also investigates the use of <method_7> for the <task_4> .	2 3 5 15 16 -1 9 6 1 14 12 13 20 21 16 -1 18 16 -1 17 22 16 -1 8 10 11 0 19 16 -1
Cost-sensitive multi-class classification from probability estimates .	naive bayes and quadratic discriminant analysis ; class probability estimates ; roc curve analysis ; multiclass probability simplex ; partition matrix ; two-class classification ; cost matrix ; multiclass classification ; cost matrices ; benchmark datasets ; systematic errors ; class partitioning ; threshold	<method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <task> <metric> <material> <otherscientificterm> <task> <otherscientificterm>	1 1 8 ; 9 5 4 ; 2 0 12	for <task_5> , it is common to classify by setting a <otherscientificterm_12> on <otherscientificterm_1> , where the <otherscientificterm_12> is determined by <method_2> . an analog for <task_5> is learning a new <task_11> of the <otherscientificterm_3> to minimize empirical misclassification costs . we analyze the interplay between <otherscientificterm_10> in the <otherscientificterm_1> and <metric_8> for <task_7> . we explore the effect on the <task_11> of five different transformations of the <otherscientificterm_6> . experiments on <material_9> with <method_0> show the effectiveness of learning a new <method_4> compared to previously proposed methods .	5 12 1 2 16 13 -1 11 3 13 -1 10 8 7 14 13 -1 6 13 -1 9 0 4 15 13 -1
An efficient approximation of the forward-backward algorithm to deal with packet loss , with applications to remote speech recognition .	hidden markov models ; tree-structure mapping of quantizer centroids ; forward-backward algorithm ; remote speech recognition ; estimating missing features ; lower resolution quantizers ; word recognition accuracy ; downsampling statistical models ; error concealment ; aurora-2 database ; fb approximation ; computational load ; estimation process ; hmms	<method> <method> <method> <task> <task> <method> <metric> <method> <task> <material> <method> <otherscientificterm> <task> <method>	10 4 2 ; 1 0 13 ; 0 0 12 ; 13 0 2 ; 6 5 10 ; 2 0 4 ; 5 0 13 ; 6 5 2 ; 8 0 3 ; 2 0 3 ; 2 0 8	this paper proposes an efficient approximation of the <method_2> , for the purpose of <task_4> , based on <method_7> . the paper discusses the role of <method_0> in the <task_12> , and presents an approximation to the <method_2> by developing <method_13> based on <method_5> , which are obtained through a <method_1> . to illustrate the effectiveness of the proposed <method_2> , we apply <method_2> to the problem of <task_8> in <task_3> , using the <material_9> . the <method_10> provides comparable <metric_6> results relative to the standard <method_2> , while reducing the <otherscientificterm_11> by a large factor -lrb- > 250 in this case -rrb- .	2 4 7 20 14 -1 0 12 13 5 1 16 17 18 21 14 -1 8 3 9 23 24 25 14 -1 10 6 11 15 19 22 14 -1
Slice sampling covariance hyperparameters of latent Gaussian models .	markov chain monte carlo sampling ; gaussian process ; hyperparameter sampling approaches ; slice sampling approach ; strong-and weak-data regimes ; probabilistic model ; bayesian framework ; unknown hyperparameters ; covariance structure ; random variables	<method> <method> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 0 8 ; 6 0 8 ; 7 0 6	the <method_1> is a popular way to specify dependencies between <otherscientificterm_9> in a <method_5> . in the <method_6> the <otherscientificterm_8> can be specified using <otherscientificterm_7> . integrating over these <otherscientificterm_7> considers different possible explanations for the data when making predictions . this integration is often performed using <method_0> . however , with non-gaussian observations standard <method_2> require careful tuning and may converge slowly . in this paper we present a <method_3> that requires little tuning while mixing well in both <otherscientificterm_4> .	1 9 5 10 -1 6 8 7 11 12 13 10 -1 10 -1 0 10 -1 2 10 -1 3 4 10 -1
Subspace projection of multichannel audio data for automatic control of motion-platform-based multimedia display systems .	haptic and vestibular sensations ; motion platform control ; multimedia display systems ; motion-platform-based multimedia display ; multichannel audio data ; motion data ; audiovisual content ; displayed environment ; motion platforms ; subspace projection	<otherscientificterm> <task> <method> <material> <material> <material> <material> <otherscientificterm> <method> <method>	4 0 1 ; 4 0 5 ; 5 0 1 ; 8 0 2 ; 2 0 0 ; 6 0 5	this paper addresses a practical problem associated with <method_2> that utilize <method_8> to create for users both <otherscientificterm_0> associated with their movement through a <otherscientificterm_7> . given <material_6> for which <material_5> is not available , the <material_5> that is required for <task_1> can be generated automatically from <material_4> such as that distributed on dvds presenting popular movie titles . this paper presents initial results of a study designed to test the effectiveness of a <method_9> of <material_4> for automatic control of <material_3> .	2 8 0 7 14 15 10 -1 6 5 1 4 11 12 13 16 10 -1 9 3 10 -1
Random Indexing using Statistical Weight Functions .	vector space technique ; distributional similarity problems ; small data sets ; high frequency attributes ; random indexing ; weighting functions ; weight functions	<method> <task> <material> <otherscientificterm> <task> <method> <otherscientificterm>	4 6 0 ; 5 0 4 ; 4 0 2 ; 0 0 1	random indexing is a <method_0> that provides an efficient and scal-able approximation to <task_1> . we present experiments showing <task_4> to be poor at handling large volumes of data and evaluate the use of <method_5> for improving the performance of <task_4> . we find that <task_4> is robust for <material_2> , but performance degrades because of the influence of <otherscientificterm_3> in large data sets . the use of appropriate <otherscientificterm_6> improves this significantly .	0 1 8 11 7 -1 4 5 9 7 -1 2 3 10 7 -1 6 7 -1
Recursive Inversion Models for Permutations .	mallows and generalized mal-lows models ; exponential family probabilistic model ; class of models ; structure search ; parameter estimation ; hierarchical structure	<method> <method> <method> <task> <task> <otherscientificterm>	3 0 2 ; 1 0 5	we develop a new <method_1> for permutations that can capture <otherscientificterm_5> and that has the <method_0> as subclasses . we describe how to do <task_4> and propose an approach to <task_3> for this <method_2> . we provide experimental evidence that this added flexibility both improves predictive performance and enables a deeper understanding of collections of permutations .	1 5 0 8 6 -1 4 3 2 7 6 -1 6 -1
Role of phase estimation in speech enhancement .	short-time fourier transform phase spectrum ; stft analysis-modification-synthesis framework ; speech enhancement algorithms ; stft phase spectra ; speech quality measures ; noise reduction ; speech enhancement ; fourier domain ; phase component ; magnitude component ; ham-ming window ; window function ; dynamic range ; spec-trogram plots	<method> <method> <method> <otherscientificterm> <metric> <task> <task> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	11 0 0 ; 11 0 3 ; 1 0 5 ; 12 2 11 ; 11 0 5 ; 7 2 2	typical <method_2> that operate in the <material_7> only modify the <method_9> . it is commonly understood that the <method_8> is perceptually unimportant , and thus , <method_8> is passed directly to the output . in recent intelligibility experiments , <method_8> has been reported that the <method_0> can provide significant intelligibility when estimated using a <otherscientificterm_11> lower in <otherscientificterm_12> than the typical <otherscientificterm_10> . motivated by this , we investigate the role of the <otherscientificterm_11> for <method_0> in relation to <task_6> . using a modified <method_1> , we show that <task_5> can be achieved by modifying the <otherscientificterm_11> used to estimate the <otherscientificterm_3> . we demonstrate this through <material_13> and results from two objective <metric_4> .	2 7 9 20 14 -1 8 14 -1 0 11 12 10 18 14 -1 6 15 14 -1 1 5 16 17 19 14 -1 3 14 -1
Direct construction of compact context-dependency transducers from data .	phonetic decision tree growing ; finite-state transducer-based asr decoders ; compact context-dependency transducers ; context sizes ; context-dependency transducer ; fst compilation ; regularization term ; recognition accuracy ; phonetic context ; n-phone orders ; phonetic features ; transducer construction ; features	<method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	7 5 4 ; 3 1 12 ; 6 0 2 ; 8 3 11 ; 2 0 1	this paper describes a new method for building <method_2> for <task_1> . instead of the conventional <method_0> followed by <method_5> , this approach incorporates the <otherscientificterm_8> splitting directly into the <task_11> . the objective function of the <method_2> is augmented with a <otherscientificterm_6> that measures the number of transducer states introduced by a split . we give results on a large spoken-query task for various <otherscientificterm_9> and other <otherscientificterm_10> that show this method can greatly reduce the size of the resulting <method_4> with no significant impact on <metric_7> . this permits using <otherscientificterm_3> and <otherscientificterm_12> that might otherwise be unmanageable .	2 1 18 13 -1 0 5 8 11 17 13 -1 6 16 13 -1 9 10 4 7 14 13 -1 3 12 15 13 -1
PLIS : a Probabilistic Lexical Inference System .	open source probabilistic lexical inference system ; lexical inference processes ; online interactive viewer ; text processing applications ; lexical inference knowledge ; textual inferences ; lexical knowledge ; integrated knowledge ; system customiza-tion ; diverse resources ; plis	<method> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <method>	10 0 3 ; 10 6 0 ; 10 0 1 ; 2 3 10	this paper presents <method_10> , an <method_0> which combines two functionalities : -lrb- i -rrb- a tool for integrating <otherscientificterm_4> from <material_9> , and -lrb- ii -rrb- a framework for scoring <otherscientificterm_5> based on the <otherscientificterm_7> . we provide <method_10> with two probabilistic implementation of this framework . <method_10> is available for download and developers of <task_3> can use <method_10> as an off-the-shelf component for injecting <otherscientificterm_6> into their applications . <method_10> is easily configurable , components can be extended or replaced with user generated ones to enable <method_8> and further research . <method_10> includes an <method_2> , which is a powerful tool for investigating <task_1> .	10 0 4 9 5 7 13 11 -1 11 -1 3 6 12 11 -1 8 11 -1 2 14 15 11 -1
Optimal Incremental Parsing via Best-First Dynamic Programming .	polynomial time dynamic programming algorithm ; probablistic best-first shift-reduce parser ; best-first shift-reduce parsing ; best-first parser ; complexity ; search	<method> <method> <task> <method> <metric> <method>	0 0 2 ; 1 5 0	we present the first provably optimal <method_0> for <task_2> , which applies the <method_0> idea of huang and sagae -lrb- 2010 -rrb- to the <method_3> of sagae and lavie -lrb- 2006 -rrb- in a non-trivial way , reducing the <metric_4> of the latter from exponential to polynomial . we prove the correctness of our <method_0> rigorously . experiments confirm that <method_0> leads to a significant speedup on a <method_1> , and makes exact <method_5> under such a model tractable for the first time .	0 2 3 4 7 6 -1 6 -1 1 5 8 6 -1
Building Reconstruction from Optical and Range Images .	3d nature of the buildings ; reconstructions of diier-ent buildings classes ; top-down robust surface ttting ; diierent range sensor types ; registered range image ; attentional focus stage ; monocular optical image ; noisy range data ; range data ; focus-of-attention area ; optical image ; model indexing	<otherscientificterm> <task> <task> <otherscientificterm> <material> <otherscientificterm> <material> <material> <material> <otherscientificterm> <material> <method>	6 0 9 ; 2 0 0 ; 11 0 5	a technique is introduced for extracting and reconstructing a wide class of building types from a <material_4> and <material_10> . an <otherscientificterm_5> , followed by <method_11> , allows <task_2> to reconstruct the <otherscientificterm_0> in the data . because of the effectiveness of <method_11> , top-down processing of <material_7> still succeeds and the algorithm is capable of detecting and reconstructing several diierent building roof classes , including at single level , at multi-leveled , peaked , and curved rooftops . the algorithm is applicable to <material_8> that may have been collected from several <otherscientificterm_3> . we demonstrate <task_1> in the presence of large amounts of noise . our results underline the usefuless of <material_8> when processed in the context of a <otherscientificterm_9> derived from the <material_6> .	4 10 12 -1 5 11 2 0 14 15 12 -1 7 12 -1 8 3 12 -1 1 12 -1 13 12 -1
Readability Indices for Automatic Evaluation of Text Simplification Systems : A Feasibility Study for Spanish .	automatic evaluation of text simplification systems ; corpus of original news texts ; measuring syntactic complexity ; linguistically motivated features ; already-existing readability for-mulae ; cognitive disabilities ; readability indices ; read-ability indices ; lexical complexity ; manual simplifications ; spanish	<task> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <material>	8 2 7 ; 5 2 9	this paper addresses the problem of <task_0> for <material_10> . we test whether <otherscientificterm_4> would be suitable for this task . we adapt three existing <method_6> -lrb- two measuring <metric_8> and one <metric_2> -rrb- to be computed automatically , which are then applied to a <material_1> and their <method_9> aimed at people with <otherscientificterm_5> . we show that there is a significant correlation between each of the three <method_6> and several <otherscientificterm_3> which might be seen as reading obstacles for various target populations . furthermore , we show that there is a significant correlation between the two <otherscientificterm_7> which measure <metric_8> .	0 10 11 -1 4 11 -1 6 8 2 1 9 5 13 11 -1 3 11 -1 7 12 11 -1
3D Reconstruction of Dynamic Scenes with Multiple Handheld Cameras .	accurate dense 3d reconstruction of dynamic scenes ; separation of static and dynamic points ; segmentation of static and dynamic points ; unified energy minimization framework ; dense depth estimation method ; data capturing setup ; synchronized video sequences ; fixed camera arrays ; fixed cameras ; natural images ; known background ; handheld cameras ; bilayer segmentation ; spatio-temporal constraints ; depth optimization	<task> <otherscientificterm> <task> <method> <method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task>	14 1 2 ; 13 2 3 ; 4 0 3 ; 6 0 4	accurate dense 3d reconstruction of dynamic scenes from <material_9> is still very challenging . most previous methods rely on a large number of <otherscientificterm_8> to obtain good results . some of these methods further require <otherscientificterm_1> , which are usually restricted to scenes with <otherscientificterm_10> . we propose a novel <method_4> which can automatically recover accurate and consistent depth maps from the <material_6> taken by a few <otherscientificterm_11> . unlike <otherscientificterm_7> , our <method_5> is much more flexible and easier to use . our <method_4> simultaneously solves <task_12> and depth estimation in a <method_3> , which combines different <otherscientificterm_13> for effective <task_14> and <task_2> . a variety of examples demonstrate the effectiveness of the proposed <method_4> .	9 15 -1 8 15 -1 1 10 15 -1 4 6 11 19 15 -1 7 5 15 -1 12 3 13 16 17 18 15 -1 14 2 15 -1
Effects of frequency shifts on perceived naturalness and gender information in speech .	geometric mean formant frequencies ; low formant frequencies ; natural voices ; gender ambiguity ; perceived naturalness ; frequency-shifted versions ; scale factors ; natural speech ; frequency-shifted sentences ; moderate correlation ; frequency-shifted sentences ; perceived gender ; formant frequencies	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	6 0 5	in <material_7> , there is a <otherscientificterm_9> between the fundamental frequency and <otherscientificterm_12> across talkers . the present study used a high-quality vocoder to manipulate these properties and determine their contribution to <otherscientificterm_4> and voice gender . the stimuli were re-synthesized sentences spoken by two adult males and two adult females . <otherscientificterm_6> were chosen for each sentence and for each talker to produce <method_5> with a specified mean fundamental frequency -lrb- f 0 -rrb- ranging from 60 hz to 450 hz in 10 steps , paired with 10 steps in <otherscientificterm_0> ranging from 850 hz to 2500 hz . listeners judged <material_8> as more natural when f 0 and <otherscientificterm_12> followed the co-variation of f 0 and <otherscientificterm_12> in <material_2> . sentences with low f 0 s and <otherscientificterm_1> were perceived as masculine , while sentences with high f 0 and high <otherscientificterm_12> were assigned high ratings of femininity . sentences with '' mismatched '' f 0 and <otherscientificterm_12> were assigned ratings near the midpoint of the range , indicating <otherscientificterm_3> . <material_10> derived from male talkers received consistently higher ratings of masculinity than those derived from females , while sentences from female talkers received higher ratings of femininity , even when assigned scale factors appropriate for the opposite gender , indicating that factors other than f 0 and mean <otherscientificterm_12> contribute to <otherscientificterm_11> .	7 9 12 13 -1 4 13 -1 6 13 -1 5 0 14 13 -1 13 -1 8 2 13 -1 1 13 -1 3 10 13 -1
Spherical Random Features for Polynomial Kernels .	spherical random fourier features ; compact explicit feature maps ; low approximation error ; random fourier features ; non-linear classification ; classification accuracy ; kernel methods ; unit sphere ; polynomial kernels ; higher-order polynomials ; affirmative answer ; large-scale learning ; approximation paradigm ; kernel approximation	<method> <method> <otherscientificterm> <material> <task> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method>	1 0 11 ; 1 0 6 ; 13 0 9 ; 6 0 11 ; 3 0 10 ; 8 0 7	compact explicit feature <method_1> provide a practical framework to scale <method_6> to <task_11> , but deriving such <method_1> for many types of kernels remains a challenging open problem . among the commonly used kernels for <task_4> are <otherscientificterm_8> , for which <otherscientificterm_2> has thus far necessitated explicit feature <method_1> of large dimensionality , especially for <otherscientificterm_9> . meanwhile , because <otherscientificterm_8> are unbounded , <otherscientificterm_8> are frequently applied to data that has been normalized to unit 2 norm . the question we address in this work is : if we know a priori that data is normalized , can we devise a more compact map ? we show that a putative <otherscientificterm_10> to this question based on <material_3> is impossible in this setting , and introduce a new <method_12> , <method_0> , which circumvents these issues and delivers a compact approximation to <otherscientificterm_8> for data on the <otherscientificterm_7> . compared to prior work , <method_0> are less rank-deficient , more compact , and achieve better <method_13> , especially for <otherscientificterm_9> . the resulting predictions have lower variance and typically yield better <metric_5> .	1 6 11 15 16 18 14 -1 4 8 2 9 14 -1 14 -1 14 -1 10 3 12 0 7 19 20 14 -1 13 17 14 -1 5 14 -1
Trailer Generation via a Point Process-Based Visual Attractiveness Model .	self-correcting point process-based attractiveness model ; graph-based trailer generation algorithm ; automatic trailer generation ; max-attractiveness trailer ; training trailers ; attractiveness model ; trailer generation ; video summarization ; trailer generators ; quality	<method> <method> <task> <method> <method> <method> <task> <method> <method> <metric>	5 0 1 ; 1 0 3 ; 1 4 8	producing attractive trailers for videos needs human expertise and creativity , and hence is challenging and costly . different from <method_7> that focuses on capturing storylines or important scenes , <task_6> aims at producing trailers that are attractive so that viewers will be eager to watch the original video . in this work , we study the problem of <task_2> , in which an attractive trailer is produced given a video and a piece of music . we propose a sur-rogate measure of video attractiveness named fix-ation variance , and learn a novel <method_0> that can effectively describe the dynamics of attractiveness of a video . furthermore , based on the <method_5> learned from existing <method_4> , we propose an efficient <method_1> to produce a <method_3> . experiments demonstrate that our <method_1> outper-forms the state-of-the-art <method_8> in terms of both <metric_9> and efficiency .	10 -1 7 6 10 -1 2 10 -1 0 10 -1 11 12 10 -1 5 4 1 3 13 10 -1
Improving Users ' Demographic Prediction via the Videos They Talk about .	direct and indirect relationships ; demographic predictive ability ; actor names ; video names ; video keywords ; bayesian method ; video websites ; indirect relationship ; real-world dataset	<otherscientificterm> <metric> <otherscientificterm> <material> <otherscientificterm> <method> <material> <otherscientificterm> <material>	3 1 2 ; 2 1 4	in this paper , we improve microblog users ' demographic prediction via the videos they talk about . first , we collect the describing words of currently popular videos , including <material_3> , <otherscientificterm_2> and <otherscientificterm_4> , from <material_6> . next , we search these describing words in users ' microblogs , and build the direct relationships between users and the appeared words . after that , we propose a <method_5> to calculate the probability of connections between users and video describing words . if the probability is beyond a threshold , an <otherscientificterm_7> is founded . last , two models are built to predict users ' demographics with the obtained <otherscientificterm_0> . based on a large <material_8> , experiment results show that our <method_5> can significantly improve these words ' <metric_1> by more than 15 % on average .	9 -1 3 2 4 6 10 11 9 -1 9 -1 5 9 -1 7 9 -1 9 -1 0 9 -1
Domain adaptation with clustered language models .	` fillup ' method ; modied optimi-sation criterion ; ord error rate ; clustered language models ; n-gram models ; adaptation data ; domain adaptation ; clustering algorithm	<method> <otherscientificterm> <metric> <method> <method> <material> <method> <method>	1 0 7 ; 0 0 4 ; 6 0 3	in this paper , a method of <method_6> for <method_3> is developed . it is based on a previously developed <method_7> , but with a <otherscientificterm_1> . the results are shown to be slightly superior to the previously published <method_0> , which can be used to adapt standard <method_4> . however , the improvement both methods give compared to models built from scratch on the <material_5> is quite small -lrb- less than 11 % relative improvement i n w <metric_2> -rrb- . this suggests that both methods are still unsatisfactory from a practical point of view .	6 3 11 8 -1 7 1 9 8 -1 0 4 10 8 -1 5 2 8 -1 8 -1
Relaxed matching kernels for robust image comparison .	baseline bag-of-features algorithm ; information-compressed features ; object recognition ; bag-of-features representation ; features ; rmks	<method> <otherscientificterm> <task> <method> <otherscientificterm> <method>	3 0 2	the popular <method_3> for <task_2> collects signatures of local image patches and discards spatial information . some have recently attempted to at least partially overcome this limitation , for instance by '' spatial pyramids '' and '' proximity '' kernels . we introduce the general formalism of '' relaxed matching kernels '' -lrb- <method_5> -rrb- that includes such approaches as special cases , allow us to derive useful general properties of these kernels , and to introduce new ones . as an example , we introduce a kernel based on matching graphs of <otherscientificterm_4> and one based on matching <otherscientificterm_1> . we show that all <method_5> are competitive and outperform in several cases recently published state-of-the-art results on standard datasets . however , we also show that a proper implementation of a <method_0> can be extremely competitive , and outperform the other methods in some cases .	3 2 7 6 -1 6 -1 5 6 -1 4 1 6 -1 6 -1 6 -1
Solving Generalized Semi-Markov Decision Processes Using Continuous Phase-Type Distributions .	generalized semi-markov decision process ; smdp solution techniques ; stochastic decision processes ; phase-type distributions ; discrete-time mdp ; mdp techniques ; continuous-time mdps ; arbitrary gsmdp ; asynchronous events ; uniformization	<method> <method> <method> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <method>	3 1 9 ; 5 0 4 ; 5 0 0 ; 4 0 0	we introduce the <method_0> as an extension of <method_6> and semi-markov decision processes -lrb- <method_0> -rrb- for modeling <method_2> with <otherscientificterm_8> and actions . using <otherscientificterm_3> and <method_9> , we show how an <method_7> can be approximated by a <method_4> , which can then be solved using existing <method_5> . the techniques we present can also be seen as an alternative approach for solving <method_0> , and we demonstrate that the introduction of phases allows us to generate higher quality policies than those obtained by standard <method_1> .	0 6 2 8 10 -1 3 9 7 4 5 11 12 13 14 10 -1 1 10 -1
On tuning of self-quotient Œµ-filter and support vector machine and its application to noise robust human detection .	histograms of oriented gradients ; support vector machine ; self-quotient Œµ-filter ; noise robust human detection ; noise corrupted images ; manual parameter setting ; local intensity gradients ; human detection ; self-quotient Œµ-filter ; tuning algorithm ; noise ; images	<method> <method> <method> <task> <material> <material> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <material>	0 0 7 ; 2 1 0 ; 0 1 2 ; 2 1 1 ; 2 0 7 ; 8 0 2 ; 7 0 3 ; 11 0 2 ; 2 1 2 ; 5 0 2 ; 2 0 3 ; 0 0 3 ; 9 0 3	this paper introduces a <method_9> of <method_2> and <method_1> , and its application to <task_3> combining <method_2> , <method_0> , and <method_2> . although <task_7> combining <method_0> and <method_2> is a powerful approach , as it uses <otherscientificterm_6> , it is difficult to handle <material_4> . on the other hand , although <task_7> combining <method_2> , <method_0> and <method_2> can realize <task_3> , <method_2> requires <material_5> . our aim is not only to set the parameter of <otherscientificterm_8> but also to train <method_2> by using numerous <material_11> without <otherscientificterm_10> and a small amount of <material_11> with <otherscientificterm_10> .	9 2 1 3 0 16 25 12 -1 7 6 4 12 -1 5 13 14 15 17 19 21 22 23 24 12 -1 8 11 10 18 20 12 -1
Context-Based Pedestrian Path Prediction .	switching linear dynamical system ; spatial layout of the environment ; intelligent vehicle domain ; stereo vision data ; pedestrian head orientation ; dynamic bayesian network ; pedestrian path prediction ; pedestrian situational awareness ; computer vision ; crossing pedestrian ; situational awareness ; pedestrian dynamics ; path prediction ; spatial layout ; latent states ; situation criticality ; slds ; curbside	<method> <otherscientificterm> <task> <material> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	2 2 6 ; 7 1 15 ; 7 3 5 ; 15 1 1 ; 15 3 5 ; 5 0 6	we present a novel <method_5> for <task_6> in the <task_2> . the <method_5> incorporates the <otherscientificterm_7> , <otherscientificterm_15> and <otherscientificterm_1> as <otherscientificterm_14> on top of a <method_0> to anticipate changes in the <otherscientificterm_11> . using <method_8> , <otherscientificterm_10> is assessed by the <otherscientificterm_4> , <otherscientificterm_15> by the distance between vehicle and pedestrian at the expected point of closest <method_5> , and <otherscientificterm_13> by the distance of the pedestrian to the <otherscientificterm_17> . our particular scenario is that of a <otherscientificterm_9> , who might stop or continue walking at the curb . in experiments using <material_3> obtained from a vehicle , we demonstrate that the proposed <method_5> results in more accurate <task_12> than only <method_16> , at the relevant short time horizon -lrb- 1 s -rrb- , and slightly outperforms a computationally more demanding state-of-the-art method .	5 6 2 19 24 18 -1 7 15 1 14 0 11 20 21 22 23 18 -1 8 10 4 13 17 18 -1 9 18 -1 3 18 -1
On analyzing video with very small motions .	scene-specific non-parametric motion basis ; linear appearance variations ; dense flow estimates ; long-term point tracking ; appearance variations ; small motions ; pca decomposition ; motion segmentation ; scene motions ; scenes	<otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <material>	7 1 3 ; 5 2 9	we characterize a class of videos consisting of very small but potentially complicated motions . we find that in these <material_9> , <otherscientificterm_1> have a direct relationship to <otherscientificterm_8> . we show how to interpret <otherscientificterm_4> captured through a <method_6> of the image set as a <otherscientificterm_0> . we propose fast , robust tools for <task_2> that are effective in <material_9> with <otherscientificterm_5> and potentially large image noise . we show example results in a variety of applications , including <task_7> and <task_3> .	10 -1 9 1 8 10 -1 4 6 0 10 -1 2 5 12 10 -1 7 3 11 10 -1
Symmetric Sub-Pixel Stereo Matching .	continuous disparity space image ; textureless and occluded areas ; reconstructed image signals ; minimal smoothness assumptions ; global smoothness assumptions ; symmetric matching process ; stereo algorithm design ; integer disparities ; sub-pixel information ; stereo images ; matching criterion ; visibility constraints ; stereo algorithm ; matching	<otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <task>	10 3 6 ; 11 0 5	two central issues in <task_6> are the <otherscientificterm_10> and the underlying smoothness assumptions . in this paper we propose a new <method_12> with novel approaches to both issues . we start with a careful analysis of the properties of the <otherscientificterm_0> , and derive a new <task_13> cost based on the <material_2> . we then use a <method_5> that employs <otherscientificterm_11> to assign disparities to a large fraction of pixels with <otherscientificterm_3> . while the <task_13> operates on <otherscientificterm_7> , <otherscientificterm_8> is maintained throughout the process . <task_4> are delayed until a later stage in which disparities are assigned in <otherscientificterm_1> . we validate our <method_12> with experimental results on <material_9> with ground truth .	6 10 15 14 -1 12 14 -1 0 13 2 14 -1 5 11 3 16 14 -1 7 8 4 14 -1 14 -1 1 14 -1
Reduced Complexity and Scaling for Asynchronous HMMS in a Bimodal Input Fusion Application .	bimodal speech and gesture user input fusion task ; asynchronous hidden markov model ; absolute recognition performance ; audiovisual recognition tasks ; scaling procedure ; fusion hmm ; ahmm characteristics ; decoding complexity ; numerical values ; complexity	<task> <method> <metric> <task> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <metric>	1 0 3 ; 4 0 8	the <method_1> can <method_1> the joint likelihood of two observation sequences , even if the streams are not synchronised . previously this <method_1> has been applied to <task_3> . the main drawback of the concept is its rather high training and <metric_7> . in this work we show how the <metric_9> can be reduced significantly with advanced running indices for the calculations . yet , the <otherscientificterm_6> and its advantages are preserved . the improvement also allows a <method_4> to keep <otherscientificterm_8> in a reasonable range . in an experimental section we compare the <metric_9> of the original and the improved concept and validate the theoretical results . then the <method_1> is tested on a <task_0> : compared to a late <method_5> an improvement of more than 10 % <metric_2> has been achieved .	1 10 -1 3 11 10 -1 7 10 -1 9 10 -1 6 10 -1 4 8 12 10 -1 10 -1 10 -1
Training audio events detectors with a sound effects corpus .	detection of non-voice sounds ; one-against-all svm classi-fiers ; audio event detection ; audio events ; birds ; traffic ; machines	<task> <method> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	4 6 0 ; 4 1 6 ; 6 6 0 ; 6 1 5 ; 4 1 5	this paper describes the work done in the framework of the vidivideo european project in terms of <task_2> . our first experiments concerned the <task_0> , such as <otherscientificterm_4> , <otherscientificterm_6> , <otherscientificterm_5> , water and steps . given the unavailability of a corpus labelled in terms of <material_3> , we used a relatively small sound effect corpus for training . our initial experiments with <method_1> for these 5 classes showed us the feasibility of using this type of data for training , thus avoiding the extremely morose task of manual labelling of a very high number of <material_3> . preliminary integration experiments are quite promising .	2 7 -1 0 4 6 5 8 9 10 11 12 7 -1 3 7 -1 1 7 -1 7 -1
Robust Tracking of Multiple Sound Sources by Spatial Integration of Room And Robot Microphone Arrays .	2d sound source localization ; weighted delay-and-sum beamforming method ; particle filter based integration ; 2d sound source tracking ; sound source tracking ; multiple sound sources ; room microphone array ; sound source tracking ; robot microphone array ; robot head ; localization errors ; sound event ; environmental sounds ; sound sources ; particle filter ; robot ; azimuth ; room	<method> <method> <task> <task> <task> <material> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 0 ; 2 0 3 ; 12 6 11 ; 7 0 15 ; 14 0 5	sound source tracking is an important function for a <otherscientificterm_15> operating in a daily environment , because the <otherscientificterm_15> should recognize where a <otherscientificterm_11> such as speech , music and other <otherscientificterm_12> originates from . this paper addresses <task_4> by integrating a <otherscientificterm_17> and a <method_8> . the <otherscientificterm_6> consists of 64 microphones attached to the walls . it provides <method_0> based on a <method_1> . the <method_8> consists of eight microphones installed on a <otherscientificterm_9> , and localizes <material_5> in <otherscientificterm_16> . the lo-calization results are integrated to track <material_13> by using a <method_14> for <material_5> . the experimental results show that <task_2> reduces <otherscientificterm_10> and provides accurate and robust <task_3> .	15 11 12 21 22 18 -1 4 17 8 18 -1 6 18 -1 0 1 19 18 -1 9 5 16 18 -1 13 14 23 18 -1 20 18 -1
Reasoning About General Games Described in GDL-II .	game description language ; sound and complete reasoning method ; game description language ; arbitrary games ; reasoning challenge ; situation calculus ; action formalisms ; human intervention ; in-complete/imperfect information ; learning	<method> <method> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method>	2 0 5 ; 5 6 6	recently the general <method_0> has been extended so as to cover <otherscientificterm_3> with <otherscientificterm_8> . <method_9> -- without <otherscientificterm_7> -- to play such games poses a <task_4> for general game-playing systems that is much more intricate than in case of complete information games . <method_6> like the <method_5> have been developed for precisely this purpose . in this paper we present a full embedding of the <method_2> into the <method_5> -lrb- with scherl and levesque 's knowledge fluent -rrb- . we formally prove that this provides a <method_1> for players ' knowledge about game states as well as about the knowledge of the other players .	0 3 8 9 10 -1 7 4 6 10 -1 5 12 10 -1 2 11 10 -1 1 10 -1
Revisiting the security of speaker verification systems against imposture using synthetic speech .	speaker verification ; false acceptance rate ; hmm-based speech synthesizer ; human speech ; synthesized speech ; sv systems ; two-step process ; synthetic speech ; background model ; speech synthesis ; svm-based ; imposture ; accuracy ; gmm-ubm-based	<task> <metric> <method> <material> <material> <method> <method> <material> <method> <task> <method> <otherscientificterm> <metric> <method>	13 6 5 ; 13 1 10 ; 7 0 11 ; 0 1 9 ; 2 0 7 ; 10 6 5	in this paper , we investigate <otherscientificterm_11> using <material_7> . although this problem was first examined over a decade ago , dramatic improvements in both <task_0> and <task_9> have renewed interest in this problem . we use a <method_2> which creates <material_7> for a targeted speaker through adaptation of a <method_8> . we use two <method_5> : standard <method_13> and a newer <method_10> . our results show when the systems are tested with <material_3> , there are zero false acceptances and zero false rejections . however , when the systems are tested with <material_4> , all claims for the targeted speaker are accepted while all other claims are rejected . we propose a <method_6> for detection of <material_4> in order to prevent this <otherscientificterm_11> . overall , while <method_5> have impressive <metric_12> , even with the proposed detector , high-quality <material_7> will lead to an unacceptably high <metric_1> .	11 7 17 14 -1 0 9 18 14 -1 2 8 19 14 -1 5 13 10 15 16 20 14 -1 3 14 -1 4 14 -1 14 -1 6 14 -1
On the relationship between phonetic modeling precision and phonetic speaker recognition accuracy .	nist 2005 speaker recognition evaluation ; phonetic speaker recognition accuracy ; phonetic speaker recognition ; statistical language models ; speaker recognition techniques ; phonetic modeling precision ; phonetic decodings ; speaker recognition ; accuracy	<task> <metric> <task> <method> <method> <metric> <method> <task> <metric>	8 5 2 ; 6 0 2 ; 5 1 1 ; 5 1 8 ; 5 1 2	speaker recognition techniques have traditionally relied on purely acoustic features and models . during the last few years , however , the field of <task_7> has started to show interest in the use of higher level features . in particular , <method_6> modeled with <method_3> -lrb- n-grams -rrb- have already shown its effectiveness in several research works . however , the relationship between <metric_5> and the <metric_8> of <task_2> has not yet been sufficiently analyzed . as part of our preparation for the <task_0> , we have performed a number of experiments that show that there is a negligible correlation between <metric_5> and <metric_1> . furthermore , our experimental results show that <task_2> results may even be better when using <method_6> in languages different from that of the speech .	9 -1 7 9 -1 6 3 9 -1 5 8 2 10 13 14 9 -1 0 12 9 -1 1 11 9 -1
Adaptation of Precision Matrix Models on Large Vocabulary Continuous Speech Recognition .	minimum phone error discriminative training ; diagonal covariance matrix models ; structured precision matrix models ; precision and mean models ; expectation maximisation framework ; row-by-row iterative formulae ; broadcast news ; adaptation techniques ; adaptation data	<method> <method> <method> <method> <method> <method> <material> <method> <material>	5 3 4 ; 2 0 1 ; 7 0 1	recently , <method_2> were found to outper-form the conventional <method_1> . <method_0> of these <method_1> gave very good unadapted performance on large vocabulary continuous speech recognition systems . to obtain state-of-the-art performance , it is important to apply <method_7> efficiently to these <method_1> . in this paper , simple <method_5> are described for both mllr mean and constrained mllr transform estimations of these <method_1> . these update formulae are derived within the standard <method_4> and are guaranteed to increase the likelihood of the <material_8> . efficient approximate schemes for these <method_7> are also investigated to further reduce the computation . experimental results are presented based on the mpe trained subspace for <method_3> , evaluated on both <material_6> and conversational telephone speech english tasks .	2 1 0 11 9 -1 9 -1 7 12 9 -1 5 9 -1 4 8 10 9 -1 9 -1 9 -1
Minivectors : an improved GMM-SVM approach for speaker verification .	kharroubi 's system ; speaker verification algorithms ; speaker verification systems ; run time ; supervectors algorithm ; accuracy levels ; real-life applications ; speaker models	<method> <method> <method> <metric> <method> <metric> <task> <method>	5 5 2	the <metric_5> achieved by state-of-the-art <method_2> are high enough for the technology to be used in <task_6> . unfortunately , the transfer from the lab to the field is not as straightforward as could be : the best performing systems can be computationally expensive to run and need large speaker model footprints . in this paper , we compare two <method_1> -lrb- gmm-svm su-pervectors and kharroubi 's gmm-svm vectors -rrb- and propose an improvement of <method_0> that : -lrb- a -rrb- achieves up to 17 % relative performance improvement when compared to the <method_4> ; -lrb- b -rrb- is 24 % faster in <metric_3> and -lrb- c -rrb- makes use of <method_7> that are 94 % smaller than those needed by the <method_4> .	5 2 6 9 8 -1 8 -1 1 0 4 8 -1
Speech recognition with phonological features : some issues to attend .	acoustic and the linguistic level ; articulatory feature driven system ; acoustic-phonetic or articulatory features ; acoustic and articulatory information ; articulatory driven asr system ; automatic speech recognition ; acoustic features ; articulatory features ; phonetic unit ; asr	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	3 0 9 ; 6 0 4 ; 2 0 5	it is often argued that <otherscientificterm_2> could be beneficial to <task_5> because <otherscientificterm_2> provide a convenient interface between the <otherscientificterm_0> . former research has shown that a combination of <otherscientificterm_3> can lead to improved <task_9> . however there exists no purely <method_4> that outper-forms state-of-the-art systems driven by <otherscientificterm_6> . in this paper we propose a novel method for improving <task_9> on the basis of <otherscientificterm_7> . it is designed to take account of -lrb- 1 -rrb- the correlations between <otherscientificterm_7> and -lrb- 2 -rrb- the fact that not all <otherscientificterm_7> are relevant for the description of a certain <otherscientificterm_8> . we also investigate to what extend an acoustic and an <method_1> make different errors .	2 5 0 13 10 -1 3 9 11 10 -1 4 6 12 10 -1 7 10 -1 8 10 -1 10 -1
Warped Magnitude and Phase-Based Features for Language Identification .	modified group delay function coefficients ; gaussian mixture model based system ; regression-based shifted delta cepstrum ; identification of spoken languages ; language identification systems ; ogi ts corpus ; magnitude-based parameterization methods ; magnitude-based features ; sdc configuration ; feature warping ; modgdf ; mfcc ; accuracy	<method> <method> <material> <task> <method> <material> <method> <otherscientificterm> <method> <method> <method> <method> <metric>	2 6 6 ; 2 1 9 ; 9 0 7 ; 11 6 6 ; 6 0 3 ; 12 5 4 ; 0 4 4 ; 9 1 0 ; 5 5 0 ; 5 5 4 ; 11 1 2 ; 7 3 1 ; 2 0 1 ; 0 0 1	to date , systems for the <task_3> have normally used <method_6> such as the <method_11> and <material_2> . this paper investigates the use of the recently proposed <method_0> in combination with traditional <otherscientificterm_7> in a <method_1> . we also examine the application of <method_9> to <otherscientificterm_7> and the <method_10> and find that it can offer a significant cumulative improvement . we find that the addition of a modified <material_2> further improves <method_1> performance beyond that obtained by a more standard <method_8> . the combination of <material_2> , <method_9> and the proposed <method_0> achieved an <metric_12> of 88.4 % in tests on 10 languages in the <material_5> , which compares very favourably with alternative <method_4> reported in the literature .	3 6 11 2 14 17 18 24 13 -1 0 7 1 25 27 13 -1 9 10 16 13 -1 8 26 13 -1 12 15 19 20 21 22 23 13 -1
Fast Rates for Exp-concave Empirical Risk Minimization .	empirical risk minimization ; linear and logistic regression ; fast generalization rates ; general optimization framework ; learning svms ; learning problems ; online algorithms ; squared hinge-loss ; portfolio selection ; stochastic optimization	<method> <task> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <method> <task>	0 0 9 ; 7 1 8 ; 1 6 5 ; 8 6 5 ; 8 1 4 ; 4 6 5	we consider <method_0> in the context of <task_9> with exp-concave and smooth losses -- a <method_3> that captures several important <task_5> including <task_1> , <method_4> with the <otherscientificterm_7> , <method_8> and more . in this setting , we establish the first evidence that <method_0> is able to attain <otherscientificterm_2> , and show that the expected loss of the <method_0> in d dimensions converges to the optimal expected loss in a rate of d/n . this rate matches existing lower bounds up to constants and improves by a log n factor upon the state-of-the-art , which is only known to be attained by an online-to-batch conversion of computationally expensive <method_6> .	0 9 3 5 1 4 7 8 11 12 13 14 15 16 10 -1 2 10 -1 10 -1
Symmetry-preserving reversible integer-to-integer wavelet transforms .	lifting-based families of symmetry-preserving reversible integer-to-integer wavelet transforms ; treatment of arbitrary length signals ; constant per-lifting-step extension ; rounding functions ; symmetric extension	<otherscientificterm> <task> <method> <otherscientificterm> <method>	4 4 2	studied are two <otherscientificterm_0> . the transforms from both of these families are shown to be compatible with <method_4> , which permits the <task_1> in a nonexpansive manner . throughout this work , particularly close attention is paid to <otherscientificterm_3> , and the properties that they must possess in various instances . <method_4> is also shown to be equivalent to <method_2> in certain circumstances .	0 5 -1 4 1 5 -1 3 5 -1 2 6 5 -1
Identifying Protein-Protein Interaction Sites on a Genome-Wide Scale .	high-throughput protein interaction data ; drug and protein design ; short sequence motifs ; probabilistic relational model ; protein interactions ; branch-and-bound algorithm ; interacting proteins ; physical interaction ; protein-protein interactions ; em algorithm ; active motifs ; computational method ; approximate inference ; motifs ; e-step	<material> <task> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	9 0 11 ; 11 0 8 ; 5 0 11 ; 0 1 2 ; 2 0 11 ; 3 0 11 ; 0 0 11 ; 11 0 13 ; 12 0 14 ; 0 0 3	protein interactions typically arise from a <otherscientificterm_7> of one or more small sites on the surface of the two proteins . identifying these sites is very important for <task_1> . in this paper , we propose a <method_11> based on <method_3> that attempts to address this task using <material_0> and a set of <material_2> . we learn the <method_11> using the <method_9> , with a <method_5> as an <otherscientificterm_12> for the <method_14> . our <method_11> searches for <otherscientificterm_13> whose presence in a pair of <otherscientificterm_6> can explain their observed interaction . it also tries to determine which motif pairs have high affinity , and can therefore lead to an interaction . we show that our <method_11> is more accurate than others at predicting new <otherscientificterm_8> . more importantly , by examining solved structures of protein complexes , we find that 2/3 of the predicted <otherscientificterm_10> correspond to actual interaction sites .	7 15 -1 1 15 -1 11 3 0 2 19 20 21 22 25 15 -1 9 5 12 14 16 18 24 15 -1 13 6 23 15 -1 15 -1 17 15 -1 8 15 -1
A fully data parallel WFST-based large vocabulary continuous speech recognition on a graphics processing unit .	large vocabulary continuous speech recognition ; graphics processing units ; personal desktop and laptop systems ; data parallel programming model ; communication-intensive graph traver-sal phase ; communication-intensive graph traversal phase ; speech data set ; close-to-peak execution efficiency ; speech inference engine ; intel core i7 ; data parallel execution ; inference process ; redundant computation ; sequential implementation ; application-level trade-offs ; accuracy	<task> <method> <otherscientificterm> <method> <task> <task> <material> <metric> <method> <material> <task> <method> <otherscientificterm> <method> <otherscientificterm> <metric>	14 0 10	tremendous compute throughput is becoming available in <otherscientificterm_2> through the use of <method_1> . however , exploiting this resource requires re-architecting an application to fit a <method_3> . the complex graph traversal routines in the <method_11> for <task_0> have been considered by many as unsuitable for extensive parallelization . we explore and demonstrate a fully data parallel implementation of a <method_8> on nvidia 's gtx280 gpu . our implementation consists of two phases-compute-intensive observation probability computation phase and <task_4> . we take advantage of dynamic elimination of <otherscientificterm_12> in the compute-intensive phase while maintaining <metric_7> . we also demonstrate the importance of exploring <otherscientificterm_14> in the <task_5> to adapt the algorithm to <task_10> on gpus . on 3.1 hours of <material_6> , we achieve more than 11 √ó speedup compared to a highly optimized <method_13> on <material_9> without sacrificing <metric_15> .	2 1 16 -1 3 16 -1 11 0 16 -1 8 16 -1 4 16 -1 12 7 16 -1 17 16 -1 14 5 10 16 -1
Correlated Bigram LSA for Unsupervised Language Model Adaptation .	relative character error rate reduction ; word error rate reduction ; bootstrapping of bigram lsa ; correlated bigram lsa approach ; mandarin rt04 test set ; automatic speech recognition ; background n-gram lm ; fractional kneser-ney smoothing ; unsupervised lm adaptation ; relative perplexity reduction ; variational em ; fractional counts ; linear interpolation ; unigram lsa ; bigram lsa ; lm adaptation ; marginal adaptation ; large-scale evaluation ; arabic ; unigram	<metric> <metric> <method> <method> <material> <task> <method> <method> <task> <metric> <method> <otherscientificterm> <method> <method> <method> <task> <method> <task> <material> <otherscientificterm>	3 0 5 ; 7 0 11 ; 10 0 3 ; 19 1 14 ; 0 5 13 ; 9 1 0 ; 13 0 2 ; 7 0 3 ; 16 1 12 ; 3 0 8 ; 8 0 5	we present a <method_3> for <task_8> for <task_5> . the <method_3> is trained using efficient <method_10> and smoothed using the proposed <method_7> which handles <otherscientificterm_11> . we address the scalability issue to large training corpora via <method_2> from <method_13> . for <task_15> , <otherscientificterm_19> and <method_14> are integrated into the <method_6> via <method_16> and <method_12> respectively . experimental results on the <material_4> show that applying <otherscientificterm_19> and <method_14> together yields 6 % -- 8 % <metric_9> and 2.5 % <metric_0> which is statistically significant compared to applying only <method_13> . on the <task_17> on <material_18> , <metric_1> from <method_14> is statistically significant compared to the unadapted baseline .	3 8 5 21 30 31 20 -1 10 7 11 22 23 28 20 -1 2 13 27 20 -1 15 19 14 6 16 12 24 29 20 -1 4 9 0 25 26 20 -1 17 18 1 20 -1
On the Role of Domain Knowledge in Analogy-Based Story Generation .	analogy-based story generation ; case-based reasoning ; ai techniques ; knowledge container ; computational narrative ; story generation ; domain knowledge	<task> <method> <method> <otherscientificterm> <task> <task> <otherscientificterm>	6 3 0 ; 6 0 5	computational narrative is a complex and interesting domain for exploring <method_2> that algo-rithmically analyze , understand , and most importantly , generate stories . this paper studies the importance of <otherscientificterm_6> in <task_5> , and particularly in <task_0> . based on the construct of <otherscientificterm_3> in <method_1> , we present a theoretical framework for incorporating <otherscientificterm_6> in <task_0> . we complement the framework with empirical results in our existing system riu .	2 7 -1 6 5 0 9 7 -1 3 1 8 7 -1 4 7 -1
Independent Vector Analysis using Non-Spherical Joint Densities for the Separation of Speech Signals .	vector representation of the source signal ; spherical joint density representations ; separation of convolved sources ; blind source separation approach ; non-spherical joint density model ; multidimensional joint densities ; frequency domain methods ; inherent signal dependencies ; convolved mixture problem ; uniform dependencies ; frequency bins ; speech signals ; permutation problem ; spherical distributions	<method> <method> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	3 0 7 ; 6 0 8 ; 3 4 1	we propose a new <method_3> that models the <otherscientificterm_7> such as those observed in <otherscientificterm_11> in order to solve the problem of separating convolved sources . the <method_6> for the <task_8> require a solution to the well-known <task_12> . our <method_3> is based on assuming a <method_0> where its <otherscientificterm_5> are non-spherical . <otherscientificterm_13> may be adequate for signals that exhibit <otherscientificterm_9> across frequencies but in case of <otherscientificterm_11> we can observe stronger dependencies for neighboring <otherscientificterm_10> and almost no dependency for <otherscientificterm_10> that are far apart . the <method_4> takes into account this phenomenon . for the <task_2> , the proposed <method_3> demonstrates consistent performance over previous methods and improved performance over the <method_1> .	3 7 11 15 14 -1 6 8 12 16 14 -1 0 5 13 14 -1 9 10 14 -1 4 14 -1 2 17 14 -1
Measuring Importance and Query Relevance in Topic-focused Multi-document Summarization .	query focused multi-document summarization ; raw frequency ; summarization systems ; query-focused summarization ; log-likelihood ratio ; llr ; modules	<task> <material> <method> <task> <otherscientificterm> <method> <otherscientificterm>	5 0 3	the increasing complexity of <method_2> makes <method_5> difficult to analyze exactly which <otherscientificterm_6> make a difference in performance . we carried out a principled comparison between the two most commonly used schemes for assigning importance to words in the context of <task_0> : <material_1> -lrb- word probability -rrb- and <otherscientificterm_4> . we demonstrate that the advantages of <otherscientificterm_4> come from its known dis-tributional properties which allow for the identification of a set of words that in its entirety defines the aboutness of the input . we also find that <method_5> is more suitable for <task_3> since , unlike <material_1> , <method_5> is more sensitive to the integration of the information need defined by the user .	2 5 6 7 -1 0 1 4 7 -1 7 -1 3 8 7 -1
Prime Compilation of Non-Clausal Formulae .	conjunctive/disjunctive normal form representation ; propositional satisfiability solving ; compilation of non-clausal formu-lae ; compilation of non-clausal formulae ; non-clausal formulae of size ; non-clausal form ; propositional formulae ; cnf formula ; formula compilation ; ai	<method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <task>	0 0 8	formula compilation by generation of prime implicates or implicants finds a wide range of applications in <task_9> . recent work on <task_8> by prime implicate/implicant generation often assumes a <method_0> . however , in many settings <otherscientificterm_6> are naturally expressed in <otherscientificterm_5> . despite a large body of work on <task_3> , in practice existing approaches can only be applied to fairly small formulae , containing at most a few hundred variables . this paper describes two novel approaches for the <task_2> either with prime implicants or implicates , that is based on <method_1> . these novel algorithms also find application when computing all prime implicates of a <method_7> . the proposed approach is shown to allow the <task_3> of size significantly larger than existing approaches .	9 10 -1 8 0 11 10 -1 6 5 10 -1 3 10 -1 2 1 10 -1 10 -1 7 10 -1
Hybrid Stochastic / Deterministic Optimization for Tracking Sports Players and Pedestrians .	baseline tracking-by-detection approaches ; missed detections ; ` tracking-by-detection ; mcmcda techniques ; detection configurations ; object detectors ; object trajectories ; multi-target scenarios ; detection hypothesis ; deterministic computation ; stochastic search ; sampler ; rjmcmc	<method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <method>	12 0 10	although <method_2> ' is a popular approach when reliable <method_5> are available , <method_1> remain a difficult hurdle to overcome . we present a hybrid stochastic/deterministic optimization scheme that uses <method_12> to perform <task_10> over the space of <otherscientificterm_4> , interleaved with <method_9> of the optimal multi-frame data association for each proposed <method_8> . since <otherscientificterm_6> do not need to be estimated directly by the <method_11> , our approach is more efficient than traditional <method_3> . moreover , our holistic formulation is able to generate longer , more reliable trajectories than <method_0> in challenging <otherscientificterm_7> .	2 5 1 13 -1 12 10 4 9 8 14 13 -1 6 11 3 13 -1 0 7 13 -1
Cross-Domain Matching for Bag-of-Words Data via Kernel Embeddings of Latent Distributions .	kernel embeddings of distributions ; multilingual wikipedia articles ; shared latent space ; multiset of features ; bag-of-words representation ; kernel-based method ; multilingual documents ; cross-domain relationships ; features ; documents ; embedding ; images	<method> <material> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <otherscientificterm> <material> <task> <material>	4 6 3 ; 6 1 11 ; 4 0 9	we propose a <method_5> for finding matching between instances across different domains , such as <material_6> and <material_11> with annotations . each instance is assumed to be represented as a <otherscientificterm_3> , e.g. , a <method_4> for <material_9> . the major difficulty in finding <otherscientificterm_7> is that the similarity between instances in different domains can not be directly measured . to overcome this difficulty , the proposed <method_5> embeds all the <otherscientificterm_8> of different domains in a <otherscientificterm_2> , and regards each instance as a distribution of its own <otherscientificterm_8> in the <otherscientificterm_2> . to represent the distributions efficiently and nonparametrically , we employ the framework of the <method_0> . the <task_10> is estimated so as to minimize the difference between distributions of paired instances while keeping unpaired instances apart . in our experiments , we show that the proposed <method_5> can achieve high performance on finding correspondence between <material_1> , between <material_9> and tags , and between <material_11> and tags .	5 6 11 14 12 -1 3 4 9 13 15 12 -1 7 12 -1 8 2 12 -1 12 -1 0 12 -1 10 12 -1
On the success of network inference using a markov routing model .	network topology inference algorithm ; markov random walk model ; real network routing ; network co-occurrence measurements ; seeming model mismatch ; topology reconstruction ; routing	<method> <method> <task> <method> <otherscientificterm> <task> <task>	1 0 6 ; 1 0 0 ; 6 0 5 ; 3 1 1 ; 0 0 5 ; 3 0 0 ; 0 0 6	in this paper we discuss why a simple <method_0> based on <method_3> and a <method_1> for <task_6> enables perfect <task_5> , despite the <otherscientificterm_4> to <task_2> .	0 3 1 6 5 4 2 8 9 10 11 12 13 14 7 -1
Computationally Efficient Nystr√∂m Approximation using Fast Transforms .	low-rank kernel matrix approximations ; structured landmark points ; kernel svm prediction ; computing kernel values ; linear svm prediction ; nystr√∂m method ; webspam data ; kernel machines ; prediction time ; time complexity ; fast transforms ; nystr√∂m approximation ; large-scale applications ; kernel values ; kernel approximation ; lib-svm ; accuracy	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <material> <method> <otherscientificterm> <metric> <method> <method> <task> <otherscientificterm> <task> <method> <metric>	15 4 4 ; 8 4 4 ; 1 0 11 ; 16 5 4 ; 10 0 1 ; 11 0 12 ; 14 0 7	our goal is to improve the training and <otherscientificterm_8> of <method_5> , which is a widely-used technique for generating <otherscientificterm_0> . when applying the <method_11> for <task_12> , both training and <otherscientificterm_8> is dominated by <otherscientificterm_3> between a data point and all landmark points . with m landmark points , this computation requires Œ∏ -lrb- md -rrb- time -lrb- flops -rrb- , where d is the input dimension . in this paper , we propose the use of a family of <method_10> to generate <otherscientificterm_1> for <method_11> . by exploiting <method_10> , e.g. , haar transform and hadamard transform , our modified <method_5> requires only Œ∏ -lrb- m -rrb- or Œ∏ -lrb- m log d -rrb- time to compute the <otherscientificterm_13> between a given data point and m landmark points . this improvement in <metric_9> can significantly speed up <task_14> and benefit prediction speed in <method_7> . for instance , on the <material_6> -lrb- more than 300,000 data points -rrb- , our proposed algorithm enables <method_2> to deliver 98 % <metric_16> and the resulting <otherscientificterm_8> is 1000 times faster than <method_15> and only 10 times slower than <method_4> -lrb- which yields only 91 % <metric_16> -rrb- .	8 5 0 17 -1 11 12 3 23 17 -1 17 -1 10 1 20 22 17 -1 17 -1 13 24 17 -1 9 14 7 18 19 21 17 -1
High Dimensional Structured Superposition Models .	gaussian widths of suitable sets ; high dimensional superposition models ; componentwise estimation error ; generic chaining ; geometric condition ; sample complexity ; statistical analysis ; superposition models ; empirical processes ; sparse matrices ; low rank	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <method> <method> <otherscientificterm> <otherscientificterm>	8 1 3 ; 3 0 6	high dimensional <method_7> characterize observations using parameters which can be written as a sum of multiple component parameters , each with its own structure , e.g. , sum of <otherscientificterm_10> and <otherscientificterm_9> , sum of sparse and rotated sparse vectors , etc. . in this paper , we consider general <method_7> which allow sum of any number of component parameters , and each component structure can be characterized by any norm . we present a simple estimator for such models , give a <otherscientificterm_4> under which the components can be accurately estimated , characterize <metric_5> of the estimator , and give high probability non-asymptotic bounds on the <otherscientificterm_2> . we use tools from <method_8> and <method_3> for the <method_6> , and our results , which substantially generalize prior work on <method_7> , are in terms of <otherscientificterm_0> .	7 10 9 11 -1 11 -1 4 5 11 -1 2 12 13 11 -1
Detection of upper airway narrowing via classification of LPC coefficients : Implications for obstructive sleep apnea diagnosis .	low and high r au conditions ; ua resistance -lrb- r au -rrb- ; obstructive sleep apnea ; unvoiced speech sounds ; turbulent breath sounds ; turbulent inspiratory sounds ; breath sounds analysis ; breath sounds recording ; r au status ; linear prediction coding ; ua narrowing ; sound characteristics ; objective indicator ; distinct clusters	<otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <material> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm>	12 1 10 ; 5 0 9 ; 1 0 6 ; 12 0 6 ; 4 0 11 ; 3 1 4	the similarities between <material_3> and <otherscientificterm_4> were used to detect change in <otherscientificterm_11> caused by narrowing of the upper airway -lrb- ua -rrb- , similar to that occurring in <otherscientificterm_2> . in 18 awake subjects , <task_1> , an index of <method_10> , was measured simultaneously with <method_7> . <method_9> was applied on <material_5> drawn from <otherscientificterm_0> and k-means was used to cluster the resulting coefficients . the resulting 2 clusters were tested for agreement with the underlying <otherscientificterm_8> . <otherscientificterm_13> were formed when r ua increased relatively high but not in cases with lower rise in r ua -lrb- p < 0.01 for all indicators . -rrb- this is the first work to show the utility of <task_1> in <task_6> confirmed by an <method_12> or <method_10> .	3 4 11 2 19 20 14 -1 1 10 7 9 14 -1 5 0 16 14 -1 8 13 14 -1 14 -1 15 17 18 14 -1
A unified approach to real time audio-to-score and audio-to-audio alignment using sequential Montecarlo inference techniques .	hidden markov model-dynamic time warping based systems ; real time alignment of music signals ; sequential montecarlo inference techniques ; audio-to-score and audio-to-audio alignment ; state tracking ; alignment problem ; hidden state ; dynamical system	<method> <task> <method> <task> <method> <task> <otherscientificterm> <method>	4 0 5 ; 7 0 5	we present a methodology for the <task_1> using <method_2> . the <task_5> is formulated as the <method_4> of a <method_7> , and differs from traditional <method_0> in that the <otherscientificterm_6> is continuous rather than discrete . the major contribution of this paper is addressing both problems of <task_3> within the same framework in a real time setting . performances of the proposed methodology on both problems are then evaluated and discussed .	1 2 8 -1 5 4 7 0 6 9 10 8 -1 3 8 -1 8 -1
Duals , Invariants , and the Recognition of Smooth Objects from their Occlucing Contours .	planar slices of the dual surface ; recognizing complex 3-d objects ; object representation scheme ; weak perspective projection ; 3-d surface ; image contours ; real images ; synthetic examples ; smooth surface ; viewing directions ; geometric relation ; occluding contours ; images	<otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	5 0 2 ; 8 0 10 ; 7 0 2 ; 3 2 12 ; 7 1 5	this paper presents a new <otherscientificterm_10> between a solid bounded by a <otherscientificterm_8> and its silhouette in <material_12> formed under <otherscientificterm_3> . the relation has the potential to be used for <task_1> from a single image . objects are mod-eled by showing them to a camera without any knowledge of their motion . the main idea is to consider the dual of the <otherscientificterm_4> and the family of dual curves of the silhouettes over all <otherscientificterm_9> . <otherscientificterm_11> correspond to <otherscientificterm_0> . we introduce an affine-invariant representation of this surface that can constructed from a sequence of <material_12> and allows an object to be recognized from arbitrary <otherscientificterm_9> . we illustrate the proposed <method_2> through <material_7> and <otherscientificterm_5> detected in <material_6> .	10 8 12 3 15 17 13 -1 1 13 -1 13 -1 4 9 11 13 -1 0 13 -1 13 -1 14 16 18 13 -1
Speechbuilder : facilitating spoken dialogue system development .	mixed-initiative spoken dialogue systems ; spoken dialogue interfaces ; human language interfaces ; human language technology ; linguistic information ; relational database ; transaction-based applications ; structured information ; speech-builder	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <task> <otherscientificterm> <method>	2 0 6	in this paper we report our attempts to facilitate the creation of <method_0> for both novice and experienced developers of <method_3> . our efforts have resulted in the creation of a utility called <method_8> , which allows developers to specify <otherscientificterm_4> about their domains , and rapidly create <otherscientificterm_1> to them . <method_8> has been used to create domains providing access to <otherscientificterm_7> contained in a <material_5> , as well as to provide <otherscientificterm_2> to control or <task_6> .	0 3 9 -1 8 4 1 9 -1 7 5 2 6 10 9 -1
Simultaneous Compaction and Factorization of Sparse Image Motion Matrices .	image coordinates of point features ; regularization of feature trajectories ; history-sensitive feature reinitialization method ; clean column merging ; temporary tracking failure ; matrix factorization methods ; missing matrix entries ; 3d reconstruction ; image noise ; temporary occlusions ; tracking systems ; motion segmentation ; feature snapping ; matrix factorization ; sparse matrices ; object geometry ; compaction ; factorization ; pose ; lighting ; feature ; appearance ; trackers ; columns ; matrices	<otherscientificterm> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	9 1 19 ; 16 1 22 ; 16 1 17 ; 5 0 11 ; 7 1 11 ; 9 1 8 ; 5 0 7 ; 11 1 1	matrices that collect the <otherscientificterm_0> tracked through video -- one column per <otherscientificterm_20> -- have often low rank , either exactly or approximately . this observation has led to many <method_5> for <task_7> , <task_11> , or <task_1> . however , <otherscientificterm_9> , <otherscientificterm_8> , and variations in <otherscientificterm_19> , <otherscientificterm_18> , or <otherscientificterm_15> often confound <method_22> . a <otherscientificterm_20> that reappears after a <otherscientificterm_4> -- whatever the cause -- is regarded as a new <otherscientificterm_20> by typical <method_10> , resulting in very <otherscientificterm_14> with many <otherscientificterm_23> and rendering <method_17> problematic . we propose a method to simultaneously factor and compact such a <method_5> by merging groups of <otherscientificterm_23> that correspond to the same <otherscientificterm_20> into single <otherscientificterm_23> . this combination of <otherscientificterm_16> and <method_17> makes <method_22> more resilient to changes in <otherscientificterm_21> and short occlusions . preliminary experiments show that imputation of <otherscientificterm_6> -- and therefore <method_13> -- becomes significantly more reliable as a result . <method_3> also required us to develop a <method_2> we call <method_12> that aligns merged <otherscientificterm_20> trajectory segments precisely to each other .	0 20 25 -1 5 7 11 1 29 30 32 33 25 -1 9 8 19 18 15 22 26 31 25 -1 4 10 14 23 17 25 -1 25 -1 27 28 25 -1 16 21 25 -1 6 13 3 25 -1
Autocalibrated signal reconstruction from linear measurements using adaptive GAMP .	joint gain calibration ; underdetermined linear measurements ; 1-based approach ; signal estimation ; sparse recovery ; adaptive gamp ; message-passing algorithm ; oracle gamp ; measurement system	<task> <otherscientificterm> <method> <task> <task> <method> <method> <method> <method>	5 4 2 ; 5 6 6 ; 5 0 4 ; 0 1 3 ; 6 0 0	in this paper , we reconstruct signals from <otherscientificterm_1> where the componentwise gains of the <method_8> are unknown a priori . the reconstruction is performed through an adaptation of the <method_6> called <method_5> that enables <task_0> and <task_3> . to evaluate our <method_5> , we apply <method_5> to the problem of <task_4> and compare <method_5> against an <method_2> . we numerically show that <method_5> yields excellent results even for a moderate amount of data . <method_5> approaches the performance of <method_7> where the gains are perfectly known asymptot-ically .	1 8 9 -1 6 5 0 3 11 13 14 9 -1 4 2 10 12 9 -1 9 -1 7 9 -1
Spike sorting at sub-Nyquist rates .	temporal occurrence of action potentials ; sampling neural data ; sparse sampling ; spike sorting ; multi-channel recordings ; spike sorting ; neural information ; sub-nyquist rates	<otherscientificterm> <task> <task> <method> <material> <task> <otherscientificterm> <otherscientificterm>	4 0 5 ; 1 0 5 ; 3 0 0 ; 6 0 2	spike sorting relies on the ability to establish the <otherscientificterm_0> and their relation to specific neurons . <otherscientificterm_6> is intrinsically compressible and as such suitable for <task_2> . potentially , this should allow for the use of <material_4> , which is particularly advantageous to improve <task_5> . in this paper we propose a novel algorithm capable of <task_1> at <otherscientificterm_7> , yielding the same performance for <task_5> as traditional schemes .	0 6 11 8 -1 2 12 8 -1 4 5 9 8 -1 1 7 3 10 8 -1
Top-down visual saliency via joint CRF and dictionary learning .	conditional random field ; graz-02 and pascal voc datasets ; structured output of crf layer ; stochastic gradient descent algorithm ; target object localization ; top-down saliency model ; top-down visual saliency ; human fixation prediction ; top-down saliency methods ; layered structure ; dictionary update ; crf parameters ; intermediate layer ; joint learning ; sparse coding ; sparse codes ; image patches ; visual dictionary ; supervised manner ; max-margin approach ; bottom ; features	<method> <material> <otherscientificterm> <method> <task> <method> <task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm>	5 4 8 ; 0 1 14 ; 9 3 5 ; 1 5 8 ; 3 0 19 ; 4 1 10 ; 8 0 4 ; 0 6 9 ; 14 0 11 ; 14 1 16 ; 15 0 0 ; 5 4 5 ; 5 0 7 ; 10 3 5 ; 1 5 5 ; 15 0 12 ; 0 1 17	top-down visual saliency is an important module of visual attention . in this work , we propose a novel <method_5> that jointly learns a <method_0> and a <material_17> . the proposed <method_5> incorporates a <otherscientificterm_9> from top to <otherscientificterm_20> : <method_0> , <otherscientificterm_14> and <otherscientificterm_16> . by using <otherscientificterm_15> as <otherscientificterm_12> , we learn a <method_0> in a <method_18> with the <otherscientificterm_2> , and meanwhile learn the <otherscientificterm_11> with <otherscientificterm_14> as <otherscientificterm_21> . for efficient and effective <task_13> , we develop a <method_19> via a <method_3> . experimental results on the <material_1> show that our <method_5> performs favorably against the state-of-the-art <method_8> for <task_4> and the <method_10> significantly improves the performance of our <method_5> . in addition , we demonstrate the merits of the proposed <method_5> by applying <method_5> to <task_7> .	22 -1 5 0 17 39 22 -1 9 20 14 16 24 25 30 32 22 -1 15 12 18 2 11 21 31 33 38 22 -1 13 19 3 27 22 -1 1 23 26 28 29 34 36 37 22 -1 8 4 10 35 22 -1
Bounds for the mixing parameter within the CC-CMA algorithm applied in non ideal multiuser environments .	cross-correlation constant modulus algirithm ; error performance surface ; blind source separation ; non-ideal multiuser environments ; cc-cma algorithm ; channel undermodelling ; surface topography ; mixing parameter ; tighter bounds ; simulation studies ; equalization ; noise	<method> <otherscientificterm> <task> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm>	2 1 3 ; 6 0 4 ; 0 0 2 ; 5 1 11 ; 2 1 10	we derive new bounds for the <otherscientificterm_7> , $ , within the <method_0> for <task_2> and <task_10> in <otherscientificterm_3> . <task_5> and <otherscientificterm_11> are considered when the complex sources are circularly symmetric . these <otherscientificterm_8> are obtained by <otherscientificterm_6> of the <otherscientificterm_1> of the <method_4> , and replace earlier work which suggested that ¬• ¬ß ¬¶ ¬© ¬® the validity of the bounds is con rmed by <method_9> .	7 0 2 10 3 5 13 15 17 12 -1 11 16 12 -1 8 6 1 4 9 14 12 -1
Performance analysis of the GLRT-based array receivers for the detection of a known signal corrupted by noncircular interference .	likelihood ratio test ; false alarm -lrb- p fa -rrb- ; data length -rrb- closed-form expression ; known signal ; closed-form expression ; glrt-based receivers ; noncircular interference ; lrt-based receivers ; glrt ; detection	<metric> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <task>	0 1 8	this paper presents a performance analysis of <metric_0> - based and generalized likelihood ratio test -lrb- <metric_8> -rrb- - based array receivers for the <task_9> of a <otherscientificterm_3> corrupted by a potentially <otherscientificterm_6> . studying the distribution of the statistics associated with the <metric_0> and <metric_8> , expressions of the probability of <task_9> -lrb- p d -rrb- and <metric_1> are given . in particular , an exact <otherscientificterm_4> of p d and p fa are given for two <method_7> and asymptotic -lrb- with respect to the <otherscientificterm_2> are given for p d and p fa for four <otherscientificterm_5> . finally illustrative examples are presented in order to strengthen the obtained results .	0 8 9 3 6 10 -1 1 11 10 -1 4 7 2 5 10 -1 10 -1
Optimal subset selection for adaptive signal representation .	signal representation ; over-complete dictionaries ; signal decomposition ; over-complete dictionary ; data vector ; cosine packets ; computational complexity ; wave packets ; sparsity ; wavelets	<method> <material> <task> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 6 1 ; 5 6 1 ; 6 5 0 ; 8 0 0 ; 9 1 7 ; 7 1 5 ; 9 6 1	recently , a number of <material_1> such as <otherscientificterm_9> , <otherscientificterm_7> , <otherscientificterm_5> etc. have been proposed . <task_2> on such <material_1> is not unique . this non-uniqueness provides us with the opportunity to adapt the <method_0> to the signal . the adaptation is based on <otherscientificterm_8> , resolution and stability of the <method_0> . the <metric_6> of the <method_0> is of primary concern . we propose a new approach for identifying the sparsest representation of a given signal in terms of a given <material_3> . we assume that the <otherscientificterm_4> can be exactly represented in terms of a known number of vectors .	1 9 7 5 2 11 12 15 16 17 10 -1 10 -1 0 10 -1 8 14 10 -1 6 13 10 -1 3 10 -1 4 10 -1
Feature-Rich Two-Stage Logistic Regression for Monolingual Alignment .	two-stage logistic regression framework ; short text snippets ; f 1 scores ; supervised aligner ; monolingual alignment ; extrinsic evaluation ; error reductions ; semantic units ; features	<method> <material> <metric> <method> <task> <task> <metric> <otherscientificterm> <otherscientificterm>	8 0 4 ; 0 0 4 ; 8 0 0 ; 1 0 3 ; 6 5 3	monolingual <task_4> is the task of pair-ing semantically similar units from two pieces of text . we report a top-performing <method_3> that operates on <material_1> . we employ a large feature set to -lrb- 1 -rrb- encode similarities among <otherscientificterm_7> -lrb- words and named entities -rrb- in context , and -lrb- 2 -rrb- address cooperation and competition for <task_4> among units in the same snippet . these <otherscientificterm_8> are deployed in a <method_0> for <task_4> . on two benchmark data sets , our <method_3> achieves <metric_2> of 92.1 % and 88.5 % , with statistically significant <metric_6> of 4.8 % and 7.3 % over the previous best <method_3> . <method_3> produces top results in <task_5> as well .	4 9 -1 3 1 13 9 -1 7 9 -1 8 0 10 11 12 9 -1 2 6 14 9 -1 9 -1
Speaker adaptation based on confidence-weighted training .	weighted smap ; speaker adaptation algorithm ; native speaker models ; model adaptation methods ; nonnative speaker environment ; discriminative adaptation procedure ; confidence measure ; parameter tying ; adaptation data ; sigmoid weight-ing ; non-linear weighting ; outliers ; tidigit	<method> <method> <method> <method> <otherscientificterm> <method> <metric> <method> <material> <otherscientificterm> <method> <otherscientificterm> <method>	6 0 1 ; 10 0 5 ; 5 0 1 ; 6 0 9 ; 2 0 4 ; 6 0 5 ; 8 0 3 ; 6 1 10 ; 10 0 1	this paper presents a novel method to enhance the performance of traditional <method_1> using <method_5> based on a novel <metric_6> and <method_10> . regardless of the distribution of the <material_8> , traditional <method_3> incorporate the <material_8> undiscriminatingly . when the data size is small and the <method_7> is extensive , adaptation based on <otherscientificterm_11> can be detrimental . a way to discriminate the contribution of each data in the adaptation is to incorporate a <metric_6> based on likelihood . we evaluate and compare the performances of the proposed <method_0> which controls the contribution of each data by <otherscientificterm_9> using a novel <metric_6> . the effectiveness of the proposed algorithm is experimentally verified by adapting <method_2> to <otherscientificterm_4> using <method_12> .	1 5 6 10 14 15 16 19 21 22 13 -1 8 3 20 13 -1 7 11 13 -1 13 -1 0 9 17 13 -1 18 13 -1
Relational Random Forests Based on Random Relational Rules .	random forests over relational data ; r 4 f ; propositional learning ; ensemble size ; tree initialization ; random forests ; computational complexity ; static proposition-alization ; dynamic propositionalization ; relational data ; forf ; node ; tree	<material> <method> <task> <otherscientificterm> <task> <material> <metric> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm>	5 0 9 ; 10 4 7 ; 9 0 5 ; 5 0 2 ; 10 6 5 ; 5 1 7	random forests have been shown to perform very well in <task_2> . <method_10> is an upgrade of <material_5> for <material_9> . in this paper we investigate shortcomings of <method_10> and propose an alternative algorithm , <method_1> , for generating <material_0> . <method_1> employs randomly generated relational rules as fully self-contained boolean tests inside each <otherscientificterm_11> in a <otherscientificterm_12> and thus can be viewed as an instance of <otherscientificterm_8> . the implementation of <method_1> allows for the simultaneous or parallel growth of all the branches of all the trees in the ensemble in an efficient shared , but still single-threaded way . experiments favorably compare <method_1> to both <method_10> and the combination of <otherscientificterm_7> together with standard <material_5> . various strategies for <task_4> and splitting of nodes , as well as resulting <otherscientificterm_3> , diversity , and <metric_6> of <method_1> are also investigated .	2 10 17 13 -1 5 9 14 18 13 -1 1 0 16 13 -1 11 12 8 13 -1 13 -1 15 19 13 -1 7 13 -1
Semi-continuous segmental probability model for speech signals .	continuous segmental probability model ; semi-continuous segmental probability model ; segmental probability modeling of speech signals ; continuous output probability density functions ; continuous mixture segmental probability model ; continuous segmental probability model ; semi-continuous segmental probability model ; semi-continuous hidden markov model ; mixture gaussian density codebook ; vector quantization codebook ; segmental probability model ; unified modeling approach ; vector quantization ; model/codebook combination ; computational complexity ; recognition accuracy	<method> <method> <task> <otherscientificterm> <method> <method> <method> <method> <method> <method> <method> <method> <task> <method> <metric> <metric>	3 1 8 ; 9 1 10 ; 14 5 1 ; 4 0 6 ; 11 0 2 ; 15 5 6 ; 15 5 7 ; 6 4 7 ; 12 1 2 ; 1 4 0 ; 11 0 12 ; 7 1 5 ; 9 0 13 ; 3 1 4	a <method_6> , which can be considered as a special form of <method_4> with <otherscientificterm_3> sharing in a <method_8> , is proposed in this paper . the amount of training data required , as well as the <metric_14> of the <method_1> -lsb- 2 -rsb- , can be significantly reduced in comparison with the <method_0> . parameters of the <method_9> and <method_10> can be mutually optimized to achieve an optimal <method_13> , which leads to a <method_11> to <task_12> and <task_2> . the experimental results show that the <metric_15> of the <method_6> is higher than the <method_7> and <method_5> .	6 4 3 8 17 20 30 16 -1 14 1 0 19 26 16 -1 9 10 13 11 12 2 18 21 25 27 29 16 -1 15 7 5 22 23 24 28 16 -1
Tractable Reasoning with Incomplete First-Order Knowledge in Dynamic Systems with Context-Dependent Actions .	knowledge base ; incomplete first-order knowledge ; reasoning problem ; projection problem ; action sequence ; dynamic systems ; context-dependent actions ; progression	<material> <otherscientificterm> <task> <task> <material> <method> <otherscientificterm> <method>	1 1 6	a basic <task_2> in <method_5> is the <task_3> : determine if a formula holds after a sequence of actions has been performed . in this paper , we propose a tractable 1 solution to the <task_3> in the presence of <otherscientificterm_1> and <otherscientificterm_6> . our solution is based on a type of <method_7> , that is , we progress the initial <material_0> wrt the <material_4> and answer the query against the resulting <material_0> . the form of reasoning we propose is always logically sound and is also logically complete when the query is in a certain normal form and the agent has complete knowledge about the context of any <otherscientificterm_6> .	2 5 3 8 -1 1 6 9 8 -1 7 0 4 8 -1 8 -1
Minimum trajectory error training for deep neural networks , combined with stacked bottleneck features .	dynamic and continuous nature of speech parameters ; deep neural networks ; dnn parameter estimation methods ; speech parameter trajectory errors ; statistical parametric speech synthesis ; mean squared error ; stacked bottleneck features ; wide linguistic context ; wide acoustic context ; synthesised speech ; dynamic constraints ; model accuracy ; training data ; training criterion ; linguistic features ; acoustic model	<otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <metric> <material> <method> <otherscientificterm> <method>	14 0 15 ; 13 0 3 ; 1 0 15 ; 13 4 6 ; 1 0 4 ; 15 0 4	recently , <method_1> have shown promise as an <method_15> for <task_4> . their ability to learn complex mappings from <otherscientificterm_14> to <method_15> has advanced the naturalness of synthesis speech significantly . however , because <method_2> typically attempt to minimise the <otherscientificterm_5> of each individual frame in the <material_12> , the <otherscientificterm_0> is neglected . in this paper , we propose a <method_13> that minimises <otherscientificterm_3> , and so takes <otherscientificterm_10> from a <otherscientificterm_8> into account during training . we combine this novel <method_13> with our previously proposed <otherscientificterm_6> , which provide <otherscientificterm_7> . both objective and subjective evaluation results confirm the effectiveness of the proposed <method_13> for improving <metric_11> and naturalness of <material_9> .	1 15 4 19 21 22 16 -1 14 17 16 -1 2 5 12 0 16 -1 13 3 10 8 18 16 -1 6 7 20 16 -1 16 -1
An integrated background model for video surveillance based on primal sketch and 3D scene geometry .	reflections of moving objects ; integrated video surveillance system ; locations of foreground blobs ; object and tra-jectory level ; background modeling methods ; primal sketch representation ; integrated background model ; camera exposure adjusting ; 3d scene geometry ; 3d scene ; background image ; pixel level ; geometric information ; false alarms ; video surveillance ; image primitives ; lbp histograms ; ground plane ; horizontal surfaces ; ground ; walls ; stairs ; shadows ; regions ; gaussians ; highlights	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	19 1 20 ; 6 0 14 ; 19 1 18 ; 18 1 21 ; 20 1 21 ; 6 4 4 ; 22 1 25 ; 6 4 1 ; 18 1 20 ; 3 2 1 ; 15 1 16 ; 24 1 15 ; 6 0 10 ; 25 1 0 ; 5 0 6	this paper presents a novel <method_6> for <task_14> . our <method_6> uses a <method_5> for image appearance and <task_8> to capture the <otherscientificterm_17> and major surfaces in the scene . the <method_6> divides the <otherscientificterm_10> into three types of <otherscientificterm_23> -- flat , sketchable and textured . the three types of <otherscientificterm_23> are modeled respectively by mixture of <method_24> , <otherscientificterm_15> and <method_16> . we calibrate the camera and recover important planes such as <otherscientificterm_19> , <otherscientificterm_18> , <otherscientificterm_20> , <otherscientificterm_21> in the <otherscientificterm_9> , and use <otherscientificterm_12> to predict the sizes and <otherscientificterm_2> to further reduce <otherscientificterm_13> . compared with the state-of-the-art <method_4> , our <method_6> is more effective , especially for indoor scenes where <otherscientificterm_22> , <otherscientificterm_25> and <otherscientificterm_0> and <otherscientificterm_7> usually cause problems . experiment results demonstrate that our <method_6> improves the performance of background/foreground separation at <otherscientificterm_11> , and the <method_1> at the <otherscientificterm_3> .	6 14 28 26 -1 5 8 17 41 26 -1 10 23 39 26 -1 24 15 16 37 38 26 -1 19 18 20 21 9 12 2 13 27 29 30 31 35 26 -1 32 33 40 26 -1 4 22 25 0 7 34 36 26 -1
Predictive state vector encoding for decentralized field estimation in sensor networks .	differential encoding of state vectors ; decentralized physics-based field estimation ; kalman prediction step ; spatio-temporal field dependencies ; clustered sensor networks ; acoustic field ; state-space equations ; communication overhead ; computational complexity ; encoding	<method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm>	0 0 7 ; 6 0 2	decentralized physics-based field estimation in <method_4> requires the exchange of state vectors between neighboring clusters . we reduce the <otherscientificterm_7> between clusters by using a <method_0> that exploits the <otherscientificterm_3> . this <otherscientificterm_9> involves a <method_2> that builds on the <method_6> governing the field 's spatio-temporal evolution . the <method_2> keeps the <metric_8> low . simulation results for an <otherscientificterm_5> demonstrate the approach .	4 10 -1 7 0 3 11 10 -1 9 2 6 12 10 -1 8 10 -1 5 1 10 -1
A novel quantization watermarking scheme by modulating the normalized correlation .	quantization based watermarking scheme ; modulated normalized correlation ; stronger noise ; watermarked signal ; normalized correlation ; embedding distortion ; well-known spread ; watermark embedding ; real images ; dither modulation ; numerical simulations ; host vector ; random vector ; valumet-ric scaling ; robustness	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric>	14 5 0 ; 11 1 12 ; 3 0 1 ; 0 0 2 ; 9 2 12	this paper presents a novel <method_0> . <method_7> is performed through modulating the <otherscientificterm_4> between the <otherscientificterm_11> and a <otherscientificterm_12> with <otherscientificterm_9> . the <otherscientificterm_3> is derived to provide the <otherscientificterm_1> in the sense of minimizing the <otherscientificterm_5> . the proposed <method_0> is theoretically invariant to <task_13> and can resist <otherscientificterm_2> than the <otherscientificterm_6> transform <otherscientificterm_9> . <method_10> on <material_8> show that <method_0> achieves the good imperceptibility and strong <metric_14> against a wide range of attacks .	0 7 15 -1 4 11 12 9 17 20 15 -1 3 1 5 18 15 -1 13 2 6 10 19 15 -1 8 14 16 15 -1
Expected Error Analysis for Model Selection .	eecient model selection algorithm ; large-scale text categorization problem ; 10-fold cross validation ; boolean decision trees ; model selection problems ; error rates ; generalization performance ; precision	<method> <task> <method> <material> <task> <metric> <metric> <metric>	5 5 0 ; 3 1 1	in order to select a good hypothesis language -lrb- or model -rrb- from a collection of possible models , one has to assess the <metric_6> of the hypothesis which is returned by a learner that is bound to use some particular model . this paper deals with a new and very eecient way of assessing this <metric_6> . we present a new analysis which characterizes the expected generalization error of the hypothesis with least training error in terms of the distribution of <metric_5> of the hypotheses in the model . this distribution can be estimated very eeciently from the data which immediately leads to an <method_0> . the analysis predicts learning curves with a very high <metric_7> and thus contributes to a better understanding of why and when over-tting occurs . we present empirical studies -lrb- controlled experiments on <material_3> and a <task_1> -rrb- which show that the <method_0> leads to <metric_5> which are often as low as those obtained by <method_2> -lrb- sometimes even superior -rrb- . however , the <method_0> is much more eecient -lrb- because the learner does not have to be invoked at all -rrb- and thus solves <task_4> with as many as thousand relevant attributes and 12,000 examples .	6 8 -1 8 -1 5 8 -1 8 -1 0 8 -1 7 9 10 8 -1 3 1 2 8 -1
An unmixing-based method for the analysis of thermal hyperspectral images .	estimation of surface emissivity ; high spectral resolution sensor ; hyperspectral sensor configurations ; thermal hyperspectral data ; black body law ; mixed pixel ; noise conditions ; simulated data ; temperature ; pixel ; accuracy	<task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <metric>	8 2 9	the <task_0> and <otherscientificterm_8> from <material_3> is a challenge . methods that estimate the <otherscientificterm_8> and emissivity on a <otherscientificterm_9> composed by one single material exist . however , the estimation of the <otherscientificterm_8> on a <otherscientificterm_5> , i.e. a <otherscientificterm_9> composed by more than one material , is more complex and has scarcely been investigated in the literature . this paper addresses this issue by proposing an estimator which linearizes the <otherscientificterm_4> around the mean <otherscientificterm_8> of each material . the performance of this estimator is studied using <material_7> with different <otherscientificterm_2> and under various <otherscientificterm_6> . the obtained results are encouraging and show an <metric_10> on the estimated <otherscientificterm_8> of 0.5 k while using <otherscientificterm_1> .	0 8 3 11 -1 9 12 11 -1 5 11 -1 4 11 -1 7 2 6 11 -1 11 -1
Reducing the footprint of the IBM trainable speech synthesis system .	spectral acoustic feature based speech representation ; small footprint formant based synthesizers ; ibm trainable speech synthesis system ; concatenative speech synthesis ; concatenative text-to-speech system ; cost function ; dataset size ; speech generation ; segment selection	<method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <task> <task>	0 0 5 ; 2 6 4 ; 6 2 4 ; 0 0 8	this paper presents a novel approach for <task_3> . this approach enables reduction of the <otherscientificterm_6> of a <method_4> , namely the <method_2> , by more than an order of magnitude . a <method_0> is used for computing a <otherscientificterm_5> during <task_8> as well as for <task_7> . initial results indicate that even with a <otherscientificterm_6> of a few megabytes it is possible to achieve quality which is significantly higher than existing <otherscientificterm_1> .	3 9 -1 6 4 2 11 12 9 -1 0 5 8 7 10 13 9 -1 1 9 -1
Query Weighting for Ranking Model Adaptation .	letor3 .0 data set ; document instance weighting methods ; ranking model adaptation ; query weighting schemes ; fine-grained similarity values ; compressing query data ; query feature vector ; query weighting ; document level ; ranking algorithms ; query weighting ; query importance ; information loss	<material> <method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <task> <metric> <otherscientificterm>	7 4 1 ; 5 0 11 ; 6 0 7 ; 10 0 2 ; 3 0 11 ; 0 5 7 ; 0 5 1	we propose to directly measure the importance of queries in the source domain to the target domain where no rank labels of documents are available , which is referred to as <method_7> . <task_10> is a key step in <task_2> . as the learning object of <method_9> is divided by query instances , we argue that it 's more reasonable to conduct importance weighting at query level than <otherscientificterm_8> . we present two <method_3> . the first compresses the query into a <otherscientificterm_6> , which aggregates all document instances in the same query , and then conducts <method_7> based on the <otherscientificterm_6> . this <method_3> can efficiently estimate <metric_11> by <task_5> , but the potential risk is <otherscientificterm_12> resulted from the compression . the second measures the similarity between the source query and each target query , and then combines these <otherscientificterm_4> for its importance estimation . adaptation experiments on <material_0> demonstrate that <method_7> significantly outperforms <method_1> .	7 10 13 -1 2 17 13 -1 9 8 13 -1 3 13 -1 6 16 13 -1 15 18 13 -1 11 5 12 13 -1 4 14 19 20 13 -1
A comparison of human and automatic musical genre classification .	mel-frequency cepstral coefficients ; subjective perception of genre definitions ; automatic musical genre classification ; genre classification systems ; human genre classification ; auditory model ; genre classification ; human annotation ; audio format ; automatic algorithms ; musical content ; features	<method> <otherscientificterm> <task> <method> <task> <method> <task> <otherscientificterm> <material> <method> <material> <otherscientificterm>	5 0 11 ; 0 0 11 ; 9 1 7 ; 0 0 5	recently there has been an increasing amount of work in the area of automatic <task_6> of music in <material_8> . such systems can be used as a way to evaluate <otherscientificterm_11> describing <material_10> as well as a way to structure large collections of music . however the evaluation and comparison of <method_3> is hindered by the <otherscientificterm_1> by users . in this work we describe a set of experiments in <task_2> . an important contribution of this work is the comparison of the automatic results with <task_4> on the same dataset . the results show that , although there is significant room for improvement , <task_6> is inherently subjective and therefore perfect results can not be expected from either <method_9> or <otherscientificterm_7> . the experiments also show that the use of <otherscientificterm_11> derived from an <method_5> have similar performance with <otherscientificterm_11> based on <method_0> .	6 8 12 -1 11 10 12 -1 3 1 12 -1 2 12 -1 4 12 -1 15 12 -1 9 7 13 14 16 12 -1
Speaking rate compensation based on likelihood criterion in acoustic model training and decoding .	spontaneous lecture speech recognition task ; acoustic model creation process ; speaking rate compensation method ; speaking rate compensation ; frame length adaptation ; frame period ; decoding process ; insertion penalty ; acoustic likelihood ; viterbi alignment ; speech analysis ; acoustic model ; input utterance ; language likelihood ; accuracy	<task> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <task> <method> <material> <otherscientificterm> <metric>	9 0 8 ; 7 5 2 ; 5 1 13 ; 3 0 1 ; 2 0 11 ; 13 1 7 ; 5 0 8 ; 5 0 2 ; 4 0 2 ; 5 1 4 ; 3 0 0 ; 1 1 6	in this paper , we propose a <method_2> using <otherscientificterm_5> and <method_4> . our <method_2> decodes an <material_12> using several sets of <otherscientificterm_5> and frame length parameters for <task_10> . then , this <method_2> selects the best set with the highest score which consists of the <otherscientificterm_8> normalized by <otherscientificterm_5> , <otherscientificterm_13> and <otherscientificterm_7> . furthermore , we apply this <method_2> to the training of the <method_11> . we calculate the <otherscientificterm_8> for each <otherscientificterm_5> and frame length using <method_9> and select the best one for each training utterance . the proposed <method_3> applied to both the <method_1> and <method_6> resulted in <metric_14> improvement of 2.9 % -lrb- absolute -rrb- for <task_0> .	2 5 4 23 24 25 15 -1 12 10 15 -1 8 13 7 17 18 21 22 15 -1 11 20 15 -1 9 16 15 -1 3 1 6 19 26 27 15 -1
Keystroke Patterns as Prosody in Digital Writings : A Case Study with Deceptive Reviews and Essays .	duration of pauses ; keystroke patterns ; deception detection ; speech analysis ; keystroke-based features ; keyboard strokes ; online authors ; editing maneuvers ; online reviews	<otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <method> <material> <otherscientificterm> <material>	7 6 1 ; 0 6 1 ; 4 0 2 ; 7 1 0	in this paper , we explore the use of <method_5> as a means to access the real-time writing process of <material_6> , analogously to prosody in <task_3> , in the context of <task_2> . we show that differences in <otherscientificterm_1> like <otherscientificterm_7> and <otherscientificterm_0> can help distinguish between truthful and deceptive writing . empirical results show that incorporating <otherscientificterm_4> lead to improved performance in <task_2> in two different domains : <material_8> and essays .	5 6 3 2 9 -1 1 7 0 10 11 13 9 -1 4 8 12 9 -1
TDOA estimation for cyclostationary sources : New correlations-based bounds and estimators .	time difference of arrival estimation ; asymptotic cram√©r-rao bounds ; additive white gaussian noise ; approximate maximum likelihood estimator ; -lrb- unbiased -rrb- estimator ; asymptotically gaussian distribution ; classical approaches ; cyclostationary signals ; cyclic cross-correlations ; mul-ticycle approach ; cyclostationarity	<task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method>	0 0 7 ; 8 0 10	we consider the problem of <task_0> for <otherscientificterm_7> in <otherscientificterm_2> . <method_6> to the problem either ignore the <method_10> and use ordinary cross-correlations , or exploit the <method_10> by using <otherscientificterm_8> , or combine these approaches into a <method_9> . despite contradicting claims in the literature regarding the performance-ranking of these approaches , there has been almost no analytical comparative performance study . we propose to regard the estimated -lrb- ordinary or cyclic -rrb- correlations as the '' front-end '' data , and based on their <otherscientificterm_5> , to compute the <method_1> for the various combinations -lrb- ordinary/single-cycle/multi-cycle -rrb- . using our cyclic-correlations-based crb -lrb- termed '' crbcrb '' -rrb- , we can bound the performance of any <method_4> which exploits a given set of correlations . moreover , we propose an <method_3> -lrb- with respect to the correlations -rrb- , and show that <method_3> attains our crbcrb asymptotically in simulations , outperforming the competitors .	0 7 2 6 12 11 -1 10 8 9 13 11 -1 11 -1 5 1 11 -1 11 -1 4 11 -1
Multi-label learning with incomplete class assignments .	ranking based multi-label learning framework ; incompletely labeled data ; incomplete class assignment ; mir flickr dataset ; incompletely labeled data ; group lasso technique ; class assignment ; optimization problem ; multi-label learning ; learning algorithm ; ranking errors	<method> <material> <otherscientificterm> <material> <material> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm>	5 0 1 ; 2 2 8 ; 9 0 7	we consider a special type of <method_8> where class assignments of training examples are incomplete . as an example , an instance whose true <otherscientificterm_6> is -lrb- c 1 , c 2 , c 3 -rrb- is only assigned to class c 1 when it is used as a training sample . we refer to this problem as <method_8> with <otherscientificterm_2> . <material_4> is frequently encountered when the number of classes is very large -lrb- hundreds as in <material_3> -rrb- or when there is a large ambiguity between classes -lrb- e.g. , jet vs plane -rrb- . in both cases , it is difficult for users to provide complete class assignments for objects . we propose a <method_0> that explicitly addresses the challenge of learning from <material_1> by exploiting the <method_5> to combine the <otherscientificterm_10> . we present a <method_9> that is empirically shown to be efficient for solving the related <task_7> . our empirical study shows that the proposed <method_0> is more effective than the state-of-the-art algorithms for <method_8> in dealing with <material_1> .	8 11 -1 6 11 -1 2 4 13 11 -1 3 11 -1 11 -1 12 11 -1 0 1 5 10 14 11 -1 9 7 11 -1
Rate-Invariant Analysis of Trajectories on Riemannian Manifolds with Application in Visual Speech Recognition .	transported square-root vector field ; statistical summarization & modeling of trajectories ; statistical analysis of video sequences ; temporal evolutions of features ; visual and audio components ; audio and visual components ; mathematical representation of trajectories ; speaker-dependent classification rate ; l 2 norm ; statistics literature ; temporal registration ; nuisance variability ; parametrization-invariant distances ; evolution patterns ; riemannian manifolds ; speech recognition ; speech classification ; activity recognition ; cost function/distance ; features ; classification	<method> <task> <task> <otherscientificterm> <method> <method> <method> <metric> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <task> <method> <otherscientificterm> <task>	0 0 16 ; 18 0 10 ; 7 0 4 ; 12 0 16 ; 0 0 12 ; 5 0 15 ; 2 0 15	in <task_2> for <task_15> , and more generally <task_17> , it is natural to treat <otherscientificterm_3> as trajec-tories on <otherscientificterm_14> . however , different <otherscientificterm_13> result in arbitrary parameterizations of these trajectories . we investigate a recent framework from <material_9> -lsb- 15 -rsb- that handles this <otherscientificterm_11> using a <method_18> for <task_10> and <task_1> . it is based on a <method_6> , termed <method_0> , and the <otherscientificterm_8> on the space of <method_0> . we apply this framework to the problem of <task_15> using both <method_5> . in each case , we extract <otherscientificterm_19> , form trajectories on corresponding manifolds , and compute <otherscientificterm_12> using <method_0> for <task_16> . on the <method_0> the <task_20> performance under metric increases significantly , by nearly 100 % under both modalities and for all choices of <otherscientificterm_19> . we obtained <metric_7> of 70 % and 96 % for <method_4> , respectively .	2 15 17 3 14 28 21 -1 13 21 -1 9 11 18 10 1 23 21 -1 6 0 8 21 -1 5 27 21 -1 19 22 25 26 21 -1 12 16 21 -1 20 24 21 -1
Cyclostationary joint phase and timing estimation for staggered modulations .	low-snr unconditional maximum likelihood framework ; offset quadrature amplitude modulation ; minimum shift keying ; non-data-aided phase ; asymptotic uml cost function ; spectral line generation ; timing estimation problem ; cyclostationary approach ; second-order non-linearity ; staggered modulations ; timing parameter ; modulations	<method> <method> <method> <task> <otherscientificterm> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 6 11 ; 5 0 4 ; 7 0 6 ; 1 6 11 ; 6 0 9 ; 7 0 3 ; 3 1 6 ; 1 1 2	this paper presents a <method_7> to the <task_3> and <task_6> for <otherscientificterm_9> . the problem is addressed under the <method_0> , and <otherscientificterm_11> such as <method_1> and <method_2> are considered . in this sense , it is found that not only the <otherscientificterm_10> but also the phase , can be jointly obtained from the <otherscientificterm_4> based on the <task_5> after a <otherscientificterm_8> .	7 3 6 9 15 17 18 19 12 -1 0 11 1 2 13 16 20 12 -1 10 4 5 8 14 12 -1
A Pitch Tracking Corpus with Evaluation on Multipitch Tracking Scenario .	pitch tracking database ; ground truth signals ; multipitch tracking systems ; timit corpus ; laryn-gograph	<method> <otherscientificterm> <method> <material> <otherscientificterm>	4 0 1 ; 1 0 0	in this paper , we introduce a novel <method_0> including <otherscientificterm_1> obtained from a <otherscientificterm_4> . the <method_0> , referenced as <method_0> , consists of 2342 phonetically rich sentences taken from the <material_3> . each sentence was at least recorded once by a male and a female native speaker . in total , the <method_0> contains 4720 recordings from 10 male and 10 female speakers . furthermore , we evaluated two <method_2> on a subset of speakers to provide a benchmark for further research activities . the <method_0> can be downloaded at	0 1 4 6 7 5 -1 3 5 -1 5 -1 5 -1 2 5 -1 5 -1
Tri-Training for Authorship Attribution with Limited Training Data .	authorship attribution ; online review domain ; three-view tri-training method ; semi-supervised method cng+svm ; labeled data ; un-labeled documents ; labeled documents ; unlabeled data ; tri-training	<task> <material> <method> <method> <material> <material> <material> <material> <method>	2 4 3 ; 2 0 0 ; 8 0 5	authorship attribution -lrb- <task_0> -rrb- aims to identify the authors of a set of documents . traditional studies in this area often assume that there are a large set of <material_6> available for training . however , in the real life , it is often difficult or expensive to collect a large set of <material_4> . for example , in the <material_1> , most reviewers -lrb- authors -rrb- only write a few reviews , which are not enough to serve as the training data for accurate classification . in this paper , we present a novel <method_2> to iteratively identify authors of <material_7> to augment the training set . the key idea is to first represent each document in three distinct views , and then perform <method_8> to exploit the large amount of <material_5> . starting from 10 training documents per author , we systematically evaluate the effectiveness of the proposed <method_2> for <task_0> . experimental results show that the proposed <method_2> outperforms the state-of-the-art <method_3> and other baselines .	0 9 -1 6 9 -1 4 9 -1 1 9 -1 2 9 -1 7 12 9 -1 8 5 11 9 -1 10 9 -1
Annotation and detection of conflict escalation in Political debates .	annotation and detection of conflict escalation ; conversational and prosodic features ; machine-mediated conflict management system ; broadcast political debates ; level conflict escalation ; indirect inference method ; direct assessment method ; direct assessment ; indirect inference ; multi-party conversations ; crowd-sourced annotations ; annotation process ; ternary classes ; continuous values ; conflict escalation ; unweighted accuracy ; agreement ; escalation ; de-escalation	<task> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <task> <method> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <metric> <otherscientificterm> <otherscientificterm>	10 0 14 ; 17 1 18 ; 8 1 7 ; 17 6 14 ; 18 6 14	conflict <otherscientificterm_17> in <material_9> refers to an increase in the intensity of conflict during conversations . here we study <task_0> in <material_3> towards a <method_2> . in this regard , we label <otherscientificterm_14> using <otherscientificterm_10> and predict it with automatically extracted <otherscientificterm_1> . in particular , to annotate the <otherscientificterm_14> we deploy two different strategies , i.e. , <method_8> and <task_7> ; the <method_6> refers to a way that annotators watch and compare two consecutive clips during the <method_11> , while the <method_5> indicates that each clip is independently annotated with respect to the level of conflict then the <otherscientificterm_4> is inferred by comparing annotations of two consecutive clips . empirical results with 792 pairs of consecutive clips in classifying three types of <otherscientificterm_14> , i.e. , <otherscientificterm_17> , <otherscientificterm_18> , and constant , show that labels from <task_7> yield higher classification performance -lrb- 45.3 % <metric_15> -lrb- ua -rrb- -rrb- than the one from <method_8> -lrb- 39.7 % ua -rrb- , although the annotations from both methods are highly correlated -lrb- œÅ = 0.74 in <otherscientificterm_13> and 63 % <metric_16> in <otherscientificterm_12> -rrb- .	17 9 19 -1 0 3 2 19 -1 14 10 1 20 19 -1 8 7 6 11 5 4 22 19 -1 21 23 24 19 -1
Lifting Techniques for Sequential Decision Making and Probabilistic Inference -LRB- Extended Abstract -RRB- .	markov chain monte carlo methods ; monte carlo tree search framework ; state-action pair symmetries ; size of state space ; generic symmetry based framework ; markov decision processes ; sequential decision making ; ai algorithms ; unconditional symmetries ; probabilistic inference ; problem size ; symmetry exploitation ; symmetric states ; contextual symmetries ; features ; computation ; work-asap-uct	<method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method>	6 1 9 ; 2 0 1 ; 8 0 13 ; 8 3 0	many traditional <method_7> fail to scale as the <otherscientificterm_3> increases exponentially with the number of <otherscientificterm_14> . one way to reduce <task_15> in such scenarios is to reduce the <otherscientificterm_10> by grouping <otherscientificterm_12> together and then running the algorithm on the reduced problem . the focus of this work is to exploit symmetry in problems of <task_6> and <task_9> . our recent <method_16> defines new <otherscientificterm_2> in <method_5> . we also apply these <otherscientificterm_2> in <method_1> . in <task_9> , we expand the notion of <otherscientificterm_8> to <otherscientificterm_13> and apply <otherscientificterm_8> in <method_0> . in future , we plan to explore interesting links in <task_11> in different problems and aim to develop a <method_4> .	7 3 14 17 -1 15 10 12 17 -1 6 9 18 17 -1 16 2 5 17 -1 1 19 17 -1 8 13 0 20 21 17 -1 17 -1
Learning and adaptation of a tongue shape modelwith missing data .	missing data ; ultrasound imaging ; data-driven techniques ; ultrasound data ; submillimetric accuracy ; tongue contours ; noise ; shadowing ; learning	<material> <method> <method> <material> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	7 1 6 ; 1 0 5	using <method_2> and <material_3> , it is possible to learn models that reconstruct the tongue shape of a speaker with <metric_4> given the location of 3 -- 4 fleshpoints , and to adapt these models to a new speaker for which little data is available . in practice , <otherscientificterm_5> extracted from <method_1> are often incomplete because of <otherscientificterm_7> , <otherscientificterm_6> and other factors . we extend these models to deal with <material_0> during <task_8> and adaptation , and show that <metric_4> can still be achieved even with relatively large amounts of <material_0> .	2 3 4 9 -1 5 1 7 6 10 11 9 -1 0 8 9 -1
A distributed wavelet compression algorithm for wireless multihop sensor networks using lifting .	multihop , distributed sensor networks ; distributed compression algorithm ; partial wavelet coefficients ; wireless sensor networks ; natural data flow ; lifting factorization ; partial computations ; wavelet transform ; central node ; compression	<task> <method> <otherscientificterm> <task> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method>	1 0 0 ; 9 2 3	we address the problem of <method_9> for <task_3> , where each of the sensors has limited power , and acquires data that should be sent to a <otherscientificterm_8> . the final goal is to have a reconstructed version of the sampled field at the <otherscientificterm_8> , with the sensors spending as little energy as possible . we propose a <method_1> for <task_0> based on the <method_5> of the <otherscientificterm_7> that exploits the <material_4> in the network to aggregate data by computing <otherscientificterm_2> that are refined as the data flows towards the <otherscientificterm_8> . a key result of our work is that by performing <method_6> we greatly reduce unnecessary transmission , significantly reducing the overall energy consumption .	9 3 8 12 10 -1 10 -1 1 0 5 7 4 2 11 10 -1 10 -1
Multiple description speech coding with diversities .	speech and audio coders ; fixed constraints ; mdc systems ; packet-lossy nature ; network communications ; algorithmic delay ; computational complexity ; speech	<material> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <material>	6 1 5 ; 2 0 7	most existing <material_0> were developed to meet a single purpose of delivering the best quality possible under <otherscientificterm_1> in bit-rate , <metric_6> , and <otherscientificterm_5> . recent expansion in <method_4> demands the additional capability to cope with the <otherscientificterm_3> associated with these <method_4> . the problem lies within the research area of multiple description coding -lrb- mdc -rrb- . in this report we investigate its essence , state its inherent limitations and tradeoffs , and propose a novel method to design efficient <method_2> for <material_7> .	0 1 6 5 9 8 -1 4 3 8 -1 8 -1 2 7 10 8 -1
Line drawing interpretation in a multi-view context .	creation of new objects ; reconstruction of real-world scenes ; multi-view stereo algorithms ; urban planing ; computer vision ; labeling algorithm ; line drawings ; furniture design ; home remodeling ; cultural heritage ; design tasks ; hand algorithms ; line-drawing interpretation ; line drawing ; 3d structure	<task> <task> <method> <task> <task> <method> <task> <task> <task> <material> <task> <method> <task> <task> <otherscientificterm>	3 1 8 ; 7 1 9 ; 8 1 9 ; 6 0 3 ; 8 1 7 ; 2 0 1 ; 11 0 12	many <task_10> involve the <task_0> in the context of an existing scene . existing work in <task_4> only provides partial support for such tasks . on the one hand , <method_2> allow the <task_1> , while on the other <method_11> for <task_12> do not take context into account . our work combines the strength of these two domains to interpret <task_6> of imaginary objects drawn over photographs of an existing scene . the main challenge we face is to identify the existing <otherscientificterm_14> that correlates with the <task_13> while also allowing the creation of new structure that is not present in the real world . we propose a <method_5> to tackle this problem , where some of the labels capture dominant orientations of the real scene while a free label allows the discovery of new orientations in the imaginary scene . we illustrate our <method_5> by interpreting <task_6> for <task_3> , <task_8> , <task_7> and <material_9> .	10 0 15 -1 4 15 -1 2 1 11 12 21 22 15 -1 6 15 -1 14 13 15 -1 15 -1 5 16 17 18 19 20 15 -1
Intersession Compensation and Scoring Methods in the i-vectors Space for Speaker Recognition .	low dimensional total factor space ; factor analysis ; speaker verification system architecture ; total variability factor space ; carrying out channel compensation ; gmm supervector space ; total factor space ; session variability characteristics ; scoring methods ; speaker recognition	<otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	3 0 2 ; 1 0 9 ; 1 0 2 ; 6 2 7	the <otherscientificterm_3> in <method_2> based on <method_1> has greatly improved <task_9> performances . <task_4> in a <otherscientificterm_0> , rather than in the <otherscientificterm_5> , allows for the application of new techniques . we propose here new intersession compensation and <method_8> . furthermore , this new approach contributes to a better understanding of the <otherscientificterm_7> in the <otherscientificterm_6> .	3 2 1 9 4 11 12 13 10 -1 0 5 10 -1 8 10 -1 7 6 14 10 -1
A keyword-aware grammar framework for LVCSR-based spoken keyword search .	weight finite-state automata ; openkws14 tamil limited-language pack tasks ; compact and deterministic grammar wfsa ; n-gram lm based approximation approach ; lvcsr-based keyword search ; n-gram wfsa ; keyword-aware grammar ; evalpart1 data ; keyword paths ; grammar	<method> <material> <method> <method> <task> <method> <method> <material> <otherscientificterm> <method>	6 1 3 ; 3 0 9 ; 8 0 5 ; 6 0 4	in this paper , we proposed a method to realize the recently developed <method_6> for <task_4> using <method_0> . the approach creates a <method_2> by inserting <otherscientificterm_8> to an existing <method_5> . tested on the <material_7> of the iarpa babel openkws13 vietnamese and <material_1> , the experimental results indicate the proposed keyword-aware framework achieves significant improvement , with about 50 % relative actual term weighted value -lrb- atwv -rrb- enhancement for both languages . comparisons between the <method_6> and our previously proposed <method_3> for the <method_9> also show that the kws performances of these two realizations are complementary .	6 4 0 14 10 -1 2 8 5 13 10 -1 7 1 10 -1 3 9 11 12 10 -1
Closed-form supervised dimensionality reduction with generalized linear models .	supervised dimensionality reduction algorithms ; class-appropriate generalized linear models ; feature extraction -lrb- dimensionality reduction -rrb- ; closed-form update rules ; unified optimization framework ; predictive model ; high-dimensional datasets ; classification	<method> <method> <method> <otherscientificterm> <method> <method> <material> <task>	1 0 5 ; 5 0 4 ; 2 0 0 ; 0 0 5 ; 3 0 0 ; 2 0 5	we propose a family of <method_0> that combine <method_2> with learning a <method_5> in a <method_4> , using data - and <method_1> , and handling both <task_7> and regression problems . our <method_0> uses simple <otherscientificterm_3> and is provably convergent . promising empirical results are demonstrated on a variety of <material_6> .	0 2 5 4 1 7 9 10 11 12 14 8 -1 3 13 8 -1 6 8 -1
Automatic estimation of language model parameters for unseen words using morpho-syntactic contextual information .	language model parameters ; european portuguese broadcast news transcription system ; word error rate ; part-of-speech word classes ; speech recognition system ; lm unigram distribution ; archived documents ; in-domain corpus ; information sources ; information dissemination ; lm retraining ; morpho-syntatic information ; closed-captioning	<otherscientificterm> <task> <metric> <otherscientificterm> <method> <otherscientificterm> <material> <material> <material> <task> <method> <otherscientificterm> <task>	12 1 9 ; 7 1 3	various <material_8> naturally contains new words that appear in a daily basis and which are not present in the vocabulary of the <method_4> but are important for applications such as <task_12> or <task_9> . to be recognized , those words need to be included in the vocabulary and the <otherscientificterm_0> updated . in this context , we propose a new method that allows including new words in the vocabulary even if no well suited training data is available , as is the case of <material_6> , and without the need of <method_10> . it uses <otherscientificterm_11> about an <material_7> and <otherscientificterm_3> to define a new <otherscientificterm_5> associated to the updated vocabulary . experiments were carried out for a <task_1> . results showed a relative reduction of 4 % in <metric_2> , with 78 % of the occurrences of those newly included words being correctly recognized .	8 4 12 9 14 13 -1 0 13 -1 6 10 13 -1 11 7 15 13 -1 3 5 13 -1 1 13 -1
FAemb : A function approximation-based embedding method for image retrieval .	public image retrieval benchmarks ; function approximation process ; high dimensional space ; higher dimensional representation ; image retrieval framework ; image retrieval problem ; image retrieval ; nonlinear function ; local features ; embedded vectors ; feature representation ; embedding method ; vlad	<material> <method> <otherscientificterm> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method>	3 0 5 ; 2 2 6 ; 11 0 6 ; 2 2 10 ; 2 2 7 ; 7 0 6 ; 1 0 9 ; 10 0 6	the objective of this paper is to design an <method_11> mapping <otherscientificterm_8> describing image -lrb- e.g. sift -rrb- to a <method_3> used for <task_5> . by investigating the relationship between the linear approximation of a <otherscientificterm_7> in <otherscientificterm_2> and state-of-the-art <method_10> used in <task_6> , i.e. , <method_12> , we first introduce a new approach for the approximation . the <otherscientificterm_9> resulted by the <method_1> are then aggregated to form a single representation used in the <method_4> . the evaluation shows that our <method_11> gives a performance boost over the state of the art in <task_6> , as demonstrated by our experiments on the standard <material_0> .	11 8 3 5 14 13 -1 7 2 10 6 12 15 17 18 19 21 13 -1 9 1 4 20 13 -1 16 13 -1
On Real-Time Detecting Duplicate Web Videos .	detecting excessive content duplication ; intelligence propriety protection ; real-time detection method ; digital devices ; hash codes ; video search ; duplicate videos ; digital format ; real-time applications ; telecommunication techniques	<task> <task> <method> <method> <otherscientificterm> <task> <material> <material> <task> <method>	5 1 1 ; 8 5 2 ; 9 1 3	with the rapid development of <method_9> and <method_3> , it is quite easy to copy , modify and republish videos in <material_7> , resulting in large volume of <material_6> on the web in recent years . in this paper we mainly investigate the problem of <task_0> , so as to facilitate <task_5> and <task_1> . a <method_2> is hence proposed , which first selects videos ' representative frames and then reduces each to a 64 bit hash code . then the similarity of any two videos can be estimated by the proportion of their similar <otherscientificterm_4> . the experiments demonstrate that our <method_2> is both efficient and effective in terms of <task_8> .	9 3 7 6 13 10 -1 0 5 1 11 10 -1 2 10 -1 4 10 -1 12 10 -1
Sparse representation classification with manifold constraints transfer .	sparse representation-based classification approaches ; multipliers ; learning and inference problems ; alternating direction method ; linear embedding method ; image data samples ; general recognition tasks ; manifold constraints ; optimized variables ; geodesic distance ; manifold priors ; recognition accuracies ; objects recognition ; optimization process ; mani-fold ; manifold ; projection	<method> <method> <task> <method> <method> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	15 0 5 ; 10 3 0 ; 9 0 4 ; 7 3 13	the fact that <material_5> lie on a <otherscientificterm_15> has been successfully exploited in many <task_2> . in this paper we leverage the specific structure of data in order to improve <task_11> in <task_6> . in particular we propose a novel framework that allows to embed <otherscientificterm_10> into <method_0> . we also show that <otherscientificterm_7> can be transferred from the data to the <otherscientificterm_8> if these are linearly correlated . using this new insight , we define an efficient <method_3> of <method_1> that can consistently integrate the <otherscientificterm_7> during the <method_13> . this is based on the property that we can recast the problem as the <otherscientificterm_16> over the <otherscientificterm_14> via a <method_4> based on the <otherscientificterm_9> . the proposed approach is successfully applied on face , digit , action and <task_12> showing a consistently increase on performance when compared to the state of the art .	5 15 2 18 17 -1 11 6 17 -1 10 0 19 17 -1 7 8 17 -1 3 1 13 21 17 -1 20 17 -1 16 14 4 9 17 -1
Single channel speech enhancement using MDL-based subspace approach in Bark domain .	minimum description length criterion ; white and colored noise ; overes-timation of the signal ; single channel speech enhancement ; optimal subspace selection ; human auditory system ; input signal-to-noise ratio ; maximum noise reduction ; mdl-subspace approach ; selection criteria ; noise subspace ; signal distortions ; empirical parameters ; subspace selection ; subspace approach ; mdl criterion ; bark domain	<method> <otherscientificterm> <otherscientificterm> <task> <method> <method> <metric> <task> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <material>	15 0 13 ; 2 6 9 ; 14 0 16	we present in this paper a novel algorithm for <task_3> . it is based on a <method_14> in the <material_16> and an <method_4> by the <method_0> . the processing in the <material_16> allows us to take into account in an optimal manner the masking properties of the <method_5> . the <method_13> provided by the <otherscientificterm_15> overcomes the limitations encountered with other <metric_9> , like the <otherscientificterm_2> -- plus -- <otherscientificterm_10> or the need for <otherscientificterm_12> . together , the resulting <method_8> in the <material_16> provides <task_7> while minimizing <otherscientificterm_11> . the performance of our algorithm is assessed in <otherscientificterm_1> . it shows that our algorithm provides high performance for a large scale of <metric_6> .	3 17 -1 14 16 4 0 20 17 -1 5 17 -1 13 15 9 2 10 12 18 19 17 -1 8 7 11 17 -1 1 17 -1 17 -1
Towards a Knowledge Compilation Map for Heterogeneous Representation Languages .	relative adequacy of representation languages ; knowledge compilation map ; comparison of languages ; generalized setting ; ai problems ; generalized framework ; boolean functions ; formal basis ; add ; obdd ; expressiveness ; mdd ; transformations ; succinctness ; languages	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	11 6 14 ; 12 1 10 ; 11 1 8 ; 10 1 13 ; 9 6 14 ; 9 1 11	the <method_1> introduced by darwiche and marquis takes advantage of a number of concepts -lrb- mainly queries , <otherscientificterm_12> , <otherscientificterm_10> , and <otherscientificterm_13> -rrb- to compare the <otherscientificterm_0> to some <task_4> . however , the framework is limited to the <otherscientificterm_2> that are interpreted in a homogeneous way -lrb- formulae are interpreted as <otherscientificterm_6> -rrb- . this prevents one from comparing , on a <otherscientificterm_7> , <material_14> that are close in essence , such as <otherscientificterm_9> , <otherscientificterm_11> , and <otherscientificterm_8> . to fill the gap , we present a <method_5> into which comparing formally heterogeneous representation <material_14> becomes feasible . in particular , we explain how the key notions of queries and <otherscientificterm_12> , <otherscientificterm_10> , and <otherscientificterm_13> can be lifted to the <otherscientificterm_3> .	1 12 10 13 0 4 15 -1 2 6 15 -1 7 14 9 11 8 16 18 20 21 15 -1 5 15 -1 17 19 15 -1
Neural networks versus codebooks in an application for bandwidth extension of speech signals .	bandwidth extension of speech signals ; objective and subjective distortion measures ; spectral envelope ; neural networks ; codebooks	<task> <metric> <otherscientificterm> <method> <otherscientificterm>	3 1 4	this paper presents two versions of an algorithm for <task_0> . we focus on the generation of the <otherscientificterm_2> and compare the performance of two different approaches -- <method_3> versus <otherscientificterm_4> -- in terms of <metric_1> .	0 5 -1 2 3 4 1 6 5 -1
A novel approach for power control in a multi-user data transmission system .	multiuser data transmission system ; ten-line vdsl-2 system ; bit rate distributions ; maximum transmission power ; overall transmission power ; transmission power ; iterative optimization ; power control	<method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task>	5 0 1 ; 2 2 1	in this paper , we present a novel approach for <task_7> in a <method_0> . the main objective of our approach is to distribute the <otherscientificterm_4> among the lines in a way , such that a certain ratio between the bit rate of the lines is achieved . given the <otherscientificterm_3> per line and the ratio of the bit rates both the <otherscientificterm_5> and the achievable bit rate for each line are found by an <method_6> . we show the impact of our novel <task_7> in an experimental section , where the approach is used for finding the <otherscientificterm_5> for a <method_1> with various <otherscientificterm_2> .	7 0 8 -1 4 8 -1 3 5 6 8 -1 9 10 8 -1
A Variational Approach to Learning Curves .	gaussian process regression ; empirical error measures ; varia-tional approach ; posterior variance ; ap-proximative relations ; replica approach ; statistical physics ; generalization error ; learning curves	<task> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <task>	7 1 3 ; 6 1 2 ; 5 0 0 ; 6 0 5 ; 5 0 8 ; 1 1 7 ; 2 0 8	we combine the <method_5> from <method_6> with a <method_2> to analyze <task_8> analytically . we apply the <method_5> to <task_0> . as a main result we derive <otherscientificterm_4> between <metric_1> , the <otherscientificterm_7> and the <otherscientificterm_3> .	5 6 2 8 11 13 14 16 9 -1 0 12 9 -1 4 1 7 3 10 15 9 -1
A two-layer lexical tree based beam search in continuous Chinese speech recognition .	crossword context-dependent triphone models ; dynamic programming ; crossword context-dependent triphone models ; chinese fuzzy syllable mapping ; continuous speech recognition ; two-layer lexical tree ; memory cost ; pronunciation modeling ; acoustic information ; search algorithm ; token-passing algorithm ; decoding	<method> <method> <method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <task>	5 0 4 ; 3 1 7 ; 5 0 9 ; 0 1 3 ; 10 0 9 ; 2 0 5	in this paper , an approach to <task_4> based on a <method_5> is proposed . the search network is maintained by the <method_5> , in which the first layer reflects the word net and the phone net while the second layer the <method_1> . because the <otherscientificterm_8> is tied in the second layer , the <otherscientificterm_6> is so small that it has the ability to process some complicated applications , such as the use of <method_0> , the <method_3> and the <method_7> . the <method_9> based on the <method_5> is also proposed , which is derived from the <method_10> . finally , an implementation of the <method_5> using the <method_2> is presented , and the experimental results show that the highly efficient <task_11> can be achieved without too much <otherscientificterm_6> .	4 5 13 12 -1 1 12 -1 8 6 0 3 7 14 16 12 -1 9 10 15 17 12 -1 18 12 -1
Robust adaptive beamforming using sequential quadratic programming .	over/under estimation of the upper bound ; quadratic convex optimization problem ; erroneous presumed steering vector ; robust beam-forming techniques ; mismatch vector ; estimation process	<otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method>	1 0 5	in this paper , a new algorithm for robust adaptive beamform-ing is developed . the basic idea of the proposed algorithm is to estimate the difference between the actual and presumed steering vectors and to use this difference to correct the <otherscientificterm_2> . the <method_5> is performed iteratively where a <task_1> is solved at each iteration . unlike other <method_3> , our algorithm does not assume that the norm of the <otherscientificterm_4> is upper bounded , and hence it does not suffer from the negative effects of <otherscientificterm_0> . simulation results show the effectiveness of the proposed algorithm .	6 -1 2 6 -1 5 1 7 6 -1 3 4 0 6 -1 6 -1
Distributed correlated Q-learning for dynamic transmission control of sensor networks .	markovian dynamical game theoretic setting ; wireless sensor network ; correlated equilibrium policies ; correlated q-learning algorithm ; distributed transmission control ; spectrum bandwidth ; distributed algorithm ; markov chain ; decentralized feature	<method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	3 0 2 ; 0 0 4 ; 7 0 5 ; 6 0 2	this paper considers a <method_0> for <task_4> in a <method_1> . the available <otherscientificterm_5> is modeled as a <otherscientificterm_7> . a <method_6> named <method_3> is proposed to obtain the <otherscientificterm_2> of the <method_1> . this <method_3> has the <otherscientificterm_8> and is easily implementable in a real <method_1> . numerical example is also provided to verify the performances of the proposed <method_3> .	0 4 1 11 9 -1 5 7 12 9 -1 6 3 2 10 13 9 -1 8 9 -1 9 -1
Introduction of speech log-spectral priors into dereverberation based on Itakura-Saito distance minimization .	maximum a posteriori estimation ; itakura-saito distance minimization ; gmm of speech mel-frequency cepstral coefficients ; maximum-likelihood estimation ; is distance minimization ; blind speech dereverberation ; multi-channel linear prediction ; unknown reverberation processes ; speech log-spectral priors ; speech distortion ; priors ; dereverberation ; reverberation	<method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 5 ; 3 0 6	it has recently been shown that a <method_6> can effectively achieve <otherscientificterm_5> based on <task_3> . this approach can estimate and cancel <otherscientificterm_7> from only a few seconds of observation . however , one problem with this approach is that <task_9> may increase if we iterate the <otherscientificterm_11> more than once based on <method_1> to further reduce the <otherscientificterm_12> . to overcome this problem , we introduce <otherscientificterm_8> into this approach , and refor-mulate it based on <method_0> . two types of <otherscientificterm_10> are introduced , a gaussian mixture model -lrb- gmm -rrb- of speech log spectra , and a <otherscientificterm_2> . in the formulation , we also propose a new versatile technique to integrate such <otherscientificterm_8> with the <method_4> in a computationally efficient manner . preliminary experiments show the effectiveness of the proposed approach .	6 5 3 14 15 13 -1 7 13 -1 9 11 1 12 13 -1 8 0 13 -1 10 13 -1 2 13 -1 4 13 -1
PP-Attachment Disambiguation Boosted by a Gigantic Volume of Unambiguous Examples .	pp-attachment disambiguation method ; machine learning method ; raw corpus ; unambiguous examples ; pp-attachment disambiguation ; lexical preferences ; attachment decisions	<method> <method> <material> <material> <task> <otherscientificterm> <otherscientificterm>	1 0 6 ; 2 0 0 ; 3 0 0 ; 2 0 3	we present a <method_0> based on a gigantic volume of <material_3> extracted from <material_2> . the <material_3> are utilized to acquire precise <otherscientificterm_5> for <task_4> . <otherscientificterm_6> are made by a <method_1> that optimizes the use of the <otherscientificterm_5> . our experiments indicate that the precise <otherscientificterm_5> work effectively .	0 3 2 9 10 11 7 -1 5 4 6 7 -1 1 8 7 -1 7 -1
Low cost duration modelling for noise robust speech recognition .	implicit geometric state duration distributions ; state transition matrices ; clean speech recognition ; connected digit recognition ; state transition probabilities ; explicit duration model ; explicit duration models ; noisy speech recognition ; true duration distributions ; acoustic probabilities ; hmm decoders ; duration models ; maximum duration ; complexity	<otherscientificterm> <method> <task> <task> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <metric>	11 0 7 ; 1 0 10	state transition matrices as used in standard <method_10> have two widely perceived limitations . one is that the <otherscientificterm_0> which they model do not accurately reflect <otherscientificterm_8> . the other is that they impose no hard limit on <otherscientificterm_12> with the result that <otherscientificterm_4> often have little influence when combined with <otherscientificterm_9> , which are of a different order of magnitude . <method_6> were developed in the past to address the first problem . these were not widely taken up because their performance advantage in <task_2> was often not sufficiently great to offset the extra <metric_13> which they introduced . however , <method_11> have much greater potential when applied to <task_7> . in <method_5> paper we present a simple and generic form of <method_5> and show that <method_5> leads to strong performance improvements when applied to <task_3> in noise .	10 16 14 -1 0 8 14 -1 12 4 9 6 14 -1 14 -1 2 13 14 -1 15 14 -1 11 7 14 -1
Exact Recovery of Hard Thresholding Pursuit .	hard thresholding pursuit ; restricted strong condition number bounding conditions ; bounded restricted strong condition number ; truncated gradient descent methods ; parameter estimation consistency ; global sparse minimizer ; simulated data ; np-hard problem ; global minimizer ; approximation guarantee ; htp-style methods	<method> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <method>	5 0 10 ; 1 2 10 ; 0 6 3	the <method_0> is a class of <method_3> for finding sparse solutions of ‚Ñì 0-constrained loss minimization problems . the <method_10> have been shown to have strong <otherscientificterm_9> and impressive numerical performance in high dimensional statistical learning applications . however , the current theoretical treatment of these <method_10> has traditionally been restricted to the analysis of <metric_4> . it remains an open problem to analyze the support recovery performance -lrb- a.k.a. , sparsistency -rrb- of this type of <method_10> for recovering the <otherscientificterm_8> of the original <task_7> . in this paper , we bridge this gap by showing , for the first time , that exact recovery of the <otherscientificterm_5> is possible for <method_10> under <otherscientificterm_1> . we further show that <method_10> are able to recover the support of certain relaxed sparse solutions without assuming <otherscientificterm_2> . numerical results on <material_6> confirms our theoretical predictions .	0 3 14 11 -1 10 9 11 -1 4 11 -1 8 7 11 -1 12 13 11 -1 5 1 11 -1 2 11 -1
Breaking Symmetries in Graph Representation .	extremal graph theory ; undirected graph search ; symmetry breaking constraints ; isomorphic representations ; symmetry breaking ; graph representation ; combinatorial problems ; undirected graph	<method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm>	4 0 5 ; 2 0 1	there are many complex <task_6> which involve searching for an <otherscientificterm_7> satisfying a certain property . these <task_6> are often highly challenging because of the large number of <method_3> of a possible solution . in this paper we introduce novel , effective and compact , <otherscientificterm_2> for <task_1> . while incomplete , <method_3> prove highly beneficial in pruning the search for a <otherscientificterm_5> . we illustrate the application of <method_4> in <otherscientificterm_5> to resolve several open instances in <method_0> .	6 7 8 -1 3 8 -1 2 1 10 8 -1 5 8 -1 4 0 9 8 -1
Building a Scientific Concept Hierarchy Database -LRB- SCHBase -RRB- .	semantically-meaningful '' phylogenetic '' structure ; evolution of scientific discourse ; hierarchical database of keyphrases ; extracted keyphrases ; scientific literature ; keyphrases/concepts ; search ; schbase ; keyphrases	<otherscientificterm> <task> <material> <method> <material> <otherscientificterm> <task> <method> <otherscientificterm>	7 6 2 ; 4 0 2	extracted <otherscientificterm_8> can enhance numerous applications ranging from <task_6> to tracking the <task_1> . we present <method_7> , a <material_2> extracted from large collections of <material_4> . <method_7> relies on a tendency of scientists to generate new abbreviations that '' extend '' existing forms as a form of signaling novelty . we demonstrate how these <otherscientificterm_5> can be extracted , and their viability as a database in relation to existing collections . we further show how <otherscientificterm_8> can be placed into a <otherscientificterm_0> and describe key features of this structure .	8 6 1 9 -1 7 2 4 10 11 9 -1 9 -1 5 9 -1 0 3 9 -1
College Towns , Vacation Spots , and Tech Hubs : Using Geo-Social Media to Model and Compare Locations .	mul-tivariate multiple linear regression ; neural network models ; location 's interest profile ; location-based interest profiles ; per-city interest model ; city-based interest models ; interest models ; demo-graphics features ; geo-social media ; vacation spots ; geo-tagged tweets ; categorical perspectives ; art ; sports	<method> <method> <otherscientificterm> <material> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <material> <material>	0 1 1 ; 0 0 2 ; 12 1 13 ; 8 0 3 ; 7 0 2	in this paper , we explore the potential of <method_8> to construct <material_3> to uncover the hidden relationships among disparate locations . through an investigation of millions of <material_10> , we construct a <method_4> based on fourteen high-level categories -lrb- e.g. , technology , <material_12> , <material_13> -rrb- . these <method_6> support the discovery of related locations that are connected based on these <otherscientificterm_11> -lrb- e.g. , college towns or <otherscientificterm_9> -rrb- but perhaps not on the individual tweet level . we then connect these <method_5> to underlying demographic data . by building <method_0> and <method_1> we show how a <otherscientificterm_2> may be estimated based purely on its <otherscientificterm_7> .	8 3 18 14 -1 10 4 12 13 17 14 -1 6 11 9 14 -1 5 14 -1 0 1 15 16 19 14 -1
Word Sense Disambiguation Using Label Propagation Based Semi-Supervised Learning .	label propagation based semi-supervised learning algorithm ; supervised word sense dis-ambiguation methods ; labeled and unlabeled data ; global consistency assumption ; manually sense-tagged data ; learning process ; benchmark corpora ; bilingual bootstrapping ; monolingual bootstrapping ; wsd	<method> <method> <material> <otherscientificterm> <material> <task> <material> <method> <method> <method>	0 0 9 ; 4 0 1 ; 0 4 9 ; 8 4 7 ; 0 4 7 ; 0 4 8	shortage of <material_4> is an obstacle to <method_1> . in this paper we investigate a <method_0> for <method_9> , which combines <material_2> in <task_5> to fully realize a <otherscientificterm_3> : similar examples should have similar labels . our experimental results on <material_6> indicate that <method_0> consistently out-performs <method_9> when only very few labeled examples are available , and its performance is also better than <method_8> , and comparable to <method_7> .	4 1 12 10 -1 0 9 2 5 3 11 10 -1 6 8 7 13 14 15 16 10 -1
Subspace matching : Unique solution to point matching with geometric constraints .	structure-from-motion and object recognition ; computation-ally hard integer problem ; linear programming-based algorithm ; vector base ; visual tasks ; feature vector ; unknown permutation ; convex set ; subspace ; noise	<task> <task> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 0 1	finding correspondences between feature points is one of the most relevant problems in the whole set of <task_4> . in this paper we address the problem of matching a <otherscientificterm_5> -lrb- or a matrix -rrb- to a given <otherscientificterm_8> . given any <otherscientificterm_3> of such a <otherscientificterm_8> , we observe a linear combination of its elements with all entries swapped by an <otherscientificterm_6> . we prove that such a <task_1> is uniquely solved in a <otherscientificterm_7> resulting from relaxing the original problem . also , if <otherscientificterm_9> is present , based on this result , we provide a robust estimate recurring to a <method_2> . we use <task_0> as motivating examples .	4 10 -1 5 8 10 -1 3 6 10 -1 1 7 11 10 -1 9 10 -1 2 10 -1
Motion Context : A New Representation for Human Action Recognition .	motion context ; human action video datasets ; rich 3d mc descriptor ; image representation techniques ; human action recognition ; direct graphical model ; local motion information ; reference point ; video sequences ; mc descriptors ; action recognition ; relative locations ; recognition configurations ; motion-based representation ; plsa -rrb- ; 3d descriptor ; human action ; 3-plsa ; mc+svm	<method> <material> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <material> <method> <task> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <method> <method>	18 0 5 ; 15 0 16 ; 2 2 6 ; 8 0 4 ; 18 6 12	one of the key challenges in <task_4> from <material_8> is how to model an <otherscientificterm_16> sufficiently . therefore , in this paper we propose a novel <method_13> called <method_0> , which is insensitive to the scale and direction of an <otherscientificterm_16> , by employing <method_3> . a <method_0> captures the distribution of the motion words -lrb- mws -rrb- over <otherscientificterm_11> in a local region of the motion image -lrb- mi -rrb- around a <otherscientificterm_7> and thus summarizes the <otherscientificterm_6> in a <otherscientificterm_2> . in this way , any <otherscientificterm_16> can be represented as a <method_15> by summing up all the <method_9> of this <otherscientificterm_16> . for <task_10> , we propose 4 different <method_12> : mw + plsa , mw+svm , <method_0> + w <method_17> -lrb- a new <method_5> by extending <method_14> , and <method_18> . we test our approach on two <material_1> from kth and weizmann institute of science -lrb- wis -rrb- and our performances are quite promising . for the <method_0> , the proposed <method_13> achieves the highest performance using the proposed w <method_17> . for the <method_0> , the best performance of the proposed <method_0> is comparable to the state of the art .	4 8 16 23 19 -1 13 0 3 19 -1 11 7 6 2 22 19 -1 15 21 19 -1 9 20 24 19 -1 10 12 17 5 14 18 19 -1 1 19 -1 19 -1
An effective and efficient utterance verification technology using word n-gram filler models .	interactive voice response systems ; utterance verification technology ; equal error rate ; word n-gram based filler model ; posterior probability based confidence measurement ; false accept rate ; false reject rate ; access control ; context-free grammar ; carrier words ; secret answer ; acoustic fillers ; robustness ; predictor ; accuracy	<method> <method> <metric> <method> <method> <metric> <metric> <task> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <method> <metric>	1 0 7 ; 14 5 0 ; 2 5 1 ; 7 0 0 ; 1 0 8 ; 1 0 0 ; 1 0 9	in this paper we propose a novel , effective , and efficient <method_1> for <task_7> in the <method_0> . the key of our <method_1> is to construct a <method_8> by using the <otherscientificterm_10> to a question and a <method_3> . the <method_1> provides rich alternatives to the <otherscientificterm_10> and can potentially improve the <metric_14> of the <method_0> . <method_1> can also absorb <otherscientificterm_9> used by callers and thus can improve the <metric_12> . we also propose using a <method_13> based on the best alternative to calculate the confidence . we show detailed experimental results on a tough uv test set that contains 930 positive and 930 negative cases and discuss types of questions that are suitable for the <method_0> . we demonstrate that our <method_1> can achieve a 2.14 % <metric_2> on average and 0.8 % <metric_5> if the <metric_6> is 2.6 % and above . this is a 49 % <metric_2> compared with the approaches using <method_11> , and a 72 % <metric_2> compared with the <method_4> .	1 7 0 16 19 21 15 -1 8 10 3 20 15 -1 14 17 15 -1 9 12 22 15 -1 13 15 -1 15 -1 18 15 -1 2 5 6 15 -1
3D Hand Pose Estimation Using Randomized Decision Forest with Segmentation Index Points .	latent regression forest-based hand pose estimation framework ; real-time 3d hand pose estimation algorithm ; segmentation index points ; randomized decision forest framework ; public benchmark datasets ; decision forest-based methods ; forest growing strategy ; randomized feature ; non-leaf nodes ; depth image ; skeletal joints ; point cloud ; leaf node ; cpu ; cen-troid ; parallelism	<method> <method> <otherscientificterm> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 0 1 ; 2 0 6 ; 3 0 1 ; 7 0 6 ; 2 0 7 ; 4 5 1 ; 0 0 6	in this paper , we propose a <method_1> using the <method_3> . our <method_1> takes a <otherscientificterm_9> as input and generates a set of <otherscientificterm_10> as output . previous <method_5> often give labels to all points in a <otherscientificterm_11> at a very early stage and vote for the joint locations . by contrast , our <method_1> only tracks a set of more flexible virtual landmark points , named <otherscientificterm_2> , before reaching the final decision at a <otherscientificterm_12> . roughly speaking , an <otherscientificterm_2> represents the <otherscientificterm_14> of a subset of <otherscientificterm_10> , which are to be located at the leaves of the branch expanded from the <otherscientificterm_2> . inspired by recent <method_0> -lrb- tang et al. 2014 -rrb- , we integrate <otherscientificterm_2> into the framework with several important improvements : first , we devise a new <method_6> , whose decision is made using a <otherscientificterm_7> guided by <otherscientificterm_2> . second , we speed-up the <method_6> since only <otherscientificterm_2> , not the <otherscientificterm_10> , are estimated at <otherscientificterm_8> . third , the experimental results on <material_4> show clearly the advantage of the proposed <method_1> over previous state-of-the-art methods , and our <method_1> runs at 55.5 fps on a normal <otherscientificterm_13> without <otherscientificterm_15> .	1 3 19 16 -1 9 10 17 16 -1 5 11 16 -1 2 12 16 -1 14 16 -1 18 20 21 23 16 -1 0 6 7 16 -1 8 22 16 -1
Dimensionality reduction and principal surfaces via Kernel Map Manifolds .	synthetic and real data sets ; manifold learning approach ; explicit projection operator ; principal surfaces ; projection operator ; kernel regression ; dimension-ality reduction ; objective function ; projection distance ; extremal points ; principal surfaces ; parametrized surface ; natural mapping ; distribution ; mapping	<material> <method> <method> <otherscientificterm> <method> <task> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task>	11 0 1 ; 1 0 6 ; 5 2 12 ; 12 0 4 ; 1 0 1 ; 0 5 1	we present a <method_1> to <task_6> that explicitly models the <method_1> as a <task_14> from low to high dimensional space . the <method_1> is represented as a <otherscientificterm_11> represented by a set of parameters that are defined on the input samples . the <method_1> also provides a <method_12> from high to low dimensional space , and a concatenation of these two <method_12> induces a <method_4> onto the <method_1> . the <method_2> allows for a clearly defined <otherscientificterm_7> in terms of <task_8> and reconstruction error . a formulation of the <method_12> in terms of <task_5> permits a direct optimization of the <otherscientificterm_7> and the <otherscientificterm_9> converge to <otherscientificterm_10> as the number of data to learn from increases . <otherscientificterm_3> have the desirable property that they , informally speaking , pass through the middle of a <otherscientificterm_13> . we provide a proof on the convergence to <otherscientificterm_10> and illustrate the effectiveness of the proposed <method_1> on <material_0> .	1 6 14 17 20 15 -1 11 16 15 -1 12 4 19 15 -1 2 7 8 15 -1 5 18 15 -1 9 10 3 15 -1 13 21 15 -1
Multidimensional independent component analysis .	multidimen-sional independent component analysis ; independent component analysis ; mica decomposition of ecg signals ; multidimensional components ; bss/ica model ; one-dimensional subspaces	<task> <method> <task> <method> <method> <otherscientificterm>	5 0 1 ; 1 0 0 ; 4 0 3	this discussion paper proposes to generalize the notion of <method_1> to the notion of <task_0> . we start from the ica or blind source separation -lrb- bss -rrb- model and show that <method_1> can be uniquely identified provided <method_1> is properly parameterized in terms of <otherscientificterm_5> . from this standpoint , the <method_4> is generalized to <method_3> . we discuss how <method_1> can be adapted to <task_0> . the relevance of these ideas is illustrated by a <task_2> .	1 0 6 -1 5 7 6 -1 4 3 9 6 -1 8 6 -1 2 6 -1
Quadtree structured restoration algorithms for piecewise polynomial images .	image restoration algorithms ; piecewise polynomial images ; iterative shrinkage ideas ; nonlinear quadtree decomposition ; piecewise polynomial signals ; nonlinear manifold ; linear space ; nonlinear transformations	<method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 1 3 ; 5 0 4 ; 7 0 0 ; 3 0 0 ; 0 0 1	iterative shrinkage of sparse and redundant representations are at the heart of many state of the art denoising and decon-volution algorithms . they assume the signal is well approximated by a few elements from an overcomplete basis of a <otherscientificterm_6> . if one instead selects the elements from a <otherscientificterm_5> it is possible to more efficiently represent <otherscientificterm_4> . this suggests that <method_0> based around <otherscientificterm_7> could provide better results for this class of signals . this paper uses <method_2> and a <method_3> to develop <method_0> suitable for <material_1> .	8 -1 6 8 -1 5 4 10 8 -1 0 7 11 8 -1 2 3 1 9 12 13 8 -1
Consistency of Spectral Partitioning of Uniform Hypergraphs under Planted Partition Model .	spectral graph partitioning methods ; random m-uniform hypergraphs ; planted partition model ; multi-way affinity relations ; higher order tensors ; rate of convergence ; computer science ; spectral algorithm ; m-uniform hypergraphs ; m-way affinities ; uniform hyper-graphs ; stochastic blockmodel ; spectral technique	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method>	2 0 8	spectral graph partitioning <method_0> have received significant attention from both practitioners and theorists in <task_6> . some notable studies have been carried out regarding the behavior of these <method_0> for infinitely large sample size -lrb- von luxburg et al. , 2008 ; rohe et al. , 2011 -rrb- , which provide sufficient confidence to practitioners about the effectiveness of these <method_0> . on the other hand , recent developments in <task_6> have led to a plethora of applications , where the model deals with <otherscientificterm_3> and can be posed as <otherscientificterm_10> . in this paper , we view these models as <otherscientificterm_1> and establish the consistency of <method_7> in this general setting . we develop a <method_2> or <method_11> for such problems using <otherscientificterm_4> , present a <method_12> suited for the purpose and study its large sample behavior . the analysis reveals that the <method_2> is consistent for <otherscientificterm_8> for larger values of m , and also the <metric_5> improves for increasing m . our result provides the first theoretical evidence that establishes the importance of <otherscientificterm_9> .	0 6 13 -1 13 -1 3 10 13 -1 13 -1 1 7 13 -1 2 11 4 12 14 13 -1 8 5 13 -1
Letizia : An Agent That Assists Web Browsing .	world wide web ; user interface agent ; browsing behavior ; browsing strategy ; user behavior ; best-first search ; web browser ; netscape ; heuristics ; letizia	<material> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method> <method>	5 3 3 ; 7 6 6 ; 2 0 5 ; 9 6 1 ; 8 0 5	letizia is a <method_1> that assists a user browsing the <material_0> . as the user operates a conventional <method_6> such as <method_7> , the agent tracks <otherscientificterm_4> and attempts to anticipate items of interest by doing concurrent , autonomous exploration of links from the user 's current position . the agent automates a <method_3> consisting of a <method_5> augmented by <method_8> inferring user interest from <otherscientificterm_2> .	1 0 14 10 -1 6 7 4 12 10 -1 3 5 8 2 9 11 13 15 10 -1
Implementation of interconnective systems .	mixed constraint-and input-output-based representations of signal processing systems ; sensitivity analysis of systems ; automated system inversion ; signal-flow graphs ; systematic strategy ; delay-free loops ; edx course	<method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	4 0 0	this paper proposes a <method_4> for the automated implementation of <method_0> . examples of the <method_4> are provided in synthesizing algorithms derived from <otherscientificterm_3> having <otherscientificterm_5> , as well as in performing <task_2> . an algorithm that follows the <method_4> , and which has been deployed online as part of an <otherscientificterm_6> , is discussed in greater focus . <method_1> designed using the algorithm is provided .	4 0 8 7 -1 3 5 2 7 -1 6 1 7 -1 7 -1
Query Translation Disambiguation as Graph Partitioning .	spectral query translation model ; word co-occurrence statistics ; query translation dis-ambiguation ; query translation disam-biguation ; query translation disambiguation ; graph partitioning problem ; cross-language information retrieval ; translation probabilities ; query words ; query translation ; trec datasets ; bilingual dictionary ; weighted graph ; translation words	<method> <metric> <task> <task> <task> <task> <task> <otherscientificterm> <otherscientificterm> <task> <material> <material> <otherscientificterm> <otherscientificterm>	1 0 2 ; 5 0 4 ; 9 0 6 ; 6 5 0 ; 10 5 0	resolving ambiguity in the process of <task_9> is crucial to <task_6> when only a <material_11> is available . in this paper we propose a novel approach for <task_3> , named '' <method_0> '' . the proposed approach views the problem of <task_4> as a <task_5> . for a given query , a <otherscientificterm_12> is first created for all possible translations of <otherscientificterm_8> based on the co-occurrence statistics of the <otherscientificterm_13> . the best translation of the query is then determined by the most strongly connected component within the <otherscientificterm_12> . the proposed approach distinguishes from previous approaches in that the translations of all <otherscientificterm_8> are estimated simultaneously . furthermore , <otherscientificterm_7> are introduced in the proposed approach to capture the uncertainty in translating queries . empirical studies with <material_10> have shown that the <method_0> achieves a relative 20 % -50 % improvement in <task_6> , compared to other approaches that also exploit <metric_1> for <task_2> .	9 6 11 17 14 -1 3 0 14 -1 4 5 16 14 -1 12 8 13 14 -1 14 -1 14 -1 14 -1 7 15 18 19 14 -1
Similarity Metric for Curved Shapes in Euclidean Space .	square root velocity mapping ; deformation space modulo shape orientation ; open and closed curves ; direct product lie groups ; orientation preserving diffeomorphisms ; shape matching approaches ; elastic shape metric ; rigid transformation matrices ; full curve ; curved shapes ; local perturbations ; geodesic curves ; deformation space ; similarity metric ; lie algebra ; computing geodesics ; pre-smoothing ; matrices ; invariance	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm>	9 0 11 ; 3 0 9 ; 13 0 9 ; 1 1 4 ; 0 0 6	in this paper , we introduce a <method_13> for <otherscientificterm_9> that can be described , distinctively , by ordered points . the proposed <method_13> represents a given curve as a point in the <otherscientificterm_12> , the direct product of <otherscientificterm_7> , such that the successive action of the <otherscientificterm_17> on a fixed starting point reconstructs the <otherscientificterm_8> . in general , both <otherscientificterm_2> are represented in the <otherscientificterm_1> and <otherscientificterm_4> . the use of <method_3> to represent <otherscientificterm_9> led to an explicit formula for <otherscientificterm_11> and the formulation of a <method_13> between shapes by the l 2-norm on the <otherscientificterm_14> . additionally , <otherscientificterm_18> to reparametrization or estimation of point correspondence between shapes is performed as an intermediate step for <task_15> . furthermore , since there is no computation of differential quantities on the curves , our <method_3> is more robust to <otherscientificterm_10> and needs no <method_16> . we compare our <method_13> with the <method_6> defined through the <method_0> , and other <method_5> .	13 9 22 19 -1 12 7 17 8 19 -1 2 1 4 23 19 -1 3 11 14 20 21 19 -1 19 -1 18 15 19 -1 10 16 24 19 -1
Speaker normalization in the MFCC domain .	maximum likelihood linear regression ; vocal tract normalization ; phoneme recognition task ; speaker independent recognisers ; parameter estimates ; mfcc domain ; filterbank domain ; recognition ; accuracy	<method> <method> <task> <method> <method> <material> <material> <task> <metric>	1 0 1 ; 2 5 7	it has been shown in several recent publications that application of <method_1> is a successful method for improving the <metric_8> of <method_3> . we argue that <method_1> can be implemented in the <material_6> and propose a model to achieve this . we show how the model can be implemented directly in the <material_5> , where <method_1> may be viewed as a constrained version of <method_0> . the <method_4> produced by the model are in accord with our ideas about how <method_1> should operate to perform <method_1> . <task_7> results on a <task_2> are presented which show a small improvement in <metric_8> .	1 8 3 9 -1 6 9 -1 5 0 9 -1 4 7 10 9 -1 2 11 9 -1
Matching of Double-Sided Document Images to Remove Interference .	canny edge detection ; historical handwritten documents ; clear textual images ; remaining background interference ; interfering strokes ; cancellation effect ; reverse side ; front side ; images	<method> <material> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	0 0 3	the national archives of singapore keeps a large volume of <material_1> . one common problem with the archives is that over the years , ink sipped through the pages of these documents such that characters on the <otherscientificterm_6> become visible and interfere with the characters on the <otherscientificterm_7> . this paper addresses this problem and develops a novel algorithm to extract <material_2> from the interference . we achieve this by mapping <material_8> from both sides of a page such that <otherscientificterm_4> seen on the <otherscientificterm_7> are matched with the strokes originating from the <otherscientificterm_6> so as to achieve a <otherscientificterm_5> . the resultant image is further subjected to an improved <method_0> to eliminate <otherscientificterm_3> . experimental results have confirmed the validity of our proposed method .	1 9 -1 6 7 9 -1 2 9 -1 8 4 5 9 -1 10 9 -1 0 3 9 -1
Divergent stereo for robot navigation : learning from bees .	computation of optical ow eld ; reeex-type control of motion ; robot 's motion ; metric depth estimation ; range computation ; funneled corridor ; visual elds ; mobile robot ; diicult task ; qualitative approach ; diierential estimation ; optical axis ; visually-guided navigation ; images	<task> <task> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <material> <task> <method> <method> <otherscientificterm> <task> <material>	0 0 9 ; 13 0 4 ; 9 0 12 ; 5 0 8 ; 11 2 7	a <method_9> to <task_12> based on the <task_0> is presented . the <method_9> is based on the use of two cameras mounted on a <material_7> and with the <otherscientificterm_11> directed in opposite directions such that the two <otherscientificterm_6> do not overlap -lrb- divergent stereo -rrb- ; <method_4> is based on the computation of the apparent image speed on <material_13> acquired during <otherscientificterm_2> . an example of <task_1> , driven by <method_10> of the ow eld measured by the two eyes , is presented . in particular it is shown how a <task_8> like navigating through a <otherscientificterm_5> with obstacles , is possible without the need for <task_3> .	9 12 0 15 17 14 -1 7 11 6 4 13 2 16 19 14 -1 1 10 14 -1 8 5 18 14 -1
Collaborative Users ' Brand Preference Mining across Multiple Domains from Implicit Feedbacks .	bayesian personalized ranking optimization criterion ; user web browsing log data ; synthetic and real world datasets ; user brand preference learning problem ; searching and browsing behaviors ; latent factor model ; implicit feedbacks ; positive feedbacks ; collaborative filtering ; brand preferences ; learning processes ; data scarcity ; collective learning	<method> <material> <material> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <task> <method>	4 6 6 ; 0 0 5 ; 2 5 5 ; 0 0 8	advanced e-applications require comprehensive knowledge about their users ' preferences in order to provide accurate personalized services . in this paper , we propose to learn users ' preferences to product brands from their <otherscientificterm_6> such as their <otherscientificterm_4> in <material_1> . the <task_3> is challenge since -lrb- 1 -rrb- the users ' <otherscientificterm_6> are extremely sparse in various product domains ; and -lrb- 2 -rrb- we can only observe <otherscientificterm_7> from users ' behaviors . in this paper , we propose a <method_5> to collaboratively mine users ' <otherscientificterm_9> across multiple domains simultaneously . by <method_12> , the <method_10> in all the domains are mutually enhanced and hence the problem of <task_11> in each single domain can be effectively addressed . on the other hand , we learn our <method_5> with an adaption of the <method_0> which is a general learning framework for <task_8> from <otherscientificterm_6> . experiments with both <material_2> show that our proposed <method_5> significantly outperforms the baselines .	13 -1 6 4 1 14 13 -1 3 7 13 -1 5 9 13 -1 12 10 13 -1 11 15 17 13 -1 0 8 16 13 -1
The Role of Macros in Tractable Planning over Causal Graphs .	exponential length plans ; planning algorithm ; causal graph ; polynomial time ; planning domains ; complexity ; macros	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric> <otherscientificterm>	2 0 1 ; 3 2 0 ; 6 0 4	the <metric_5> of existing planners is bounded by the length of the resulting plan , a fact that limits planning to domains with relatively short solutions . we present a novel <method_1> that uses the <otherscientificterm_2> of a domain to decompose it into sub-problems and stores subproblem plans in memory as <otherscientificterm_6> . in many domains , the resulting plan can be expressed using relatively few <otherscientificterm_6> , making it possible to generate <otherscientificterm_0> in <otherscientificterm_3> . we show that our <method_1> is complete , and that there exist special cases for which it is optimal and polynomial . experimental results demonstrate the potential of using <otherscientificterm_6> to solve <task_4> with long solution plans .	5 7 -1 1 2 6 8 7 -1 0 3 9 7 -1 7 -1 10 7 -1
Two-stream emotion recognition for call center monitoring .	two-stream processing of speech signals ; semantics of the conversation ; real-word call-center data ; emotion detection ; ldc corpus ; two-stream process ; extracting emotion ; acoustic features ; emotion category ; call-center data ; confidence level ; probabilistic measure ; semantics	<task> <otherscientificterm> <material> <task> <material> <method> <task> <otherscientificterm> <otherscientificterm> <material> <metric> <metric> <otherscientificterm>	0 0 3 ; 5 0 6	we present a technique for <task_0> for <task_3> . the first stream recognises emotion from <otherscientificterm_7> while the second stream recognises emotion from the <otherscientificterm_1> . a <metric_11> is derived for each of the individual streams and the <otherscientificterm_8> from the two streams is recognised . the output of the two streams is combined to generate a score for a particular <otherscientificterm_8> . the <metric_10> of each stream is used to weigh the scores from the two streams while generating the final score . this technique is extremely significant for <material_9> that have some <otherscientificterm_12> associated with the speech . the proposed technique is evaluated on the <material_4> and on the <material_2> . experiments suggest that use of a <method_5> provides better results than the existing techniques of <task_6> only from <otherscientificterm_7> .	0 3 14 13 -1 7 1 13 -1 11 8 13 -1 13 -1 10 13 -1 9 12 13 -1 13 -1 4 2 15 13 -1
Target Tracking with Online Feature Selection in FLIR Imagery .	particle filter-based target tracking algorithm ; dual foreground and background model ; online feature selection technique ; unified bayesian estimation framework ; particle filtering approach ; foreground-based target model ; online feature selection ; joint target tracking ; tracking confidence ; target tracking ; feature selection ; flir imagery ; target representation ; feature ; tracker	<method> <method> <method> <method> <method> <method> <method> <task> <metric> <task> <task> <task> <method> <otherscientificterm> <method>	1 0 12 ; 0 0 11 ; 5 1 14 ; 2 0 8 ; 4 0 10	we present a <method_0> for <task_11> . a <method_1> is proposed for <method_12> which supports robust and accurate <task_9> and size estimation . a novel <method_2> is introduced that is able to adaptively select the optimal <otherscientificterm_13> to maximize the <metric_8> . moreover , a coupled <method_4> is developed for <task_7> and <task_10> in an <method_3> . the experimental results show that the proposed <method_0> can accurately track poorly-visible targets in <task_11> even with strong ego-motion . the <metric_8> performance is improved when compared to the <method_14> with a <method_5> and without <method_6> .	0 11 15 -1 1 12 9 16 15 -1 2 13 8 19 15 -1 4 7 10 3 20 15 -1 17 15 -1 14 5 6 18 15 -1
Signal processing challenges for radio astronomical arrays .	square kilometre array ; data processing systems ; imaging limitations ; image reconstruction ; computational requirements ; radio telescopes	<method> <task> <otherscientificterm> <task> <otherscientificterm> <material>	0 6 5	current and future <material_5> , in particular the <method_0> , are envisaged to produce large images -lrb- > 10 8 pixels -rrb- with over 60 db dynamic range . this poses a number of <task_3> and technological challenges , which will require novel approaches to <task_3> and design of <task_1> . in this paper , we sketch the limitations of current algorithms by extrapolating their <otherscientificterm_4> to future <material_5> as well as by discussing their <otherscientificterm_2> . we discuss a number of potential research directions to cope with these challenges .	5 0 7 6 -1 3 1 6 -1 4 2 6 -1 6 -1
Semantic Co-segmentation in Videos .	video object segmentation datasets ; temporally connected segments ; semantic objects ; semantic co-segmentation ; object-like tracklets ; visual semantics ; co-segmentation process ; tracking-based approach ; object properties ; submodular function ; cluttered backgrounds ; deformed shapes ; appearances ; shapes	<material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	7 0 2 ; 12 6 8 ; 12 1 13 ; 13 6 8	discovering and segmenting objects in videos is a challenging task due to large variations of objects in <otherscientificterm_12> , <otherscientificterm_11> and <otherscientificterm_10> . in this paper , we propose to segment objects and understand their <otherscientificterm_5> from a collection of videos that link to each other , which we refer to as <method_3> . without any prior knowledge on videos , we first extract <otherscientificterm_2> and utilize a <method_7> to generate multiple <otherscientificterm_4> across the video . each tracklet maintains <otherscientificterm_1> and is associated with a predicted category . to exploit rich information from other videos , we collect tracklets that are assigned to the same category from all videos , and co-select tracklets that belong to true objects by solving a <otherscientificterm_9> . this function accounts for <otherscientificterm_8> such as <otherscientificterm_12> , <otherscientificterm_13> and motions , and hence facilitates the <task_6> . experiments on three <material_0> show that the proposed algorithm performs favorably against the other state-of-the-art methods .	12 11 10 14 -1 5 3 14 -1 2 7 4 15 14 -1 1 14 -1 14 -1 9 16 17 18 14 -1 8 13 6 14 -1
Magnetic beamforming for wireless power transfer .	near-field wireless power transfer ; semidefinite programming problem ; magnetic resonant coupling ; receiver coil ; semidefinite relaxation ; identical tx resistances ; uncoordinated benchmark scheme ; equal current allocation ; mrc-wpt system ; rx load ; tx coils ; minimum power ; magnetic beamforming ; tx coil ; voltage sources ; optimization problem ; peak voltage ; rx coil ; wpt efficiency ; magnetic fields ; deliverable power ; beam ; txs ; rx	<task> <task> <task> <otherscientificterm> <method> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 0 0 ; 22 1 23 ; 13 1 17	magnetic resonant coupling -lrb- mrc -rrb- is an efficient method for realizing the <task_0> . the use of multiple transmitters -lrb- <otherscientificterm_22> -rrb- each with one coil can be applied to enhance the wpt performance by focusing the <otherscientificterm_19> from all <otherscientificterm_10> in a <otherscientificterm_21> toward the <otherscientificterm_3> , termed as '' <method_12> '' . in this paper , we study the optimal <method_12> for an <method_8> with multiple <otherscientificterm_22> and a single <otherscientificterm_23> . we formulate an <task_15> to jointly design the currents flowing through different <otherscientificterm_22> so as to minimize the total power drawn from their <otherscientificterm_14> , subject to the <otherscientificterm_11> required by the <otherscientificterm_9> as well as the <otherscientificterm_22> ' constraints on the <otherscientificterm_16> and current . for the special case of <otherscientificterm_5> and neglecting all <otherscientificterm_22> ' constraints on the <otherscientificterm_16> and current , we show that the optimal current magnitude of each <task_2> is proportional to the mutual inductance between its <otherscientificterm_13> and the <otherscientificterm_17> . in general , the problem is a non-convex quadratically constrained quadratic programming -lrb- qcqp -rrb- problem , which is reformulated as a <task_1> . we show that its <method_4> is tight . numerical results show that <method_12> significantly enhances the <otherscientificterm_20> as well as the <metric_18> over the <method_6> of <metric_7> .	0 25 24 -1 22 19 10 21 3 12 24 -1 8 23 26 24 -1 15 14 24 -1 11 9 16 27 24 -1 5 2 13 17 24 -1 1 24 -1 4 24 -1
Variable-length versus fixed-length coding : On tradeoffs for soft-decision decoding .	variable-length codes ; fixed-length codes ; bit-wise channel reliability information ; variable-length soft-decision decoder ; quantization bit rate ; variable block lengths ; media transmission ; awgn channels ; transmission errors ; bcjr algorithm ; error robustness ; trellis representation ; source correlation ; audio coding ; hard-decision decoding ; soft-decision decoding	<method> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <task> <method> <otherscientificterm> <method> <metric> <method> <otherscientificterm> <task> <method> <method>	11 0 9 ; 11 0 0 ; 10 5 14 ; 12 1 0 ; 4 1 0 ; 4 1 12 ; 0 4 7 ; 12 1 5 ; 5 2 0 ; 2 0 3 ; 0 0 8 ; 1 4 0 ; 0 0 13 ; 0 0 6	variable-length codes -lrb- <method_0> -rrb- are widely used in <task_6> . compared to <method_1> , <method_0> can represent the same message with a lower bit rate , thus having a better compression performance . but inevitably , <method_0> are very sensitive to <otherscientificterm_8> . in this work , based on the <method_11> for <method_0> and the <method_9> , we present a <method_3> utilizing <otherscientificterm_2> and achieving a better <metric_10> in contrast to <method_14> . given the application of <method_0> in <task_13> showing both <otherscientificterm_12> and <otherscientificterm_5> , a strong dependency of performance is observed for both . therefore , we point out tradeoffs of -lrb- soft-decision -rrb- decoded flcs and <method_0> depending on <metric_4> , <otherscientificterm_12> , and block length . we find that <method_0> over <method_7> are only recommended for very low <otherscientificterm_12> in combination with very short block lengths and <method_15> .	0 6 30 16 -1 1 28 16 -1 8 27 16 -1 11 9 3 2 10 14 17 18 19 26 16 -1 13 12 5 24 25 29 16 -1 20 21 22 16 -1 4 23 16 -1
Predictive Projections .	nearest neighbor style learning ; linear dimensionality reduction algorithm ; high dimensional state spaces ; synthetic pendulum balancing domain ; reinforcement learning algorithms ; learning control policies ; visually guided control ; robot domain ; features	<method> <method> <otherscientificterm> <material> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 7 ; 3 0 1	this paper addresses the problem of <task_5> in very <otherscientificterm_2> . we propose a <method_1> that discovers predictive projections : projections in which accurate predictions of future states can be made using simple <method_0> . the goal of this work is to extend the reach of existing <method_4> to domains where they would otherwise be inap-plicable without extensive engineering of <otherscientificterm_8> . the <method_1> is demonstrated on a <material_3> , as well as on a <otherscientificterm_7> requiring <otherscientificterm_6> .	5 2 9 -1 1 0 9 -1 4 8 9 -1 3 7 6 10 11 9 -1
Optimizing components for handheld two-way speech translation for an English-iraqi Arabic system .	handheld two-way speech translation system ; field usable handheld device ; translation quality feedback ; speech-to-speech translation ; training time ; back translations ; handheld device ; fieldable systems ; tts components ; handheld ; asr ; iraqi ; english	<method> <method> <otherscientificterm> <task> <metric> <otherscientificterm> <task> <method> <method> <material> <task> <material> <material>	1 0 3 ; 6 0 3 ; 12 1 11	this paper described our <method_0> for <material_12> and <material_11> . the focus is on developing a <method_1> for <task_3> . the computation and memory limitations on the <material_9> impose critical constraints on the <task_10> , smt , and <method_8> . in this paper we discuss our approaches to optimize these components for the <task_6> and present performance numbers from the evaluations that were an integral part of the project . since one major aspect of the transtac program is to build <method_7> , we spent significant effort on developing an intuitive interface that minimizes the <metric_4> for users but also provides useful information such as <otherscientificterm_5> for <otherscientificterm_2> .	0 12 11 16 13 -1 1 3 14 15 13 -1 9 10 8 13 -1 6 13 -1 7 4 13 -1
Corroborating Text Evaluation Results with Heterogeneous Measures .	text evaluation measure ; n-gram based measures ; human-produced references ; text evaluation ; heterogeneous measures ; rouge ; bleu	<metric> <method> <otherscientificterm> <task> <method> <metric> <metric>	6 6 1 ; 6 1 5 ; 5 6 1	automatically produced texts -lrb- e.g. translations or summaries -rrb- are usually evaluated with <method_1> such as <metric_6> or <metric_5> , while the wide set of more sophisticated measures that have been proposed in the last years remains largely ignored for practical purposes . in this paper we first present an in-depth analysis of the state of the art in order to clarify this issue . after this , we formalize and verify empirically a set of properties that every <metric_0> based on similarity to <otherscientificterm_2> satisfies . these properties imply that corroborating system improvements with additional measures always increases the overall reliability of the evaluation process . in addition , the greater the heterogeneity of the measures -lrb- which is measurable -rrb- the higher their combined reliability . these results support the use of <method_4> in order to consolidate <task_3> results .	1 6 5 8 9 10 7 -1 7 -1 0 2 7 -1 7 -1 7 -1 7 -1
Directions in Hybrid Intelligence : Complementing AI Systems with Human Intelligence .	machine and human intelligence ; hybrid intelligence systems ; reasoning methods ; human intelligence ; ai systems	<otherscientificterm> <method> <method> <material> <method>	1 0 4 ; 2 0 3 ; 2 0 1 ; 1 0 3 ; 0 0 1	hybrid intelligence systems combine <otherscientificterm_0> to overcome the shortcomings of existing <method_4> . this paper reviews recent research efforts towards developing <method_1> focusing on <method_2> for optimizing access to <material_3> and on gaining comprehensive understanding of humans as helpers of <method_4> . it concludes by discussing short and long term research directions .	0 4 6 10 5 -1 1 2 3 7 8 9 5 -1 5 -1
Greedy Layer-Wise Training of Deep Networks .	deep belief networks ; greedy layer-wise unsupervised learning algorithm ; greedy layer-wise unsu-pervised training strategy ; complexity theory of circuits ; non-linear and highly-varying functions ; deep multi-layer neural networks ; internal distributed representations ; hidden causal variables ; input distribution ; shallow architectures ; computational elements ; generative model ; gradient-based optimization ; optimization problem ; supervised task ; random initialization ; deep architectures ; non-linearities ; optimization ; generalization	<method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <task> <otherscientificterm> <method> <otherscientificterm> <task> <method>	16 4 9 ; 15 0 12	complexity theory of circuits strongly suggests that <method_16> can be much more efficient -lrb- sometimes exponentially -rrb- than <otherscientificterm_9> , in terms of <otherscientificterm_10> required to represent some functions . <method_5> have many levels of <otherscientificterm_17> allowing them to compactly represent highly <otherscientificterm_4> . however , until recently it was not clear how to train such <method_16> , since <method_12> starting from <otherscientificterm_15> appears to often get stuck in poor solutions . hin-ton et al. recently introduced a <method_1> for <method_0> , a <method_11> with many layers of <otherscientificterm_7> . in the context of the above <task_13> , we study this algorithm empirically and explore variants to better understand its success and extend it to cases where the inputs are continuous or where the structure of the <otherscientificterm_8> is not revealing enough about the variable to be predicted in a <task_14> . our experiments also confirm the hypothesis that the <method_2> mostly helps the <task_18> , by initializing weights in a region near a good local minimum , giving rise to <method_6> that are high-level abstractions of the input , bringing better <method_19> .	16 9 10 5 21 20 -1 17 4 20 -1 12 15 22 20 -1 1 0 11 7 20 -1 13 20 -1 8 14 20 -1
A Model for Aggregating Contributions of Synergistic Crowdsourcing Workflows .	quality control methods ; iterative improvement workflow ; assembly model ; task processing ; crowdsourcing tasks ; iterative method ; crowdsourcing topics ; pomdp	<method> <method> <method> <method> <task> <method> <material> <method>	7 0 5	one of the most important <material_6> is to study the effective <method_0> so as to reduce the cost and to guarantee the quality of <method_3> . as an effective approach , <method_1> is known to choose the best result from multiple workflows . however , for complex <task_4> that consists of a certain number of subtasks under some specific constraints , but can not be split into subtasks to be crowdsourced , the approach merely considers the best workflow without integrating the contributions of all workflows , which potentially results in extra costs for more iterations . in this paper , we propose an <method_2> to integrate the best output of subtasks from different workflows . moreover , we devise an efficient <method_5> based on <method_7> to improve the quality of assembled output . empirical studies confirms the superiority of our proposed <method_2> .	6 0 3 8 -1 1 8 -1 4 8 -1 8 -1 2 9 8 -1 5 7 8 -1
Random Multiresolution Representations for Arbitrary Sensor Network Graphs .	distributed multiresolution representation of sensor network data ; local neighborhoods of the communication graph ; long distance coordination ; distributed encoding algorithm ; large-scale summaries ; large-scale trends ; mobile collector ; randomized encoding ; cluster heads ; small-scale details ; local details ; lossless representation ; de-terministic hierarchies ; sensor node ; sensor nodes ; local querier ; global querier ; distributed computation ; lossy ; encoding ; robustness	<method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <metric>	8 1 12 ; 0 0 4 ; 6 6 16 ; 5 1 10	we propose a <method_0> so that <material_4> are readily available by querying a small fraction of <otherscientificterm_14> , anywhere in the network , and <otherscientificterm_9> are available by querying a larger number of sensors , locally in the region of interest . a <otherscientificterm_16> -lrb- such as a <method_6> or unmanned aerial vehicle -rrb- can obtain a <method_18> to <method_11> of the network data , according to the desired resolution . a <method_15> -lrb- such as a <otherscientificterm_13> -rrb- can also obtain either <otherscientificterm_5> or <otherscientificterm_10> , by querying its immediate neighborhood . we want the <otherscientificterm_19> to be robust to arbitrary , even time-varying , wireless communication con-nectivity graphs . thus we want to avoid <otherscientificterm_8> or <otherscientificterm_12> that are not robust to single points of failure . we propose a <method_7> which enables both <metric_20> , and <method_17> that does not require <otherscientificterm_2> or awareness of network connectivity at individual sensors . our <method_3> operates on <otherscientificterm_1> .	0 4 14 9 23 21 -1 16 6 18 11 24 21 -1 15 13 5 10 25 21 -1 19 21 -1 22 21 -1 8 12 21 -1 7 20 17 2 21 -1
Maximum Variance Correction with Application to A * Search .	maximum variance correction ; maximum variance unfolding ; speed-up a * search ; man-ifold learning literature ; manifold learning algorithm ; search time ; manifold learning ; post-processing embed-dings ; mvu embeddings ; heuristics	<method> <task> <task> <material> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method>	0 0 8 ; 8 0 9 ; 0 0 1 ; 4 0 7	in this paper we introduce <method_0> , which finds large-scale feasible solutions to <task_1> by <otherscientificterm_7> from any <method_4> . <method_0> increases the scale of <otherscientificterm_8> by several orders of magnitude and is naturally parallel . this unprecedented scala-bility opens up new avenues of applications for <task_6> , in particular the use of <otherscientificterm_8> as effective <method_9> to <task_2> . we demonstrate unmatched reductions in <otherscientificterm_5> across several non-trivial a * benchmark search problems and bridge the gap between the <material_3> and one of its most promising high impact applications .	0 1 7 4 13 14 10 -1 8 11 10 -1 6 9 2 12 10 -1 5 3 10 -1
Sub-state tying in tied mixture hidden Markov models .	complexity-accuracy tradeoff solution ; classification error rate ; gaussian density sharing ; state emission probabilities ; sub-state level ; gaussian sharing ; reduction technique ; optimization technique ; whole-state tying ; sub-state tying ; error rate ; gaussians	<method> <metric> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <task> <task> <metric> <method>	1 4 5 ; 7 0 0 ; 2 1 9 ; 5 1 8	an approach is proposed for partial tying of states of tied-mixture hidden markov models . to facilitate tying at the <otherscientificterm_4> , the <otherscientificterm_3> are constructed in two stages , or equivalently , are viewed as a '' mixture of mixtures of <method_11> . '' this paradigm allows , and is complemented with , an <method_7> to seek the best <method_0> , which jointly exploits <method_2> and <task_9> . experimental results on the e-set show that the <metric_1> is reduced by over 20 % compared to standard <method_5> and <task_8> . the approach is then embedded within the recently developed procedure of combined parameter training and <method_6> . experiments with the overall technique show that the <metric_10> is further reduced by 8 % .	12 -1 4 3 11 12 -1 7 0 2 9 14 15 12 -1 1 5 8 13 16 12 -1 12 -1 6 12 -1
Signal Subspace Speech Enhancement for Audible Noise Reduction .	perceptual evaluation of speech quality ; segmental signal-to-noise ratio ; assumption of white noise ; subspace-based speech enhancement scheme ; estimated speech autocorrelation matrix ; audible noise reduction scheme ; human auditory system ; audible noise quantity ; audible noise reduction ; signal subspace technique ; colored noise case ; informal listening tests ; sub-space methods ; masking properties	<task> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <method> <material>	5 4 12 ; 0 5 12 ; 2 2 4 ; 0 1 11 ; 9 0 5 ; 1 5 12 ; 1 1 0 ; 5 0 10 ; 13 0 7	a novel <method_3> based on a criterion of <task_8> is considered . <material_13> of the <method_6> is used to define the <otherscientificterm_7> in the eigen-domain . subsequently , an <method_5> is developed based on a <method_9> . we derive the eigen-decomposition of the <otherscientificterm_4> with the <otherscientificterm_2> and outline the implementation of our proposed <method_5> . we further extend the <method_5> to the <task_10> . simulation results show that our proposed <method_5> outperforms many existing <method_12> in terms of <metric_1> , <task_0> and <otherscientificterm_11> .	3 8 13 14 -1 6 7 23 14 -1 5 9 19 14 -1 4 2 17 14 -1 10 22 14 -1 12 1 0 11 15 16 18 20 21 14 -1
Defining constraints for multilinear speech processing .	phonotactic description of the language ; internal structure of phonologial features ; phonological and the phonetic domains ; multilinear representations of speech utterances ; phonetic and phonological information ; explicit structural constraints ; well-formed syllable structures ; speech recognition applications ; constraint relaxation procedure ; fine-grained information ; constraint model ; precedence relations ; underspecified input ; phonological domain ; phonetic realisations ; speech recognition ; phonetic domain ; rankings ; features ; robustness	<task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric>	19 2 15 ; 9 0 7 ; 8 0 12 ; 19 5 8 ; 13 2 0	this paper presents a <method_10> for the interpretation of <task_3> which can provide important <otherscientificterm_9> for <task_7> . the <method_10> uses <otherscientificterm_5> specifying overlap and <otherscientificterm_11> between <otherscientificterm_18> in both the <otherscientificterm_2> in order to recognise <otherscientificterm_6> . in the <material_13> , these constraints together form a complete <task_0> , while in the <otherscientificterm_16> , the constraints define the <otherscientificterm_1> based on <otherscientificterm_14> . the constraints are enhanced by a <method_8> to cater for <otherscientificterm_12> and allows output representations to be extrapolated based on the <otherscientificterm_4> contained in the constraints and the <otherscientificterm_17> which have been assigned to them . this <method_8> thus addresses issues of <metric_19> in <task_15> .	10 3 9 7 22 20 -1 5 11 18 2 6 20 -1 13 0 16 1 14 25 20 -1 8 12 4 17 23 20 -1 21 24 20 -1
Parallel GPU implementation of null space based alternating optimization algorithm for large-scale matrix rank minimization .	large-scale matrix rank minimization problems ; null space based algorithm ; matrix rank minimization problem ; computing inverse matrix ; parallel gpu computing ; singular value decomposition ; alternating optimization algorithm ; parallel implementation ; low-rank solution ; computational cost ; signal processing ; large-scale problem ; gpu	<task> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <metric> <task> <task> <material>	3 1 5 ; 2 0 10 ; 1 0 8 ; 6 0 0	this paper provides an <method_6> for <task_0> and its <task_7> on <material_12> . the <task_2> has a lot of important applications in <task_10> , and several useful algorithms have been proposed . however most algorithms can not be applied to a <task_11> because of high <metric_9> . this paper proposes a <method_1> , which provides a <method_8> without <otherscientificterm_3> nor <otherscientificterm_5> . the <method_1> can be parallelized easily without any approximation and can be applied to a <task_11> . numerical examples show that the <method_1> provides a <method_8> efficiently and can be speed up by <method_4> .	6 0 7 12 17 13 -1 2 10 15 13 -1 11 9 13 -1 1 8 3 5 14 13 -1 13 -1 4 16 13 -1
Learning and matching multiscale template descriptors for real-time detection , localization and tracking .	training video sequence ; salient locations ; partial occlusion ; local descriptors ; object template ; normalized intensity ; object-specific variability ; video stream ; low-level tracking ; live video ; shape ; detection	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <material> <otherscientificterm> <task>	11 1 8 ; 7 0 4 ; 1 0 8 ; 8 0 6	we describe a system to learn an <otherscientificterm_4> from a <material_7> , and localize and track the corresponding object in <material_9> . the template is decomposed into a number of <otherscientificterm_3> , thus enabling <task_11> and <task_8> in spite of <otherscientificterm_2> . each local descriptor aggregates contrast invariant statistics -lrb- <otherscientificterm_5> and gradient orientation -rrb- across scales , in a way that enables matching under significant scale variations . <task_8> during the <material_0> enables capturing <otherscientificterm_6> due to the <otherscientificterm_10> of the object , which is encapsulated in the descriptor . <otherscientificterm_1> on both the template and the target image are used as hypotheses to expedite matching .	4 7 9 14 12 -1 3 11 8 2 13 12 -1 5 12 -1 0 6 10 1 16 12 -1 15 12 -1
Demodulation for wireless ATM network using modified SOM network .	data link control protocols ; medium access control ; self-organizing-map demodulator ; rician flat fading channels ; rician fading channels ; semi-blind adaptive demodulator ; training sequence ; linear interpolation ; decision feedback ; demodulation problem ; lidf-som	<method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <material> <method> <otherscientificterm> <task> <method>	10 4 4 ; 1 0 6 ; 2 0 7 ; 1 1 0 ; 8 0 7 ; 0 0 5 ; 0 0 6	we study the <task_9> in time division multiple access -lrb- tdma -rrb- wireless asynchronous transfer mode -lrb- atm -rrb- networks , where <otherscientificterm_3> are considered . a <method_7> with <otherscientificterm_8> combined with a modified version of the <method_2> is proposed for such a system . we obtain the <material_6> by exploiting <method_1> and <method_0> such that a <method_5> is implemented . simulation results show that <method_10> obtains 0.4 ‚àí 1.0 db gain over <otherscientificterm_4> as compared to lidf alone .	9 3 11 -1 7 8 2 14 16 11 -1 6 1 0 5 13 15 17 18 11 -1 10 4 12 11 -1
Maximum Likelihood Based Temporal Frame Selection .	fixed frame rate ; phoneme recognition task ; frame selection approach ; pitch asynchronous representation ; speech recognition systems ; time axis ; noisy frames	<otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm>	0 3 4	in this paper , we propose a maximum likelihood -lrb- ml -rrb- based <method_2> . a <otherscientificterm_0> adopted in most state-of-the-art <method_4> can face some problems , such as accidentally meeting <otherscientificterm_6> , assigning the same importance to each frame , and <method_3> . as an attempt to avoid those problems , our approach selects reliable frames from a fine resolution along the <otherscientificterm_5> . in a <task_1> , we show that significant improvements are achieved with the <method_2> comparing to a system with a <otherscientificterm_0> .	2 7 -1 0 4 6 3 8 7 -1 5 7 -1 1 7 -1
Topic-specific parser design in an air travel natural language understanding application .	supervised and unsupervised subject selection modes ; natural language understanding applications ; darpa communicator task ; semantic parsing ; smoothing mechanism ; data sparseness ; training corpus ; subject-specific parsers ; application domain ; parser ; accuracy	<method> <task> <task> <task> <method> <otherscientificterm> <material> <method> <material> <method> <metric>	9 0 8 ; 4 0 5 ; 3 0 1 ; 4 0 7 ; 7 4 9	in this paper we contrast a traditional approach to <task_3> for <task_1> in which a single <method_9> captures a whole <material_8> , with an alternative approach consisting of a collection of smaller parsers , each able to handle only a portion of the domain . we implement this topic-specific parsing strategy by fragmenting the <material_6> into subject specific subsets and developing from each subset a corresponding subject <method_9> . we demonstrate this procedure on the <task_2> , and we observe that given an appropriate <method_4> to overcome <otherscientificterm_5> , the set of <method_7> performs as effectively -lrb- in <metric_10> terms -rrb- as the original <method_9> . we present experiments both under <method_0> .	3 1 9 8 12 14 11 -1 6 11 -1 2 4 5 7 10 13 15 16 11 -1 11 -1
Speaker clustering using vector quantization and spectral clustering .	vector of vq code frequencies ; speaker diarization error rate ; bic stopping criterion ; cluster number estimation ; utterance length distributions ; speaker clustering method ; spectral clustering algorithm ; conversational speech recordings ; hierarchical agglomerative clustering ; short utterances ; eigen structure ; similarity matrix ; speech segment ; similarity measure ; purity metrics ; cosine ; clustering	<otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <method> <material> <method> <material> <otherscientificterm> <otherscientificterm> <method> <metric> <metric> <otherscientificterm> <method>	2 0 8 ; 11 0 6 ; 6 0 16 ; 3 0 16 ; 8 0 5 ; 5 0 7 ; 14 5 5 ; 10 0 6 ; 3 0 6	we present a <method_5> for <material_7> that contain <material_9> from multiple speakers . the proposed <method_5> represents a <method_12> with a <otherscientificterm_0> and uses a <otherscientificterm_15> between two vectors as their <metric_13> . the <method_16> is performed by a <method_6> with <method_3> based on an <otherscientificterm_10> of the <otherscientificterm_11> . we conducted experiments on five test sets with different <otherscientificterm_4> to compare the proposed <method_5> with the conventional approach based on a <method_8> using <otherscientificterm_2> . the results show that the proposed <method_5> significantly outperforms the conventional one in <metric_1> and <metric_14> .	5 7 9 23 17 -1 12 0 15 13 17 -1 16 6 3 10 11 19 20 21 25 26 17 -1 4 8 2 18 22 17 -1 1 14 24 17 -1
Reconstruction of 3-D Figure Motion from 2-D Correspondences .	3d motion of articulated models ; partial or missing data ; human motion sequences ; iterative batch algorithm ; 3d kinematic model ; maximum aposteriori trajectory ; 2d correspondences ; dynamic smoothing ; 2d measurements ; kinematic constraints	<task> <material> <material> <method> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm>	3 0 5 ; 4 0 9	we present a method for computing the <task_0> from <material_6> . an <method_3> is proposed which estimates the <otherscientificterm_5> based on the <otherscientificterm_8> subject to a number of constraints . these include -lrb- i -rrb- <otherscientificterm_9> based on a <method_4> , -lrb- ii -rrb- joint angle limits , -lrb- iii -rrb- <method_7> and -lrb- iv -rrb- 3d key frames which can be specified the user . the framework handles any variation in the number of constraints as well as <material_1> . this method is shown to obtain favorable reconstruction results on a number of complex <material_2> .	0 6 10 -1 3 5 8 11 10 -1 9 4 7 12 10 -1 1 10 -1 2 10 -1
MLLR transforms as features in speaker recognition .	maximum likelihood linear regression ; support vector machines ; frame-based cepstral speaker recognition models ; baseline and mllr-based systems ; cepstral gaussian mixture ; speech recognition systems ; text-independent speaker verification ; speaker features ; affine transforms ; spoken words ; adaptation transforms ; high-dimensional vectors ; speaker recognition ; svm systems ; acoustic models ; features ; recognizer	<method> <method> <method> <method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <method>	0 0 16 ; 1 0 7 ; 4 1 13 ; 7 0 11 ; 5 0 12 ; 5 4 13 ; 10 0 5 ; 1 0 11 ; 5 4 4 ; 15 0 12	we explore the use of <method_10> employed in <method_5> as <otherscientificterm_15> for <task_12> . this approach is attractive because , unlike standard <method_2> , it normalizes for the choice of <otherscientificterm_9> in <task_6> . <otherscientificterm_8> are computed for the gaussian means of the <method_14> used in a <method_16> , using <method_0> . the <otherscientificterm_11> formed by the transform coefficients are then modeled as <otherscientificterm_7> using <method_1> . the resulting <method_5> is competitive , and in some cases significantly more accurate , than state-of-the-art <method_4> and <method_13> . further improvements are obtained by combining <method_3> .	10 5 15 12 22 24 27 17 -1 2 9 6 8 17 -1 14 16 0 18 17 -1 11 7 1 19 21 25 17 -1 4 13 20 23 26 17 -1 3 17 -1
Video Event Understanding Using Natural Language Descriptions .	natural language descriptions of the training videos ; spa-tio temporal annotations of actions and roles ; topic-based semantic re-latedness measure ; spatio temporal annotations ; complex event understanding ; posterior regularization objective ; trecvid-med11 event kit ; role recognition ; video description ; weak supervision ; high-level summary	<material> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <material> <task> <material> <otherscientificterm> <material>	2 3 5	human action and <task_7> play an important part in <task_4> . state-of-the-art methods learn action and role models from detailed <otherscientificterm_3> , which requires extensive human effort . in this work , we propose a method to learn such models based on <material_0> , which are easier to collect and scale with the number of actions and roles . there are two challenges with using this form of <otherscientificterm_9> : first , these descriptions only provide a <material_10> and often do not directly mention the actions and roles occurring in a video . second , natural language descriptions do not provide <otherscientificterm_1> . to tackle these challenges , we introduce a <method_2> between a <material_8> and an action and role label , and incorporate <method_2> into a <otherscientificterm_5> . our event recognition system based on these action and role models matches the state-of-the-art method on the <material_6> , despite weaker supervision .	7 4 11 -1 3 11 -1 0 11 -1 9 10 11 -1 11 -1 1 12 11 -1 2 8 5 11 -1
Processing Complex Sentences in the Centering Framework .	resolution of intia-sentential anaphora ; functional information structure ; centering model	<task> <otherscientificterm> <method>	2 0 0	we extend the <method_2> for the <task_0> and specify how to handle complex sentences . an empirical evaluation indicates that the <otherscientificterm_1> guides the search for an antecedent within the sentence .	2 0 4 3 -1 1 3 -1
Trading Computation for Communication : Distributed Stochastic Dual Coordinate Ascent .	distributed stochastic dual coordinate ascent algorithm ; stochastic dual coordinate ascent methods ; stochas-tic dual coordinate ascent method ; distributed stochastic gradient descent methods ; regularized loss minimization problems ; stochas-tic gradient descent methods ; real data sets ; distributed optimization algorithm ; theoretical guarantees ; star network ; distributed framework ; multipliers ; computation ; svms	<method> <method> <method> <method> <task> <method> <material> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method>	1 4 5 ; 5 0 4 ; 10 0 13 ; 2 0 7 ; 7 4 3	we present and study a <method_7> by employing a <method_2> . <method_1> enjoy strong <otherscientificterm_8> and often have better performances than <method_5> in optimizing <task_4> . it still lacks of efforts in studying <method_1> in a <method_10> . we make a progress along the line by presenting a <method_0> in a <method_9> , with an analysis of the tradeoff between <otherscientificterm_12> and communication . we verify our analysis by experiments on <material_6> . moreover , we compare the proposed <method_7> with <method_3> and distributed alternating direction methods of <otherscientificterm_11> for optimizing <method_13> in the same <method_10> , and observe competitive performances .	7 2 1 18 14 -1 8 5 4 15 16 14 -1 10 14 -1 0 9 12 14 -1 6 14 -1 3 11 13 17 19 14 -1
Tracking Forecast Memories in stochastic decoders .	tracking forecast memories ; stochastic channel de-coders ; edge memories ; stochastic de-coders ; hardware complexity ; asic implementations ; decoding	<task> <method> <otherscientificterm> <method> <metric> <method> <task>	0 0 6	this paper proposes <task_0> as a novel method for implementing re-randomization and de-correlation of stochastic bit streams in <method_1> . we show that <task_0> are able to achieve <task_6> performance similar to that of the previous methods in the literature -lrb- i.e. , <otherscientificterm_2> or ems -rrb- , but they exhibit much lower <metric_4> . <task_0> significantly reduce the area requirements of <method_5> of <method_3> .	0 1 7 -1 6 2 4 8 7 -1 5 3 7 -1
Kernel information embeddings .	nonparametric estimates of mutual information ; ` conditional dimensionality reduction ; joint -lrb- input ; latent data representatives ; parzen window estimates ; mi-based objective function ; dimensionality reduction ; plain mi ; manifold alignment ; supervision signal ; conditional mi ; embedding algorithms ; embedding method	<method> <task> <otherscientificterm> <material> <method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method>	0 0 11 ; 5 0 6 ; 4 0 2	we describe a family of <method_11> that are based on <method_0> . using <method_4> of the distribution in the <otherscientificterm_2> , embedding -rrb- - space , we derive a <otherscientificterm_5> for <task_6> that can be optimized directly with respect to a set of <material_3> . various types of <otherscientificterm_9> can be introduced within the framework by replacing <method_7> with several forms of <otherscientificterm_10> . examples of the semi - -lrb- un -rrb- supervised algorithms that we obtain this way are a new model for <task_8> , and a new type of <method_12> that performs <task_1> ' .	11 0 14 13 -1 4 2 5 6 3 15 16 13 -1 9 7 10 13 -1 8 12 1 13 -1
The Distinctiveness , Detectability , and Robustness of Local Image Features .	database of model features ; classifying local image features ; local image features ; computation time ; quantitative models ; image data ; image deformations ; discriminant classifier ; regression network ; recognition time ; local features ; phase feature ; detection distributions ; recognition task ; sift ; scalability ; features ; distinctiveness ; detectability ; classifier ; robustness	<otherscientificterm> <task> <otherscientificterm> <metric> <method> <material> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <otherscientificterm> <metric> <metric> <method> <metric>	10 0 1 ; 8 4 13 ; 3 5 8 ; 17 1 20 ; 8 0 12 ; 3 5 13 ; 1 0 13 ; 10 0 13 ; 19 1 8 ; 17 1 18 ; 18 1 20 ; 5 0 8 ; 9 5 13 ; 8 0 13 ; 14 6 2	we introduce a new method that characterizes typical <otherscientificterm_2> -lrb- e.g. , <method_14> -lsb- 9 -rsb- , <otherscientificterm_11> -lsb- 3 -rsb- -rrb- in terms of their <metric_17> , <metric_18> , and <metric_20> to <otherscientificterm_6> . this is useful for the task of <task_1> in terms of those three properties . the importance of this <task_1> for a <method_13> using <otherscientificterm_10> is as follows : a -rrb- reduce the <metric_9> due to a smaller number of <otherscientificterm_16> present in the test image and in the <otherscientificterm_0> ; b -rrb- improve the <metric_9> since only the most useful <otherscientificterm_16> for the <method_13> are kept in the model database ; and c -rrb- increase the <metric_15> of the <method_13> given the smaller number of <otherscientificterm_16> per model . a <method_7> is trained to select well behaved feature points . a <method_8> is then trained to provide <method_4> of the <otherscientificterm_12> for each selected feature point . it is important to note that both the <method_19> and the <method_8> use <material_5> alone as their input . experimental results show that the use of these trained <method_8> not only improves the performance of our <method_13> , but <method_8> also significantly reduces the <metric_3> for the <method_13> .	2 14 11 17 18 20 6 25 31 32 36 21 -1 1 21 -1 13 10 9 16 0 22 28 29 34 21 -1 15 21 -1 7 26 21 -1 8 4 12 30 33 21 -1 19 5 23 24 27 35 21 -1
Automatic detection of vocal fold paralysis and edema .	database of disordered speech ; known pattern recognition methods ; nearest mean classifier ; fisher linear discriminant ; vocal fold pathology ; √£-nearest neighbor classifier ; vocal fold edema ; vocal fold paralysis ; receiver operating characteristic ; linear prediction analysis ; linear projection methods ; false alarm ; feature reduction ; feature extraction ; edema ; classifier ; detection ; classifiers	<material> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <task> <task> <task> <otherscientificterm> <method> <task> <method>	3 1 5 ; 5 1 2 ; 16 1 8 ; 10 0 12 ; 3 6 17 ; 9 0 12 ; 7 1 6 ; 6 6 4 ; 9 0 13 ; 13 0 12 ; 7 1 14	in this paper we propose a combined scheme of <method_9> for <task_13> along with <method_10> for <task_12> followed by <method_1> on the purpose of discriminating between normal and pathological voice samples . two different cases of speech under <otherscientificterm_4> are examined : <otherscientificterm_7> and <otherscientificterm_6> . three known <method_17> are tested and compared in both cases , namely the <method_3> , the <method_5> , and the <method_2> . the performance of each <method_15> is evaluated in terms of the probabilities of <task_11> and <task_16> or the <otherscientificterm_8> . the datasets used are part of a <material_0> developed by massachusetts eye and ear infirmary . the experimental results indicate that <otherscientificterm_7> and <otherscientificterm_14> can easily be detected by any of the aforementioned <method_17> .	9 13 10 12 1 22 24 27 28 18 -1 4 7 6 25 26 18 -1 17 3 5 2 19 20 23 18 -1 15 11 16 8 21 18 -1 0 18 -1 29 18 -1
Image processing techniques for blind TV ghost cancellation .	ghost cancellation reference signal ; tv synchronisation signal ; equalizer structure ; ghosts cancellation ; channel characteristics ; tv image ; vertical edges ; convergence	<otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	6 0 4 ; 6 3 5	this paper describes a technique to <task_3> without a <otherscientificterm_0> . the existing <otherscientificterm_6> in <material_5> are used to estimate the <otherscientificterm_4> . with the estimating results , the coefficients of the equalizer are updated . in this paper , a method to speed up the <otherscientificterm_7> is given . the <otherscientificterm_2> for cancelling all kinds of ghosts is discussed too . a new improved solution is achieved by interpreting the <otherscientificterm_1> as a genuine edge .	3 0 8 -1 6 5 4 9 10 8 -1 8 -1 7 8 -1 2 8 -1 1 8 -1
Approximate Dimension Equalization in Vector-based Information Retrieval .	generalized vector space model ; vector space model ; latent semantic indexing ; training corpus of text ; vector-based information retrieval methods ; large and small collections ; mono-lingual and bilingual text ; term -- term correlations ; translingual retrieval ; high-dimensional vectors ; bilingual collections ; lsi	<method> <method> <method> <material> <method> <material> <material> <otherscientificterm> <task> <otherscientificterm> <material> <method>	0 6 4 ; 2 1 0 ; 2 6 4 ; 3 0 9 ; 1 0 8 ; 11 1 1 ; 9 0 4 ; 9 0 0 ; 1 1 2 ; 1 6 4 ; 1 1 11	vector-based information retrieval methods such as the <method_1> , <method_2> , and the <method_0> represent both queries and documents by <otherscientificterm_9> learned from analyzing a <material_3> . <method_1> scales well to large collections , but can not represent <otherscientificterm_7> , which prevents <method_1> from being used in <task_8> . <method_1> and <method_11> can represent <otherscientificterm_7> , but do not scale well to very large retrieval collections . we present a novel method we call approximate dimension equalization -lrb- ade -rrb- that combines ideas from <method_1> , <method_11> , and <method_1> to produce a method that performs well on large collections , scales well computationally , and can represent <otherscientificterm_7> . we compare the performance of ade to the other methods on both <material_5> of both <material_6> . ade outperforms all other methods on large <material_10> , and performs close to the best in all other cases .	1 2 0 9 3 13 14 15 16 19 20 21 22 12 -1 7 8 17 12 -1 11 12 -1 18 23 12 -1 12 -1 5 6 12 -1
Smart Vision Chip Fabricated Using Three Dimensional Integration Technology .	smart vision chip ; photo detector compactly ; dimensional lsi technology ; smart vision chips ; biological structure ; biological function ; neuromorphic systems	<method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method>	3 1 3 ; 5 1 4 ; 2 0 6 ; 2 0 3	the <method_0> has a large potential for application in general purpose high speed image processing systems . in order to fabricate <method_3> including <otherscientificterm_1> , we have proposed the application of three <method_2> for <method_3> . three <method_2> has great potential to realize new <method_6> inspired by not only the <otherscientificterm_5> but also the <otherscientificterm_4> . in this paper , we describe our three <method_2> for <method_3> and the design of <method_3> .	0 7 -1 3 1 2 7 -1 6 5 4 9 10 7 -1 8 11 7 -1
Robust and Discriminative Self-Taught Learning .	robust and discriminative self-taught learning approach ; structured sparse regularization ; transfer learning methods ; semi-supervised learning methods ; machine learning problems ; dictionary basis vectors ; unlabeled data ; labeled data ; unlabeled images ; labeled images ; iterative algorithm ; optimization problem ; supervision information	<method> <method> <method> <method> <task> <otherscientificterm> <material> <material> <material> <material> <method> <task> <otherscientificterm>	3 1 2 ; 10 0 11 ; 1 0 5 ; 3 0 4 ; 2 0 4 ; 0 0 5	the lack of training data is a common challenge in many <task_4> , which is often tackled by <method_3> or <method_2> . the former requires <material_8> from the same distribution as the labeled ones and the latter leverages <material_9> from related homogenous tasks . however , these restrictions often can not be satisfied . to address this , we propose a novel <method_0> to utilize any <material_6> without the above restrictions . our new <method_0> employs a robust loss function to learn the dictionary , and enforces the <method_1> to automatically select the optimal <otherscientificterm_5> and incorporate the <otherscientificterm_12> contained in the <material_7> . we derive an efficient <method_10> to solve the <task_11> and rigorously prove its convergence . promising results in extensive experiments have validated the proposed <method_0> .	4 3 2 14 17 18 13 -1 8 9 13 -1 13 -1 0 6 13 -1 1 5 12 16 19 13 -1 7 15 13 -1 10 11 13 -1
Sequential Neural Models with Stochastic Layers .	blizzard and timit speech modeling data sets ; stochastic and sequential neural generative model ; stochastic recurrent neural networks ; deterministic recurrent neural network ; structured variational inference network ; deterministic and stochastic layers ; state space model ; recurrent neural networks ; latent state representation ; nonlinear recursive structure ; polyphonic music modeling ; recurrent neural network ; latent path	<material> <method> <method> <method> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm>	2 0 1 ; 7 2 8 ; 9 0 11 ; 2 0 3	how can we efficiently propagate uncertainty in a <method_8> with <method_7> ? this paper introduces <method_2> which glue a <method_3> and a <method_6> together to form a <method_1> . the clear separation of <otherscientificterm_5> allows a <method_4> to track the factorization of the <method_2> 's posterior distribution . by retaining both the <otherscientificterm_9> of a <method_11> and averaging over the uncertainty in a <otherscientificterm_12> , like a <method_6> , we improve the state of the art results on the <material_0> by a large margin , while achieving comparable performances to competing methods on <task_10> .	8 7 2 3 6 1 15 13 -1 5 4 14 17 13 -1 9 11 12 0 10 13 -1 16 13 -1
Combining time - and frequency-domain convolution in convolutional neural network-based phone recognition .	speaker and speaking style variations ; timit phone recognition task ; convolutional neural networks ; image recognition ; background motivations ; small translations ; hierarchical manner ; frequency axis ; spectral representation ; time-domain convolution ; speech recognition ; network architecture ; error rate ; convolution	<otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <metric> <otherscientificterm>	9 0 11 ; 8 0 2 ; 2 0 3 ; 2 0 10 ; 12 5 1	convolutional neural networks have proved very successful in <task_3> , thanks to their tolerance to <otherscientificterm_5> . <method_2> have recently been applied to <task_10> as well , using a <method_8> as input . however , in this case the translations along the two axes -- time and frequency -- should be handled quite differently . so far , most authors have focused on <otherscientificterm_13> along the <otherscientificterm_7> , which offers invariance to <otherscientificterm_0> . other researchers have developed a different <method_11> that applies <otherscientificterm_9> in order to process a longer time-span of input in a <otherscientificterm_6> . these two <method_2> have different <otherscientificterm_4> , and both offer significant gains over a standard fully connected network . here we show that the two <method_11> can be readily combined , like their advantages . with the combined model we report an <metric_12> of 16.7 % on the <task_1> , a new record on this dataset .	3 5 2 17 14 -1 10 8 16 18 14 -1 14 -1 13 7 0 14 -1 11 9 6 15 14 -1 14 -1 4 14 -1 19 14 -1
An Extensive Empirical Study of Collocation Extraction Methods .	automatic collocation extraction methods ; natural language processing ; precision-recall measures ; statistical classification	<method> <task> <method> <method>	2 0 0	this paper presents a status quo of an ongoing research study of collocations -- an essential linguistic phenomenon having a wide spectrum of applications in the field of <task_1> . the core of the work is an empirical evaluation of a comprehensive list of <method_0> using <method_2> and a proposal of a new approach integrating multiple basic methods and <method_3> . we demonstrate that combining multiple independent techniques leads to a significant performance improvement in comparison with individual basic methods .	1 4 -1 0 2 3 5 4 -1 4 -1
Structured Parameter Elicitation .	partially observable markov decision processes ; problem parameter elicitation ; factored belief representation ; special structural properties ; uncertainty planning tasks ; autonomous agent ; parameter elicitation ; parameter values ; computational complexity ; factorization ; momdp ; symmetry ; sarsop	<method> <method> <method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <metric> <otherscientificterm> <method> <otherscientificterm> <method>	12 1 10 ; 0 0 4 ; 0 0 6 ; 2 0 0 ; 0 4 10 ; 9 1 11	the behavior of a complex system often depends on parameters whose values are unknown in advance . to operate effectively , an <method_5> must actively gather information on the <otherscientificterm_7> while progressing towards its goal . we call this <method_1> . <method_0> provide a principled framework for such <task_4> , but they suffer from high <metric_8> . however , <method_0> for <task_6> often possess <otherscientificterm_3> , specifically , <otherscientificterm_9> and <otherscientificterm_11> . this work identifies these properties and exploits <method_0> for efficient solution through a <method_2> . the experimental results show that our new <method_0> outperform <method_12> and <method_10> , two of the fastest general-purpose <method_0> available , and can handle significantly larger problems .	13 -1 5 7 13 -1 1 0 13 -1 4 8 15 13 -1 6 3 9 11 16 19 13 -1 2 17 13 -1 12 10 14 18 13 -1
Robust Low Rank Kernel Embeddings of Multivariate Distributions .	hierarchical low rank decomposition of kernels embeddings ; latent and low rank information ; latent and low rank structures ; kernel embedding of distributions ; low rank structures ; kernel embedding literature ; real world distributions ; machine learning ; robust embedding ; model misspeci-fication ; rank embeddings ; density estimation	<method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <task> <task> <task> <otherscientificterm> <task>	3 0 7	kernel embedding of distributions has led to many recent advances in <task_7> . however , <otherscientificterm_2> prevalent in <otherscientificterm_6> have rarely been taken into account in this setting . furthermore , no prior work in <task_5> has addressed the issue of <task_8> when the <otherscientificterm_1> are misspecified . in this paper , we propose a <method_0> which can exploit such <otherscientificterm_4> in data while being robust to <task_9> . we also illustrate with empirical evidence that the estimated low <otherscientificterm_10> lead to improved performance in <task_11> .	7 13 12 -1 2 6 12 -1 5 8 1 12 -1 0 4 9 12 -1 10 11 3 12 -1
Deep hashing for compact binary codes learning .	deep hashing approach ; supervised dh ; large scale visual search ; nonlinear relationship of samples ; binary codes learning methods ; real-valued feature descrip-tor ; hierarchical non-linear transformations ; compact binary codes ; deep neural network ; dis-criminative power ; discrimi-native term ; intra-class variations ; inter-class variations ; binary vector ; linear projection ; binary codes ; dh	<method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	0 0 7 ; 8 0 15 ; 5 1 13 ; 4 0 14 ; 16 0 1 ; 7 0 2 ; 14 0 13	in this paper , we propose a new <method_0> to learn <otherscientificterm_7> for <task_2> . unlike most existing <method_4> which seek a single <method_14> to map each sample into a <otherscientificterm_13> , we develop a <method_8> to seek multiple <otherscientificterm_6> to learn these <otherscientificterm_15> , so that the <otherscientificterm_3> can be well exploited . our <method_0> is learned under three constraints at the top layer of the <method_8> : 1 -rrb- the loss between the original <otherscientificterm_5> and the learned <otherscientificterm_13> is minimized , 2 -rrb- the <otherscientificterm_15> distribute evenly on each bit , and 3 -rrb- different bits are as independent as possible . to further improve the <otherscientificterm_9> of the learned <otherscientificterm_15> , we extend <method_16> into <method_1> by including one <otherscientificterm_10> into the objective function of <method_16> which simultaneously maximizes the <otherscientificterm_12> and minimizes the <otherscientificterm_11> of the learned <otherscientificterm_15> . experimental results show the superiority of the proposed <method_0> over the state-of-the-arts .	0 7 2 18 23 17 -1 4 14 13 8 6 15 3 19 21 24 17 -1 5 20 17 -1 22 17 -1 9 16 1 10 12 11 17 -1
Scene understanding by statistical modeling of motion patterns .	discovery and statistical representation of motion patterns ; low level cues of noisy optical flow ; pixel level representation of motion patterns ; learning of patterns of activity ; conditional expectation of optical flow ; temporally segmented clips of video ; hierarchical , unsupervised fashion ; pedestrian and vehicular traffic ; gaussian mixture model ; dense optical flow ; motion patterns ; surveillance sequences ; motion model ; static camera ; related methods ; motion patterns ; kl divergence ; object detection ; k-means	<task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <otherscientificterm> <material> <method> <material> <otherscientificterm> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method>	18 0 8 ; 4 0 2 ; 12 0 15 ; 16 0 15 ; 8 0 5	we present a novel method for the <task_0> in a scene observed by a <otherscientificterm_13> . <method_14> involving <task_3> rely on trajectories obtained from <task_17> and tracking systems , which are unreliable in complex scenes of crowded motion . we propose a <method_8> model representation of salient patterns of optical flow , and present an algorithm for learning these patterns from <material_9> in a <otherscientificterm_6> . using <otherscientificterm_1> , <method_18> is employed to initialize a <method_8> for <material_5> . the components of this <method_8> are then filtered and instances of <otherscientificterm_15> are computed using a simple <method_12> , by linking components across space and time . <otherscientificterm_10> are then initialized and membership of instances in different <otherscientificterm_15> is established by using <otherscientificterm_16> between <method_8> distributions of pattern instances . finally , a <otherscientificterm_2> is proposed by deriving <otherscientificterm_4> . results of extensive experiments are presented for multiple <material_11> containing numerous patterns involving both <material_7> .	0 13 14 19 -1 3 17 19 -1 8 9 6 19 -1 1 18 5 20 24 19 -1 15 12 22 19 -1 10 23 19 -1 16 21 19 -1 2 4 19 -1
Modeling Dynamic Multi-Topic Discussions in Online Forums .	evolution of topic discussion ; evolution of topic discussions ; dynamic topic discussion models ; time lapse factor ; sociological phenomena ; online forums ; social network ; information flow ; topic discussions ; recommendation systems ; internet	<task> <task> <method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <method> <material>	0 0 4 ; 3 3 2	in the form of <otherscientificterm_8> , users interact with each other to share knowledge and exchange information in <material_5> . modeling the <task_0> reveals how information propagates on <material_10> and can thus help understand <otherscientificterm_4> and improve the performance of applications such as <method_9> . in this paper , we argue that a user 's participation in <otherscientificterm_8> is motivated by either her friends or her own preferences . inspired by the theory of <otherscientificterm_7> , we propose <method_2> by mining influential relationships between users and individual preferences . reply relations of users are exploited to construct the fundamental influential <method_6> . the property of discussed topics and <otherscientificterm_3> are also considered in our <method_2> . furthermore , we propose a novel measure called participationrank to rank users according to how important they are in the <method_6> and to what extent they prefer to participate in the discussion of a certain topic . the experiments show our model can simulate the <task_1> well and predict the tendency of user 's participation accurately .	8 5 11 -1 0 10 4 9 12 11 -1 11 -1 7 2 11 -1 11 -1 6 13 11 -1 3 11 -1 11 -1
Learning Label Trees for Probabilistic Modelling of Implicit Feedback .	user 's item selection process ; implicit feedback models ; probabilistic approach ; collaborative filtering ; tree-structured distributions ; evaluation protocol ; implicit feedback	<otherscientificterm> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm>	5 0 1 ; 6 0 2 ; 2 0 3	an efficient <method_2> to <task_3> with <otherscientificterm_6> , based on modelling the <otherscientificterm_0> . ‚Ä¢ <otherscientificterm_4> over items for scalability . ‚Ä¢ a principled and efficient algorithm for learning effective item trees from data . ‚Ä¢ a fix for the standard <method_5> for <method_1> , addressing its unrealistic assumptions .	2 3 6 0 9 10 7 -1 4 7 -1 7 -1 5 1 8 7 -1
Nested Monte-Carlo Search .	nested levels of random games ; nested monte-carlo search ; random games ; morpion solitaire ; abstract problems ; state space ; samegame	<otherscientificterm> <method> <material> <material> <task> <otherscientificterm> <material>	3 1 6	many problems have a huge <otherscientificterm_5> and no good heuristic to order moves so as to guide the search toward the best positions . <material_2> can be used to score positions and evaluate their interest . <material_2> can also be improved using random games to choose a move to try at each step of a game . <method_1> addresses the problem of guiding the search toward better states when there is no available heuristic . <method_1> uses <otherscientificterm_0> in order to guide the search . the <method_1> is studied theoretically on simple <task_4> and applied successfully to three different games : <material_3> , <material_6> and 16x16 sudoku .	5 2 7 -1 7 -1 1 7 -1 7 -1 0 7 -1 4 8 7 -1
Understanding Probabilistic Sparse Gaussian Process Approximations .	fully independent training conditional ; variational free energy approximations ; gaussian processes ; computational cost ; sparse approximations ; theoretical properties ; superficial similarities ; inference	<method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	0 1 1	good <otherscientificterm_4> are essential for practical <task_7> in <method_2> as the <metric_3> of exact methods is prohibitive for large datasets . the <method_0> and the <method_1> are two recent popular methods . despite <otherscientificterm_6> , these approximations have surprisingly different <otherscientificterm_5> and behave differently in practice . we thoroughly investigate the two methods for regression both analytically and through illustrative examples , and draw conclusions to guide practical application .	4 7 2 3 8 -1 0 1 9 8 -1 6 5 8 -1 8 -1
Re-thinking non-rigid structure from motion .	object shape space ; man-ifold of dimensionality ; linear basis method ; orthographic video sequence ; initialization algorithm ; nrsfm problem ; linear subspace ; non-rigid structure	<otherscientificterm> <otherscientificterm> <method> <material> <method> <task> <otherscientificterm> <otherscientificterm>	6 0 0	we present a novel approach to <otherscientificterm_7> from motion -lrb- nrsfm -rrb- from an <material_3> , based on a new interpretation of the problem . existing approaches assume the <otherscientificterm_0> is well-modeled by a <otherscientificterm_6> . our approach only assumes that small neighborhoods of shapes are well-modeled with a <otherscientificterm_6> . this constrains the shapes to belong to a <otherscientificterm_1> equal to the number of degrees of freedom of the object . after showing that the problem is still overconstrained , we present a solution composed of a novel <method_4> , followed by a robust extension of the locally smooth manifold learning algorithm tailored to the <task_5> . we finally present some test cases where the <method_2> fails -lrb- and is actually not meant to work -rrb- while the proposed approach is successful .	7 3 8 -1 0 6 9 8 -1 8 -1 1 8 -1 4 8 -1 5 8 -1
Learning Sparse Gaussian Graphical Models with Overlapping Blocks .	data matrix of p variables ; block coordinate descent method ; cancer gene expression data ; densely connected components ; joint optimization problem ; cancer driver genes ; network estimation methods ; overlapping blocks ; network estimate ; synthetic data ; network structure ; priori ; convex	<otherscientificterm> <method> <material> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 3 8	we present a novel framework , called grab -lrb- graphical models with overlapping blocks -rrb- , to capture <otherscientificterm_3> in a <method_8> . grab takes as input a <otherscientificterm_0> and n samples and jointly learns both a network of the p variables and densely connected groups of variables -lrb- called ` blocks ' -rrb- . grab has four major novelties as compared to existing <method_6> : 1 -rrb- it does not require blocks to be given a <otherscientificterm_11> . 2 -rrb- blocks can overlap . 3 -rrb- it can jointly learn a <otherscientificterm_10> and <otherscientificterm_7> . 4 -rrb- it solves a <task_4> with the <method_1> that is <otherscientificterm_12> in each step . we show that grab reveals the underlying <otherscientificterm_10> substantially better than four state-of-the-art competitors on <material_9> . when applied to <material_2> , grab outperforms its competitors in revealing known functional gene sets and potentially novel <otherscientificterm_5> .	3 8 14 13 -1 0 13 -1 6 11 13 -1 13 -1 10 7 13 -1 13 -1 4 1 12 13 -1 9 13 -1
Unimodal Bandits : Regret Lower Bounds and Optimal Algorithms .	continuous sets of arms ; asymptotic lower bounds ; discrete unimodal bandits ; stochastic multi-armed bandits ; unimodal structure ; asymptotic regret ; order-optimal regret ; unimodal function ; ucb algorithm ; non-stationary environments ; bounded interval ; finite graph ; osub	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	9 2 12 ; 1 0 2	we consider <method_3> where the expected reward is a <otherscientificterm_7> over partially ordered arms . this important class of problems has been recently inves-the set of arms is either discrete , in which case arms correspond to the vertices of a <otherscientificterm_11> whose structure represents similarity in rewards , or continuous , in which case arms belong to a <otherscientificterm_10> . for <otherscientificterm_2> , we derive <otherscientificterm_1> for the regret achieved under any algorithm , and propose <method_12> , an algorithm whose regret matches this lower bound . our algorithm optimally exploits the <otherscientificterm_4> of the problem , and surprisingly , its <otherscientificterm_5> does not depend on the number of arms . we also provide a regret upper bound for <method_12> in <otherscientificterm_9> where the expected rewards smoothly evolve over time . the analytical results are supported by numerical experiments showing that <method_12> performs significantly better than the state-of-the-art algorithms . for <otherscientificterm_0> , we provide a brief discussion . we show that combining an appropriate discretization of the set of arms with the <method_8> yields an <otherscientificterm_6> , and in practice , outperforms recently proposed algorithms designed to exploit the <otherscientificterm_4> .	3 7 13 -1 11 10 13 -1 2 1 12 15 13 -1 4 13 -1 5 14 13 -1 9 13 -1 13 -1 0 13 -1
Generalized Gaussian process models .	generalized gaussian process model ; gaussian process models ; closed-form efficient taylor approximation ; exponential family distribution ; task-specific output domains ; generalized gp model ; model-specific closed-form approximations ; approximate inference algorithms ; task-specific gp models ; unifying framework ; observation likelihood ; computer vision ; gp regression ; likelihood function ; counting ; inference ; classification	<method> <method> <method> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <task> <task>	8 0 11 ; 7 0 5 ; 12 6 1 ; 3 0 1 ; 16 1 14 ; 2 0 0 ; 12 1 16 ; 2 0 15 ; 0 0 1 ; 16 6 1	we propose a <method_0> , which is a <method_9> that encompasses many existing <method_1> , such as <method_12> , <task_16> , and <otherscientificterm_14> . in the <method_0> , the <otherscientificterm_10> of the <method_1> is itself parameterized using the <otherscientificterm_3> . by deriving <method_7> for the <method_5> , we are able to easily apply the same <method_0> to all other <method_1> . novel <method_1> are created by changing the parameterization of the <otherscientificterm_13> , which greatly simplifies their creation for <material_4> . we also derive a <method_2> for <task_15> on the <method_0> , and draw interesting connections with other <otherscientificterm_6> . finally , using the <method_0> , we create several new <method_1> and show their efficacy in building <method_8> for <task_11> .	0 9 1 12 16 14 20 22 24 27 17 -1 10 3 21 17 -1 7 5 19 17 -1 13 4 17 -1 2 15 6 23 25 17 -1 18 26 17 -1
Multiple Non-Redundant Spectral Clustering Views .	spectral clustering objective function ; dimensionality reduction ; clustering solution ; high-dimensional setting ; clustering algorithms ; subspaces	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm>	4 0 2	many <method_4> only find one <method_2> . however , data can often be grouped and interpreted in many different ways . this is particularly true in the <otherscientificterm_3> where different <otherscientificterm_5> reveal different possible groupings of the data . instead of committing to one <method_2> , here we introduce a novel method that can provide several non-redundant clustering solutions to the user . our approach simultaneously learns non-redundant <otherscientificterm_5> that provide multiple views and finds a <method_2> in each view . we achieve this by augmenting a <method_0> to incorporate <method_1> and multiple views and to penalize for redundancy between the views .	4 2 7 6 -1 6 -1 3 5 6 -1 6 -1 6 -1 0 1 6 -1
From contours to 3D object detection and pose estimation .	bag of boundaries ; object-centered representations of point-based object features ; non-rigid , locally affine shape deformations ; detecting object occurrences ; view-dependent shape templates ; convex optimization problem ; view-invariant object detection ; sparse object model ; pose estimation ; viewer-centered framework ; object boundaries ; background clutter ; image contours ; deformable grids ; mid-level feature ; benchmark datasets ; inference ; bobs	<method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <task> <method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task> <otherscientificterm>	0 6 14 ; 7 0 3 ; 6 1 8 ; 4 0 7	this paper addresses <task_6> and <task_8> from a single image . while recent work fo-cuses on <otherscientificterm_1> , we revisit the <method_9> , and use <otherscientificterm_12> as basic features . given training examples of arbitrary views of an object , we learn a <method_7> in terms of a few <otherscientificterm_4> . the <method_7> are jointly used for <task_3> and estimating their 3d poses in a new image . instrumental to this is our new <otherscientificterm_14> , called <method_0> , aimed at lifting from individual edges toward their more informative summaries for identifying <otherscientificterm_10> amidst the <otherscientificterm_11> . in <task_16> , <otherscientificterm_17> are placed on <otherscientificterm_13> both in the image and the <method_7> , and then matched . this is formulated as a <task_5> that accommodates invariance to <otherscientificterm_2> . evaluation on <material_15> demonstrates our competitive results relative to the state of the art .	6 8 21 18 -1 1 9 12 18 -1 7 4 22 18 -1 3 20 18 -1 14 0 10 11 19 18 -1 16 18 -1 17 13 18 -1 5 2 18 -1
An Association Network for Computing Semantic Relatedness .	cognitive human perceptions of relatedness ; rich structures of wikipedia ; computing semantic relatedness ; limited lexical coverage ; free association norms ; cognitive process ; free association ; perceptional gap ; human perceptions ; textual windows ; lexical coverage ; co-occurrences ; sparseness	<otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	6 0 8	to judge how much a pair of words -lrb- or texts -rrb- are semantically related is a <method_5> . however , previous algorithms for <task_2> are largely based on <otherscientificterm_11> within <otherscientificterm_9> , and do not actively leverage <otherscientificterm_0> . to bridge this <otherscientificterm_7> , we propose to utilize <otherscientificterm_6> as signals to capture such <otherscientificterm_8> . however , <otherscientificterm_6> , being manually evaluated , has <otherscientificterm_3> and is inherently sparse . we propose to expand <otherscientificterm_10> and overcome <otherscientificterm_12> by constructing an association network of terms and concepts that combines signals from <otherscientificterm_4> and five types of <otherscientificterm_11> extracted from the <material_1> . our evaluation results validate that simple algorithms on this network give competitive results in computing semantic re-latedness between words and between short texts .	5 13 -1 2 11 9 0 13 -1 7 6 8 14 13 -1 3 13 -1 10 12 4 13 -1 1 13 -1
Cumulative Attribute Space for Age and Crowd Density Estimation .	body/face pose -lrb- view angle -rrb- estimation ; sparse and imbalanced training data ; high dimensional vector-formed feature input ; sparse and imbalanced image samples ; sparse and imbalanced data ; low-level visual features ; human age estimation ; uncertain viewing conditions ; observable visual features ; crowd density estimation ; labelled training data ; computer vision problems ; cumulative attribute space ; sparse training data ; large feature variations ; cumulative attribute concept ; crowd counting ; regression models ; mapping function ; intrinsic ambiguities ; regression model ; scalar-valued output ; regression problem ; imbalanced sampling ; age estimation ; scalar values ; accuracy	<task> <material> <otherscientificterm> <material> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <material> <task> <otherscientificterm> <material> <otherscientificterm> <method> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <task> <otherscientificterm> <metric>	21 0 18 ; 3 0 12 ; 12 0 5 ; 3 0 5 ; 18 0 22 ; 1 0 22 ; 24 1 16 ; 15 4 17 ; 6 6 11 ; 9 1 0 ; 6 1 9 ; 15 0 20 ; 26 5 15 ; 18 0 11 ; 4 0 20 ; 0 6 11 ; 9 6 11	a number of <task_11> such as <task_6> , <task_9> and <task_0> can be formulated as a <task_22> by learning a <otherscientificterm_18> between a <otherscientificterm_2> and a <otherscientificterm_21> . such a <task_22> is made difficult due to <material_1> and <otherscientificterm_14> caused by both <otherscientificterm_7> and <otherscientificterm_19> between <otherscientificterm_8> and the <otherscientificterm_25> to be estimated . encouraged by the recent success in using attributes for solving <task_11> with <material_13> , this paper introduces a novel <method_15> for learning a <method_20> when only <material_4> are available . more precisely , <otherscientificterm_5> extracted from <material_3> are mapped onto a <otherscientificterm_12> where each dimension has clearly defined semantic interpretation -lrb- a label -rrb- that captures how the scalar output value -lrb- e.g. age , people count -rrb- changes continuously and cumulatively . extensive experiments show that our <method_15> gains notable advantage on <metric_26> for both <task_24> and <task_16> when compared against conventional <method_17> , especially when the <material_10> is sparse with <method_23> .	11 6 9 0 22 18 2 21 28 32 36 37 38 41 43 44 27 -1 1 14 7 19 8 25 33 27 -1 13 15 20 4 39 42 27 -1 5 3 12 29 30 31 27 -1 34 35 40 27 -1
Hierarchical Recognition of Human Activities Interacting with Objects .	semantic description of occurring events ; recognition of hierarchical human-object interactions ; human-object interactions ; motion estimation ; recognition decisions ; semantic layer ; object recognition ; airport-like environment ; activity recognition ; semantic-level recognition ; recognition ; accuracy ; feedback	<task> <task> <otherscientificterm> <task> <task> <otherscientificterm> <task> <otherscientificterm> <task> <task> <task> <metric> <otherscientificterm>	3 1 9 ; 6 1 3 ; 10 1 0 ; 9 0 1	the paper presents a system that recognizes humans interacting with objects . we delineate a new framework that integrates <task_6> , <task_3> , and <task_9> for the reliable <task_1> . the framework is designed to integrate <task_4> made by each component , and to probabilistically compensate for the failure of the components with the use of the decisions made by the other components . as a result , <otherscientificterm_2> in an <otherscientificterm_7> , such as ' a person carrying a baggage ' , ' a person leaving his/her baggage ' , or ' a person snatching another 's baggage ' , are recognized . the experimental results show that not only the performance of the final <task_8> is superior to that of previous approaches , but also the <metric_11> of the <task_6> and the <task_3> increases using <otherscientificterm_12> from the <otherscientificterm_5> . several real examples illustrate the superior performance in <task_10> and <task_0> .	13 -1 6 3 9 1 14 15 17 13 -1 4 13 -1 2 7 13 -1 13 -1 8 11 12 5 16 13 -1
Image Feature Learning for Cold Start Problem in Display Advertising .	discrimina-tive and meaningful features ; handcrafted image features ; feature learning architecture ; image display ads ; dis-criminative image features ; online display advertising ; real world dataset ; cold start problem ; human heuristic ; sift features ; handcrafted features ; raw pixels ; multimedia features ; historical information ; user feedback ; image ads	<otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <task> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	2 4 10 ; 12 6 1 ; 6 5 10 ; 2 0 4 ; 11 0 4 ; 11 1 14 ; 6 5 2 ; 2 0 0 ; 12 1 9 ; 9 6 1	in <task_5> , state-of-the-art click through rate -lrb- ctr -rrb- prediction algorithms rely heavily on <otherscientificterm_13> , and they work poorly on growing number of new ads without any <otherscientificterm_13> . this is known as the the <task_7> . for <material_15> , current state-of-the-art systems use <otherscientificterm_1> such as <otherscientificterm_12> and <otherscientificterm_9> to capture the attractiveness of ads . however , these <otherscientificterm_10> are task dependent , inflexible and heuristic . in order to tackle the <task_7> in <material_3> , we propose a new <method_2> to learn the most <otherscientificterm_4> directly from <material_11> and <otherscientificterm_14> in the target task . the proposed <method_2> is flexible and does not depend on <otherscientificterm_8> . extensive experiments on a <material_6> with 47 billion records show that our <method_2> outperforms existing <otherscientificterm_10> significantly , and <method_2> can extract <otherscientificterm_0> .	5 13 16 -1 7 16 -1 15 1 12 9 18 25 26 16 -1 10 16 -1 3 2 4 11 14 20 21 22 16 -1 16 -1 8 17 19 23 24 16 -1
Different Structures for Evaluating Answers to Complex Questions : Pyramids Wo n't Topple , and Neither Will Human Assessors .	trec qa tracks ; nugget pyramids scheme ; dis-criminative power ; nugget-based methodology ; assessor opinions ; classification tasks ; micro-and macro-averaging ; manual assessment ; nugget importance	<material> <method> <metric> <method> <method> <task> <task> <task> <otherscientificterm>	6 3 5	the idea of '' nugget pyramids '' has recently been introduced as a refinement to the <method_3> used to evaluate answers to complex questions in the <material_0> . this paper examines data from the 2006 evaluation , the first large-scale deployment of the <method_1> . we show that this method of combining judgments of <otherscientificterm_8> from multiple assessors increases the stability and <metric_2> of the evaluation while introducing only a small additional burden in terms of <task_7> . we also consider an alternative method for combining <method_4> , which yields a distinction similar to <task_6> in the context of <task_5> . while the two approaches differ in terms of underlying assumptions , their results are nevertheless highly correlated .	3 0 9 -1 1 9 -1 8 2 7 9 -1 4 6 5 10 9 -1 9 -1
A probabilistic approach to simultaneous extraction of beats and downbeats .	hidden markov models ; automatic extraction of beat structure ; impulsive and harmonic components ; imposed deterministic rules ; modeling beat sequences ; viterbi decoder ; observation vectors ; reassigned spectrogram ; beat labels ; musical piece ; lattice rescoring ; statistical approach	<method> <task> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <method>	0 0 11 ; 11 0 4 ; 9 0 1 ; 5 1 10	this paper focuses on the <task_1> from a <material_9> . a novel <method_11> to <task_4> based on the application of <method_0> is introduced . the resulting <otherscientificterm_8> are obtained by running the <method_5> and subsequent <method_10> . for the <otherscientificterm_6> we propose a new feature set that is based on the <method_2> of the <otherscientificterm_7> . different components of <otherscientificterm_6> have been investigated for their efficiency . the main advantage of the proposed approach is the absence of <otherscientificterm_3> . all the parameters are learned from the training data , and the experimental results show the efficiency of the proposed schema .	1 9 15 12 -1 11 4 0 13 14 12 -1 8 5 10 16 12 -1 6 2 7 12 -1 12 -1 3 12 -1 12 -1
Feature extraction in Through-the-Wall radar imaging .	synthetic aperture through-the-wall radar imaging experiments ; classi ¬ø cation methods ; classi ¬ø cation ; automatic target classi ; through-the-wall radar imaging ; support vector machines ; recursive splitting tree ; stationary objects ; real data ; enclosed structures ; optimum parameters ; feature extraction ; indoor targets ; raw data ; sar image ; su-perquadrics ; segmentation	<material> <method> <otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm>	10 0 11 ; 13 0 14 ; 6 0 11 ; 15 0 11 ; 0 0 8 ; 6 0 10 ; 8 0 1 ; 15 1 2 ; 16 1 11	this paper deals with the problem of <task_3> - ¬ø cation or <method_4> . the proposed scheme considers <otherscientificterm_7> in <otherscientificterm_9> and works on the <material_14> rather than the <material_13> . it comprises <otherscientificterm_16> , <method_11> based on <otherscientificterm_15> , and <otherscientificterm_2> . we present a <method_6> to obtain <otherscientificterm_10> for <method_11> . <method_5> and nearest neighbor classi ¬ø ers are then applied to successfully classify among different <otherscientificterm_12> . the <method_1> are tested and evaluated using <material_8> generated from <material_0> .	3 4 17 -1 7 9 14 13 19 17 -1 16 11 15 2 21 25 26 17 -1 6 10 5 18 20 23 17 -1 12 17 -1 1 8 0 22 24 17 -1
Summarizing Spoken and Written Conversations .	meeting and email data ; meetings and emails domains ; conversation summarization system ; general conversational features ; domain-dependent systems ; conversational features ; domain-specific features ; emails	<material> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material>	3 0 2 ; 2 4 4 ; 4 0 0	in this paper we describe research on summarizing conversations in the <material_1> . we introduce a <method_2> that works in multiple domains utilizing <otherscientificterm_3> , and compare our results with <method_4> for <material_0> . we find that by treating meetings and <material_7> as conversations with <otherscientificterm_3> in common , we can achieve competitive results with state-of-the-art systems that rely on more <otherscientificterm_6> .	1 8 -1 2 3 4 0 9 10 11 8 -1 7 6 5 8 -1
Blind beamformer for constant modulus signals based on relevance vector machine .	constant modulus signals ; constant modulus algorithm ; relevance vector machine ; probabilistic bayesian learning procedure ; assumption of gaussian prior ; blind beamforming method ; crowded interference signals ; error function ; beamfomer	<otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	3 0 5 ; 4 0 3 ; 1 0 5 ; 5 0 0 ; 6 0 5 ; 5 0 8 ; 7 3 5 ; 3 0 8 ; 2 0 5	the <method_5> for <otherscientificterm_0> based on <method_2> is proposed . the proposed <method_5> is obtained by incorporating the <method_1> - like <otherscientificterm_7> into the conventional <method_5> . the <method_5> formulates the parameters of <method_8> by exploiting a <method_3> with <otherscientificterm_4> for parameters . the simulation results show that the proposed <method_5> can restore the desired signals with <otherscientificterm_6> .	5 0 2 13 18 9 -1 1 7 12 16 9 -1 8 3 4 10 11 15 17 9 -1 6 14 9 -1
Efficient Conversion of X.Y Surround Sound Content to Binaural Head-Tracked Form for HRTF-Enabled Playback .	binaural presentation of x.y sound ; ≈øxed playback cost ; virtual audio principles ; reference room con≈øg-uration ; spatio-temporal representation ; x.y setup ; multipole expansion ; listening area ; binaural signal ; user pose ; computational cost ; head-tracked playback ; ear position	<task> <metric> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <metric> <material> <otherscientificterm>	10 5 0 ; 2 0 0 ; 6 0 8 ; 12 2 6	binaural presentation of x.y sound is usually performed using <otherscientificterm_2> -- that is , by attempting to virtually reproduce the setup of the x+y loudspeakers in the <otherscientificterm_3> . the <metric_10> of such <task_0> is linear in the number of channels in the <otherscientificterm_5> . we present a novel scheme that computes , offline , a <method_4> of the sound ≈øeld in the <otherscientificterm_7> and store it as a <otherscientificterm_6> . during <material_11> , the <material_8> is obtained by evaluating the <otherscientificterm_6> at the <otherscientificterm_12> corresponding to the current <otherscientificterm_9> , resulting in a <metric_1> . the representation is further extended to incorporate individualized hrtfs at no additional cost . simulation results are presented .	2 3 15 13 -1 10 0 5 14 13 -1 4 7 6 13 -1 11 8 12 9 1 16 17 13 -1 13 -1 13 -1
Tandem acoustic modeling in large-vocabulary recognition .	etsi aurora noisy digits ; small-vocabulary , high-noise task ; tandem approach ; neural-net preprocessor ; feature inputs ; hmm baseline ; spontaneous speech ; posterior probabilities ; context-independent models ; acoustic signal ; word-error rates ; sub-word units ; error-rate reductions ; context-dependent models ; spine1	<material> <material> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm> <metric> <method> <method>	3 0 7 ; 2 0 9 ; 12 5 2 ; 1 5 2	in the <method_2> to modeling the <otherscientificterm_9> , a <method_3> is first discriminatively trained to estimate <otherscientificterm_7> across a phone set . these are then used as <otherscientificterm_4> for a conventional hidden markov model -lrb- hmm -rrb- based speech recognizer , which relearns the associations to <otherscientificterm_11> . in this paper , we apply the <method_2> to the data provided for the first speech in noisy environments -lrb- <method_14> -rrb- evaluation conducted by the naval research laboratory -lrb- nrl -rrb- in august 2000 . in our previous experience with the <material_0> -lrb- a <material_1> -rrb- the <method_2> achieved <metric_12> of over 50 % relative to the <method_5> . for <method_14> , a larger task involving more <material_6> , we find that , when <method_8> are used , the <method_2> continue to result in large reductions in <metric_10> relative to those achieved by systems using standard mfc or plp features . however , these improvements do not carry over to <method_13> . this may be attributable to several factors which are discussed in the paper .	2 9 3 7 16 17 15 -1 4 11 15 -1 14 15 -1 0 1 12 18 19 15 -1 5 15 -1 6 8 10 15 -1 13 15 -1
Variable Bandwidth Image Denoising Using Image-based Noise Models .	image intensity dependent noise variance ; spatial and photometric similarities ; variable bandwidth approach ; image formation process ; image denoising ; quadratic function ; variable bandwidth ; variational formulation ; restoration quality ; rgb one ; raw space ; noise model ; reconstruction process ; accuracy	<otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <metric>	7 0 4 ; 13 5 12 ; 7 0 1 ; 2 1 0 ; 10 2 11 ; 11 4 3 ; 5 0 7	this paper introduces a <method_7> for <task_4> based on a <otherscientificterm_5> over <method_7> of <otherscientificterm_6> . these <method_7> are scale adaptive and reflect <otherscientificterm_1> between pixels . the bandwidth of the <method_7> is observation-dependent towards improving the <metric_13> of the <method_12> and is constrained to be locally smooth . we analyze the evolution of the <method_11> form the <otherscientificterm_10> to the <otherscientificterm_9> , by propagating <method_11> over the <method_3> . the experimental results demonstrate that the use of a <method_2> and an <otherscientificterm_0> ensures better <metric_8> .	7 4 5 6 15 21 14 -1 1 17 14 -1 13 12 16 14 -1 11 10 9 3 19 20 14 -1 2 0 8 18 14 -1
An Evolutionary Algorithm Extended by Ecological Analogy and its Application to the Game of Go .	infrequently used knowledge ; evolutionary algorithms ; ecological systems ; activation value ; variation-making operator ; go knowledge ; go maxims ; features ; patterns	<otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 4 ; 6 6 5 ; 8 6 5	the following two important <otherscientificterm_7> of human experts ' knowledge are not realized by most <method_1> : one is that it is various and the other is that the amount of knowledge , including <otherscientificterm_0> , is large . to imitate these <otherscientificterm_7> , we introduce an <otherscientificterm_3> for individuals and a new <method_4> , splitting , both of which are inspired by <method_2> . this algorithm is applied to the game of go and a large amount of knowledge evaluated as appropriate by a human expert is acquired . various kinds of <otherscientificterm_5> may be acquired such as <otherscientificterm_8> , sequences of moves , and <otherscientificterm_6> , part of which has already been realized .	7 1 0 9 -1 3 4 2 10 9 -1 9 -1 5 8 11 12 9 -1
Disentangling Factors of Variation for Facial Expression Recognition .	contrac-tive discriminative analysis feature extractor ; multi-scale contractive convolutional network ; contractive auto-encoder ; facial expression recognition ; toronto face database ; emotion classification algorithm ; 2d face images ; hierarchy of features ; semi-supervised approach ; feature representation ; deep learning ; state-of-art accuracy ; facial traits ; emotion-related factors ; accuracy	<method> <method> <method> <task> <material> <method> <task> <otherscientificterm> <method> <method> <task> <metric> <otherscientificterm> <otherscientificterm> <metric>	14 5 2 ; 6 0 3 ; 8 0 6 ; 0 0 2 ; 8 0 3 ; 9 0 0 ; 1 1 2	we propose a <method_8> to solve the task of <task_3> in <task_6> using recent ideas in <task_10> for handling the factors of variation present in data . an <method_5> should be both robust to -lrb- 1 -rrb- remaining variations due to the pose of the face in the image after centering and alignment , -lrb- 2 -rrb- the identity or morphology of the face . in order to achieve this invariance , we propose to learn a <otherscientificterm_7> in which we gradually filter the factors of variation arising from both -lrb- 1 -rrb- and -lrb- 2 -rrb- . we address -lrb- 1 -rrb- by using a <method_1> in order to obtain invariance to translations of the <otherscientificterm_12> in the image . using the <method_9> produced by the <method_1> , we train a <method_0> , a novel variant of the <method_2> , designed to learn a representation separating out the <otherscientificterm_13> from the others -lrb- which mostly capture the subject identity , and what is left of pose after the <method_1> -rrb- . this <method_8> beats the state-of-the-art on a recently proposed dataset for <task_3> , the <material_4> , moving the <metric_11> from 82.4 % to 85.0 % , while the <method_1> and cda improve <metric_14> of a standard <method_2> by 8 % .	8 3 6 10 17 18 15 -1 5 15 -1 7 15 -1 15 -1 1 12 19 21 15 -1 9 0 2 13 16 20 22 15 -1
Kernel-based invariant subspace method for hyperspectral target detection .	kernel principal component analysis ; linear mixture model ; small target detection of hyperspectral images ; subspaces of target and background ; kernel-based invariant subspace detection method ; generalized likelihood ratio test ; aviris hyperspectral data ; hyperspectral target detection ; hyperspectral image ; spectral variability ; hyperspectral images ; pixel ; noise ; target	<method> <method> <task> <otherscientificterm> <method> <metric> <material> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 1 1 ; 1 3 4 ; 0 3 4 ; 4 0 7 ; 0 0 11 ; 4 0 2 ; 0 0 3	in this paper , a <method_4> is proposed for <task_2> . the <method_4> combines <method_0> and <method_1> . the <method_0> is used to describe each <otherscientificterm_11> in the <material_10> as mixture of <otherscientificterm_13> , background and <otherscientificterm_12> . the <method_0> is used to build <otherscientificterm_3> . a <metric_5> is used to detect whether each <otherscientificterm_11> in <otherscientificterm_8> includes <otherscientificterm_13> . the numerical experiments are performed on <material_6> with 126 bands . the experimental results show the effectiveness of the proposed <method_4> and prove that this <method_4> can commendably overcome <otherscientificterm_9> in the <task_7> , and <method_4> has good ability to separate <otherscientificterm_13> from background .	4 2 20 14 -1 0 1 15 16 17 14 -1 11 10 13 12 19 14 -1 3 21 14 -1 5 8 14 -1 6 14 -1 9 7 18 14 -1
SIFT Flow : Dense Correspondence across Different Scenes .	transfer of moving objects ; temporally adjacent frame ; discontinuity-preserving spatial model ; matching of objects ; database of videos ; computer vision ; scene/object appearances ; spatial discontinu-ities ; histogram intersection ; optical flow ; static image ; query image ; sift flow ; bag-of-visual-words representation ; image registration ; image matching ; image ; recognition	<otherscientificterm> <otherscientificterm> <method> <task> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <method> <task> <task> <otherscientificterm> <task>	14 3 5 ; 17 4 15 ; 13 0 8	while <task_14> has been studied in different areas of <task_5> , aligning images depicting different scenes remains a challenging problem , closer to <task_17> than to <task_15> . analogous to <otherscientificterm_9> , where an <otherscientificterm_16> is aligned to its <otherscientificterm_1> , we propose <otherscientificterm_12> , a method to align an <otherscientificterm_16> to its neighbors in a large <otherscientificterm_16> collection consisting of a variety of scenes . for a <material_11> , <otherscientificterm_8> on a <method_13> is used to find the set of nearest neighbors in the database . the <otherscientificterm_12> algorithm then consists of matching densely sampled <otherscientificterm_12> between the two images , while preserving <otherscientificterm_7> . the use of <otherscientificterm_12> allows robust matching across different <otherscientificterm_6> and the <method_2> allows <task_3> located at different parts of the scene . experiments show that the proposed approach is able to robustly align complicated scenes with large spatial distortions . we collect a large <material_4> and apply the <otherscientificterm_12> algorithm to two applications : -lrb- i -rrb- motion field prediction from a single <material_10> and -lrb- ii -rrb- motion synthesis via <otherscientificterm_0> .	14 5 17 15 19 20 18 -1 9 16 1 12 18 -1 11 8 13 21 18 -1 18 -1 7 18 -1 6 2 3 18 -1 18 -1
Detecting Spammers in Community Question Answering .	community question answering ; graph regulariza-tion constraints ; spam-ming activities ; social information ; optimization problem ; text-based predic-tor ; cqa portal ; cqa sites ; spammers	<method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <material> <material> <material>	1 0 3 ; 1 0 5	as the popularity of <method_0> increases , <method_2> also picked up in numbers and variety . on <material_7> , <material_8> often pretend to ask questions , and select answers which were published by their partners or themselves as the best answers . these fake best answers can not be easily detected by neither existing methods nor common users . in this paper , we address the issue of detecting <material_8> on <material_7> . we formulate the task as an <task_4> . <otherscientificterm_3> is incorporated by adding <otherscientificterm_1> to the <otherscientificterm_5> . to evaluate the proposed approach , we crawled a data set from a <material_6> . experimental results demonstrate that the proposed method can achieve better performance than some state-of-the-art methods .	0 2 9 -1 7 8 9 -1 9 -1 9 -1 4 3 9 -1 1 5 10 11 9 -1 9 -1 6 9 -1
Use of the pitch synchronous wavelet transform as a new decomposition method for WI .	pitch synchronous wavelet transform ; waveform interpolation paradigm ; causal , stable iir filters ; characteristic waveform decomposition method ; flexible quantisation of parameters ; evolutionary waveform domain ; wavelet filter bank ; waveform surfaces ; evolutionary surfaces ; characteristic surfaces ; iir filters ; decomposed surfaces ; evolution domain ; decomposition mechanism ; fir filters ; unvoiced speech ; pitch-cycle waveforms ; multi-scale characterisation ; wi decomposition ; fir counterparts ; voiced speech ; filtering	<method> <method> <method> <method> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <otherscientificterm> <task> <method> <otherscientificterm> <material> <method>	14 0 6 ; 10 0 8 ; 3 0 1	a new <method_3> based on wavelets is proposed for the <method_1> . in <method_1> , <otherscientificterm_16> are filtered in the <otherscientificterm_12> to decompose the signal into two <otherscientificterm_7> , one characterising <material_20> and a second representing <material_15> . the slow roll-off of <method_14> leads , however , to a significant interrelationship between the <otherscientificterm_11> . here we present the <method_0> as an alternative <method_13> . <method_21> is again performed in the <material_5> , producing <otherscientificterm_9> at several resolutions . this <task_17> leads to more <otherscientificterm_4> , especially at higher rates than <method_1> 's 2.4 kb/s . <method_14> are replaced in the <method_6> by <method_2> which achieve significant delay reductions over their <otherscientificterm_19> . furthermore , <method_10> track the dynamic aspects of the <otherscientificterm_8> faster , overcoming problems existing in the current <method_18> .	3 1 25 22 -1 16 12 7 20 15 22 -1 14 11 22 -1 0 13 21 22 -1 5 9 22 -1 17 4 22 -1 23 22 -1 6 2 19 24 22 -1
Monte Carlo model-space noise adaptation for speech recognition .	gaussian mixture models ; spliced and projected mfcc features ; silence and speech frames ; gmm speech model ; single-gaussian noise model ; monte carlo method ; parallel model combination ; adaptation techniques ; model-space joint ; silence frames ; mfcc	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method>	4 3 5 ; 5 6 6 ; 4 1 3 ; 5 0 1 ; 5 0 5 ; 5 0 8 ; 5 4 10 ; 1 4 10 ; 6 1 8 ; 3 3 5	we describe a <method_5> for model-space noise adaptation of <method_0> . this <method_5> combines a <method_4> with the <method_3> to produce an adapted <method_5> . <method_5> is similar to <method_6> or <method_8> , except that <method_5> applies to <otherscientificterm_1> rather than to <method_10> plus dynamic features . we demonstrate the necessity of re-estimating the noise using both the <otherscientificterm_2> rather than just estimating <method_5> from <otherscientificterm_9> , and obtain improvements on a matched test set without added noise using a system that includes all standard <method_7> .	5 0 11 -1 4 3 12 14 16 21 11 -1 6 8 1 10 13 15 17 18 19 20 11 -1 2 9 7 11 -1
Real-time multiple sound source localization using a circular microphone array based on single-source confidence measures .	blind source separation methods ; weak sound source sparsity ; real-time adaptative localization approach ; lo-calization ambiguities ; circular array ; linear arrays	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 1 ; 4 0 2 ; 2 0 3	we propose a novel <method_2> for multiple sources using a <otherscientificterm_4> , in order to suppress the <otherscientificterm_3> faced with <otherscientificterm_5> , and assuming a <otherscientificterm_1> which is derived from <method_0> . our proposed <method_2> performs very well both in simulations and in real conditions at 50 % real-time .	2 4 3 5 1 0 7 8 9 6 -1 6 -1
An Unsupervised Method for Word Sense Tagging using Parallel Corpora .	word sense disambiguation ; diier-ing translator preferences ; in-uence of context ; machine translation systems ; word-level translation correspondences ; cross-language lexicalizations ; sense disam-biguation ; translation correspondences ; parallel corpora ; unsupervised method ; pseudo-translations ; dif-cult	<task> <otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <material> <method> <otherscientificterm> <otherscientificterm>	4 0 6 ; 1 1 2 ; 7 3 8 ; 9 0 0	we present an <method_9> for <task_0> that exploits <otherscientificterm_7> in <material_8> . the <method_9> takes advantage of the fact that <otherscientificterm_5> of the same concept tend to be consistent , preserving some core element of its semantics , and yet also variable , reeecting <otherscientificterm_1> and the <otherscientificterm_2> . working with <material_8> introduces an extra complication for evaluation , since it is <otherscientificterm_11> to nd a corpus that is both sense tagged and parallel with another language ; therefore we use <otherscientificterm_10> , created by <method_3> , in order to make possible the evaluation of the <method_9> against a standard test set . the results demonstrate that <task_4> are a valuable source of information for <task_6> .	9 0 7 8 15 16 12 -1 5 1 2 14 12 -1 11 10 3 12 -1 13 12 -1
How Things are Intended to Work : Capturing Functional Knowledge in Device Design .	cfrl -lrb- causal functional representation language -rrb- ; engineer 's design rationale ; design support system ; causal mechanism ; functional specifications ; physical specification ; explicit representation ; physical structure ; design process ; manipulation	<method> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	4 0 1 ; 3 1 7 ; 2 0 4 ; 0 0 5 ; 2 0 5	when designing a device , the final product of the <method_8> is usually considered to be a <otherscientificterm_5> of a device . however , the design of the <otherscientificterm_3> underlying the <otherscientificterm_5> , i.e. how the device is intended to work to achieve its function , is a product just as important as the <otherscientificterm_5> , if not more . capturing this knowledge of <otherscientificterm_3> is necessary in order to understand the <otherscientificterm_5> of the device as well as to evaluate and refine the specifications during the <method_8> . despite the importance of such knowledge , existing <method_8> do not support its <method_6> or <otherscientificterm_9> . we describe a <method_2> under development in which knowledge of both the <otherscientificterm_3> and the <otherscientificterm_7> of a device being designed is explicitly represented and manipulated . the <method_2> allows the designer to provide <otherscientificterm_4> at various levels of abstraction in a language called <method_0> . the <method_0> acquired from the user enables the <method_2> to evaluate the <otherscientificterm_5> as <method_2> is being developed in order to provide useful feedback to the designer . furthermore , <otherscientificterm_4> provide an important basis for recording the <task_1> .	8 5 10 -1 3 10 -1 10 -1 10 -1 6 9 12 10 -1 2 7 13 10 -1 4 0 14 15 10 -1 11 10 -1
Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks .	large-scale visual recognition challenge ; convolutional neural networks ; pascal voc 2007 and 2012 datasets ; object and action classification ; rich mid-level image representations ; large-scale annotated datasets ; hand-designed low-level features ; image classification methods ; pascal voc dataset ; limited training data ; mid-level image representation ; visual recognition tasks ; annotated image samples ; image representations ; learning cnns ; reuse layers ; image statistics ; image classification ; images	<task> <method> <material> <task> <method> <material> <otherscientificterm> <method> <material> <material> <method> <task> <material> <method> <task> <otherscientificterm> <material> <task> <material>	13 0 3 ; 18 3 8 ; 1 0 17 ; 0 0 4 ; 6 0 7 ; 5 0 13 ; 0 0 13	convolutional neural networks -lrb- cnn -rrb- have recently shown outstanding <task_17> performance in the <task_0> . the success of <task_0> is attributed to their ability to learn <method_4> as opposed to <otherscientificterm_6> used in other <method_7> . <task_14> , however , amounts to estimating millions of parameters and requires a very large number of <material_12> . this property currently prevents application of <task_0> to problems with <material_9> . in this work we show how <method_13> learned with <task_0> on <material_5> can be efficiently transferred to other <task_11> with limited amount of training data . we design a method to <otherscientificterm_15> trained on the <task_0> to compute <method_10> for <material_18> in the <material_8> . we show that despite differences in <material_16> and tasks in the two datasets , the <method_13> leads to significantly improved results for <task_3> , outperforming the current state of the art on <material_2> . we also show promising results for <task_3> .	17 0 22 19 -1 4 6 7 14 23 24 19 -1 12 19 -1 9 19 -1 13 5 11 25 26 19 -1 15 21 19 -1 10 18 8 20 19 -1 16 3 2 19 -1
Recurrent Models of Visual Attention .	convolutional neural network baseline ; dynamic visual control problem ; recurrent neural network model ; translation invariance built-in ; convolutional neural networks ; reinforcement learning methods ; image or video ; image classification tasks ; task-specific policies ; cluttered images ; computation scales ; large images ; image pixels	<method> <task> <method> <otherscientificterm> <method> <method> <material> <task> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm>	7 5 2 ; 2 4 0 ; 5 0 8 ; 5 0 2 ; 4 0 11 ; 2 0 8	applying <method_4> to <material_11> is computationally expensive because the amount of <otherscientificterm_10> linearly with the number of <otherscientificterm_12> . we present a novel <method_2> that is capable of extracting information from an <material_6> by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution . like <method_4> , the proposed <method_2> has a degree of <otherscientificterm_3> , but the amount of computation <method_2> performs can be controlled independently of the input image size . while the <method_2> is non-differentiable , <method_2> can be trained using <method_5> to learn <otherscientificterm_8> . we evaluate our <method_2> on several <task_7> , where <method_2> significantly outperforms a <method_0> on <material_9> , and on a <task_1> , where <method_2> learns to track a simple object without an explicit training signal for doing so .	4 11 10 12 18 13 -1 2 6 13 -1 3 13 -1 5 8 16 17 19 13 -1 14 15 13 -1
Bilingual Sense Similarity for Statistical Machine Translation .	hierarchical phrase-based machine translation system ; sense similarity scores ; statistical machine translation ; vector space model ; parallel corpora ; translation model ; similarity scores ; sense similarity ; rules ; features ; phrases	<method> <metric> <task> <method> <material> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 0 2 ; 6 5 5 ; 3 0 1 ; 9 0 5 ; 5 0 2 ; 10 1 8	this paper proposes new algorithms to compute the <otherscientificterm_7> between two units -lrb- words , <otherscientificterm_10> , <otherscientificterm_8> , etc. -rrb- from <material_4> . the <metric_1> are computed by using the <method_3> . we then apply the algorithms to <task_2> by computing the <otherscientificterm_7> between the source and target side of <task_2> rule pairs . <metric_6> are used as additional <otherscientificterm_9> of the <method_5> to improve <task_2> performance . significant improvements are obtained over a state-of-the-art <method_0> .	7 10 8 4 17 11 -1 1 3 14 11 -1 2 6 11 -1 9 5 12 13 15 16 11 -1 0 11 -1
Corpus-based analysis of English spoken by Japanese students in view of the entire phonemic system of English .	hidden markov models ; japanese english ; phonemic system of english ; je database ; wsj database ; je pronunciation ; tree diagram ; english pronunciation ; speech recognition ; japanese students ; japanese ; english	<method> <task> <method> <material> <material> <task> <method> <material> <task> <material> <material> <material>	11 1 10 ; 4 1 3	english and <material_10> are quite different languages both phoneti-cally and linguistically and it is often very difficult for <material_9> to master <material_7> . to help students improve their pronunciation proficiency , a <material_10> national project of '' advanced utilization of multimedia for education '' has started in 2000 and under this project , a large database of <material_11> words and sentences read by 200 <material_9> was built mainly for call system development . this paper describes a corpus-based analysis and comparison of american <material_11> -lrb- ae -rrb- and <task_1> by using <material_4> and the new <material_3> . here , <method_0> , which are widely-used acoustic modeling techniques of <task_8> , were firstly made for individual phonemes in the two kinds of <material_11> , and then , a <method_6> was drawn for the entire phonemes of each hmm set . the analysis and comparison of the two trees showed many interesting characteristics of <task_1> , some of which are well-known habits observed in <task_5> . the authors consider that this study showed statistical differences between ae and <task_1> in view of the entire <method_2> for the first time .	10 9 7 13 12 -1 11 12 -1 1 4 3 14 12 -1 0 12 -1 8 6 12 -1 5 12 -1
Predicting Tongue Positions from Acoustics and Facial Features .	electromagnetic articulograph sensors ; jaw and lip information ; concatenating bimodal acoustic-visual units ; support vector regression ; acoustic-to-ema mapping system ; talking head ; tongue sensors ; tongue animation ; tongue information	<otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	3 0 4 ; 4 0 5 ; 0 0 4 ; 7 0 5 ; 4 0 7 ; 1 1 8	we test the hypothesis that adding information regarding the positions of <otherscientificterm_0> on the lips and jaw can improve the results of a typical <method_4> , based on <method_3> , that targets the <otherscientificterm_6> . our initial motivation is to use such a <method_4> in the context of adding a <method_7> to a <otherscientificterm_5> built on the basis of <task_2> . for completeness , we also train a <method_4> that maps only <otherscientificterm_1> to <otherscientificterm_8> .	0 4 3 6 10 12 9 -1 7 5 2 11 13 14 9 -1 1 8 15 9 -1
TRIC-track : Tracking by Regression with Incrementally Learned Cascades .	multiple temporal scale motion model ; shape and deformation parameters ; local image patches ; cvpr 2013 benchmark ; cascaded regression search ; part-based tracking ; generic objects ; appearance model ; part locations ; cascaded regression ; incremental learning ; online fashion ; spatial constraints ; occlusions ; appearance	<method> <otherscientificterm> <otherscientificterm> <material> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	0 0 13 ; 10 0 9 ; 9 0 6 ; 10 0 6	this paper proposes a novel approach to <task_5> by replacing local matching of an <method_7> by direct prediction of the displacement between <otherscientificterm_2> and <otherscientificterm_8> . we propose to use <method_9> with <method_10> to track <otherscientificterm_6> without any prior knowledge of an object 's structure or <otherscientificterm_14> . we exploit the <otherscientificterm_12> between parts by implicitly learning the <otherscientificterm_1> of the object in an <otherscientificterm_11> . we integrate a <method_0> to initialise our <method_4> close to the target and to allow <method_0> to cope with <otherscientificterm_13> . experimental results show that our tracker ranks first on the <material_3> .	5 7 2 8 15 -1 9 10 6 14 17 18 19 15 -1 12 1 11 15 -1 0 4 13 16 15 -1 3 15 -1
On the application of reverberation suppression to robust speech recognition .	single-channel reverberation suppression algorithm ; moderately reverber-ant data ; reverberation-robust speech recognition ; acoustic models ; inferred guidelines ; early reflections ; residual late-reverberation ; reverberation tail ; training data ; reverberation compensation ; reverberation conditions ; speech recognizer ; design parameters ; optimum configuration ; recognition	<method> <material> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	2 0 0 ; 9 0 11 ; 1 0 11	in this paper , we study the effect of the <otherscientificterm_12> of a <method_0> on <task_2> . at the same time , <method_9> at the <method_11> is investigated . the analysis reveals that it is highly beneficial to attenuate only the <otherscientificterm_7> after approximately 50 ms while coping with the <otherscientificterm_5> and <otherscientificterm_6> by training the <method_11> on <material_1> . it will be shown that the overall system at its <otherscientificterm_13> yields a very promising <task_14> performance even in strongly reverberant environments . since the <method_0> is evidenced to significantly reduce the dependency on the <material_8> , it allows for a very efficient training of <method_3> that are suitable for a wide range of <otherscientificterm_10> . finally , experiments with an '' ideal '' <method_0> are carried out to cross-check the <otherscientificterm_4> .	12 0 2 16 15 -1 9 11 17 15 -1 7 5 6 1 18 15 -1 13 14 15 -1 8 15 -1 3 10 15 -1
A New Tractable Subclass of the Rectangle Algebra .	polynomial path-consistency algorithm ; 2-dimensional euclidean space ; orthogonal basis ; decision method ; interval algebra ; propagation techniques ; rectangle algebra ; weak preconvexity ; interval networks ; inversion ; convexity ; intersection	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 0 8 ; 11 1 9	this paper presents the 169 permitted relations between two rectangles whose sides are parallel to the axes of some <otherscientificterm_2> in a <otherscientificterm_1> . elaborating <otherscientificterm_6> just like <method_4> , it deenes the concept of <otherscientificterm_10> as well as the ones of <otherscientificterm_7> and strong precon-vexity . it introduces afterwards the fundamental operations of <otherscientificterm_11> , composition and <otherscientificterm_9> and demonstrates that the concept of <otherscientificterm_7> is preserved by the operation of composition whereas the concept of strong preconvexity is preserved by the operation of <otherscientificterm_11> . finally , tting the <method_5> conceived to solve <method_8> , it shows that the <method_0> is a <method_3> for the problem of proving the consistency of strongly precon-vex rectangle networks .	2 1 12 -1 6 4 10 7 12 -1 11 9 14 12 -1 5 8 13 12 -1
Long-term Causal Effects via Behavioral Game Theory .	ad pricing policy ; latent space approach ; behavioral game theory ; behavioral model ; policy changes ; temporal model ; multiagent economies ; causal inference ; latent behaviors ; adaptation period ; baseline policy ; ignorability assumptions ; classical methodology	<otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	11 0 7 ; 9 2 0 ; 3 0 8	planned experiments are the gold standard in reliably comparing the causal effect of switching from a <otherscientificterm_10> to a new <otherscientificterm_0> . one critical shortcoming of classical experimental methods , however , is that they typically do not take into account the dynamic nature of response to <otherscientificterm_4> . for instance , in an experiment where we seek to understand the effects of a new <otherscientificterm_0> on auction revenue , agents may adapt their bidding in response to the experimental pricing changes . thus , causal effects of the new <otherscientificterm_0> after such <otherscientificterm_9> , the long-term causal effects , are not captured by the <method_12> even though they clearly are more indicative of the value of the new <otherscientificterm_0> . here , we formalize a framework to define and estimate long-term causal effects of <otherscientificterm_4> in <otherscientificterm_6> . central to our approach is <method_2> , which we leverage to formulate the <otherscientificterm_11> that are necessary for <task_7> . under such <otherscientificterm_11> we estimate long-term causal effects through a <method_1> , where a <method_3> of how agents act conditional on their <otherscientificterm_8> is combined with a <method_5> of how behaviors evolve over time .	10 0 13 -1 4 13 -1 13 -1 9 15 13 -1 12 13 -1 6 14 13 -1 2 11 7 16 13 -1
Online Graph Pruning for Pathfinding On Grid Maps .	hierarchical pathfinding algorithms ; uniform-cost grid environments ; small memory overheads ; memory overhead ; suboptimal paths ; macro operator ; intermediate nodes ; grid map ; search strategy ; video games ; nodes ; robotics ; grids	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <material> <otherscientificterm>	8 0 12 ; 11 1 9 ; 10 3 7	pathfinding in <otherscientificterm_1> is a problem commonly found in application areas such as <material_11> and <material_9> . the state-of-the-art is dominated by <method_0> which are fast and have <otherscientificterm_2> but usually return <otherscientificterm_4> . in this paper we present a novel <method_8> , specific to <otherscientificterm_12> , which is fast , optimal and requires no <otherscientificterm_3> . our <method_8> can be described as a <method_5> which identifies and selectively expands only certain <otherscientificterm_10> in a <otherscientificterm_7> which we call jump points . <otherscientificterm_6> on a path connecting two jump points are never expanded . we prove that this <method_8> always computes optimal solutions and then undertake a thorough empirical analysis , comparing our <method_8> with related works from the literature . we find that searching with jump points can speed up a * by an order of magnitude and more and report significant improvement over the current state of the art .	1 11 9 15 13 -1 0 2 4 13 -1 8 12 3 14 13 -1 5 10 7 6 16 13 -1 13 -1 13 -1 13 -1
Lower Bounds on Rate of Convergence of Cutting Plane Methods .	o -lrb- 1 / ‚àö -rrb- iterations ; cutting plane method ; support vector methods ; multivari-ate performance score ; linear svms ; objective function ; hinge loss ; counter examples ; svm-perf	<otherscientificterm> <method> <method> <metric> <method> <otherscientificterm> <otherscientificterm> <material> <method>	7 0 4 ; 3 5 2 ; 8 6 1	in a recent paper joachims -lsb- 1 -rsb- presented <method_8> , a <method_1> for training linear support vector machines -lrb- svms -rrb- which converges to an accurate solution in o -lrb- 1 / / 2 -rrb- iterations . by tightening the analysis , teo et al. -lsb- 2 -rsb- showed that o -lrb- 1 / / -rrb- iterations suffice . given the impressive convergence speed of <method_1> on a number of practical problems , it was conjectured that these rates could be further improved . in this paper we disprove this conjecture . we present <material_7> which are not only applicable for training <method_4> with <otherscientificterm_6> , but also hold for <method_2> which optimize a <metric_3> . however , surprisingly , these problems are not inherently hard . by exploiting the structure of the <otherscientificterm_5> we can devise an algorithm that converges in <otherscientificterm_0> .	8 1 12 9 -1 9 -1 9 -1 9 -1 7 10 11 9 -1 4 6 2 3 9 -1 9 -1
Modeling human interaction in meetings .	recognition of group actions ; joint behaviour of participants ; audio and visual features ; corpus of meetings ; hmm-based approaches ; raw data ; global behaviour ; meeting actions ; discussions ; browsing	<task> <otherscientificterm> <otherscientificterm> <material> <method> <material> <otherscientificterm> <task> <otherscientificterm> <task>	8 6 7 ; 5 0 2	this paper investigates the <task_0> in meetings by modeling the <otherscientificterm_1> . many <task_7> , such as presentations , <otherscientificterm_8> and consensus , are characterised by similar or complementary behaviour across participants . recognising these meaningful actions is an important step towards the goal of providing effective <task_9> and sum-marisation of processed meetings . in this work , a <material_3> was collected in a room equipped with a number of microphones and cameras . the <material_3> was labeled in terms of a pre-defined set of <task_7> characterised by <otherscientificterm_6> . in experiments , <otherscientificterm_2> for each participant are extracted from the <material_5> and the interaction of participants is modeled using <method_4> . initial results on the <material_3> demonstrate the ability of the system to recognise the set of <task_7> .	0 1 10 -1 7 8 11 10 -1 9 10 -1 3 10 -1 6 10 -1 2 12 10 -1 5 4 10 -1
Real-Time Pose Estimation Piggybacked on Object Detection .	compact and simple model ; traffic surveillance dataset ; pose estimation ; vehicle detection ; object detector ; 3d objects ; c++ code ; cod20k dataset ; image features ; pose estimator ; viewpoint/pose annotation ; object score ; classification ; kitti ; detection ; accuracy	<method> <material> <task> <task> <method> <material> <otherscientificterm> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <method> <task> <metric>	3 5 4 ; 2 0 4 ; 15 5 4 ; 4 0 3	we present an <method_4> coupled with <task_2> directly in a single <method_0> , where the <method_4> shares extracted <otherscientificterm_8> with the <method_9> . the output of the <task_12> of each candidate window consists of both <otherscientificterm_11> and likelihood map of poses . this <method_4> introduces negligible overhead during <task_14> so that the <method_4> is still capable of real time operation . we evaluated the proposed <method_4> on the problem of <task_3> . we used existing datasets with <otherscientificterm_10> -lrb- wcvp , <material_5> , <method_13> -rrb- . besides that , we collected a new <material_1> cod20k which fills certain gaps of the existing datasets and we make <method_4> public . the experimental results show that the proposed <method_4> is comparable with state-of-the-art approaches in terms of <metric_15> , but <method_4> is considerably faster -- easily operating in real time -lrb- matlab with <otherscientificterm_6> -rrb- . the source codes and the collected <material_7> are made public along with the paper .	4 2 0 8 9 18 16 -1 12 11 16 -1 14 16 -1 3 17 20 16 -1 10 5 13 16 -1 1 16 -1 19 16 -1 15 6 16 -1
Using semantic class information for rapid development of language models within ASR dialogue systems .	atis and darpa communicator travel corpora ; language model training data ; probabilistic context free grammar ; natural language understanding module ; context free grammar ; dialogue system developers ; finite state parses ; semantic classes ; artificial data	<material> <material> <method> <method> <method> <method> <otherscientificterm> <method> <material>	7 0 3 ; 6 0 8 ; 6 0 2	when <method_5> tackle a new domain , much effort is required ; the development of different parts of the system usually proceeds independently . yet it may be profitable to coordinate development efforts between different modules . here , we focus our efforts on extending small amounts of <material_1> by integrating <method_7> that were created for a <method_3> . by converting <otherscientificterm_6> of a training corpus into a <method_2> and subsequently generating <material_8> from the <method_4> , we can significantly reduce perplexity and asr word error for situations with little training data . experiments are presented using data from the <material_0> .	5 9 -1 9 -1 1 7 3 10 9 -1 6 2 8 4 11 12 9 -1 9 -1
Density geodesics for similarity clustering .	riemannian geometry of curved surfaces ; algebraic context-independent sample-distance measures ; path-bottleneck or path-average distances ; principled context-adaptive similarity metric ; unit-hypercube uniform density ; density-geodesic distance measure ; context-dependent metric modifications ; similarity metric selection ; pairwise affinity clustering ; canonical metric ; euclidean distance ; bottleneck principle ; feature vectors ; geodesics ; robustness	<otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric>	11 0 6 ; 6 0 2 ; 7 0 8 ; 10 6 1 ; 0 0 5 ; 4 0 9	we address the problem of <task_7> in <task_8> . traditional techniques employ standard <method_1> , such as the <otherscientificterm_10> . more recent <method_6> employ the <method_11> to develop <otherscientificterm_2> and define similarities based on <otherscientificterm_13> determined according to these metrics . this paper develops a <method_3> for pairs of <otherscientificterm_12> utilizing the probability density of all data . specifically , based on the postulate that <otherscientificterm_10> is the <method_9> for data drawn from a <otherscientificterm_4> , a <metric_5> stemming from <otherscientificterm_0> is derived . comparisons with alternative metrics demonstrate the superior properties such as <metric_14> .	7 8 18 15 -1 1 10 19 15 -1 6 11 2 13 16 17 15 -1 3 12 15 -1 9 4 5 0 20 21 15 -1 14 15 -1
Efficient Searching Top-k Semantic Similar Words .	top-k semantic similar words ; semantic meaning between words ; word sense disambiguation ; document summarization ; efficient strategies ; precision ; recall	<otherscientificterm> <otherscientificterm> <task> <task> <method> <metric> <metric>	2 1 3 ; 5 1 6	measuring the <otherscientificterm_1> is an important issue because it is the basis for many applications , such as <task_2> , <task_3> , and so forth . although it has been explored for several decades , most of the studies focus on improving the effectiveness of the problem , i.e. , <metric_5> and <metric_6> . in this paper , we propose to address the efficiency issue , that given a collection of words , how to efficiently discover the top-k most semantic similar words to the query . this issue is very important for real applications yet the existing state-of-the-art strategies can not satisfy users with reasonable performance . <method_4> on searching <otherscientificterm_0> are proposed . we provide an extensive comparative experimental evaluation demonstrating the advantages of the introduced strategies over the state-of-the-art approaches .	1 2 3 8 7 -1 5 6 9 7 -1 7 -1 7 -1 4 7 -1 0 7 -1
Information-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation .	unlabeled target domain ; unsupervised domain adaptation ; labeled source domain ; information-theoretic metric ; gradient-based methods ; misclassification error ; sentiment analysis ; object recognition ; feature space ; classification accuracies ; domain-invariant features ; classifiers ; classi-fiers ; hyperparameters	<material> <task> <material> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method>	2 0 1 ; 1 0 12 ; 2 0 0 ; 2 0 12	we study the problem of <task_1> , which aims to adapt <method_12> trained on a <material_2> to an <material_0> . many existing approaches first learn <otherscientificterm_10> and then construct <method_11> with them . we propose a novel approach that jointly learn the both . specifically , while the method identifies a <otherscientificterm_8> where data in the source and the target domains are similarly distributed , it also learns the <otherscientificterm_8> discriminatively , optimizing an <otherscientificterm_3> as an proxy to the expected <otherscientificterm_5> on the target domain . we show how this optimization can be effectively carried out with simple <method_4> and how <method_13> can be cross-validated without demanding any labeled data from the target domain . empirical studies on benchmark tasks of <task_7> and <task_6> validated our modeling assumptions and demonstrated significant improvement of our method over competing ones in <task_9> .	1 12 2 0 15 16 17 18 14 -1 10 11 14 -1 14 -1 8 3 5 14 -1 4 14 -1 13 14 -1
Prior Knowledge in Support Vector Kernels .	support vector learning machines ; group transfonnations ; prior knowledge ; kernel functions ; locality ; images ; invari-ances	<task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm>	1 1 2	we explore methods for incorporating <otherscientificterm_2> about a problem at hand in <task_0> . we show that both <otherscientificterm_6> under <otherscientificterm_1> and <otherscientificterm_2> about <otherscientificterm_4> in <material_5> can be incorporated by constructing appropriate <method_3> .	2 0 7 -1 6 1 4 5 3 8 7 -1
A Methodology for Evaluating Robustness of Face Recognition Algorithms with Respect to Variations in Pose Angle and Illumination Angle .	bayesian intra-personal classifier -rrb- ; linear discriminant analysis -rrb- ; principle component analysis ; subspace analysis methods ; face recognition algorithms ; probabilistic learning methods ; pose angle ; pose angles ; robustness measure ; illumination angle ; subspace methods ; recognition robustness ; illumination angles ; face images ; pose	<method> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <metric> <otherscientificterm> <material> <otherscientificterm>	3 1 5 ; 1 6 3 ; 2 1 1 ; 2 6 3 ; 1 1 5 ; 10 4 5 ; 2 1 5 ; 1 1 0	in this paper , we present a methodology for precisely comparing the robustness of <method_4> with respect to changes in <otherscientificterm_6> and <otherscientificterm_9> . for this study , we have chosen four widely-used algorithms : two <method_3> -lrb- <method_2> and <method_1> and two <method_5> -lrb- hidden markov models -lrb- hmm -rrb- and <method_0> . we compare the <metric_11> of these algorithms using a novel database -lrb- facepix -rrb- that captures <material_13> with a wide range of <otherscientificterm_7> and <otherscientificterm_12> . we propose a method for deriving a <metric_8> for each of these algorithms , with respect to <otherscientificterm_14> and <otherscientificterm_9> changes . the results of this comparison indicate that the <method_10> perform more robustly than the <method_5> in the presence of <otherscientificterm_14> and <otherscientificterm_9> changes .	4 6 9 15 -1 3 2 1 5 0 16 17 18 19 20 22 23 15 -1 11 13 7 12 15 -1 8 14 15 -1 21 15 -1
Localization using combinations of model views .	weak perspective projection ; weak perspective approximation ; iterative solution ; model views ; perspective distortions ; 2d view ; localization ; localiza-tion	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method>	2 0 4	a method for <task_6> , the act of recognizing the environment , is presented . the method is based on representing the scene as a set of 2 0 views and predicting the appearances of novel views by linear combinations of the <otherscientificterm_3> . the method accurately approximates the appearance of scenes under <otherscientificterm_0> . analysis of this projection as well as experimental results demonstrate that in many cases this approximation is suficient t o accurately describe the scene . when <otherscientificterm_1> is invalid , either a larger number of models can be acquired or an <method_2> t o account for the <otherscientificterm_4> can be employed . the method has several advantages over other approaches . it uses relatively rich representations ; the representations are 2d rather than 9d ; and <method_7> can be done f r o m only a single <otherscientificterm_5> .	6 8 -1 3 8 -1 0 8 -1 8 -1 1 2 9 8 -1 4 8 -1 8 -1
The Synthy Approach for End to End Web Services Composition : Planning with Decoupled Causal and Resource Reasoning .	functional and non-functional requirements ; synthy service composition system ; composing web services end ; staged composition approach ; web services composition ; semantic web services ; business web services ; viewing software components ; web services ; application integration ; web services ; goal-directed reasoning ; telecom domain ; ai planning ; contextual information ; composing services ; composition scenarios ; ontologies ; soap ; wsdl ; ai	<otherscientificterm> <method> <task> <method> <task> <method> <method> <method> <method> <task> <method> <method> <material> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <task>	17 1 11 ; 7 0 4 ; 6 0 4 ; 12 0 16 ; 6 0 7 ; 19 1 11 ; 3 0 14 ; 10 0 9 ; 18 1 5	web services offer a unique opportunity to simplify <task_9> by defining common , web-based , platform-neutral , standards for publishing service descriptions to a registry , finding and invoking them -- not necessarily by the same parties . <method_7> as <method_8> , the current solutions to <task_4> based on <method_6> -lrb- using <method_19> , bpel , <method_18> etc. -rrb- or <method_5> -lrb- using <otherscientificterm_17> , <method_11> etc. -rrb- are both piecemeal and insufficient for building practical applications . inspired by the work in <task_13> on decoupling causal -lrb- planning -rrb- and resource reasoning -lrb- scheduling -rrb- , we introduced the first integrated work in <task_2> to end from specification to deployment by synergistically combining the strengths of the current approaches . the solution is based on a novel two -- <method_3> that addresses the information model-ing aspects of <method_8> , provides support for <otherscientificterm_14> while <task_15> , employs efficient de-coupling of <otherscientificterm_0> , and leads to improved scalability and failure handling . a prototype of the solution has been implemented in the <method_1> and applied to a number of <otherscientificterm_16> from the <material_12> . the application of planning to <method_8> has also brought new plan and planner usability-driven research issues to the fore for <task_20> .	9 7 29 21 -1 8 4 6 19 18 5 17 11 22 23 24 26 27 30 21 -1 13 21 -1 2 28 21 -1 3 14 15 0 25 21 -1 1 16 12 21 -1
The Local Projective Shape of Smooth Surfaces and their Outlines .	relative orientation of rim tangents ; oriented projective differential geometry ; inflections of apparent contours ; local shape of surfaces ; theoretical framework ; convexities ; concavities	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	6 1 2	this paper examines projectively invariant local properties of smooth curves and surfaces . <method_1> is proposed as a <method_4> for establishing such invariants and describing the <otherscientificterm_3> and their outlines . this <method_4> is applied to two problems : a projective proof of koenderink 's famous characterization of <otherscientificterm_5> , <otherscientificterm_6> , and <otherscientificterm_2> ; and the determination of the <otherscientificterm_0> at frontier points .	1 7 -1 4 3 7 -1 5 6 2 0 8 7 -1
Fast and Accurate k-means For Large Datasets .	approximate nearest neighbor search ; memory requirements ; running time ; k-means problem ; approximation guarantee ; k-means ; algorithms-both ; clustering ; disk	<method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm>	1 1 2 ; 0 0 5	clustering is a popular problem with many applications . we consider the <task_3> in the situation where the data is too large to be stored in main memory and must be accessed sequentially , such as from a <otherscientificterm_8> , and where we must use as little memory as possible . our algorithm is based on recent theoretical results , with significant improvements to make it practical . our approach greatly simplifies a recently developed algorithm , both in design and in analysis , and eliminates large constant factors in the <otherscientificterm_4> , the <otherscientificterm_1> , and the <otherscientificterm_2> . we then incorporate <method_0> to compute <method_5> in o -lrb- nk -rrb- -lrb- where n is the number of data points ; note that computing the cost , given a solution , takes Œ∏ -lrb- nk -rrb- time -rrb- . we show that our algorithm compares favorably to existing <method_6> theoretically and experimentally , thus providing state-of-the-art performance in both theory and practice .	9 -1 3 8 9 -1 9 -1 4 1 2 10 9 -1 11 9 -1 0 5 9 -1
Rapid Object Recognition from Discriminative Regions of Interest .	discriminative power of local appearance patterns ; object representation and recognition ; cognitive computer vision systems ; intelligent video surveillance systems ; gaus-sian image noise ; discriminative local patterns ; partial object occlusions ; posterior en-tropy measure ; local information content ; object recognition ; robot vision ; recognition system ; background clutter ; object models ; object identification ; detection tasks ; multi-modal interfaces ; object views ; discriminative regions ; robust recognition ; partial occlusion ; scale variation ; local information ; recognition ; noise	<otherscientificterm> <task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <task> <method> <otherscientificterm> <method> <task> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	3 6 2 ; 6 1 21 ; 22 0 14 ; 20 5 11 ; 6 1 24 ; 20 1 4 ; 10 1 3 ; 21 1 24 ; 3 1 16 ; 24 1 12 ; 7 0 18 ; 9 6 2 ; 5 0 13 ; 12 1 15 ; 16 6 2 ; 8 0 1 ; 10 6 2 ; 14 0 19	object <task_23> and detection represent a relevant component in <method_2> , such as in <task_10> , <task_3> , or <task_16> . <task_14> from <otherscientificterm_22> has recently been investigated with respect to its potential for <task_19> , e.g. , in case of <otherscientificterm_6> , <otherscientificterm_21> , <otherscientificterm_24> , and <otherscientificterm_12> in <task_15> . this work contributes to this research by a thorough analysis of the <otherscientificterm_0> and by proposing to exploit <otherscientificterm_8> to model <task_1> . we identify <otherscientificterm_18> in the <otherscientificterm_17> from a <metric_7> , and then derive <method_13> from selected <otherscientificterm_5> . for <task_23> , we determine rapid attentive search for locations of high information content from learned decision trees . the <method_11> is evaluated by various degrees of <otherscientificterm_20> and <otherscientificterm_4> , resulting in highly <task_19> even in the presence of severe occlusion effects .	23 2 10 3 16 14 26 32 34 37 40 42 25 -1 22 19 6 21 24 12 15 27 28 30 33 35 39 43 25 -1 0 8 1 41 25 -1 18 17 7 13 5 36 38 25 -1 25 -1 29 31 25 -1
Distributed Gaussian particle filtering using likelihood consensus .	gaussian particle filter ; likelihood consensus scheme ; global state estimate ; wireless sensor network ; target tracking problem ; joint likelihood function ; local communications ; distributed implementation ; local gpf ; particle weights	<method> <method> <otherscientificterm> <method> <task> <otherscientificterm> <method> <method> <method> <otherscientificterm>	0 0 3 ; 6 0 5 ; 8 0 4	we propose a <method_7> of the <method_0> for use in a <method_3> . each sensor runs a <method_8> that computes a <otherscientificterm_2> . the updating of the <otherscientificterm_9> at each sensor uses the <otherscientificterm_5> , which is calculated in a distributed way , using only <method_6> , via the recently proposed <method_1> . a significant reduction of the number of particles can be achieved by means of another <method_1> . the performance of the proposed <method_8> is demonstrated for a <task_4> .	7 0 3 11 10 -1 8 2 10 -1 9 5 6 1 12 10 -1 10 -1 4 13 10 -1
A Filtering Approach to Underdetermined Blind Source Separation With Application to Temporomandibular Disorders .	diagnosis of temporomandibu-lar disorders ; temporomandibular joint sounds ; underdetermined blind source separation problem ; underdetermined blind source separation ; copyrighted component ; tem-poromandibular disorders ; fastica algorithm ; filtering approach ; mixing matrix ; temporomandibular disorders ; 1-norm algorithm ; ltering approach ; ieee ; abstract	<task> <otherscientificterm> <task> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <method>	11 0 1 ; 6 0 8 ; 11 0 3	a <method_11> to <task_3> with application to <otherscientificterm_9> this item was submitted to loughborough university 's institutional repository by the/an author . <method_11> to <task_3> with application to <otherscientificterm_5> . however , permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution to servers or lists , or to reuse any <method_4> of this work in other works must be obtained from the <material_12> . <method_13> this paper addresses the <task_2> , using a <method_7> . we have developed an extension of the <method_6> which exploits the disparity in the kurtoses of the underlying sources to estimate the <otherscientificterm_8> and thereafter the recovery of the sources is achieved by employing the <method_10> . also , we demonstrate how promising <method_6> can be to extract the sources , without utilizing the <method_10> . furthermore , we illustrate how this <method_11> is particularly suitable to the separation of the <otherscientificterm_1> , crucial in the <task_0> .	11 3 9 14 -1 5 17 14 -1 4 12 13 14 -1 2 7 14 -1 6 16 14 -1 8 10 14 -1 15 14 -1
Flexibly Exploiting Prior Knowledge in Empirical Learning .	inductive learning of decision trees ; representa tiveness of data ; model-based or domain-theory knowledge ; knowledge acquisition strategies ; empirical learning-the rules ; strategy-a human analyst ; human expertise ; machine-induction system ; task automation ; printing error ; machine induction ; modfl-demed feature ; domain theory ; weak rules ; printing-plant humidity ; default bias ; domain-theory-denvcd features ; inductively-derived rules ; learning system ; decision trees ; analyst-specified model ; banding ; svslem ; veracitv	<task> <material> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method>	20 0 0 ; 20 0 10 ; 2 1 6 ; 16 1 12 ; 3 0 8 ; 20 0 12 ; 3 0 12 ; 7 0 4 ; 7 0 19 ; 20 0 8 ; 3 0 19 ; 7 0 20 ; 3 0 4 ; 20 0 4 ; 16 1 6 ; 3 0 20 ; 20 0 19 ; 10 1 6 ; 7 0 6 ; 10 0 4 ; 3 0 10	this paper presents a method to incorporate knowledge from possibly imperfect models and domain theories into <task_0> for classification the approach assumes that a model or <method_12> reflects useful prior knowledge of th < task thus the <otherscientificterm_15> should accept the model s predictions as accurate even in the face of somewhat contradictory data which may be unrepresen-lative or noisy however our approach allows the <method_22> to abandon the model or domain theorv , or portions thereof in the fact of suffi-cientlv contradictory data in particular we use c4 5 to induce <otherscientificterm_19> from data that ha \ t heen augmented b \ model or <otherscientificterm_16> ' we weakly bias the <method_22> to select model-derived features dur ing decision tree induction but this preference is not dogmatically applied our experiments vary imperfection in a model the <material_1> and the <method_23> with which <otherscientificterm_11> are preferred 1 introduction when <otherscientificterm_6> is nonexistent or very weak relative to a particular domain/task and when data is plentiful <task_10> from data mav be the only reasonable approach to <task_8> in contrast , when expertise is strong , then encoding the expert s model or <method_12> via traditional <method_3> ma > be the best approach in fact , this <otherscientificterm_6> may stem from induction over a much larger data sample than is available at the time <task_8> is undertaken in many cases , however , conditions are indeterminate as to whether sole reliance on <task_10> or <otherscientificterm_6> is most appropriate <otherscientificterm_6> may not be ` perfect and/or data may not be as plentiful as desired in cases where some data is available and <otherscientificterm_6> is less than perfect an advantageous strategy may be to exploit both in an appropriate way there is a growing body of work that combines <otherscientificterm_2> with empirical learning from data clark and matwin -lsb- 1993 -rsb- assume that an <method_20> mediates <otherscientificterm_4> derived from a <method_7> are ace3pted as long as they do not contradict the biases found in the model evans and fisher -lsb- 1994 -rsb- employ a similar <method_5> may specify <otherscientificterm_13> -lrb- e g when <otherscientificterm_14> is low , a certain kind of <otherscientificterm_9> known as <method_21> is more likely , to occur -rrb- if <otherscientificterm_17> indicate an opposite trend then the <method_18> s default strategy is to reject the ...	0 12 15 22 19 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 24 -1
Head-Driven Hierarchical Phrase-based Translation .	chi-ang 's hierarchical phrase-based model ; head-driven hpb ; nist mt test sets ; chiang 's model ; reordering search space ; syntax-driven information ; translation rules ; chinese-english translation ; head information ; reordering ; bleu	<method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <metric>	2 5 1 ; 1 4 3 ; 7 5 1 ; 2 5 7 ; 10 5 3	this paper presents an extension of <method_0> , called <method_1> , which incorporates <otherscientificterm_8> in <otherscientificterm_6> to better capture <otherscientificterm_5> , as well as improved <task_9> between any two neighboring non-terminals at any stage of a derivation to explore a larger <otherscientificterm_4> . experiments on <task_7> on four <material_2> show that the <method_1> significantly outperforms <method_3> with average gains of 1.91 points absolute in <metric_10> .	0 1 8 6 5 9 4 11 -1 7 2 3 10 12 13 14 15 16 11 -1
Optimal Asset Allocation using Adaptive Dynamic Programming .	computerized asset allocation -lrb- portfolio management -rrb- ; neural network based reinforcement learning ; reinforcement learning ; high dimensional state space ; reinforcement learning based algorithms ; asset allocation strategy ; markovian decision problem ; artificial exchange rate ; heuristic benchmark policy ; value function approximators ; german stock market ; problem setting ; neural networks ; asset allocation ; liquid capital ; dynamic programming ; policy	<task> <method> <method> <otherscientificterm> <method> <method> <task> <metric> <method> <method> <material> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm>	5 4 8 ; 15 0 16 ; 14 3 10 ; 7 0 5 ; 6 0 13 ; 1 0 11 ; 5 0 16 ; 3 2 11 ; 15 1 4 ; 12 0 9 ; 15 0 6	in recent years , the interest of investors has shifted to <task_0> to exploit the growing dynamics of the capital markets . in this paper , <method_13> is formalized as a <task_6> which can be optimized by applying <method_15> or <method_4> . using an <metric_7> , the <method_5> optimized with <method_2> is shown to be equivalent to a <otherscientificterm_16> computed by <method_15> . the <method_5> is then tested on the task to invest <otherscientificterm_14> in the <material_10> . here , <method_12> are used as <method_9> . the resulting <method_5> is superior to a <method_8> . this is a further example which demonstrates the applicability of <method_1> to a <task_11> with a <otherscientificterm_3> .	0 17 -1 13 6 15 4 22 26 28 17 -1 7 5 2 16 19 21 24 17 -1 14 10 20 17 -1 12 9 27 17 -1 8 18 17 -1 23 25 17 -1
Rao-Blackwellised particle filtering for blind system identification .	time-varying finite impulse response model ; sequential monte carlo methods ; time-varying autoregressive model ; nonlinear sequential state estimation problem ; convolution of the sources ; ar and fir coefficients ; rao-blackwellised particle filtering algorithm ; joint posterior distribution ; state space model ; blind system identification ; additive noise ; multi-sensor measurements ; bayesian solution ; numerical approximation ; particle filter	<method> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method>	13 0 3 ; 6 0 9 ; 12 0 3 ; 4 0 11 ; 12 0 14 ; 2 0 8 ; 13 0 12	this paper develops a <method_6> for <task_9> . the <method_8> under consideration uses a <method_2> for the sources , and a <method_0> for the channel . the <otherscientificterm_11> result from the <otherscientificterm_4> with the channels in the presence of <otherscientificterm_10> . a <method_13> to the optimal <method_12> for the <task_3> is implemented using <method_1> . the <method_12> is applied to improve the efficiency of the <method_14> by marginalizing out the <otherscientificterm_5> from the <otherscientificterm_7> . simulation results are given to verify the performance of the proposed <method_6> .	6 9 17 15 -1 8 2 0 21 15 -1 11 4 10 19 15 -1 13 12 3 1 16 18 22 15 -1 14 5 7 20 15 -1 15 -1
Designing Spatially Coherent Minimizing Flows for Variational Problems Based on Active Contours .	application-specific spatially coherent minimizing flows ; canonical l 2 inner product ; classical gradient flows ; active contours method ; active contours literature ; irrelevant local minima ; inner products ; gradient descents ; variational problems ; gradient flows ; active contours ; spatial coherence ; admissible deformations ; gradient	<otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 2 8	this paper tackles an important aspect of the <task_8> involving <otherscientificterm_10> , which has been largely overlooked so far : the optimization by <otherscientificterm_9> . classically , the definition of a <otherscientificterm_13> depends directly on the choice of an inner product structure . this consideration is largely absent from the <otherscientificterm_4> . most authors , overtly or covertly , assume that the space of <otherscientificterm_12> is ruled by the <otherscientificterm_1> . the <otherscientificterm_2> reported in the literature are relative to this particular choice . in this paper , we investigate the relevance of using other <method_6> , yielding other <method_7> , and some other minimizing flows not deriving from any inner product . in particular , we show how to induce different degrees of <otherscientificterm_11> into the minimizing flow , in order to decrease the probability of getting trapped into <otherscientificterm_5> . we show with some numerical experiments that the sensitivity of the <method_3> to initial conditions , which seriously limits its applicability and its efficiency , is alleviated by our <otherscientificterm_0> .	8 10 9 15 14 -1 13 14 -1 4 14 -1 12 1 14 -1 2 14 -1 6 7 14 -1 14 -1 11 5 14 -1
Multi-task Gaussian Process Learning of Robot Inverse Dynamics .	multi-task learning problem ; inverse dynamics problem ; multi-task gaussian process ; robotic manipulator ; latent functions ; adaptive control ; inter-task similarity ; inertial parameters ; end effector ; inverse dynamics	<task> <task> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 3 ; 7 0 6	the <task_1> for a <method_3> is to compute the torques needed at the joints to drive it along a given trajectory ; it is beneficial to be able to learn this function for <task_5> . a <method_3> will often need to be controlled while holding different loads in its <otherscientificterm_8> , giving rise to a <task_0> . by placing independent gaussian process priors over the <otherscientificterm_4> of the <otherscientificterm_9> , we obtain a <method_2> prior for handling multiple loads , where the <otherscientificterm_6> depends on the underlying <otherscientificterm_7> . experiments demonstrate that this <method_3> is effective in sharing information among the various loads , and generally improves performance over either learning only on single tasks or pooling the data over all tasks .	1 3 5 11 10 -1 8 0 10 -1 4 9 2 6 7 12 10 -1 10 -1
Strategy Representation and Reasoning for Incomplete Information Concurrent Games in the Situation Calculus .	strategy representation and reasoning ; multi-agent epistemic situation calculus ; incomplete information concurrent games ; strategy representation and reasoning ; strategy programming language ; concrete game models ; logical frameworks ; strategy programs ; multi-agent system ; golog	<method> <method> <otherscientificterm> <task> <method> <method> <method> <method> <task> <method>	3 0 2 ; 5 0 6	strategy representation and reasoning for <otherscientificterm_2> has recently received much attention in <task_8> and ai communities . however , most of the <method_6> are based on <method_5> , lack the abilities to reason about strategies explicitly or specify strategies procedurally , and ignore the issue of coordination within a coalition . in this paper , by a simple extension of a variant of <method_1> with a strategy sort , we develop a general framework for <task_3> for <otherscientificterm_2> . based on <method_9> , we propose a <method_4> which can be conveniently used to specify collective strategies of coalitions at different granularities . we present a formalization of joint abilities of coalitions under commitments to <method_7> . different kinds of individual strategic abilities can be distinguished in our framework . both strategic abilities in atl and joint abilities of ghaderi et al. can be considered as joint abilities under special programs in our framework . we illustrate our work with a variant of levesque 's squirrels world .	2 8 10 -1 6 5 12 10 -1 1 3 11 10 -1 9 4 10 -1 10 -1 7 10 -1 10 -1 10 -1
Representing Sentence Structure in Hidden Markov Models for Information Extraction .	hidden markov models ; hmm training ; information extractors ; objective function ; biomedical domains ; free text ; grammatical structure ; binary relations ; extractors	<method> <method> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <method>	4 2 7 ; 3 0 1 ; 8 0 7	we study the application of <method_0> to learning <otherscientificterm_2> for $ - ary relations from <material_5> . we propose an approach to representing the <otherscientificterm_6> of sentences in the states of the model . we also investigate using an <otherscientificterm_3> during <method_1> which maximizes the ability of the learned models to identify the phrases of interest . we evaluate our methods by deriving <method_8> for two <otherscientificterm_7> in <material_4> . our experiments indicate that our approach learns more accurate models than several baseline approaches .	0 2 5 9 -1 6 9 -1 3 1 11 9 -1 8 7 4 10 12 9 -1 9 -1
A Generalized Optical Flow Constraint and its Physical Interpretation .	apparent motion of image irradiance patterns ; fluid mechanic mass conservation principle ; extended optical flow constraint ; extended optical flow constraints ; synthetic and meteorological images ; invariance brightness based hypothesis ; optical flow constraint ; motion estimation ; image sequences ; optical flow	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <task> <material> <otherscientificterm>	6 6 5 ; 8 5 7 ; 1 0 6 ; 9 1 3	this paper addresses the issue of <task_7> on <material_8> . the standard <task_7> used to compute the <otherscientificterm_0> is an <method_5> called the <otherscientificterm_6> . other equations can be used , in particular the <otherscientificterm_2> , which is a variant of the <otherscientificterm_6> , inspired by the <method_1> . in this paper , we propose a physical interpretation of this <otherscientificterm_2> and a new model unifying the <otherscientificterm_9> and the <otherscientificterm_3> . we present results obtained for <material_4> .	7 8 12 10 -1 0 5 6 11 10 -1 2 1 13 10 -1 9 3 14 10 -1 4 10 -1
Classifying Facial Action .	detecting and classifying facial actions ; facial action coding system ; automated facial expression analysis ; local image features ; facial muscle contractions ; motion ow elds ; holistic spatial analysis ; template matching ; principal components ; action combinations ; facial actions ; image sequences ; facial expression ; wrinkles ; generalization	<task> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <method> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm> <task>	10 1 9	the <method_1> , -lrb- facs -rrb- , devised by ekman and friesen -lrb- 1978 -rrb- , provides an objective means for measuring the <otherscientificterm_4> involved in a <otherscientificterm_12> . in this paper , we approach <task_2> by <task_0> . we generated a database of over 1100 <material_11> of 24 subjects performing over 150 distinct <material_10> or <otherscientificterm_9> . we compare three diierent approaches to classifying the <material_10> in these images : <method_6> based on <method_8> of graylevel images ; explicit measurement of <otherscientificterm_3> such as <otherscientificterm_13> ; and <task_7> with <otherscientificterm_5> . on a dataset containing six individual actions and 20 subjects , these methods had 89 % , 57 % , and 85 % performances respectively for <task_14> to novel subjects . when combined , performance improved to 92 % .	1 4 12 15 -1 2 0 15 -1 11 10 9 16 15 -1 6 8 3 13 7 5 15 -1 15 -1 14 15 -1
Vector-sensor array processing for estimating angles and times of arrival of multipath communication signals .	vector-sensor array processing ; multipath channel estimation ; vector-sensor array ; mobile localization ; music-type algorithm ; angles-of-arrival aoas ; space-time-polarization parameterization ; resolution performance ; multi-path channels ; space-time-polarization domain ; accuracy	<method> <task> <otherscientificterm> <task> <method> <otherscientificterm> <method> <metric> <otherscientificterm> <material> <metric>	0 0 5 ; 2 0 4 ; 1 1 3 ; 6 5 8	we develop <method_0> to estimate the <otherscientificterm_5> and time delays of mul-tipath channels in the <material_9> . a <method_4> for joint angle and delay estimation with a <otherscientificterm_2> is derived . potential applications include <task_1> and <task_3> . simulation results show that the <method_6> of the <otherscientificterm_8> results in improved <metric_10> and <metric_7> .	0 5 9 12 11 -1 4 2 13 11 -1 1 3 14 11 -1 6 8 10 7 15 11 -1
Voice source analysis using biomechanical modeling and glottal inverse filtering .	deterministic vocal fold model ; estimated glottal flow ; glottal inverse filtering ; glottal flow waveform ; glottal flow signal ; glottal flow ; natural speech ; biomechanical model ; deterministic components ; vocal folds ; inverse filtering ; optimization process ; parameters	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm>	10 0 3 ; 7 0 3 ; 8 2 4 ; 2 1 7	this paper studies the use of <method_2> together with a <method_7> of the <otherscientificterm_9> to simulate the <otherscientificterm_3> . the <otherscientificterm_3> is first estimated by <method_10> the acoustic speech pressure signal of <material_6> . the <otherscientificterm_1> is used as a template in an <method_11> which searches for a set of <otherscientificterm_12> for a <method_0> such that the model output reproduces the <otherscientificterm_1> . the results indicate that the method can reproduce the main <method_8> of the <otherscientificterm_4> with good accuracy .	2 7 9 3 15 17 13 -1 10 6 14 13 -1 1 11 12 0 13 -1 8 4 5 16 13 -1
Scene cut detection from MPEG video stream coded without B pictures .	mpeg-1 video bit streams ; macroblock types ; gop structure ; gop boundaries ; scene cuts ; matching degree	<material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	2 2 0	in this paper we propose an algorithm that automatically detects clear scene cut locations from an <material_0> coded with a <otherscientificterm_2> of m = 1 , without b pictures . the algorithm detects <otherscientificterm_4> at p t ype pictures by monitoring the percentage of intra-macroblocks per p picture . while <otherscientificterm_4> at i pictures are detected by matching the macroblocks type of the two p pictures at the <otherscientificterm_3> . a \ type matching parameter '' -lrb- tmp -rrb- is developed to estimate the <otherscientificterm_5> between the <otherscientificterm_1> of two p pictures . it is shown that the method is able to identify the location of <otherscientificterm_4> in p and i pictures with a high success rate .	0 2 7 6 -1 4 6 -1 3 6 -1 5 1 6 -1 6 -1
Speeded-up , relaxed spatial matching .	large scale image retrieval ; relaxed matching process ; spatial matching model ; single feature correspondences ; image retrieval ; rigidity constraints ; search engine ; geometric invariance ; computational complexity ; geometry re-ranking ; mapping constraints ; space requirements ; discrim-inative power ; hough voting ; transformation space ; non-rigid objects ; one-to-one mapping ; assumptions ; registration ; recognition ; descriptors ; features ; detection	<task> <method> <method> <material> <task> <otherscientificterm> <method> <otherscientificterm> <metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <task>	21 1 8 ; 21 1 20 ; 19 1 18 ; 22 1 18 ; 16 2 15 ; 12 1 5 ; 19 1 22 ; 21 1 10 ; 9 3 6 ; 18 1 0 ; 1 0 9 ; 7 1 5 ; 12 1 7 ; 5 1 10	a wide range of properties and <otherscientificterm_17> determine the most appropriate <method_2> for an application , e.g. <task_19> , <task_22> , <task_18> , or <task_0> . most notably , these include <otherscientificterm_12> , <otherscientificterm_7> , <otherscientificterm_5> , <otherscientificterm_10> , <otherscientificterm_17> made on the underlying <otherscientificterm_21> or <otherscientificterm_20> and , of course , <metric_8> . having <task_4> in mind , we present a very simple model inspired by <method_13> in the <otherscientificterm_14> , where votes arise from <material_3> . a <method_1> allows for multiple matching surfaces or <otherscientificterm_15> under <method_16> , yet is linear in the number of correspondences . we apply <method_1> to <task_9> in a <method_6> , yielding superior performance with the same <otherscientificterm_11> but a dramatic speed-up compared to the state of the art .	17 2 19 22 18 0 26 27 30 33 23 -1 12 7 5 10 21 20 8 24 25 29 31 35 36 37 23 -1 4 13 14 3 23 -1 1 15 16 28 23 -1 32 34 23 -1
ReACTR : Realtime Algorithm Configuration through Tournament Rankings .	automated algorithm configuration ; demonstrative instances ; static config-urators ; parameter space ; steady stream ; parameter settings ; non-dynamic setting ; react system ; problem domain ; static environment ; configuration tools ; ranking scheme ; gga ; smac ; trueskill ; paramils	<method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <method> <method> <method> <method>	12 6 10 ; 14 6 11 ; 13 1 12 ; 15 1 13 ; 13 6 10 ; 6 0 2 ; 15 6 10 ; 13 6 2 ; 13 3 6	it is now readily accepted that <method_0> is a necessity for ensuring optimized performance of solvers on a particular <material_8> . even the best developers who have carefully designed their solver are not always able to manually find the best <otherscientificterm_5> for it . yet , the opportunity for improving performance has been repeatedly demonstrated by <method_10> like <method_15> , <method_13> , and <method_12> . however , all these techniques currently assume a <otherscientificterm_9> , where <otherscientificterm_1> are procured beforehand , potentially unlimited time is provided to adequately search the <otherscientificterm_3> , and the solver would never need to be retrained . this is not always the case in practice . the <method_7> , proposed in 2014 , demonstrated that a solver could be configured during runtime as new instances arrive in a <otherscientificterm_4> . this paper further develops that approach and shows how a <method_11> , like <method_14> , can further improve the configurator 's performance , making it able to quickly find good parameterizations without adding any overhead on the time needed to solve any new instance , and then continuously improve as new instances are evaluated . the enhancements to <method_7> that we present enable us to even outperform existing <method_2> like <method_13> in a <otherscientificterm_6> .	0 8 16 -1 5 16 -1 10 15 13 12 17 19 20 21 23 16 -1 9 1 3 16 -1 16 -1 16 -1 7 4 18 16 -1 11 14 22 24 25 16 -1
A semi-blind MIMO channel estimation scheme for MRT .	closed-form semi-blind solution ; maximum ratio transmission ; mean squared error ; matrix perturbation theory ; semi-blind channel estimation ; channel matrix ; training lengths ; beamforming vectors ; beamforming vector ; estimation technique ; snr ; snrs	<method> <method> <metric> <method> <task> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm>	9 0 6 ; 9 0 0	in this paper , we investigate <task_4> for multiple input multiple output -lrb- mimo -rrb- quasi-static flat fading channels when <method_1> is employed . we propose a <method_0> for estimating the optimum transmit and receive <otherscientificterm_7> of the <otherscientificterm_5> . employing <method_3> , we develop expressions for the <metric_2> in the <otherscientificterm_8> and average received <metric_10> of both the semi-blind and the conventional least squares estimation -lrb- <method_0> -rrb- schemes . it is found that the proposed <method_9> outperforms <method_0> for a wide range of <metric_6> and training <otherscientificterm_11> .	4 1 12 -1 0 7 5 12 -1 3 2 8 10 12 -1 9 6 11 13 14 12 -1
Acquiring Comparative Commonsense Knowledge from the Web .	open information extraction methods ; disambiguated commonsense assertions ; joint optimization model ; integer linear programming ; semantic coherence scores ; cleaning ; wordnet ; bears ; web ; commonsense	<method> <otherscientificterm> <method> <method> <metric> <task> <material> <otherscientificterm> <material> <otherscientificterm>	8 0 0 ; 3 0 2 ; 3 1 4 ; 4 5 2	applications are increasingly expected to make smart decisions based on what humans consider basic <otherscientificterm_9> . an often overlooked but essential form of <otherscientificterm_9> involves comparisons , e.g. the fact that <otherscientificterm_7> are typically more dangerous than dogs , that tables are heavier than chairs , or that ice is colder than water . in this paper , we first rely on <method_0> to obtain large amounts of comparisons from the <material_8> . we then develop a <method_2> for <task_5> and disambiguating this knowledge with respect to <material_6> . this <method_2> relies on <method_3> and <metric_4> . experiments show that our <method_2> outperforms strong baselines and allows us to obtain a large knowledge base of <otherscientificterm_1> .	9 10 -1 7 10 -1 0 8 11 10 -1 2 5 6 10 -1 3 4 12 13 14 10 -1 10 -1
Resources for Urdu Language Processing .	corpus and lexical resources ; crulp ; urdu	<material> <material> <material>	1 0 2	urdu is spoken by more than 100 million speakers . this paper summarizes the <material_0> being developed for <material_2> by the <material_1> , in pakistan .	3 -1 0 2 1 4 3 -1
Minimizing the Reprojection Error in Surface Reconstruction from Images .	contour generators of the surface ; gradient descent surface evolution ; reprojection error functional ; apparent contour constraints ; computation of derivative ; image-based surface reconstruction ; surface moves ; visibility changes ; contour generators ; reprojection error	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	9 5 8	this paper addresses the problem of <task_5> . the main contribution is the computation of the exact derivative of the <otherscientificterm_2> . this allows its rigorous minimization via <method_1> . the main difficulty has been to correctly take into account the <otherscientificterm_7> that occur when the <otherscientificterm_6> . a geometric and analytical study of these changes is presented and used for the <task_4> . our analysis shows the strong influence that the movement of the <method_8> has on the <otherscientificterm_9> . as a consequence , during the proper minimization of the <otherscientificterm_9> , the <otherscientificterm_0> are automatically moved to their correct location in the images . therefore , current methods adding additional silhouettes or <otherscientificterm_3> to ensure this alignment can now be understood and justified by a single criterion : the <otherscientificterm_9> .	5 10 -1 2 10 -1 1 10 -1 7 6 10 -1 4 10 -1 8 9 11 10 -1 0 10 -1 10 -1
Fast Structural Binary Coding .	fast structural binary coding ; geometric relationships between database examples ; supervised binary coding approach ; hamming distance ranking list ; stochastic gradient descent method ; discrete optimization objective ; lever-aging supervised information ; short binary codes ; binary coding techniques ; high-dimensional data samples ; coding functions ; information retrieval ; continuous surrogate ; hamming space ; image search ; euclidean space ; image datasets ; coding quality ; coding function ; precision ; states-of-the-art	<method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <metric> <otherscientificterm> <metric> <material>	13 2 15 ; 12 2 5 ; 14 5 2 ; 14 5 20 ; 5 0 18 ; 0 6 2 ; 12 0 18	binary coding techniques , which compress originally <material_9> into <otherscientificterm_7> , are becoming increasingly popular due to their efficiency for <task_11> . <otherscientificterm_6> can dramatically enhance the <metric_17> , and hence improve search performance . there are few methods , however , that efficiently learn <otherscientificterm_10> that optimize the <metric_19> at the top of the <otherscientificterm_3> while approximately preserving the <otherscientificterm_1> . in this paper , we propose a novel <method_2> , namely <method_0> , to optimize the <metric_19> at the top of a <otherscientificterm_3> and ensure that similar images can be returned as a whole . the key idea is to train disciplined <otherscientificterm_10> by optimizing a lower bound of the area under the roc -lrb- receiver operating characteristic -rrb- curve -lrb- auc -rrb- and penalize this objective so that the <otherscientificterm_1> in the original <otherscientificterm_15> are approximately preserved in the <otherscientificterm_13> . to find such a <otherscientificterm_18> , we relax the original <otherscientificterm_5> with a <otherscientificterm_12> , and then derive a <method_4> to optimize the surrogate objective efficiently . empirical studies based upon two <material_16> demonstrate that the proposed <method_2> achieve superior <task_14> performance to the <material_20> .	9 7 11 6 21 -1 17 21 -1 10 19 3 1 21 -1 2 0 27 21 -1 22 21 -1 15 13 23 26 28 21 -1 18 5 12 4 24 25 21 -1
Convolutional Neural Fabrics .	sparse homogeneous local connectivity pattern ; part labels dataset ; response maps ; 3d trellis ; embedded architectures ; fabric size ; image classification ; semantic segmentation ; parameters ; layers ; mnist ; cnns ; back-propagation	<otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <material> <method> <method>	3 0 2 ; 12 0 8 ; 1 5 7	despite the success of <method_11> , selecting the optimal architecture for a given task remains an open problem . instead of aiming to select a single optimal architecture , we propose a '' <method_11> '' that embeds an exponentially large number of architectures . the <method_11> consists of a <otherscientificterm_3> that connects <otherscientificterm_2> at different <otherscientificterm_9> , scales , and channels with a <otherscientificterm_0> . the only hyper-parameters of a <method_11> are the number of channels and <otherscientificterm_9> . while individual architectures can be recovered as paths , the <method_11> can in addition ensemble all <otherscientificterm_4> together , sharing their weights where their paths overlap . <otherscientificterm_8> can be learned using standard methods based on <method_12> , at a cost that scales linearly in the <otherscientificterm_5> . we present benchmark results competitive with the state of the art for <task_6> on <material_10> and cifar10 , and for <task_7> on the <material_1> .	11 13 -1 13 -1 3 2 9 0 14 13 -1 13 -1 4 13 -1 8 15 13 -1 12 5 16 13 -1
Transforming HMMs for speaker-independent hands-free speech recognition in the car .	linear regression-based model adaptation procedure ; digit error rate ; quiet office ; adaptation utterances ; recording condition ; acoustic conditions ; hands-free recognition ; hmm ; hmms	<method> <metric> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <method> <method>	0 0 6 ; 0 0 8	in the absence of <method_8> trained with speech collected in the target environment , one may use <method_8> trained with a large amount of speech collected in another <otherscientificterm_4> -lrb- e.g. , <otherscientificterm_2> , with high quality microphone -rrb- . however , this may result in poor performance because of the mismatch between the two <otherscientificterm_5> . we propose a <method_0> to reduce such a mismatch . with some <material_3> collected for the target environment , the <method_0> transforms the <method_8> trained in a quiet condition to maximize the likelihood of observing the <material_3> . the transformation must be designed to maintain speaker-independence of the <method_7> . our speaker-independent test results show that with this <method_0> about 1 % <metric_1> can be achieved for <task_6> , using target environment speech from only 20 speakers .	8 4 2 9 -1 5 9 -1 0 9 -1 3 11 9 -1 9 -1 7 10 9 -1
Cross-Validation Optimization for Large Scale Hierarchical Classification Kernel Methods .	large scale text classification tasks ; cross-validation log likelihood ; kernel multi-class models ; hierarchical class structure ; predictive probabilities ; kernel parameters	<task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 5	we propose a highly efficient framework for <method_2> with a large and structured set of classes . <otherscientificterm_5> are learned automatically by maximizing the <otherscientificterm_1> , and <otherscientificterm_4> are estimated . we demonstrate our approach on <task_0> with <otherscientificterm_3> , achieving state-of-the-art results in an order of magnitude less time than previous work .	2 5 6 -1 1 4 7 6 -1 0 3 6 -1
Combination of speech features using smoothed heteroscedastic linear discriminant analysis .	feature combination techniques ; feature combination ; statistic estimation ; lda ; recognition ; hlda ; pca	<method> <method> <method> <method> <task> <method> <method>	6 1 3 ; 3 1 5 ; 6 0 0	feature combination techniques based on <method_6> , <method_3> and <method_5> are compared in experiments where limited amount of training data is available . success with <method_1> can be quite dependent on proper estimation of statistics required by the used technique . insufficiency of training data is , therefore , an important problem , which has to be taken in to account in our experiments . besides of some standard approaches increasing robustness of <method_2> , methods based on combination of <method_3> and <method_5> are proposed . an improved <task_4> performance obtained using these methods is demonstrated in experiments .	6 3 5 8 10 7 -1 1 7 -1 7 -1 2 9 7 -1 4 0 7 -1
Efficient multi-label ranking for multi-class learning : Application to object recognition .	pascal voc 2006 and 2007 data sets ; im-balanced data distributions ; binary classification problems ; block coordinate descent ; visual object recognition ; multi-label learning ; ranking approach ; multi-label ranking ; multi-label learning	<material> <otherscientificterm> <task> <otherscientificterm> <task> <task> <method> <method> <method>	5 0 4 ; 6 0 8	multi-label learning is useful in <task_4> when several objects are present in an image . conventional approaches implement <method_8> as a set of <task_2> , but <method_8> suffer from <otherscientificterm_1> when the number of classes is large . in this paper , we address <method_8> with many classes via a <method_6> , termed <method_7> . given a test image , the proposed scheme aims to order all the object classes such that the relevant classes are ranked higher than the irrelevant ones . we present an efficient algorithm for <method_7> based on the idea of <otherscientificterm_3> . the proposed algorithm is applied to <task_4> . empirical results on the <material_0> show promising results in comparison to the state-of-the-art algorithms for <method_8> .	4 10 9 -1 8 2 1 9 -1 6 7 11 9 -1 9 -1 3 9 -1 9 -1 9 -1
Distributional vectors encode referential attributes .	supervised regression model ; structured knowledge bases ; distributional representations ; distribu-tional representations ; distributional vectors ; word referents ; distributional methods ; baseline error ; referential attributes ; spain ; accuracy	<method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <material> <metric>	0 0 2 ; 4 0 8	distributional methods have proven to excel at capturing fuzzy , graded aspects of meaning -lrb- italy is more similar to <material_9> than to germany -rrb- . in contrast , it is difficult to extract the values of more specific attributes of <otherscientificterm_5> from <method_3> , attributes of the kind typically found in <material_1> -lrb- italy has 60 million inhabitants -rrb- . in this paper , we pursue the hypothesis that <otherscientificterm_4> also implicitly encode <otherscientificterm_8> . we show that a standard <method_0> is in fact sufficient to retrieve such attributes to a reasonable degree of <metric_10> : when evaluated on the prediction of both categorical and numeric attributes of countries and cities , the <method_0> consistently reduces <otherscientificterm_7> by 30 % , and is not far from the upper bound . further analysis suggests that our <method_0> is able to '' ob-jectify '' <method_2> for entities , anchoring <method_2> more firmly in the external world in measurable ways .	9 11 -1 5 3 1 11 -1 4 8 13 11 -1 0 10 11 -1 7 12 11 -1
Robust Bayesian Analysis applied to Wiener filtering of speech .	objective quality measures ; robust bayesian analysis ; speech enhancement algorithms ; speech activity decision ; power spectral density ; undesirable artifacts ; enhanced speech ; noise estimates ; wiener algorithm ; mitigating artifacts ; clean speech ; heuristic methods ; noise estimate ; signal-to-noise ratio	<metric> <method> <method> <task> <otherscientificterm> <otherscientificterm> <material> <task> <method> <task> <material> <method> <task> <metric>	2 0 4 ; 12 1 3	commonly used <method_2> estimate the <otherscientificterm_4> of the noise to be removed , or make a decision about the presence of speech in a particular frame , and estimate the <material_10> based on these . errors in a <task_12> or <task_3> may result in <otherscientificterm_5> , and some errors may be more damaging than others . <method_1> is used to analyze the sensitivity of algorithms to errors in <task_7> and improve <metric_13> while <task_9> in the <material_6> . the findings explain why some common heuristic changes to the wiener filter algorithm are effective . a standard <method_8> is used for comparison , <metric_0> are used to quantify improvement , and insights into the underlying mechanisms of <method_11> are offered .	2 4 10 15 14 -1 12 3 5 1 16 14 -1 7 13 9 6 14 -1 14 -1 8 14 -1
Heterogeneous Visual Features Fusion via Sparse Multimodal Machine .	object categorization and scene understanding image data sets ; sparse multimodal learning approach ; single-label and multi-label image classification tasks ; group-wise and individual point of views ; scene and object cat-egorization methods ; joint structured sparsity regularizations ; image and video information ; visual feature descriptors ; heterogeneous visual features ; elementary visual characteristics ; global convergence ; vision tasks ; optimization algorithm ; image features ; heterogeneous features ; non-smooth objective ; shape ; features	<material> <method> <task> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 0 11 ; 1 0 14 ; 5 0 14 ; 7 0 6 ; 12 0 15	to better understand , search , and classify <task_6> , many <otherscientificterm_7> have been proposed to describe <otherscientificterm_9> , such as the <otherscientificterm_16> , the color , the texture , etc. . how to integrate these <otherscientificterm_8> and identify the important ones from them for specific <task_11> has become an increasingly critical problem . in this paper , we propose a novel <method_1> to integrate such <otherscientificterm_14> by using the <method_5> to learn the feature importance of for the <task_11> from both <otherscientificterm_3> . a new <method_12> is also introduced to solve the <otherscientificterm_15> with rigorously proved <otherscientificterm_10> . we applied our <method_1> to five broadly used <material_0> for both <task_2> . for each data set we integrate six different types of popularly used <otherscientificterm_13> . compared to existing <method_4> using either single modality or multi-modalities of <otherscientificterm_17> , our <method_1> always achieves better performances measured .	6 7 9 16 22 18 -1 8 11 19 18 -1 1 14 5 3 20 21 18 -1 12 15 10 23 18 -1 18 -1 0 2 18 -1 13 18 -1
Information retrieval-based dynamic time warping .	information retrieval-based dynamic time warping ; dynamic time warping approaches ; baseline subsequence-dtw implementation ; non-linearly matching subsequences ; pure diagonal matching ; dynamic programming algorithm ; large scale implementations ; qbe-std task ; audio matching ; matching accuracy ; search collection ; memory footprint ; indexing techniques ; ir-dtw ; s-dtw	<method> <method> <method> <otherscientificterm> <task> <method> <task> <task> <task> <metric> <method> <otherscientificterm> <method> <method> <method>	13 4 1 ; 5 0 3 ; 12 0 10 ; 5 0 8 ; 9 4 4 ; 5 0 10 ; 0 6 5	in this paper we introduce a novel <method_5> called <method_0> used to find <otherscientificterm_3> between two time series where matching start and end points are not known a priori . in this paper our <method_5> is applied for <task_8> within the query by example -lrb- qbe -rrb- spoken term detection -lrb- std -rrb- task , although <method_5> is applicable to many other problems . the main advantages of the proposed <method_5> in comparison to similar approaches are twofold . on the one hand , <method_13> requires a much smaller <otherscientificterm_11> than standard <method_1> . on the other hand , <method_5> allows for the application of <method_12> to the <method_10> for increased matching speed , which makes <method_13> suitable for application in <task_6> . we show through preliminary experimentation with a <task_7> that the <otherscientificterm_11> is greatly reduced in comparison to a <method_2> and that its <metric_9> is much better than that of <task_4> and just slightly worse than that of <method_14> .	5 0 3 17 22 15 -1 8 19 15 -1 15 -1 13 11 1 16 15 -1 18 21 15 -1 12 10 6 20 15 -1
Dependence Minimizing Regression with Model Selection for Non-Linear Causal Inference under Non-Gaussian Noise .	least-squares independence regression ; additive non-gaussian noise models ; non-linear causal relationship ; causal inference method ; squared-loss mutual information ; causal inference algorithm ; additive noise model ; tuning parameters ; real-world datasets ; kernel width ; regularization parameter ; data-dependent fashion ; estimator ; overfitting ; cross-validation	<method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method>	9 1 10 ; 9 6 7 ; 0 4 3 ; 0 6 5 ; 0 0 6	the discovery of <otherscientificterm_2> under <method_1> has attracted considerable attention recently because of their high flexibility . in this paper , we propose a novel <method_5> called <method_0> . <method_0> learns the <method_6> through minimization of an <method_12> of the <otherscientificterm_4> between inputs and residuals . a notable advantage of <method_0> over existing approaches is that <otherscientificterm_7> such as the <otherscientificterm_9> and the <otherscientificterm_10> can be naturally optimized by <method_14> , allowing us to avoid <method_13> in a <otherscientificterm_11> . through experiments with <material_8> , we show that <method_0> compares favorably with the state-of-the-art <method_3> .	2 1 15 -1 5 0 19 15 -1 6 12 4 20 15 -1 7 9 10 14 13 11 16 17 15 -1 8 3 18 15 -1
An efficient algorithm for Co-segmentation .	markov random field based segmen-tation ; maximum flow procedure ; optimization model ; histogram differences ; optimization problems ; foreground appearance ; polynomial time ; foreground pixels ; gaussian prior ; simultaneous segmentation ; co-segmentation problem ; images	<method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <material>	1 0 6 ; 0 0 10	this paper is focused on the <task_10> -lsb- 1 -rsb- -- where the objective is to segment a similar object from a pair of <material_11> . the background in the two <material_11> may be arbitrary ; therefore , <method_9> of both <material_11> must be performed with a requirement that the appearance of the two sets of <otherscientificterm_7> in the respective <material_11> are consistent . existing approaches -lsb- 1 , 2 -rsb- cast this <task_10> as a <method_0> of the image pair with a regularized difference of the two histograms -- assuming a <otherscientificterm_8> on the <otherscientificterm_5> -lsb- 1 -rsb- or by calculating the sum of squared differences -lsb- 2 -rsb- . both are interesting formulations but lead to difficult <task_4> , due to the presence of the second -lrb- histogram difference -rrb- term . the model proposed here bypasses measurement of the <otherscientificterm_3> in a direct fashion ; we show that this enables obtaining efficient solutions to the underlying <method_2> . our new algorithm is similar to the existing methods in spirit , but differs substantially in that it can be solved to optimal-ity in <otherscientificterm_6> using a <method_1> on an appropriately constructed graph . we discuss our ideas and present promising experimental results .	10 11 12 -1 9 7 12 -1 0 8 5 14 12 -1 12 -1 4 12 -1 3 2 13 12 -1 6 1 12 -1
Database Pruning for Unsupervised Building of Text-To-Speech Voices .	unit selection speech synthesis techniques ; speech recognition confidence measures ; automatic segmentation of databases ; manually supervised tasks ; quality systems ; segmentation processes ; phonetic transcription ; segmentation errors	<method> <method> <task> <task> <method> <method> <task> <otherscientificterm>	6 6 3	unit selection speech synthesis techniques lead the speech synthesis state of the art . <task_2> is necessary in order to build new voices . they may contain errors and <method_5> may introduce some more . <method_4> require a significant effort to find and correct these <otherscientificterm_7> . <task_6> is crucial and is one of the <task_3> . the possibility to automatically remove incorrectly transcribed units from the inventory will help to make the process more automatic . here we present a new technique based on <method_1> that reaches to remove 90 % of incorrectly transcribed units from a database . the cost for it is loosing only a 10 % of correctly transcribed units .	2 8 -1 8 -1 5 4 8 -1 7 6 8 -1 3 9 8 -1 8 -1 1 8 -1 8 -1
A Hassle-Free Unsupervised Domain Adaptation Method Using Instance Similarity Features .	unlabeled target domain instances ; labeled source domain instances ; unsupervised domain adaptation method ; unsu-pervised domain adaptation method ; instance similarity features ; computational cost ; nlp tasks ; nlp ; scl	<otherscientificterm> <material> <method> <method> <otherscientificterm> <metric> <task> <task> <method>	4 0 1 ; 3 4 8 ; 0 0 4 ; 2 0 7 ; 5 5 8 ; 3 0 6 ; 8 6 6 ; 0 0 3 ; 5 5 3 ; 8 6 2 ; 6 5 3	we present a simple yet effective <method_3> that can be generally applied for different <task_6> . our <method_3> uses <otherscientificterm_0> to induce a set of <otherscientificterm_4> . these <otherscientificterm_4> are then combined with the original <otherscientificterm_4> to represent <material_1> . using three <task_6> , we show that our <method_3> consistently out-performs a few baselines , including <method_8> , an existing general <method_2> widely used in <task_7> . more importantly , our <method_3> is very easy to implement and incurs much less <metric_5> than <method_8> .	3 6 15 9 -1 0 4 12 17 9 -1 1 10 9 -1 8 2 7 13 16 19 20 9 -1 5 11 14 18 9 -1
An evaluation of unsupervised acoustic model training for a dysarthric speech interface .	acoustic unit descriptors ; unsupervised acoustic model training approaches ; vector quantization ; speaker-independent phoneme recognition baseline ; unsupervised acoustic model training ; slot filling f-score ; hidden markov models ; home automation task ; frame-based gaussian posteriorgrams ; recognition rates ; gaussian posteri-orgram ; unsupervised fashion ; dysarthric speech ; posteriorgram-based representations ; dysarthric-speech recognition ; posteriorgrams	<method> <method> <method> <method> <method> <metric> <method> <task> <method> <metric> <method> <method> <material> <method> <task> <method>	1 0 14 ; 11 0 8 ; 0 6 8 ; 1 4 3 ; 9 5 1 ; 15 0 0 ; 9 5 3 ; 10 5 13 ; 9 5 13 ; 2 0 8 ; 4 0 12 ; 9 5 0	in this paper , we investigate <method_1> for <task_14> . these <method_1> are first , <method_8> , obtained from <method_2> , second , so-called <method_0> , which are <method_6> of phone-like units , that are trained in an <method_11> , and , third , <method_15> computed on the <method_0> . experiments were carried out on a database collected from a <task_7> and containing nine speakers , of which seven are considered to utter <material_12> . all <method_1> delivered significantly better <metric_9> than a <method_3> , showing the suitability of <method_4> for <material_12> . while the <method_0> led to the most compact representation of an utterance for the subsequent semantic inference stage , <method_13> resulted in higher <metric_9> , with the <method_10> achieving the highest <metric_5> of 97.02 % .	1 14 17 16 -1 8 2 0 6 11 15 18 19 22 26 16 -1 7 12 16 -1 9 3 4 20 21 23 27 16 -1 24 25 28 16 -1
Comparative evaluation of the dual transform domain echo canceller for DMT-based systems .	dual transform domain echo canceller ; time domain signals ; data toeplitz matrix ; dmt-based communication systems ; low error floor ; digital echo cancellers ; toeplitz matrix ; full-duplex transmission ; transmitted signal ; computational cost ; computational complexity ; adaptive filters ; convergence curves ; complexity ; echo	<method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <task> <otherscientificterm> <metric> <metric> <method> <otherscientificterm> <metric> <otherscientificterm>	12 5 0 ; 6 0 1 ; 5 0 14 ; 8 3 6 ; 11 0 14 ; 12 1 9 ; 7 2 3 ; 9 5 0	in <method_3> where <task_7> is required , <method_5> are employed to cancel <otherscientificterm_14> by means of <method_11> . in order to reduce the <metric_10> of these cancellers , the structure of the <otherscientificterm_6> containing the <otherscientificterm_8> is usually exploited to transform the <otherscientificterm_1> and perform the emulation and adaptive update in a more convenient domain -lrb- e.g. frequency domain -rrb- . in this paper , we consider a recently proposed <method_0> , which is based on the general decomposition of the <otherscientificterm_2> . a comprehensive comparative performance evaluation of the proposed <method_0> with the existing methods is provided . this evaluation includes the comparison of the <otherscientificterm_12> and <metric_9> of the <method_0> . the comparison shows that the proposed <method_0> achieves a faster convergence with a <otherscientificterm_4> with no increase in the <metric_13> .	3 7 5 14 11 18 20 22 15 -1 10 6 8 1 17 19 15 -1 0 2 15 -1 15 -1 16 21 23 15 -1 12 9 15 -1
Multiple classifiers by constrained minimization .	nasal/oral vowel classification task ; combination strategy ; classification accuracy ; artificial data ; classification errors ; error rate ; ensemble ; classifier ; classifiers	<task> <method> <metric> <material> <otherscientificterm> <metric> <method> <method> <method>	1 0 8 ; 2 5 7 ; 5 5 8 ; 8 0 2 ; 8 4 7 ; 3 1 0	the paper describes an approach to combining multiple <method_8> in order to improve <metric_2> . since individual <method_8> in the <method_6> should somehow be uncorrelated to yield higher <metric_2> than a single <method_7> , we propose to train <method_8> by minimizing the correlation between their <otherscientificterm_4> . a simple <method_1> for three <method_8> is then proposed and its achievable <metric_5> is analyzed and compared to individual single <method_7> performance . the proposed approach has been evaluated on <material_3> and a <task_0> . theoretical analyses and experimental results illustrate the effectiveness of the proposed approach .	8 2 13 9 -1 6 7 4 11 14 9 -1 1 5 10 12 9 -1 3 0 15 9 -1 9 -1
Model Checking Probabilistic Knowledge : A PSPACE Case .	model checking probabilistic knowledge of memory-ful semantics ; reachability of probabilistic knowledge ; undecidable model checking problems ; pspace-complete case ; limit-sure knowledge ; atomic propositions ; syntactic restrictions ; logic language ; ltl	<task> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 0 7	model checking probabilistic knowledge of memory-ful semantics is undecidable , even for a simple formula concerning the <otherscientificterm_1> of a single agent . this result suggests that the usual approach of tackling <task_2> , by finding <otherscientificterm_6> over the <otherscientificterm_7> , may not suffice . in this paper , we propose to work with an additional restriction that agent 's knowledge concerns a special class of <otherscientificterm_5> . a <material_3> is identified with this additional restriction , for a <otherscientificterm_7> combining <method_8> with <otherscientificterm_4> of a single agent .	1 9 -1 2 6 7 10 9 -1 5 9 -1 3 8 4 0 9 -1
Optimized distributed 2D transforms for irregularly sampled sensor network grids using wavelet lifting .	dynamic programming algorithms ; minimum cost coding scheme assignment ; energy-efficient lifting-based 2d transform ; irregular spatial sampling ; wireless sensor networks ; recursive dp formulation ; 2d transforms ; data decorrelation ; wavelet decomposition ; backward transmissions ; unidirectional computation	<method> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task>	0 0 2 ; 2 0 4 ; 2 0 10 ; 1 0 2	we address the design and optimization of an <method_2> for <method_4> with <method_3> . the <method_2> is designed to allow for <task_10> found in existing path-wise transforms , thereby eliminating costly <otherscientificterm_9> often required by existing <otherscientificterm_6> , while simultaneously achieving greater <otherscientificterm_7> than those path-wise transforms . we also propose a framework for optimizing the <method_2> via an extension of standard <method_0> , where a selection is made among alternative coding schemes -lrb- e.g. , different number of levels in the <otherscientificterm_8> -rrb- . a <method_5> is provided and an algorithm is given that finds the <method_1> for our proposed <method_2> .	2 4 3 13 11 -1 10 9 6 7 14 11 -1 0 8 12 11 -1 5 1 15 11 -1
LPQP for MAP : Putting LP Solvers to Better Use .	linear programming based relaxation ; quadratic programming relaxation ; lp pairwise auxiliary variables ; synthetic and real-world data ; qp equivalent terms ; non-convex objective ; map inference ; lp relaxation ; kullback-leibler divergence ; belief propagation ; dual decomposition	<method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	9 1 10	map inference for general energy functions remains a challenging problem . while most efforts are channeled towards improving the <method_0> , this work is motivated by the <method_1> . we propose a novel <task_6> that penalizes the <otherscientificterm_8> between the <otherscientificterm_2> , and <otherscientificterm_4> given by the product of the unar-ies . we develop two efficient algorithms based on variants of this relaxation . the algorithms minimize the <otherscientificterm_5> using <method_9> and <otherscientificterm_10> as building blocks . experiments on <material_3> show that the solutions returned by our algorithms substantially improve over the <otherscientificterm_7> .	11 -1 0 1 11 -1 6 8 2 4 11 -1 11 -1 5 9 10 12 11 -1 3 7 11 -1
Robust speech dereverberation based on non-negativity and sparse nature of speech spectrograms .	sparse nature of speech spectrograms ; non-negative matrix factor deconvolution ; blind deconvolution problem ; blind dereverberation method ; iterative algorithm ; subband envelope ; reverberant version ; non-negative constraints ; speaker movement ; optimization	<otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task>	7 2 2 ; 3 0 8 ; 3 0 5 ; 4 0 9	this paper presents a <method_3> designed to recover the <otherscientificterm_5> of an original speech signal from its <otherscientificterm_6> . the problem is formulated as a <task_2> with <otherscientificterm_7> , regularized by the <otherscientificterm_0> . we derive an <method_4> for its <task_9> , which can be seen as a special case of the <otherscientificterm_1> . we confirmed through experiments that the <method_3> is fast and robust to <task_8> .	3 5 6 13 10 -1 2 7 0 11 10 -1 4 9 1 14 10 -1 8 12 10 -1
Object recognition and segmentation by non-rigid quasi-dense matching .	non-rigid deformations of the imaged surfaces ; local affine transformation estimates ; non-rigid quasi-dense matching method ; match propagation algorithm ; global geometric constraints ; local image gradients ; geometrically consistent matches ; non-rigid image registration ; geometrically consistent groups ; quasi-dense pixel matches ; partial occlusion ; quasi-dense matching ; background clutter ; viewpoint changes ; local properties ; object recognition ; recognition criterion ; geometric deformations ; propagation	<otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task>	5 0 3 ; 1 0 2 ; 12 1 10 ; 2 0 9 ; 10 1 13 ; 2 0 7 ; 3 0 2 ; 11 0 2 ; 13 1 17 ; 5 0 2 ; 2 0 15	in this paper , we present a <method_2> and its application to <task_15> and segmentation . the <method_2> is based on the <method_3> which is here extended by using <otherscientificterm_5> for adapting the <task_18> to smooth <otherscientificterm_0> . the adaptation is based entirely on the <otherscientificterm_14> of the images and the <method_2> can be hence used in <task_7> where <otherscientificterm_4> are not available . our <method_2> for <task_15> and seg-mentation is directly built on the <task_11> . the <otherscientificterm_9> between the <method_2> and test images are grouped into <otherscientificterm_8> using a <method_2> which utilizes the <otherscientificterm_1> obtained during the <task_18> . the number and quality of <otherscientificterm_6> is used as a <otherscientificterm_16> and the location of the matching pixels directly provides the segmentation . the experiments demonstrate that our <method_2> is able to deal with extensive <otherscientificterm_12> , <otherscientificterm_10> , large scale and <otherscientificterm_13> , and notable <otherscientificterm_17> .	2 15 19 -1 3 5 18 0 20 26 29 19 -1 14 7 4 25 19 -1 11 27 30 19 -1 9 8 1 21 23 19 -1 19 -1 6 16 22 24 28 19 -1
A Scalable Interdependent Multi-Issue Negotiation Protocol for Energy Exchange .	interdependent multi-issue negotiation ; renewable energy generation ; off-grid homes ; negotiation protocol ; strategy profile ; pareto-optimal outcomes ; electricity storage	<task> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method>	3 0 2 ; 1 1 6	we present a novel <method_3> to facilitate energy exchange between <otherscientificterm_2> that are equipped with <task_1> and <method_6> . our <method_3> imposes restrictions over negotiation such that <method_3> reduces the complex <task_0> to one where agents have a <otherscientificterm_4> in subgame perfect nash equilibrium . we show that our <method_3> is concurrent , scalable and ; under certain conditions ; leads to <otherscientificterm_5> .	3 2 1 6 8 9 7 -1 0 4 7 -1 5 7 -1
Continuous Relaxations for Discrete Hamiltonian Monte Carlo .	estimating normalization constants -lrb- partition functions ; continuous relaxation inference algorithms ; gradient-based hamiltonian monte carlo ; discrete variable undirected models ; gaussian integral trick ; approximate probabilistic inference ; continuous representation ; discrete optimization ; continuous systems ; illustrative problems ; continuous relaxations ; inference	<task> <method> <method> <method> <method> <task> <method> <task> <method> <task> <otherscientificterm> <task>	9 0 1 ; 4 0 3 ; 2 0 11 ; 6 0 11 ; 10 0 7	continuous relaxations play an important role in <task_7> , but have not seen much use in <task_5> . here we show that a general form of the <method_4> makes it possible to transform a wide class of <method_3> into fully <method_8> . the <method_6> allows the use of <method_2> for <task_11> , results in new ways of <task_0> -rrb- , and in general opens up a number of new avenues for <task_11> in difficult discrete systems . we demonstrate some of these <method_1> on a number of <task_9> .	7 5 17 12 -1 4 3 8 14 12 -1 6 2 11 0 15 16 12 -1 1 9 10 13 12 -1
Detection of OOV words using generalized word models and a semantic class language model .	recall and precision rates ; generalized word models ; context-independent crossword models ; spontaneous speech ; language model ; semantic categories ; theoretic optimum ; out-of-vocabulary words ; oov word ; recognition accuracy ; oov-detection ; crossword	<metric> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <task> <method>	5 0 4 ; 9 5 1 ; 1 0 4 ; 4 0 3	this paper describes an approach to detect <otherscientificterm_7> in <material_3> using a <method_4> built on <otherscientificterm_5> and a new type of <method_1> consisting of a mixture of specific and general acoustic units . we demonstrate the construction of the <method_1> as replacements for surnames in a german spontaneous travel planning task gsst -lsb- 1 -rsb- . we show that the use of our <method_1> improves <metric_9> in cases where <otherscientificterm_7> appear and does not lead to a degradation of the overall <metric_9> . in our experiments we measured <metric_0> of <task_10> which are close to their <otherscientificterm_6> . furthermore , we compared the effect of using <method_11> - triphones vs. using <method_2> . we show that when using <method_1> with <method_11> - triphones , the expected number of consequential errors following an <otherscientificterm_8> can be reduced significantly by 37 % .	7 3 4 5 1 13 15 16 12 -1 12 -1 9 14 12 -1 0 10 6 12 -1 12 -1 11 2 12 -1
A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data -LRB- and Nothing Else -RRB- .	bilingual lexicon extraction ; induced bilingual vector spaces ; language pair agnostic approach ; bilingual vector spaces ; bootstrapping fashion ; confidence estimation ; non-parallel data ; seed lexicon	<task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric> <material> <otherscientificterm>	2 0 0 ; 6 0 2	we present a new <method_2> to inducing <otherscientificterm_3> from <material_6> without any other resource in a <otherscientificterm_4> . the paper systematically introduces and describes all key elements of the <method_2> : -lrb- 1 -rrb- starting point or <otherscientificterm_7> , -lrb- 2 -rrb- the <metric_5> and selection of new dimensions of the space , and -lrb- 3 -rrb- convergence . we test the quality of the <otherscientificterm_1> , and analyze the influence of the different components of the <method_2> in the task of <task_0> for two language pairs . results reveal that , contrary to conclusions from prior work , the seeding of the <method_2> has a heavy impact on the quality of the learned lexicons . we also show that our <method_2> outperforms the best performing fully corpus-based ble methods on these test sets .	2 3 6 4 10 8 -1 7 5 8 -1 1 0 9 8 -1 8 -1 8 -1
Halftone visual cryptography by iterative halftoning .	halftone visual cryptography ; iterative halftoning method ; visual sharing scheme ; constrained iterative halftoning ; reconstructed secret images ; binary valued shares ; halftone shares ; natural images ; construction method ; image quality ; secret image	<method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <method> <metric> <material>	1 0 8 ; 8 0 6 ; 1 0 0 ; 0 6 2 ; 8 0 0 ; 10 3 5	halftone visual cryptography -lrb- <method_0> -rrb- is a <method_2> where a <material_10> is encoded into <otherscientificterm_6> taking meaningful visual information . in this paper , novel <method_8> of <method_0> based on an <method_1> is proposed . the <material_10> is concurrently embedded into <otherscientificterm_5> while these shares are halftoned by <otherscientificterm_3> . the proposed <method_8> is able to generate <otherscientificterm_6> showing <material_7> with high <metric_9> . <material_4> , obtained by stacking qualified shares together , does not suffer from cross interference of share images . simulations are provided to show the effectiveness of our proposed <method_8> .	0 2 10 6 15 11 -1 8 1 12 14 16 11 -1 5 3 17 11 -1 7 9 4 13 11 -1 11 -1 11 -1
Bi-orthogonal filter banks with directional vanishing moments -LSB- image representation applications -RSB- .	directional vanishing moments ; 2-d nonseparable filter banks ; snr and visual quality ; contourlet transform ; nonlinear approximation ; mapping technique ; design problem ; design procedure ; filters	<otherscientificterm> <method> <metric> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm>	5 0 7	in this paper we study <method_1> that annihilate information along a certain discrete direction . this is done by having <otherscientificterm_8> with <otherscientificterm_0> . we study the approximation property of such <otherscientificterm_8> and the <task_6> providing conditions for its solvability . in particular we completely characterize the solution and propose a <method_7> utilizing the <method_5> . <method_4> experiments with the <otherscientificterm_3> indicate that compared with the traditional <otherscientificterm_8> , the new <otherscientificterm_8> designed with <otherscientificterm_0> provide gains in <metric_2> due to their short size .	1 9 -1 8 0 9 -1 6 9 -1 7 5 4 10 9 -1 3 2 9 -1
Extended Discriminative Random Walk : A Hypergraph Approach to Multi-View Multi-Relational Transductive Learning .	dis-criminative random walk framework ; multi-view , multi-relational data ; random walk operator ; in-network classification setting ; real-life data sources ; non-network data ; reaction networks ; single graphs ; random walks ; biological data ; gene networks ; rela-tional information ; collaboration networks ; multi-way relations ; class imbalance ; drw framework ; class-imbalanced data ; multi-view data ; transductive inference ; multi-way interactions ; inference ; graph ; hypergraphs ; edges	<method> <material> <otherscientificterm> <task> <material> <material> <method> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <material> <material> <task> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 6 4 ; 9 1 10 ; 12 1 6 ; 6 6 19 ; 12 6 19 ; 18 0 7 ; 15 0 20 ; 9 6 4 ; 0 0 18	transductive <task_20> on graphs has been garner-ing increasing attention due to the connected nature of many <material_4> , such as online social media and <material_9> -lrb- protein-protein interaction network , <method_10> , etc. -rrb- . typically <otherscientificterm_11> in the data is encoded as <otherscientificterm_23> in a <otherscientificterm_21> but often it is important to model <otherscientificterm_19> , such as in <method_12> and <method_6> . in this work we model <otherscientificterm_13> as <otherscientificterm_22> and extend the <method_0> , originally proposed for <task_18> on <otherscientificterm_7> , to the case of multiple <otherscientificterm_22> . we use the extended <method_15> for <task_20> on <material_1> in a natural way , by representing attribute descriptions of the data also as <otherscientificterm_22> . we further exploit the structure of <otherscientificterm_22> to modify the <otherscientificterm_2> to take into account <otherscientificterm_14> in the data . this work is among very few approaches to explicitly address <otherscientificterm_14> in the <task_3> , using <otherscientificterm_8> . we compare our approach to methods proposed for <task_20> on <otherscientificterm_22> , and to methods proposed for <material_17> and show that empirically we achieve better performance . we also compare to methods specifically tailored for <material_16> and show that our approach achieves comparable performance even on <material_5> .	20 4 9 10 25 26 32 24 -1 11 23 21 19 12 6 27 28 29 24 -1 13 22 0 18 7 30 33 24 -1 15 1 31 24 -1 24 -1 2 14 24 -1 3 8 24 -1 17 24 -1
Harnessing Cognitive Features for Sarcasm Detection .	eye-movement patterns of human readers ; sarcastic and non sarcastic sentences ; linguistic and stylistic features ; readers eye movement data ; cogni-tive features ; nlp applications ; f-score -rrb- ; cognitive features ; review summarization ; sarcasm detection ; feature vector ; statistical classification ; dialog systems ; sentiment analysis ; sarcasm	<otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <task> <metric> <otherscientificterm> <task> <task> <method> <task> <task> <task> <otherscientificterm>	13 6 5 ; 8 1 12 ; 12 6 5 ; 0 0 4 ; 2 0 9 ; 3 0 7 ; 12 1 13 ; 8 6 5 ; 10 0 9	in this paper , we propose a novel mechanism for enriching the <method_10> , for the task of <task_9> , with <otherscientificterm_4> extracted from <otherscientificterm_0> . <task_9> has been a challenging research problem , and its importance for <task_5> such as <task_8> , <task_12> and <task_13> is well recognized . <otherscientificterm_14> can often be traced to incongruity that becomes apparent as the full sentence unfolds . this presence of incongruity-implicit or explicit-affects the way readers eyes move through the text . we observe the difference in the behaviour of the eye , while reading <material_1> . motivated by this observation , we augment traditional <otherscientificterm_2> for <task_9> with the <otherscientificterm_7> obtained from <material_3> . we perform <task_11> using the enhanced feature set so obtained . the <otherscientificterm_2> improve <task_9> by 3.7 % -lrb- in terms of <metric_6> , over the performance of the best reported system .	10 9 4 0 19 24 15 -1 5 8 12 13 14 16 17 18 22 23 15 -1 15 -1 15 -1 1 15 -1 21 15 -1 2 7 3 15 -1 11 20 15 -1
A light transport model for mitigating multipath interference in Time-of-flight sensors .	continuous-wave time-of-flight range imaging ; direct and global light transport ; multipath interference ; scene dependent errors ; depth accuracy ; kinect sensor ; optical reflections ; computer vision ; tof camera ; spatial location ; imaging sensor ; tof cameras ; depth images ; graphics	<method> <material> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <material>	3 2 11 ; 1 0 2 ; 11 0 12 ; 1 1 8	continuous-wave time-of-flight -lrb- tof -rrb- range imaging has become a commercially viable technology with many applications in <task_7> and <material_13> . however , the <otherscientificterm_12> obtained from <material_11> contain <otherscientificterm_3> due to <otherscientificterm_2> . specifically , <otherscientificterm_2> occurs when multiple <otherscientificterm_6> return to a single <otherscientificterm_9> on the <otherscientificterm_10> . many prior approaches to rectifying <otherscientificterm_2> rely on sparsity in <otherscientificterm_6> , which is an extreme simplification . in this paper , we correct <otherscientificterm_2> by combining the standard measurements from a <method_8> with information from <material_1> . we report results on both simulated experiments and physical experiments -lrb- using the <otherscientificterm_5> -rrb- . our results , evaluated against ground truth , demonstrate a quantitative improvement in <metric_4> .	7 13 14 -1 12 11 3 2 15 17 14 -1 6 9 10 14 -1 14 -1 8 1 16 18 14 -1 14 -1 5 14 -1
A Spectral Algorithm for Latent Tree Graphical Models .	expectation maximization ; synthetic and real datasets ; local-minimum-free spectral algorithm ; latent variable models ; parameter learning algorithms ; latent variable models ; local search heuris-tics ; arbitrary tree topologies ; probabilistic modeling ; joint distribution ; speech analysis ; observed variables ; em ; bioinformatics ; tree	<method> <material> <method> <method> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <method> <material> <otherscientificterm>	6 0 4 ; 4 0 5 ; 2 4 12 ; 10 1 13 ; 1 5 2 ; 7 0 2 ; 0 6 6 ; 3 0 8 ; 2 0 5	latent variable models are powerful tools for <task_8> , and have been successfully applied to various domains , such as <task_10> and <material_13> . however , <method_4> for <method_5> have predominantly relied on <method_6> such as <method_0> . we propose a fast , <method_2> for learning <method_5> with <otherscientificterm_7> , and show that the <otherscientificterm_9> of the <otherscientificterm_11> can be reconstructed from the marginals of triples of <otherscientificterm_11> irrespective of the maximum degree of the <otherscientificterm_14> . we demonstrate the performance of our <method_2> on <material_1> ; for large training sizes , our <method_2> performs comparable to or better than <method_12> while being orders of magnitude faster .	8 10 13 19 23 15 -1 4 5 6 0 16 17 22 15 -1 2 7 9 11 14 21 24 15 -1 1 18 20 15 -1
Robust transmission of compressed images over noisy Gaussian channels .	list-based iterative trellis decoder ; uncompressed raw image data ; image communication systems ; compressed image formats ; viterbi decoder ; channel errors ; reconstructed image ; power ; post-processor	<method> <material> <method> <method> <method> <otherscientificterm> <material> <otherscientificterm> <method>	8 0 0 ; 0 4 4	many <method_2> have constraints on bandwidth , <otherscientificterm_7> and time which prohibit transmission of <material_1> . <method_3> , however , are extremely sensitive to bit errors which can seriously degrade the quality of the image at the receiver . a new <method_0> is proposed which accepts feedback from a <method_8> which can detect <otherscientificterm_5> in the <material_6> . experimental results are shown which indicate the new <method_0> provides signiicant improvement over the standard <method_4> .	2 7 1 3 9 -1 9 -1 0 8 5 6 10 9 -1 4 11 9 -1
Quality-fair HTTP adaptive streaming over LTE network .	quality-fair adaptive streaming solution ; http adaptive streaming applications ; video content complexity ; fair video quality ; heterogeneous has users ; ssim quality metric ; video content characteristics ; end-user video quality ; channel condition ; quality fairness ; lte cell ; radio resource ; wireless channel ; video qualities ; channel conditions	<method> <task> <metric> <metric> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <material> <material> <otherscientificterm> <otherscientificterm>	0 0 3 ; 5 5 0 ; 6 1 8 ; 9 5 0	in <task_1> multiple video clients sharing the same <material_12> may experience different <otherscientificterm_13> as result of both different <metric_2> and different <otherscientificterm_14> . this causes unfairness in the <metric_7> . in this paper , we propose a <method_0> to deliver <metric_3> to has clients competing for the same resources in an <otherscientificterm_10> . in the <method_0> the share of <material_11> is optimized according to <otherscientificterm_6> and <otherscientificterm_8> . the proposed <method_0> is compared with other state-of-the-art strategies and numerical results in terms of <metric_5> shows that <method_0> significantly improves the <metric_9> among <otherscientificterm_4> .	1 12 13 2 14 15 -1 7 15 -1 0 3 10 16 15 -1 11 6 8 18 15 -1 5 9 4 17 19 15 -1
MKPM : A multiclass extension to the kernel projection machine .	multiclass kernel projection machines ; kernel projection machine framework ; pattern recognition problems ; dynamic programming approach ; multiclass case ; output codes ; global classifier ; optimization problem ; numerical simulations ; co-regularization scheme ; projection dimensions	<method> <method> <task> <method> <task> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm>	0 0 7 ; 5 0 0	we introduce <method_0> , a new formalism that extends the <method_1> to the <task_4> . our <method_0> is based on the use of <otherscientificterm_5> and <method_0> implements a <method_9> by simultaneously constraining the <otherscientificterm_10> associated with the individual predictors that constitute the <method_6> . in order to solve the <task_7> posed by our <method_0> , we propose an efficient <method_3> . <method_8> conducted on a few <task_2> illustrate the soundness of our <method_0> .	0 1 4 11 -1 5 9 10 6 13 11 -1 7 3 8 12 11 -1 2 11 -1
Defeasible Inclusions in Low-Complexity DLs : Preliminary Notes .	circumscribed dl-lite r complexity ; cir-cumscribed low-complexity dls ; nexp np ; polynomial hierarchy ; abnormality predicates ; existential restrictions ; el family ; dl-lite ; exptime-hard	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm>	6 6 1 ; 7 6 1 ; 7 1 6 ; 2 0 0	we analyze the complexity of reasoning with <method_1> such as <method_7> and the <method_6> , under suitable restrictions on the use of <otherscientificterm_4> . we prove that in <otherscientificterm_0> drops from <otherscientificterm_2> to the second level of the <otherscientificterm_3> . in el , reasoning remains <otherscientificterm_8> , in general . however , by restricting the possible occurrences of <otherscientificterm_5> , we obtain membership in œÉ p 2 and œÄ p 2 for an extension of el .	1 7 6 4 10 11 12 9 -1 0 2 3 13 9 -1 8 9 -1 5 9 -1
Ordinal regression for interaction quality prediction .	spearman 's rank correlation coefficient ; euclidean and manhattan errors ; cohen 's agreement rate ; ordinal regression predictor ; spoken dialogue system ; ordinal regression problem ; corpus of dialogues ; evaluation metrics ; ordinal regression ; regression models ; classifiers	<metric> <otherscientificterm> <metric> <method> <method> <task> <material> <metric> <task> <method> <method>	0 1 1 ; 7 5 3 ; 0 6 7 ; 10 1 9 ; 1 6 7	the automatic prediction of the quality of a dialogue is useful to keep track of a <method_4> 's performance and , if necessary , adapt its behaviour . <method_10> and <method_9> have been suggested to make this prediction . the parameters of these models are learnt from a <material_6> evaluated by users or experts . in this paper , we propose to model this task as an <task_5> . we apply support vector machines for <task_8> on a <material_6> where each system-user exchange was given a rate on a scale of 1 to 5 by experts . compared to previous models proposed in the literature , the <method_3> has significantly better results according to the following <metric_7> : <metric_2> with experts ratings , <metric_0> , and <otherscientificterm_1> .	4 10 11 -1 9 15 11 -1 6 11 -1 5 11 -1 8 11 -1 12 13 14 16 11 -1
Named Entity Translation with Web Mining and Transliteration .	bilingual con-textual co-occurrence ; named entity translation ; maximum entropy model ; pronunciation similarity ; translit-eration approach ; translation candidates ; transliteration information ; web mining ; web information ; precision ; transliteration ; recall	<otherscientificterm> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <task> <metric>	8 0 4 ; 9 5 1 ; 6 0 7 ; 9 1 11 ; 3 0 2 ; 0 0 2 ; 11 5 1 ; 3 1 0 ; 2 0 5	this paper presents a novel approach to improve the <task_1> by combining a <method_4> with <method_7> , using <otherscientificterm_8> as a source to complement <task_10> , and using <otherscientificterm_6> to guide and enhance <method_7> . a <method_2> is employed to rank <otherscientificterm_5> by combining <otherscientificterm_3> and <otherscientificterm_0> . experimental results show that our approach effectively improves the <metric_9> and <metric_11> of the <task_1> by a large margin .	1 4 7 8 10 6 13 15 12 -1 2 5 3 0 17 18 20 21 12 -1 9 11 14 16 19 12 -1
A Pointwise Approach to Pronunciation Estimation for a TTS Front-End .	japanese pronunciation estimation ; pointwise prediction ; pronunciation estimator ; annotated words ; word boundaries ; joint n-gram ; japanese/chinese	<task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <material>	2 0 4	overview ‚óè objective : create a <method_2> that is robust and adaptable to new domains ‚óè focus on <material_6> , where we must estimate <otherscientificterm_4> as well ‚óè approach : <method_1> , which tags all <otherscientificterm_4> and pronunciations independently ‚óè <method_1> : ‚óè robust : relies on dictionaries less than previous methods ‚óè adaptable : it can be learned from single <otherscientificterm_3> , not full sentences ‚óè evaluation on <task_0> shows improvement over traditional joint n-gram	2 6 4 1 3 0 5 8 7 -1
Social Planning : Achieving Goals by Altering Others ' Mental States .	cognitive task of social planning ; flexible problem solver ; social plans ; social scenarios ; social planning ; computational approach ; sfps	<task> <method> <otherscientificterm> <task> <task> <method> <method>	6 6 1 ; 5 0 4 ; 1 0 2	in this paper , we discuss a <method_5> to the <task_0> . first , we specify a class of planning problems that involve an agent who attempts to achieve its goals by altering other agents ' mental states . next , we describe <method_6> , a <method_1> that generates <otherscientificterm_2> of this sort , including ones that include deception and reasoning about other agents ' beliefs . we report the results for experiments on <task_3> that involve different levels of sophistication and that demonstrate both <method_6> 's capabilities and the sources of its power . finally , we discuss how our <method_5> to <task_4> has been informed by earlier work in the area and propose directions for additional research on the topic .	5 0 7 -1 7 -1 6 1 2 8 10 7 -1 3 7 -1 9 7 -1
Low Rank Approximation using Error Correcting Coding Matrices .	low rank approximations of large matrices ; principal component analysis ; low rank approximations ; error correcting codes ; low-rank matrix approximation ; gaussian random matrices ; structured random matrices ; subspace of vectors ; low coherence ; web search ; computer vision ; text mining ; face recognition ; randomized algorithms ; hadamard matrices ; log factor ; approximation errors ; singular values ; rank-k approximation ; matrices	<otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <task> <task> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	11 1 10 ; 5 1 6 ; 11 1 12 ; 13 0 0 ; 12 1 10 ; 9 1 11	low-rank matrix approximation is an integral component of tools such as <method_1> , as well as is an important instrument used in applications like <task_9> , <task_11> and <task_10> , e.g. , <task_12> . recently , <method_13> were proposed to effectively construct <otherscientificterm_0> . in this paper , we show how <otherscientificterm_19> from <method_3> can be used to find such <otherscientificterm_2> . the benefits of using these <method_3> are the following : -lrb- i -rrb- they are easy to generate and they reduce randomness significantly . -lrb- ii -rrb- code <otherscientificterm_19> have <otherscientificterm_8> and have a better chance of preserving the geometry of an entire <otherscientificterm_7> ; -lrb- iii -rrb- unlike fourier transforms or <otherscientificterm_14> , which require sampling o -lrb- k log k -rrb- columns for a <method_18> , the <otherscientificterm_15> is not necessary in the case of <method_3> . -lrb- iv -rrb- under certain conditions , the <otherscientificterm_16> can be better and the <otherscientificterm_17> obtained can be more accurate , than those obtained using <otherscientificterm_5> and other <material_6> .	1 9 11 10 12 21 23 25 26 20 -1 13 0 24 20 -1 19 3 2 20 -1 20 -1 8 20 -1 7 14 18 15 22 20 -1
Bayesian Estimation of Time-Frequency Coefficients for Audio Signal Enhancement .	time-frequency structure of sound signals ; markov chain monte carlo methods ; audio signal processing approaches ; posterior distribution of interest ; time-varying filtering techniques ; speech enhancement ; bayesian paradigm ; audio waveforms ; bayesian model ; noise power ; time-frequency characteristics ; prior knowledge ; speech	<otherscientificterm> <method> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	4 0 5 ; 12 6 0 ; 6 0 0	the <method_6> provides a natural and effective means of exploiting <otherscientificterm_11> concerning the <otherscientificterm_0> such as <material_12> and music -- something which has often been overlooked in traditional <method_2> . here , after constructing a <method_8> and prior distributions capable of taking into account the <otherscientificterm_10> of typical <otherscientificterm_7> , we apply <method_1> in order to sample from the resultant <otherscientificterm_3> . we present <task_5> results which compare favourably in objective terms with standard <method_4> -lrb- and in several cases yield superior performance , both objectively and subjectively -rrb- ; moreover , in contrast to such methods , our results are obtained without an assumption of <otherscientificterm_11> of the <otherscientificterm_9> .	6 11 0 12 2 15 16 13 -1 8 10 7 1 3 13 -1 5 4 14 13 -1
The temporal organisation of speech as gauged by speech synthesis .	quantitative and qualitative effects ; simulation of speech rhythm ; word grouping boundaries ; language models ; temporal component ; temporal issues ; language system ; speech styles ; statistical analysis ; speech synthesis ; speech coherence ; qualitative parameters ; speech rate	<otherscientificterm> <task> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <metric>	4 0 1	the simulation of speech by means of <task_9> involves , among other things , the ability to mimic typical delivery for different <otherscientificterm_7> . this requires a realistic imitation of the manner in which speakers organize their information flow in time -lrb- i.e. , <otherscientificterm_2> -rrb- , as well their <metric_12> with its variations . the originality of our model is grounded in two levels . first , it is assumed that the <method_4> plays a dominant role in the <task_1> , whereas in traditional <method_3> , <otherscientificterm_5> are mostly put aside . second , the outcome of our temporal modeling , based on <method_8> and <otherscientificterm_11> , results from the harmonization of various layers -lrb- segmental , syllabic , phrasal -rrb- . the benefit of a multidimensional model is the possibility of imposing subtle <otherscientificterm_0> at various levels , which is a key for respecting a specific <method_6> as well as <otherscientificterm_10> and fluency for different <otherscientificterm_7> .	9 7 13 -1 2 12 13 -1 13 -1 4 1 3 5 14 13 -1 13 -1 8 11 13 -1
Selection of optimal dimensionality reduction method using chernoff bound for segmental unit input HMM .	power linear discriminant analysis ; heteroscedastic discriminant analysis ; linear discriminant analysis ; segmental unit input hmm ; performance comparison method ; dimensionality reduction method ; relative recognition ; chernoff bound ; speech recognition ; features ; hmms	<method> <method> <method> <method> <method> <method> <task> <otherscientificterm> <task> <otherscientificterm> <method>	5 1 3 ; 2 1 1 ; 6 5 5 ; 5 0 8 ; 0 6 5 ; 3 0 8 ; 5 0 5	to precisely model the time dependency of <otherscientificterm_9> , <method_3> with a <method_5> has been widely used for <task_8> . <method_2> and <method_1> are popular approaches to reduce the dimen-sionality . we have proposed another <method_5> called <method_0> to select the best <method_5> that yields the highest <task_6> performance . this <method_5> on the basis of trial and error requires much time to train <method_10> and to test the <task_6> performance for each <method_5> . in this paper we propose a <method_4> without training or testing . we show that the proposed <method_4> using the <otherscientificterm_7> can rapidly and accurately evaluate the <task_6> performance .	9 3 5 8 2 12 15 17 11 -1 1 13 11 -1 0 6 16 18 11 -1 10 14 11 -1 4 11 -1 7 11 -1
A noise-robust ASR back-end technique based on weighted viterbi recognition .	weighted viterbi recognition algorithm ; acoustic front-end features ; viterbi decoding stage ; speech recognition systems ; weighted viterbi recognition ; acoustic models ; adaptation data ; noisy conditions ; environment adaptation ; confidence/robustness factor ; clean data ; speech frame ; front-end features ; snr estimate ; lpcc ; snr ; plp ; mfcc	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <material> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <material> <method>	2 2 13 ; 16 6 12 ; 17 6 12 ; 17 1 14 ; 16 0 8 ; 12 2 4 ; 0 0 15 ; 10 0 5 ; 17 6 4 ; 14 1 16 ; 14 6 12 ; 16 6 4 ; 14 6 4 ; 16 0 0 ; 0 4 8 ; 7 2 3	the performance of <method_3> trained in quiet degrades significantly under <otherscientificterm_7> . to address this problem , a <method_0> that is a function of the <otherscientificterm_15> of each <otherscientificterm_11> is proposed . <method_5> trained on <material_10> , and the <otherscientificterm_1> are kept unchanged in this <method_0> . instead , a <otherscientificterm_9> is assigned to the output observation probability of each <otherscientificterm_11> according to its <otherscientificterm_13> during the <otherscientificterm_2> . comparative experiments are conducted with <method_4> with different <otherscientificterm_12> such as <method_17> , <method_14> and <material_16> . results show consistent improvements with all three feature vectors . for a reasonable size of <material_6> , <method_0> outperforms <method_8> using <material_16> .	3 7 34 18 -1 0 15 11 5 25 18 -1 10 1 26 18 -1 9 13 2 19 18 -1 4 12 17 14 16 20 21 22 24 27 28 29 30 31 18 -1 18 -1 23 32 33 18 -1
Robust detection of nonstationary random signals belonging to p-point uncertainty classes .	p-point uncertainty classes ; reduced prior knowledge ; local cosine bases ; nonstationary random signals ; deflection criterion ; signal-adaptive operation ; robust detectors ; time-frequency implementation ; estimator-correlator approach	<otherscientificterm> <otherscientificterm> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <method>	6 0 3	we present two <method_6> for <task_3> that belong to <otherscientificterm_0> , one being based on an <method_8> , the other using the <otherscientificterm_4> . apart of stable performance , these <method_6> have the advantage of requiring only <otherscientificterm_1> . using <method_2> , we provide an intuitive and highly efficient <method_7> of these <method_6> along with an extension that permits <otherscientificterm_5> . simulation results illustrate the robustness of the proposed <method_6> .	6 3 0 8 4 10 9 -1 1 9 -1 2 7 5 9 -1 9 -1
Nonparametric estimation of the precision-recall curve .	statistical estimation of pr curves ; precision-recall curve ; theoretical and computational nature ; scoring functions ; asymptotic normality ; pr curve ; resampling procedure ; classification data ; sup norm ; confidence bands ; visual tool ; pr space ; bootstrap	<task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	4 2 5 ; 7 0 0	the <method_1> is a widely used <method_10> to evaluate the performance of <otherscientificterm_3> in regards to their capacities to discriminate between two populations . the purpose of this paper is to examine both theoretical and practical issues related to the <task_0> based on <material_7> . consistency and <otherscientificterm_4> of the empirical counterpart of the <otherscientificterm_5> in <otherscientificterm_8> are rigorously established . eventually , the issue of building <otherscientificterm_9> in the <otherscientificterm_11> is considered and a specific <method_6> based on a smoothed and truncated version of the empirical distribution of the data is promoted . arguments of <otherscientificterm_2> are presented to explain why such a <otherscientificterm_12> is preferable to a `` naive '' <otherscientificterm_12> in this setup .	1 10 3 13 -1 0 7 15 13 -1 4 5 8 14 13 -1 9 11 6 13 -1 2 13 -1
How NOT To Evaluate Your Dialogue System : An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation .	technical and non-technical domains ; end-to-end dialogue systems ; automatic evaluation metrics ; text sum-marization ; supervised labels ; evaluation metrics ; task completion ; machine translation ; response quality	<material> <task> <metric> <task> <material> <metric> <metric> <task> <metric>	7 0 1 ; 7 1 3 ; 3 0 1 ; 5 0 1 ; 2 0 1	we investigate <metric_5> for <task_1> where <material_4> , such as <metric_6> , are not available . recent works in <task_1> have adopted metrics from <task_7> and <task_3> to compare a model 's generated response to a single target response . we show that these metrics correlate very weakly or not at all with human judgements of the <metric_8> in both <material_0> . we provide quantitative and qualitative results highlighting specific weaknesses in existing metrics , and provide recommendations for future development of better <metric_2> for <task_1> .	5 1 4 6 13 9 -1 7 3 10 11 12 9 -1 8 0 9 -1 2 14 9 -1
Maximal Recursive Rule : A New Social Decision Scheme .	rsd -lrb- random serial dictatorship -rrb- rules ; maximal recursive rule ; randomized social choice functions ; ex post efficiency ; social choice settings ; random dictatorship rules ; random dictatorship ; stochastic dominance ; strict preferences ; strategyproofness ; indifferences ; rsd	<otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	9 1 3	in <otherscientificterm_4> with <otherscientificterm_8> , <otherscientificterm_5> were characterized by gibbard -lsb- 1977 -rsb- as the only <method_2> that satisfy <otherscientificterm_9> and <metric_3> . in the more general domain with <otherscientificterm_10> , <otherscientificterm_0> are the well-known and perhaps only known generalization of <otherscientificterm_6> . we present a new generalization of <otherscientificterm_6> for <otherscientificterm_10> called <otherscientificterm_1> as an alternative to <method_11> . we show that <otherscientificterm_1> is polynomial-time computable , weakly strategyproof with respect to <otherscientificterm_7> , and , in some respects , outperforms <method_11> on efficiency .	4 8 5 2 9 3 13 12 -1 10 0 6 12 -1 1 11 12 -1 7 12 -1
Semi-Supervised Learning with Explicit Misclassification Modeling .	classification expectation maximization algorithm ; classification maximum likelihood ; probabilistic misclassification model ; labeled data ; semi-supervised algorithm ; labeled-unlabeled data ; labeling process ; discriminant classifiers ; un-labeled data ; unlabeled data ; classifier parameters ; originality ; imperfections	<method> <metric> <method> <material> <method> <material> <task> <method> <material> <material> <otherscientificterm> <metric> <otherscientificterm>	8 1 2	this paper investigates a new approach for training <method_7> when only a small set of <material_3> is available together with a large set of <material_9> . this algorithm optimizes the <metric_1> of a set of <material_5> , using a variant form of the <method_0> . its <metric_11> is that it makes use of both <material_8> and of a <method_2> for these data . the parameters of the label-error model are learned together with the <otherscientificterm_10> . we demonstrate the effectiveness of the approach on four data-sets and show the advantages of this method over a previously developed <method_4> which does not consider <otherscientificterm_12> in the <task_6> .	7 3 9 13 -1 1 5 0 13 -1 11 8 2 14 13 -1 10 13 -1 4 13 -1
Prof-Life-Log : Personal interaction analysis for naturalistic audio streams .	speech activity detection ; contemporary speech and language processing techniques ; contemporary speech technology ; life logging applications ; naturalistic audio streams ; personal audio recordings ; environmental sniffing techniques ; prof-life-log corpus ; analysis system ; speaker diarization	<method> <method> <method> <task> <material> <material> <method> <material> <method> <task>	7 0 4 ; 9 1 6 ; 9 0 8 ; 1 0 5 ; 0 1 9 ; 5 0 8 ; 6 0 8 ; 2 0 3 ; 0 0 8	analysis of <material_5> is a challenging and interesting subject . using <method_1> , it is possible to mine <material_5> for a wealth of information that can be used to measure a person 's engagement with their environment as well as other people . in this study , we propose an <method_8> that uses <material_5> to automatically estimate the number of unique people and environments which encompass the total engagement within the recording . the proposed <method_8> uses <method_0> , <task_9> and <method_6> , and is evaluated on <material_4> from the <material_7> . we also report performance of the individual systems , and also present a combined analysis which reveals the interaction of the subject with both people and environment . hence , this study establishes the efficacy and novelty of using <method_2> for <task_3> .	5 10 -1 1 14 10 -1 8 16 10 -1 0 9 6 4 7 11 12 13 15 17 19 10 -1 10 -1 18 10 -1
Enhancing model-based skin color detection : From low-level RGB features to high-level discriminative binary-class features .	model-based skin color detection ; high-level binary-class features ; low-level rgb feature ; bayesian model adaptation ; non-skin rgb models ; log likelihood ratio ; baseline f1 scores ; discriminative feature ; feature fusion ; lighting conditions ; background-foreground correlation	<task> <otherscientificterm> <otherscientificterm> <method> <method> <metric> <metric> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	6 5 1 ; 1 0 0 ; 3 1 8 ; 10 4 2	we propose two very effective <otherscientificterm_1> to enhance <task_0> . first we find that the <metric_5> of the testing data between skin and <method_4> can be a good <otherscientificterm_7> . we also find that namely the <otherscientificterm_10> provides another complementary feature compared to the conventional <otherscientificterm_2> . further improvement can be accomplished by <method_3> and <method_8> . by jointly considering both schemes of <method_3> and <method_8> , we attain the best system performance . experimental results show that the proposed <otherscientificterm_1> improves the 68 % to 84 % <metric_6> to as high as almost 90 % in a wide range of <otherscientificterm_9> .	1 0 13 11 -1 5 4 7 11 -1 10 2 15 11 -1 3 8 11 -1 14 11 -1 6 12 11 -1
3D Variational Brain Tumor Segmentation using a High Dimensional Feature Set .	variational brain tumor seg-mentation algorithm ; tumor and normal tissue ; appearance of tumor tissue ; appearance of normal brain ; high dimensional feature set ; cancer patient mri scans ; manually segmented data ; texture segmentation ; tumor segmentation ; registered atlases ; generative models ; mri data ; prior information ; statistical model ; conditional model ; validation	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <task> <task> <material> <method> <material> <otherscientificterm> <method> <method> <task>	11 0 7 ; 13 0 1 ; 11 0 8 ; 14 4 10 ; 5 5 15 ; 7 0 0 ; 6 0 13 ; 5 5 0 ; 4 0 0 ; 4 0 7 ; 11 0 4 ; 9 0 4 ; 11 1 9	tumor segmentation from <material_11> is an important but time consuming task performed manually by medical experts . automating this process is challenging due to the high diversity in <otherscientificterm_2> , among different patients and , in many cases , similarity between <otherscientificterm_1> . one other challenge is how to make use of <otherscientificterm_12> about the <otherscientificterm_3> . in this paper we propose a <method_0> that extends current approaches from <task_7> by using a <otherscientificterm_4> calculated from <material_11> and <material_9> . using <material_6> we learn a <method_13> for <otherscientificterm_1> . we show that using a <method_14> to discriminate between normal and abnormal regions significantly improves the segmentation results compared to traditional <method_10> . <task_15> is performed by testing the <method_0> on several <material_5> .	11 19 16 -1 2 1 16 -1 12 3 16 -1 0 7 4 9 17 22 25 26 27 28 29 16 -1 6 13 18 23 16 -1 14 20 16 -1 10 15 21 24 16 -1
Transfer Learning Using Task-Level Features with Application to Information Retrieval .	probabilistic transfer learning model ; empirical bayes method ; transfer learning methods ; task mixture selection ; variational approximation techniques ; hierarchical bayesian model ; task-level features ; information retrieval ; model parameters	<method> <method> <method> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm>	4 0 1 ; 7 5 0 ; 0 0 3 ; 6 0 0 ; 0 4 2	we propose a <method_0> that uses <otherscientificterm_6> to control the <method_3> in a <method_5> . these <otherscientificterm_6> , although rarely used in existing approaches , can provide additional information to <method_0> complex task distributions and allow effective transfer to new tasks especially when only limited number of data are available . to estimate the <otherscientificterm_8> , we develop an <method_1> based on <method_4> . our experiments on <task_7> show that the proposed <method_0> achieves significantly better performance compared with other <method_2> .	0 6 3 5 12 13 9 -1 9 -1 8 1 4 10 9 -1 7 2 11 14 9 -1
Past and Future of DL-Lite .	minimal temporal description logics ; temporal conceptual data models ; temporal and atemporal constraints ; temporal knowledge bases ; satisfiability problem ; computational complexity	<otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <metric>	4 0 3 ; 0 0 1	we design <otherscientificterm_0> that are capable of expressing various aspects of <method_1> and investigate their <metric_5> . we show that , depending on the required types of <otherscientificterm_2> , the <task_4> for <otherscientificterm_3> in the resulting logics can be nlogspace - , np-and pspace-complete , as well as undecidable .	0 1 5 8 6 -1 2 4 3 7 6 -1
Modeling Social Causality and Responsibility Judgment in Multi-Agent Interactions : Extended Abstract .	social causality and responsibility judgment ; domain-independent computational model ; psychological attribution theory ; causal knowledge	<task> <method> <method> <otherscientificterm>	1 0 0	based on <method_2> , this paper presents a <method_1> to automate <task_0> according to an agent 's <otherscientificterm_3> and observations of interaction . the proposed <method_1> is also empirically validated via experimental study .	2 1 0 3 5 4 -1 4 -1
Multiagent Reinforcement Learning : Theoretical Framework and an Algorithm .	general-sum stochas-tic games ; multiagent q-learning method ; multiagent reinforcement learning ; zero-sum stochas-tic games ; nash equilibrium ; nash equilibria ; speciied conditions ; learning techniques	<method> <method> <task> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	0 0 2 ; 1 0 4 ; 6 2 4	in this paper , we adopt <method_0> as a framework for <task_2> . our work extends previous work by littman on <material_3> to a broader framework . we design a <method_1> under this framework , and prove that <method_1> converges to a <otherscientificterm_4> under <otherscientificterm_6> . this <method_1> is useful for nding the optimal strategy when there exists a unique <otherscientificterm_4> in the game . when there exist multiple <otherscientificterm_5> in the game , this <method_1> should be combined with other <method_7> to nd optimal strategies .	0 2 9 8 -1 3 8 -1 1 4 6 10 11 8 -1 8 -1 5 7 8 -1
Colorization by Patch-Based Local Low-Rank Matrix Completion .	local matrix completion problem ; matrix completion ; natural images ; low-rank assumption ; low-rank structure ; patch-based approach ; benchmark images ; admm subproblem ; color pixels ; divide-and-conquer	<task> <method> <material> <otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <otherscientificterm> <method>	6 5 5 ; 9 0 7	colorization aims at recovering the original color of a monochrome image from only a few <otherscientificterm_8> . a state-of-the-art approach is based on <method_1> , which assumes that the target color image is low-rank . however , this <otherscientificterm_3> is often invalid on <material_2> . in this paper , we propose a <method_5> that divides the image into patches and then imposes a <otherscientificterm_4> only on groups of similar patches . each <task_0> is solved by an accelerated version of alternating direction <method_5> of multipliers -lrb- admm -rrb- , and each <otherscientificterm_7> is solved efficiently by <method_9> . experiments on a number of <material_6> demonstrate that the proposed <method_5> outperforms existing approaches .	8 10 -1 1 10 -1 3 2 10 -1 5 4 10 -1 0 7 9 12 10 -1 11 10 -1
RL-TOPS : An Architecture for Modularity and Re-Use in Reinforcement Learning .	reinforcement learning techniques ; robot learning ; simulated environment ; teleo-reactive planning ; hybrid system ; rl-tops architecture	<method> <task> <task> <method> <method> <method>	5 0 1 ; 3 1 0 ; 0 3 4 ; 3 3 4	this paper introduces the <method_5> for <task_1> , a <method_4> combining <method_3> and <method_0> . the aim of this <method_5> is to speed up learning by decomposing complex tasks into hierarchies of simple behaviours which can be learnt more easily . behaviours learnt in this way can subsequently be re-used to solve a variety of problems , reducing the need to learn every new task from scratch . it is even possible to learn multiple behaviours simultaneously , thus making more eecient use of experience . we demonstrate these advantages in a simple <task_2> .	5 1 4 3 0 7 8 9 10 6 -1 6 -1 6 -1 6 -1 2 6 -1
Bayesian Transduction .	posterior probability of labellings ; real world data ; support vector machine ; linear discriminant functions ; kernel space ; version space ; classification loss ; volume ratio ; inference principle ; confidence measure ; equivalence classes ; hypothesis space ; ergodic billiard ; bayesian analysis ; risk-sensitive applications ; binary classification ; classifiers-a feature ; posterior measure ; transduction ; induction	<otherscientificterm> <material> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <metric> <otherscientificterm> <otherscientificterm> <method> <task> <task> <task> <otherscientificterm> <metric> <method> <task>	16 0 14 ; 4 2 15 ; 13 0 6 ; 18 6 8 ; 1 5 13	transduction is an <method_8> that takes a training sample and aims at estimating the values of a function at given points contained in the so-called working sample as opposed to the whole of input space for <task_19> . <method_18> provides a <metric_9> on single predictions rather than <otherscientificterm_16> particularly important for <task_14> . the possibly infinite number of functions is reduced to a finite number of <otherscientificterm_10> on the working sample . a rigorous <task_13> reveals that for standard <task_6> we can not benefit from considering more than one test point at a time . the probability of the label of a given test point is determined as the <metric_17> of the corresponding subset of <otherscientificterm_11> . we consider the pac setting of <task_15> by <method_3> -lrb- perceptrons -rrb- in <otherscientificterm_4> such that the probability of labels is determined by the <otherscientificterm_7> in <otherscientificterm_5> . we suggest to sample this region by an <method_12> . experimental results on <material_1> indicate that <task_13> compares favourably to the well-known <method_2> , in particular if the <otherscientificterm_0> is used as a <metric_9> to exclude test points of low confidence .	8 19 18 24 20 -1 9 16 14 21 20 -1 10 20 -1 13 6 23 20 -1 20 -1 17 11 22 20 -1 15 3 4 7 5 20 -1 12 25 20 -1
Laryngealization and features for Chinese tonal recognition .	corpora of tonal production data ; extraction of f0 features ; f0 feature extraction ; laryngeal-ization/creaky voice quality ; lowest tone ; tonal recognition ; contrastive phonation ; laryngealization ; feature ; cantonese ; mandarin	<material> <task> <task> <metric> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material>	7 0 2 ; 7 0 5 ; 2 0 5	it is well known that the <otherscientificterm_4> in <material_10> , a language without <otherscientificterm_6> , often co-occurs with <metric_3> , and we provide evidence that this is also the case for the <otherscientificterm_4> in <material_9> . however , the effects of <otherscientificterm_7> on <task_2> for <task_5> , as well as the potential of <otherscientificterm_7> as a <otherscientificterm_8> for improving <task_5> , have not been well-discussed in the literature . we give evidence from a <material_0> for <material_9> and <material_10> that <otherscientificterm_7> is prevalent and significantly disturbs the <task_1> , and suggest that <otherscientificterm_7> may in fact be a <otherscientificterm_8> that could improve <task_5> .	4 10 6 3 9 11 -1 7 2 5 8 12 14 11 -1 0 1 13 11 -1
Lattice-based System Combination for Statistical Machine Translation .	lattice-based system combination model ; chinese-to-english translation test sets ; system combination methods ; one-to-one mappings ; consensus translations ; candidate translations ; phrase alignments ; confusion networks ; lattices	<method> <material> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm>	1 5 0 ; 0 0 6 ; 2 0 4 ; 7 0 2 ; 8 0 0	current <method_2> usually use <method_7> to find <otherscientificterm_4> among different systems . requiring <method_3> between the words in <task_5> , <method_7> have difficulty in handling more general situations in which several words are connected to another several words . instead , we propose a <method_0> that allows for such <otherscientificterm_6> and uses <otherscientificterm_8> to encode all <task_5> . experiments show that our <method_0> achieves significant improvements over the state-of-the-art baseline system on <material_1> .	2 7 4 12 13 9 -1 3 5 9 -1 0 6 8 11 14 9 -1 1 10 9 -1
A Deeper Look at Saliency : Feature Contrast , Semantics , and Beyond .	visual saliency modeling ; high level considerations ; visual saliency models ; salient object segmentation ; human gaze prediction ; deep learning model ; salient objects ; model behaviour ; training data ; fcns	<task> <otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <otherscientificterm> <material> <method>	4 1 3	in this paper we consider the problem of <task_0> , including both <task_4> and <method_3> . the overarching goal of the paper is to identify <otherscientificterm_1> relevant to deriving more sophisticated <method_2> . a <method_5> based on fully convolutional networks -lrb- <method_9> -rrb- is presented , which shows very favorable performance across a wide variety of benchmarks relative to existing proposals . we also demonstrate that the manner in which <material_8> is selected , and ground truth treated is critical to resulting <otherscientificterm_7> . recent efforts have explored the relationship between human gaze and <otherscientificterm_6> , and we also examine this point further in the context of <method_9> . close examination of the proposed and alternative <method_5> serves as a vehicle for identifying problems important to developing more comprehensive <method_5> going forward .	0 4 3 11 10 -1 1 2 10 -1 5 9 10 -1 8 7 10 -1 6 10 -1 10 -1
Efficient segmentation using feature-based graph partitioning active contours .	tile/block-based or superpixel-based multiscale grouping of the pixels ; graph partitioning active contours ; graph-based image segmentation problem ; quadratic memory requirements ; continuous optimization framework ; contour optimization process ; constant memory requirement ; image partitioning ; image size ; gpac algorithm ; graph-based approaches ; complexity ; approximations ; accuracy	<otherscientificterm> <method> <task> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <metric> <method> <metric>	1 0 7 ; 1 0 2 ; 1 4 10 ; 6 0 9	graph partitioning active contours -lrb- <method_1> -rrb- is a recently introduced approach that elegantly embeds the <task_2> within a <method_4> . <method_1> can be used within parametric snake-based or implicit level set-based active contour continuous paradigms for <task_7> . however , <method_1> similar to many other <method_10> has <otherscientificterm_3> which severely limits the scalability of the algorithm to practical problem domains . an n xn image requires o -lrb- n -lrb- 4 -rrb- -rrb- computation and memory to create and store the full graph of pixel inter-relationships even before the start of the <method_5> . for example , an 1024x1024 grayscale image needs over one terabyte of memory . <method_12> using <otherscientificterm_0> reduces this <metric_11> by trading off <metric_13> . this paper describes a new algorithm that implements the exact <method_9> using a <otherscientificterm_6> of a few kilobytes , independent of <otherscientificterm_8> .	1 2 4 16 14 -1 7 15 14 -1 10 3 17 14 -1 5 14 -1 14 -1 12 14 -1 0 11 13 18 14 -1
Microsegment-based connected digit recognition .	word error rate ; acoustic phonetic models ; recognition system ; phonetic models ; orthographic supervision ; hmm engine ; hmm-based recognizer ; error analysis ; unlabeled data ; word-based models ; pronunciation	<metric> <method> <method> <method> <otherscientificterm> <method> <method> <method> <material> <method> <otherscientificterm>	4 2 8 ; 1 0 2 ; 5 0 9 ; 8 0 3 ; 0 5 2	by building <method_1> which explicitly represent as much knowledge of <otherscientificterm_10> in a small domain -lrb- the digits -rrb- as possible , we can create a <method_2> which not only performs well but allows for meaningful <method_7> and improvement . an <method_6> for the digits and a few associated words was constructed in accord with these principles . about 65 <method_3> were trained on 140 carefully labeled utterances , then iteratively trained on <material_8> under <otherscientificterm_4> . the basic <method_2> achieved less than 3 % <metric_0> on digit strings of unknown length from unseen test speakers , and 1.4 % on 7-digit strings of known length . this is competitive with <method_9> using the same <method_5> and similar parameter settings . as an <method_2> , <method_2> allows meaningful analysis of errors and relatively straightforward means of improvement .	1 10 2 7 13 11 -1 6 11 -1 3 8 4 12 15 11 -1 0 16 11 -1 14 11 -1 9 5 11 -1
Face Recognition via the Overlapping Energy Histogram .	eigen-faces , 2dpca and energy histogram ; parameter selection methods ; face recognition problem ; yale face database ; energy histogram approach ; overlapping energy histogram ; dct coefficients ; training dataset ; selecting threshold ; recognition	<method> <method> <task> <material> <method> <method> <otherscientificterm> <material> <task> <task>	5 0 6 ; 5 0 2 ; 6 0 2 ; 3 5 1	in this paper we investigate the <task_2> via the <method_5> of the <otherscientificterm_6> . particularly , we investigate some important issues relating to the <task_9> performance , such as the issue of <task_8> and the number of bins . these <method_1> utilise information obtained from the <material_7> . experimentation is conducted on the <material_3> and results indicate that the proposed <method_1> perform well in selecting the threshold and number of bins . furthermore , we show that the proposed <method_5> approach outperforms the <method_0> significantly .	2 5 6 11 12 13 10 -1 9 8 10 -1 1 7 10 -1 3 14 10 -1 0 4 10 -1
Multi-layered Decomposition of Recurrent Scenes .	optical flow field of objects ; bounding box aspect ratio ; spatio-temporal grid of histograms ; road traffic junction ; autocovariance of self-similarity ; context gait recognition ; periodic spatio-temporal patterns ; global fundamental period ; timing device ; traffic accidents ; road junctions ; spatial appearance ; anomalous events ; broken-down vehicles ; pedestrians jay-walking ; traffic junctions ; temporal aspects ; adverse behaviour ; anomalies ; feature	<otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 1 14 ; 8 0 15 ; 13 1 9 ; 14 6 12 ; 1 1 0 ; 9 6 12 ; 13 6 12	there is considerable interest in techniques capable of identifying <otherscientificterm_18> and unusual events in busy outdoor scenes , e.g. <otherscientificterm_10> . many approaches achieve this by exploiting deviations in <otherscientificterm_11> from some expected norm accumulated by a model over time . in this work we show that much can be gained from explicitly modelling <otherscientificterm_16> in detail . specifically , many <otherscientificterm_15> are regulated by lights controlled by a <method_8> of considerable precision , and it is in these situations that we advocate a model which learns <otherscientificterm_6> with a view to highlighting <otherscientificterm_12> such as <otherscientificterm_13> , <otherscientificterm_9> , or <method_14> . more specifically , by estimating <otherscientificterm_4> , used previously in the <task_5> , we characterize a scene by identifying a <otherscientificterm_7> . as our model , we introduce a <method_2> built in accordance with some chosen <otherscientificterm_19> . this model is then used to classify objects found in subsequent test data . in particular we demonstrate the effect of such characterization experimentally by monitoring the <metric_1> and <otherscientificterm_0> detected on a <otherscientificterm_3> , enabling our model to discriminate between people and cars sufficiently well to provide useful warnings of <otherscientificterm_17> in real time .	18 10 20 -1 11 20 -1 16 20 -1 15 8 6 12 13 9 21 22 23 24 26 27 20 -1 14 20 -1 4 5 7 20 -1 2 19 20 -1 25 20 -1
An Extension of the ICP Algorithm for Modeling Nonrigid Objects with Mobile Robots .	iterative closest point algorithm ; 3d models of objects ; rigid surface assumption ; nonrigid object models ; simultaneously registering scans ; modeling 3d objects ; model-ing nonrigid objects ; local scan patches ; high-dimensional optimization problems ; hierarchical method ; mathematical framework ; surface configuration ; mobile robot ; local deformations	<method> <task> <otherscientificterm> <method> <task> <task> <otherscientificterm> <method> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm>	12 0 1 ; 9 0 8 ; 9 0 7 ; 9 0 12 ; 2 0 0 ; 0 0 6	the <method_0> -lsb- 2 -rsb- is a popular method for <task_5> from range data . the classical <method_0> rests on a <otherscientificterm_2> . building on recent work on <method_3> -lsb- 5 ; 16 ; 9 -rsb- , this paper presents an <method_0> capable of <otherscientificterm_6> , where individual scans may be subject to <otherscientificterm_13> . we describe an integrated <method_10> for <task_4> and recovering the <otherscientificterm_11> . to tackle the resulting <task_8> , we introduce a <method_9> that first matches a coarse skeleton of scan points , then adapts <method_7> . the <method_9> is implemented for a <method_12> capable of acquiring <task_1> .	0 5 14 -1 2 19 14 -1 3 6 13 20 14 -1 10 4 11 14 -1 8 9 7 16 17 14 -1 12 15 18 14 -1
Higher-order gradient descent by fusion-move graph cut .	optimization of higher-order potentials ; higher-order binary energy minimization ; higher-order graph cuts ; fusion move algorithm ; higher-order energies ; proposal labelings ; fusion move ; vision problems ; optimization ; first-order	<task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method>	2 0 0	markov random field is now ubiquitous in many formulations of various <task_7> . recently , <task_0> became practical using <otherscientificterm_2> : the combination of i -rrb- the <method_3> , ii -rrb- the reduction of <method_1> to <method_9> , and iii -rrb- the <method_3> . in the <otherscientificterm_6> , it is crucial for the success and efficiency of the <method_8> to provide proposals that fits the energies being optimized . for <otherscientificterm_4> , it is even more so because they have richer class of null potentials . in this paper , we focus on the efficiency of the <otherscientificterm_2> and present a simple technique for generating <otherscientificterm_5> that makes the algorithm much more efficient , which we empirically show using examples in stereo and image denoising .	7 10 -1 0 2 3 1 9 11 10 -1 6 8 10 -1 4 10 -1 10 -1
Bayesian Unsupervised Signal Classification by Dirichlet Process Mixtures of Gaussian Processes .	real signals -lrb- mrna expression profiles ; monte carlo markov chain algorithm ; bayesian clustering approaches ; dirichlet process model ; gaussian processes parameters ; classifying signals ; gaussian processes ; bayesian technique ; mixture model ; noise ; clusters	<material> <method> <method> <method> <otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <otherscientificterm>	7 0 5	this paper presents a <method_7> aimed at <task_5> without prior training -lrb- clustering -rrb- . the <method_7> consists of modelling the observed signals , known only through a finite set of samples corrupted by <otherscientificterm_9> , as <method_6> . as in many other <method_2> , the <otherscientificterm_10> are defined thanks to a <method_8> . in order to estimate the number of <otherscientificterm_10> , we assume a priori a countably infinite number of <otherscientificterm_10> , thanks to a <method_3> over the <otherscientificterm_4> . computations are performed thanks to a dedicated <method_1> , and results involving <material_0> -rrb- are presented .	7 5 12 11 -1 9 6 11 -1 2 10 8 11 -1 3 4 11 -1 1 0 11 -1
Information Capacity and Robustness of Stochastic Neuron Models .	hh ion channel density ; density of ion channels ; average firing rate ; ion channel stochasticity ; macroscopic behavior ; neuronal models ; spike trains ; information capacity ; neuron encodes ; information rate ; neuronal excitability ; precision ; membrane ; reliability ; accuracy ; neuron	<otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <metric> <otherscientificterm> <metric> <metric> <otherscientificterm>	3 0 5 ; 9 5 3 ; 14 5 6 ; 7 2 1	the <metric_13> and <metric_14> of <method_6> have been shown to depend on the nature of the stimulus that the <otherscientificterm_8> . adding <otherscientificterm_3> to <method_5> results with a <otherscientificterm_4> that replicates the input-dependent <metric_13> and <metric_11> of real neurons . we calculate the amount of information that an ion channel based stochastic hodgkin-huxley -lrb- hh -rrb- <otherscientificterm_15> model can encode about a wide set of stimuli . we show that both the <metric_9> and the information per spike of the <otherscientificterm_3> is similar to the values reported experimentally . moreover , the amount of information that the <otherscientificterm_8> is correlated with the amplitude of fluctuations in the input , and less so with the <metric_2> of the <otherscientificterm_15> . we also show that for the <otherscientificterm_0> , the <otherscientificterm_7> is robust to changes in the <otherscientificterm_1> in the <otherscientificterm_12> , whereas changing the ratio between the na + and k + ion channels has a considerable effect on the information that the <otherscientificterm_15> can encode . this suggests that neurons may maximize their <otherscientificterm_7> by appropriately balancing the density of the different ion channels that underlies <otherscientificterm_10> .	13 14 6 8 19 16 -1 3 5 4 11 17 16 -1 15 16 -1 9 18 16 -1 16 -1 2 20 16 -1 0 7 1 12 16 -1
Learning image representations from the pixel level via hierarchical sparse coding .	invariant and discriminative image representations ; two-layer sparse coding scheme ; high-order dependency among patterns ; rst layer codes ; handwritten digit recognition ; local image neighborhood ; sparse coding methods ; local patches ; hand-designed descriptors ; pixel level ; data encoding ; rst layer ; caltech101 benchmark ; object recognition ; codebook learning ; local regions ; image representations ; image ; features	<task> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material> <task> <task> <otherscientificterm> <method> <material> <otherscientificterm>	11 0 7 ; 9 2 1 ; 10 1 14 ; 6 0 7 ; 1 0 16	we present a method for learning <method_16> using a <method_1> at the <otherscientificterm_9> . the <otherscientificterm_11> encodes <otherscientificterm_7> of an <material_17> . after pooling within <otherscientificterm_15> , the <otherscientificterm_3> are then passed to the second layer , which jointly encodes signals from the region . unlike traditional <method_6> that encode <otherscientificterm_7> independently , this approach accounts for <otherscientificterm_2> in a <otherscientificterm_5> . we develop algorithms for <task_10> and <task_14> , and show in experiments that the method leads to more <task_0> . the algorithm gives excellent results for <task_4> on mnist and <task_13> on the <material_12> . this marks the rst time that such accuracies have been achieved using automatically learned <otherscientificterm_18> from the <otherscientificterm_9> , rather than using <otherscientificterm_8> .	16 1 9 21 24 19 -1 11 7 17 20 19 -1 15 3 19 -1 6 2 5 23 19 -1 10 14 0 22 19 -1 4 13 12 19 -1 19 -1
Automatic intelligibility assessment of pathologic speech in head and neck cancer based on auditory-inspired spectro-temporal modulations .	interspeech 2012 speaker trait pathology sub-challenge ; auditory-inspired spectro-temporal modulation features ; speaker trait challenge problem ; automatic speech intelligibility assessment ; spectro-temporal modulation features ; non-intelligible speech ; radical surgery ; pathologic speech ; speech intelligibility ; tumor size ; anatomical structures ; chemotherapy ; svm ; gmm ; location ; radiology ; speech	<method> <otherscientificterm> <task> <task> <otherscientificterm> <material> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <material>	1 0 7 ; 10 0 16 ; 14 1 15 ; 15 1 11 ; 12 1 13 ; 6 1 15 ; 1 0 3	oral , head and neck cancer represents 3 % of all cancers in the united states and is the 6th most common cancer worldwide . depending on the <otherscientificterm_9> , <otherscientificterm_14> and staging , patients are treated by <otherscientificterm_6> , <otherscientificterm_15> , <method_11> or a combination of those treatments . as a result , their <otherscientificterm_10> for <material_16> are impaired and this leads to some negative impact on their <otherscientificterm_8> . as a part of the <method_0> , this study explored the use of <otherscientificterm_1> for <task_3> of those <material_7> . the averaged spectro-temporal modulations of <material_16> considered as either intelligible or non-intelligible in the challenge database were analyzed and it was found that the <material_5> tends to have its modulation amplitude peaks shift towards a smaller rate and scale . based on <method_12> and <method_13> , variants of <otherscientificterm_4> were tested on the <task_2> and the resulting performances on both the development and the test datasets are comparable to the baseline performance .	17 -1 9 14 6 15 11 20 21 23 17 -1 10 16 8 19 17 -1 0 1 3 7 18 24 17 -1 17 -1 5 22 17 -1
A general DSP processor at the cost of 23K gates and 1/2 a man-year design time .	16-bit fixed point dsp processor ; mac commercial dsp processors ; performance/gate count ratio ; communication infrastructure applications ; computational units ; clock frequency ; assembler instructions ; design time ; rtl code ; hardware accelerators ; i/o facilities ; heterogeneous processors ; debugger ; net-list ; as-sembler ; benchmarking	<method> <method> <metric> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <method> <method> <otherscientificterm> <metric> <otherscientificterm> <method>	14 1 12 ; 0 0 9 ; 11 0 3 ; 4 1 6 ; 12 1 8	this paper describes the design and implementation of a <method_0> . the <method_0> is intended as a platform for <method_9> and allows additional <otherscientificterm_4> and <otherscientificterm_6> to be added . the <method_10> can also be customized to the needs of a specific application . <method_15> has shown that the <method_0> , without any <method_9> , has a performance comparable to single <method_1> . the architecture has been successfully synthesized in a 0.13 m process , resulting in a <metric_13> of about 23000 gates , and a <otherscientificterm_5> of 195 mhz , making the <metric_2> very competitive . it is also small enough to integrate 100 <method_11> on a chip for example for <task_3> . the complete <metric_7> , including architecture and instruction set planning , <otherscientificterm_14> , <otherscientificterm_12> , instruction set simulator , <otherscientificterm_8> and complete verification was about half a person-year .	0 16 -1 9 4 6 18 20 16 -1 10 15 16 -1 1 16 -1 13 5 2 16 -1 19 16 -1 11 3 17 21 16 -1
Convolutional Neural Networks for Sentence Classification .	convolutional neural networks ; task-specific and static vectors ; learning task-specific vectors ; sentence-level classification tasks ; pre-trained word vectors ; question classification ; hyperparameter tuning ; sentiment analysis ; static vectors ; cnn models ; fine-tuning	<method> <otherscientificterm> <method> <task> <material> <task> <method> <task> <method> <method> <method>	8 0 0 ; 7 1 5 ; 4 0 3 ; 6 1 8	we report on a series of experiments with <method_0> trained on top of <material_4> for <task_3> . we show that a simple <method_0> with little <method_6> and <method_8> achieves excellent results on multiple benchmarks . <method_2> through <method_10> offers further gains in performance . we additionally propose a simple modification to the architecture to allow for the use of both <otherscientificterm_1> . the <method_9> discussed herein improve upon the state of the art on 4 out of 7 tasks , which include <task_7> and <task_5> .	0 4 3 14 11 -1 6 8 2 12 15 11 -1 10 11 -1 1 11 -1 9 7 5 13 11 -1
Learning Abstract Concept Embeddings from Multi-Modal Data : Since You Probably Ca n't See What I Mean .	commonly-occurring abstract lexical concepts ; linguistic and perceptual input ; abstract conceptual representation ; concrete noun concepts ; human language learning ; language-only models ; everyday language ; multi-modal approach ; concrete concepts ; semantic representations ; multi-modal embeddings ; perceptual information ; nlp	<otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <method> <material> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task>	1 0 9 ; 7 4 5	models that acquire <method_9> from both <otherscientificterm_1> are of interest to researchers in <task_12> because of the obvious parallels with <task_4> . performance advantages of the <method_7> over <method_5> have been clearly established when models are required to learn <otherscientificterm_3> . however , such concepts are comparatively rare in <material_6> . in this work , we present a new means of extending the scope of <method_7> to more <otherscientificterm_0> via an approach that learns <otherscientificterm_10> . our architecture out-performs previous approaches in combining input from distinct modalities , and propagates <otherscientificterm_11> on <otherscientificterm_8> to abstract concepts more effectively than alternatives . we discuss the implications of our results both for optimizing the performance of <method_7> and for theories of <task_2> .	9 1 12 4 14 13 -1 7 5 3 15 13 -1 6 13 -1 0 10 13 -1 11 8 13 -1 13 -1
Belief Revision with General Epistemic States .	epistemic state ; classical iterated belief revision rules ; semantical characterisation of geps ; iterated belief revision ; mathematical structure ; epistemic states ; conditional beliefs ; epis-temic state ; belief algebra ; epistemic state ; belief set ; belief algebras ; 1-1 correspondence ; ax-iomatic characterisation ; binary relation ; total preorder ; rules	<method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm>	13 0 5 ; 8 6 4 ; 6 2 9 ; 6 0 13	in order to properly regulate <method_3> , darwiche and pearl -lrb- 1997 -rrb- model belief revision as revising <otherscientificterm_5> by propositions . an <otherscientificterm_9> in their sense consists of a <otherscientificterm_10> and a set of <otherscientificterm_6> . although the denotation of an <otherscientificterm_7> can be indirectly captured by a <otherscientificterm_15> on the set of worlds , it is unclear how to directly capture the structure in terms of the beliefs and <otherscientificterm_6> it contains . in this paper , we first provide an <method_13> for <otherscientificterm_5> by using nine <otherscientificterm_16> about beliefs and <otherscientificterm_6> , and then argue that the last two <otherscientificterm_16> are too strong and should be eliminated for characterising the belief state of an agent . we call a structure which satisfies the first seven <otherscientificterm_16> a general <method_0> . to provide a <method_2> , we introduce a <otherscientificterm_4> called <method_8> , which is in essence a certain <otherscientificterm_14> defined on the power set of worlds . we then establish a <otherscientificterm_12> between <method_0> and <otherscientificterm_11> , and show that total preorders on worlds are special cases of <otherscientificterm_11> . furthermore , using the notion of <otherscientificterm_11> , we extend the <otherscientificterm_1> of darwiche and pearl to our setting of general <otherscientificterm_5> .	3 5 17 -1 9 10 6 20 17 -1 7 15 17 -1 13 16 18 21 17 -1 17 -1 0 19 17 -1 2 4 8 14 17 -1 12 11 17 -1
Prediction of time series using Yule-Walker equations with kernels .	autoregressive model ; ar model parameters ; pre-image problem ; yule-walker equations ; kernel machines ; covariance function ; input space ; feature space ; model parameters	<method> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 1 5 ; 3 0 1 ; 4 0 0 ; 7 2 3	the <method_0> is a well-known technique to analyze time series . the <method_3> provide a straightforward connection between the <otherscientificterm_1> and the <otherscientificterm_5> of the process . in this paper , we propose a nonlinear extension of the <method_0> using <method_4> . to this end , we explore the <method_3> in the <otherscientificterm_7> , and show that the <otherscientificterm_8> can be estimated using the concept of expected kernels . finally , in order to predict once the <method_0> identified , we solve a <task_2> by getting back from the <otherscientificterm_7> to the <otherscientificterm_6> . we also give new insights into the convex-ity of the <task_2> . the relevance of the proposed method is evaluated on several time series .	0 9 -1 3 1 5 10 11 9 -1 4 12 9 -1 7 8 13 9 -1 2 6 9 -1 9 -1 9 -1
DNNF-based Belief State Estimation .	best-first belief state update algorithm ; dnnf-based belief state estimation algorithm ; best-first trajec-tory enumeration algorithm ; probabilistic concurrent constraint automata ; mode estimation of pccas ; factored hidden markov models ; polynomial-time bounded algorithm ; mexec algorithm ; sd-dnnf-based representation ; embedded systems ; polynomial time ; declarative models ; probabilistic data ; physical plant ; cnf ; accuracy ; robustness	<method> <method> <method> <method> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <metric> <metric>	3 6 5 ; 2 0 4 ; 7 4 2 ; 10 1 7	as <method_9> grow increasingly complex , there is a pressing need for diagnosing and monitoring capabilities that estimate the system state robustly . this paper is based on approaches that address the problem of <metric_16> by reasoning over <method_11> of the <otherscientificterm_13> , represented as a variant of <method_5> , called <method_3> . prior work on <method_4> is based on a <method_2> . two algorithms have since made improvements to the <method_2> : 1 -rrb- the <method_0> has improved the <metric_15> of <method_2> and 2 -rrb- the <method_7> has introduced a <method_6> using a smooth deterministic decomposable negation normal form -lrb- sd-dnnf -rrb- representation . this paper introduces a new <method_1> that merges the <otherscientificterm_10> bound of the <method_7> with the <metric_15> of the <method_2> . this paper also presents an encoding of a <method_1> as a <method_14> with <material_12> , suitable for compilation into an <method_8> . the <method_8> supports computing k belief states from k previous belief states in the <method_2> .	9 17 -1 16 11 13 5 3 18 17 -1 4 2 19 17 -1 0 15 7 6 17 -1 20 21 17 -1 1 10 17 -1 14 12 8 17 -1
Digital face makeup by example .	skin detail layer ; face structure layer ; color layer ; physical makeup ; face makeup ; transferring makeup ; face structure ; color	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm>	0 1 2 ; 1 1 0	this paper introduces an approach of creating <task_4> upon a face image with another image as the style example . our approach is analogous to <otherscientificterm_3> , as we modify the <otherscientificterm_7> and skin detail while preserving the <otherscientificterm_6> . more precisely , we first decompose the two images into three layers : <otherscientificterm_1> , <otherscientificterm_0> , and <otherscientificterm_2> . thereafter , we transfer information from each layer of one image to corresponding layer of the other image . one major advantage of the proposed method lies in that only one example image is required . this renders <task_4> by example very convenient and practical . equally , this enables some additional interesting applications , such as applying makeup by a portraiture . the experiment results demonstrate the effectiveness of the proposed approach in faithfully <task_5> .	4 8 -1 3 7 6 8 -1 1 0 2 9 10 8 -1 8 -1 8 -1 8 -1 8 -1 8 -1
Attention-based LSTM Network for Cross-Lingual Sentiment Classification .	long short term memory network ; attention-based bilingual representation learning model ; bilingual lstm network ; manually labeled data ; hierarchical attention mechanism ; sentence-level attention model ; word-level attention model ; supervised learning algorithms ; sentiment classification methods ; cross-lingual sentiment classification ; distributed semantics ; resource-poor languages ; sentiment resources ; word sequences ; resource-rich language ; english ; chinese	<method> <method> <task> <material> <method> <method> <method> <method> <method> <task> <otherscientificterm> <material> <otherscientificterm> <material> <material> <material> <material>	7 0 8 ; 3 0 7 ; 4 0 2 ; 15 1 16 ; 15 0 4	most of the state-of-the-art <method_8> are based on <method_7> which require large amounts of <material_3> . however , the labeled resources are usually imbalanced in different languages . <task_9> tackles the problem by adapting the <otherscientificterm_12> in a <material_14> to <material_11> . in this study , we propose an <method_1> which learns the <otherscientificterm_10> of the documents in both the source and the target languages . in each language , we use <method_0> to <method_4> the documents , which has been proved to be very effective for <material_13> . meanwhile , we propose a <method_4> for the <task_2> . the <method_5> learns which sentences of a document are more important for determining the overall sentiment while the <method_6> learns which words in each sentence are decisive . the proposed <method_4> achieves good results on a benchmark dataset using <material_15> as the source language and <material_16> as the target language .	8 7 3 18 19 17 -1 9 17 -1 12 14 11 17 -1 1 10 17 -1 0 4 13 17 -1 2 20 17 -1 17 -1 5 6 21 22 17 -1
Catching heuristics are optimal control policies .	continuous partially observable markov decision process ; rational account of human ball-catching behavior ; generating reactive and predictive behavior ; stochastic optimal control theory ; stochastic optimal control ; ratio of system ; immediate visual feedback ; computational solutions ; control problem ; modeling catching ; observation noise ; reaction time ; task duration ; interception strategies ; ground contact ; airborne ball ; unifying explanation ; ball-catching agent ; perceptual latency ; ball trajectory ; model parameters ; heuristics ; noise	<method> <otherscientificterm> <task> <method> <otherscientificterm> <metric> <otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	21 0 8 ; 0 0 9 ; 13 0 8 ; 11 1 12 ; 13 0 21 ; 3 0 9 ; 7 0 8 ; 14 1 18 ; 3 0 0 ; 6 0 21 ; 22 6 20	two seemingly contradictory theories attempt to explain how humans move to intercept an <otherscientificterm_15> . one theory posits that humans predict the <otherscientificterm_19> to optimally plan future actions ; the other claims that , instead of performing such complicated computations , humans employ <method_21> to reactively choose appropriate actions based on <otherscientificterm_6> . in this paper , we show that <method_13> appearing to be <method_21> can be understood as <method_7> to the optimal <task_8> faced by a <method_17> acting under uncertainty . <task_9> as a <method_0> and employing <method_3> , we discover that the four main <method_21> described in the literature are optimal solutions if the catcher has sufficient time to continuously visually track the ball . specifically , by varying <otherscientificterm_20> such as <otherscientificterm_22> , time to <otherscientificterm_14> , and <otherscientificterm_18> , we show that different strategies arise under different circumstances . the catcher 's policy switches between <task_2> based on the <metric_5> to <otherscientificterm_10> and the ratio between <otherscientificterm_11> and <otherscientificterm_12> . thus , we provide a <otherscientificterm_1> and a <method_16> for seemingly contradictory theories of target interception on the basis of <otherscientificterm_4> .	15 23 -1 19 21 6 33 23 -1 13 7 8 17 9 24 26 28 30 23 -1 0 3 25 29 32 23 -1 31 34 23 -1 20 22 14 18 27 23 -1 2 5 10 11 12 23 -1
Non-lexical neural architecture for fine-grained POS Tagging .	pos and morphological tagging task ; meaningful word representations ; raw character stream ; character stream ; feature engineering ; prediction stage ; word representations ; neural architectures ; word representation ; convolutional network ; modelling stages ; german	<task> <method> <material> <otherscientificterm> <method> <otherscientificterm> <method> <method> <method> <method> <method> <material>	2 0 6 ; 9 0 8 ; 9 6 10 ; 9 0 6 ; 7 0 6 ; 2 0 7 ; 9 0 5	in this paper we explore a pos tagging application of <method_7> that can infer <method_6> from the <material_2> . it relies on two <method_10> that are jointly learnt : a <method_9> that infers a <method_8> directly from the <otherscientificterm_3> , followed by a <otherscientificterm_5> . models are evaluated on a <task_0> for <material_11> . experimental results show that the <method_9> can infer <method_1> , while for the <otherscientificterm_5> , a well designed and structured strategy allows the <method_9> to outperform state-of-the-art results , without any <method_4> .	7 6 2 13 17 18 12 -1 10 9 8 3 5 14 15 12 -1 0 11 12 -1 1 4 16 19 12 -1
Segmentation-Aware Deformable Part Models .	spatial support of slic superpixels ; object-specific and background changes ; enhanced , background-invariant features ; sliding window detectors ; dense sift descriptors ; soft segmentation masks ; low-level hog features ; bottom-up segmentation ; segmentation masks ; feature variation ; candidate window ; seg-mentation ; ap ; detection ; segmentation	<method> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <task> <method>	8 0 2 ; 14 0 9 ; 9 2 1 ; 0 0 6	in this work we propose a technique to combine <method_7> , coming in the form of slic superpixels , with <method_3> , such as deformable part models -lrb- dpms -rrb- . the merit of our approach lies in ` cleaning up ' the <otherscientificterm_6> by exploiting the <method_0> ; this can be understood as using <method_14> to split the <otherscientificterm_9> into <otherscientificterm_1> . rather than committing to a single <method_11> we use a large pool of slic superpixels and combine them in a scale - , position-and object-dependent manner to build <method_5> . the <method_8> can be computed fast enough to repeat this process over every <otherscientificterm_10> , during training and <task_13> , for both the root and part filters of dpms . we use these <method_8> to construct <otherscientificterm_2> to train dpms . we test our approach on the pascal voc 2007 , outperforming the standard dpm in 17 out of 20 classes , yielding an average increase of 1.7 % <metric_12> . additionally , we demonstrate the robustness of this approach , extending it to <method_4> for large displacement optical flow .	7 3 15 -1 6 0 14 9 1 17 18 19 15 -1 11 5 15 -1 8 15 -1 10 13 16 15 -1 2 15 -1 12 15 -1
Principal mixture speaker adaptation for improved continuous speech recognition .	speaker-independent speech recognition systems ; speaker adaptation ; principal mixture speaker adaptation method ; full multivariate mixture gaussian densities ; full mixture sa models ; speaker 's characteristics ; hmm observation density ; acoustic hmm ; gaussian densities ; recognition speed ; si models ; principle mixtures ; speaker variabilities ; speaker variation ; hmm complexity ; observation density ; recognition accuracy ; cdhmm	<method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <metric> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <metric> <method>	17 0 0 ; 1 0 13 ; 16 5 2 ; 2 0 14 ; 8 2 7 ; 9 5 10 ; 9 5 4 ; 16 5 10 ; 9 5 2	nowadays , almost all <method_0> use <method_17> with multivariate mixture gaussian as <otherscientificterm_15> to cover <otherscientificterm_12> . it has been shown that given sufficient training data , the more mixtures are used in the <otherscientificterm_6> , the better the <method_0> 's perform . however , <method_7> with more <otherscientificterm_8> is more complex and slows down <metric_9> . another efficient way to handle <otherscientificterm_13> is to use <method_1> . yet , even though speaker adaptation of <otherscientificterm_3> can increase <metric_16> , it does not improve <metric_9> . in this paper , we introduce a <method_2> which reduces <metric_14> by choosing only the <otherscientificterm_11> corresponding to a particular <otherscientificterm_5> . we show that our <method_2> both improves <metric_16> by 31.8 % when compared to <method_10> , and reduces <metric_9> by 30 % , when compared to <method_4> .	0 17 15 12 19 18 -1 6 18 -1 7 8 9 23 18 -1 13 1 20 18 -1 3 16 18 -1 2 14 22 18 -1 11 5 21 24 25 26 27 18 -1
Learning priors for calibrating families of stereo cameras .	online calibration of additional cameras ; stereo camera calibration ; unknown prior distribution ; online camera recalibration ; computer vision systems ; offline-calibrated cameras ; repeated texture ; point correspondences ; real-world scenes ; calibration problem ; recalibration information ; features ; planar ; robustness ; accuracy ; calibration	<task> <task> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <metric> <task>	3 0 4 ; 14 1 13	online camera recalibration is necessary for long-term deployment of <method_4> . existing algorithms assume that the source of <otherscientificterm_10> is a set of <otherscientificterm_11> in a general 3d scene ; and that enough <otherscientificterm_11> are observed that the <task_9> is well-constrained . however , these assumptions are frequently invalid outside the laboratory . <otherscientificterm_8> often lack texture , contain <otherscientificterm_6> , or are mostly <otherscientificterm_12> , making <task_15> difficult or impossible . in this paper we consider the <task_15> of families of stereo cameras , where each camera is assumed to have parameters drawn from a common but <otherscientificterm_2> . we show how estimation of this prior using a small-number of <otherscientificterm_5> -lrb- e.g. from the same production line -rrb- allows <task_0> using a small number of <otherscientificterm_7> ; and that using the estimated prior significantly increases the <metric_14> and <metric_13> of <task_1> .	4 17 16 -1 10 11 9 16 -1 8 16 -1 6 12 15 16 -1 2 16 -1 18 16 -1
Friends and enemies : a novel initialization for speaker diarization .	bayesian information criterion ; absolute cluster purity improvement ; iterative cluster merging ; diarization error rate ; initialization algorithm ; rt05s evaluation ; agglomerative clustering ; speaker diarization ; clusters ; clustering ; robustness	<otherscientificterm> <metric> <method> <metric> <method> <metric> <method> <task> <otherscientificterm> <method> <metric>	2 0 9 ; 6 0 7	the task of <task_7> consists of answering the question '' who spoke when ? '' . the most commonly used approach to <task_7> is <method_6> of multiple initial <otherscientificterm_8> . even though the initial <method_9> is greatly modified by <method_2> and possibly multiple resegmentations of the data , the <method_4> is a key module for system performance and <metric_10> . in this paper we present a novel approach that obtains a desired initial number of <otherscientificterm_8> in three steps . it first computes possible speaker change points via a standard technique based on the <otherscientificterm_0> . it then classifies the resulting segments into '' friend '' and '' enemy '' groups to finally creates an initial set of <otherscientificterm_8> for the system . we test this algorithm with the dataset used in the <metric_5> , where we show a 13 % <metric_3> relative improvement and a 2.5 % <metric_1> with respect to our previous algorithm .	7 11 -1 6 8 11 -1 9 2 4 10 13 11 -1 12 11 -1 0 11 -1 11 -1 11 -1 5 3 1 11 -1
Computational Semantics of Noun Compounds in a Semantic Space Model .	meaning of noun compounds ; similarity judgment test ; semantic space model ; constituent word vectors ; computing compound vectors ; multiple-choice synonym test ; emergent meanings ; comparison algorithm ; noun compounds ; accuracy ; predication	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <metric> <otherscientificterm> <method> <otherscientificterm> <metric> <otherscientificterm>	10 1 1 ; 7 0 0 ; 7 0 8 ; 5 1 1 ; 2 0 0	this study examines the ability of a <method_2> to represent the <otherscientificterm_0> such as '' information gathering '' or '' weather forecast '' . a new algorithm , comparison , is proposed for <task_4> from <otherscientificterm_3> , and compared with other algorithms -lrb- i.e. , <otherscientificterm_10> and centroid -rrb- in terms of <metric_9> of <metric_5> and <otherscientificterm_1> . the result of both tests is that the <method_7> is , on the whole , superior to other algorithms , and in particular achieves the best performance when <otherscientificterm_8> have <otherscientificterm_6> . furthermore , the <method_7> also works for novel <otherscientificterm_8> that do not occur in the corpus . these findings indicate that a <method_2> in general and the <method_7> in particular has sufficient ability to compute the <otherscientificterm_0> .	2 0 11 -1 4 3 10 9 5 1 12 15 11 -1 7 8 6 11 -1 14 11 -1 13 16 11 -1
Probing the Linguistic Strengths and Limitations of Unsupervised Grammar Induction .	raw word or tag sequences ; unsupervised ccg parsers ; grammar induction algorithms ; unlabeled dependencies ; syntactic structure ; grammar induction ; supervision ; ccgbank	<material> <method> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <material>	5 0 4 ; 0 0 4 ; 2 0 3	work in <task_5> should help shed light on the amount of <otherscientificterm_4> that is discoverable from <material_0> . but since most current <method_2> produce <otherscientificterm_3> , it is difficult to analyze what types of constructions these <method_2> can or can not capture , and , therefore , to identify where additional <otherscientificterm_6> may be necessary . this paper provides an in-depth analysis of the errors made by <method_1> by evaluating <method_1> against the labeled dependencies in <material_7> , hinting at new research directions necessary for progress in <task_5> .	5 4 0 9 10 8 -1 2 3 6 11 8 -1 1 7 8 -1
Neurocalibration : A Neural Network That Can Tell Camera Calibration Parameters .	camera m o del parameters ; computer vision tasks ; automated active lenses ; random initial weights ; world 3d points ; 2d image pixels ; camera c alibration ; camera calibration ; perspective-projection-transformation matrix ; rotational transformation ; calibrating cameras ; synthetic data ; noise conditions ; real images ; neural approach ; neural approaches ; calibration problems ; calibrating network ; orthogonality constraints ; accuracy	<otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <task> <material> <otherscientificterm> <material> <method> <method> <task> <method> <otherscientificterm> <metric>	14 0 6 ; 7 6 1 ; 14 0 10 ; 15 4 17 ; 2 2 10 ; 19 5 14 ; 11 5 14 ; 14 0 1 ; 4 1 5 ; 17 0 8 ; 13 5 14 ; 14 0 16	camera calibration is a primary crucial step in many <task_1> . in this paper we present a new <method_14> for <task_6> . unlike some existing <method_15> , our <method_17> can tell the <otherscientificterm_8> between the <otherscientificterm_4> and the corresponding <otherscientificterm_5> . starting from <otherscientificterm_3> , the net can specify the <otherscientificterm_0> satisfying the <otherscientificterm_18> on the <otherscientificterm_9> . the <method_14> is shown to solve four diierent types of <task_16> that are found in <task_1> . moreover , <method_14> can be extended to the more diicult problem of <task_10> with <otherscientificterm_2> . the validity and performance of our <method_14> are tested with both <material_11> under different <otherscientificterm_12> and with <material_13> . experiments have shown the <metric_19> and the eeciency of our <method_14> .	1 22 20 -1 14 6 21 20 -1 15 17 8 4 5 24 29 30 20 -1 3 0 18 9 20 -1 16 28 32 20 -1 10 2 23 25 20 -1 27 31 20 -1 11 12 13 26 20 -1
Trading Accuracy for Numerical Stability : Orthogonalization , Biorthogonalization and Regularization .	geometric significance of biorthogonal bases ; homotopy or tuning parameter ; nonlinear projection operators ; signal processing applications ; real exponential signals ; ill-conditioned inverse problem ; signal processing literature ; tradeoff analysis ; regularization methods ; regularization techniques ; convex programming ; numerical stability ; continuation methods ; signal processing ; accuracy	<otherscientificterm> <otherscientificterm> <method> <task> <material> <task> <material> <task> <method> <method> <method> <otherscientificterm> <method> <task> <metric>	1 0 7 ; 13 1 10 ; 10 1 2 ; 13 1 12 ; 14 1 11 ; 5 5 8 ; 0 0 8 ; 0 0 3 ; 10 1 12 ; 12 1 2	this paper presents two novel <method_8> motivated in part by the <otherscientificterm_0> in <task_3> . these <method_8> , in particular , draw upon the structural relevance of orthogonality and biorthogonality principles and are presented from the perspectives of <task_13> , <method_10> , <method_12> and <method_2> . each method is specifically endowed with either a <otherscientificterm_1> to facilitate <task_7> between <metric_14> and <otherscientificterm_11> . an example involving a basis comprised of <material_4> illustrates the utility of the proposed <method_8> on an <task_5> and the results are compared to standard <method_9> from the <material_6> .	8 0 3 22 23 15 -1 13 10 12 2 17 18 19 24 25 15 -1 1 7 14 11 16 20 15 -1 4 5 9 6 21 15 -1
Robust Boltzmann Machines for recognition and denoising .	un-labeled noisy data ; unsupervised fashion ; visual recognition ; posterior inference ; multiplicative gating ; boltzmann machines ; image denoising ; spatial structure ; face databases ; denoising ; in-painting ; occlusions ; noise ; recognition ; corruptions	<material> <method> <task> <task> <method> <material> <task> <otherscientificterm> <material> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm>	13 1 9 ; 11 1 12 ; 0 0 1 ; 6 1 10	while <material_5> have been successful at un-supervised learning and density modeling of images and speech data , <material_5> can be very sensitive to <otherscientificterm_12> in the data . in this paper , we introduce a novel model , the robust boltz-mann machine -lrb- robm -rrb- , which allows <material_5> to be robust to <otherscientificterm_14> . in the domain of <task_2> , the robm is able to accurately deal with <otherscientificterm_11> and <otherscientificterm_12> by using <method_4> to induce a scale mixture of gaussians over pixels . <task_6> and <otherscientificterm_10> correspond to <task_3> in the robm . our model is trained in an <method_1> with <material_0> and can learn the <otherscientificterm_7> of the occluders . compared to standard algorithms , the robm is significantly better at <task_13> and <task_9> on several <material_8> .	5 12 15 -1 14 15 -1 2 11 4 6 17 15 -1 10 3 19 15 -1 18 15 -1 1 0 7 16 15 -1
Adaptive Support Vector Machine for Time-Varying Data Streams Using Martingale .	adaptive support vector machine ; time-varying data streams ; adiabatic incremental learning ; one-pass incre-mental algorithm ; sliding window ; martingale approach ; data stream ; historical information ; hypothesis testing ; clas-sifier	<method> <material> <method> <method> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method>	5 0 0 ; 0 0 1 ; 0 6 3	introduction in this paper we propose an efficient <method_0> for <material_1> based on the <method_5> -lsb- 2 -rsb- and using <method_2> -lsb- 1 -rsb- . when a new data point is observed , <method_8> decides whether any change has occurred . once a change is detected , <otherscientificterm_7> about previous data is removed from the memory . the <method_0> is a <method_3> that 1 . does not require a <otherscientificterm_4> on the <material_6> , 2 . does not require monitoring the performance of the <method_9> as data points are streaming , and 3 . works well for high dimensional , multi-class data streams .	0 1 5 2 11 12 10 -1 8 10 -1 7 10 -1 3 13 10 -1 4 6 10 -1 9 10 -1 10 -1
Structured Prediction Energy Networks .	structured prediction energy networks ; feed-forward and iterative structured prediction techniques ; tractable learning and prediction problems ; energy function of candidate labels ; benchmark multi-label classification tasks ; minimal structural assumptions ; interpretable structure learning ; dis-criminative features ; multi-label classification ; multi-label problems ; high-order interactions ; learning features ; structured prediction ; deep architecture ; graphical models ; structure learning ; deep learning ; prediction problem ; dependencies ; back-propagation	<method> <method> <task> <otherscientificterm> <task> <otherscientificterm> <task> <otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <task> <method> <method> <method> <method> <task> <otherscientificterm> <method>	0 0 9 ; 13 0 3 ; 13 0 14 ; 0 0 12 ; 16 0 17 ; 4 0 6	we introduce <method_0> , a flexible framework for <task_12> . a <method_13> is used to define an <otherscientificterm_3> , and then predictions are produced by using <method_19> to iteratively optimize the energy with respect to the labels . this <method_13> captures <otherscientificterm_18> between labels that would lead to intractable <method_14> , and performs <method_15> by automatically learning <otherscientificterm_7> of the structured output . one natural application of our technique is <task_8> , which traditionally has required strict prior assumptions about the interactions between labels to ensure <task_2> . we are able to apply <method_0> to <task_9> with substantially larger label sets than previous applications of <task_12> , while modeling <otherscientificterm_10> using <otherscientificterm_5> . overall , <method_16> provides remarkable tools for <otherscientificterm_11> of the inputs to a <task_17> , and this work extends these techniques to <otherscientificterm_11> of the outputs . our experiments provide impressive performance on a variety of <task_4> , demonstrate that our technique can be used to provide <task_6> , and illuminate fundamental trade-offs between <method_1> .	0 12 24 20 -1 13 3 19 22 20 -1 18 14 15 7 23 20 -1 8 2 20 -1 9 21 20 -1 10 5 25 20 -1 16 11 17 26 20 -1
Theme identification in telephone service conversations using quaternions of speech features .	real-life telephone customer care service ; automatic speech recognition system ; quaternion algebra framework ; extracting word frequency ; casual customer calling ; theme classification accuracy ; human/human conversation ; features ; feature ; features	<method> <method> <method> <task> <otherscientificterm> <metric> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm>	5 5 7	the paper introduces new <otherscientificterm_7> for describing possible focus variation in a <material_6> . the application considered is a <method_0> . the purpose is to hypothesize the dominant theme of conversations between a <otherscientificterm_4> . conversations are processed by an <method_1> that provides hypotheses used for <task_3> . <otherscientificterm_9> are extracted in different , broadly defined and partially overlapped , time segments . combinations of each <otherscientificterm_8> in different segments are represented in a <method_2> . the advantage of the proposed <otherscientificterm_7> is made evident by the statistically significant improvements in <metric_5> .	7 6 10 -1 0 10 -1 4 10 -1 1 3 9 10 -1 10 -1 8 2 10 -1 5 11 10 -1
Learning Mixtures of Ranking Models .	tensor decomposition techniques ; mallows mixture model ; polynomial time algorithm ; bad local optima ; ranking data ; mallows models ; top-k prefix ; heterogeneous population ; probabilistic models ; rankings	<method> <method> <method> <otherscientificterm> <task> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	0 0 2 ; 7 2 4	this work concerns learning <method_8> for <task_4> in a <otherscientificterm_7> . the specific problem we study is learning the parameters of a <method_1> . despite being widely studied , current heuristics for this problem do not have theoretical guarantees and can get stuck in <otherscientificterm_3> . we present the first <method_2> which provably learns the parameters of a mixture of two <method_5> . a key component of our <method_2> is a novel use of <method_0> to learn the <otherscientificterm_6> in both the <otherscientificterm_9> . before this work , even the question of identifiability in the case of a mixture of two <method_5> was unresolved .	8 4 7 12 10 -1 1 10 -1 3 10 -1 2 5 10 -1 0 6 9 11 10 -1 10 -1
Automatic Labeling of Voiced Consonants for Morphological Analysis of Modern Japanese Literature .	automatic labeling of voiced consonant marks ; compulsory voiced consonant marks ; japanese literary text ; binary classification problem ; voiced consonant mark ; annotated corpus ; meiji era ; literary japanese ; pre-processing step ; pointwise prediction ; training corpus ; morphological analysis ; morphological analyzers ; surface information ; dictionary-based approach ; learning	<task> <material> <material> <task> <material> <material> <material> <material> <method> <method> <material> <task> <method> <otherscientificterm> <method> <task>	8 0 11 ; 6 2 2 ; 8 1 14 ; 9 4 14	since the present-day japanese use of <material_4> had established in the <material_6> , modern <material_2> written in the <material_6> often lacks <material_1> . this deteriorates the performance of <method_12> using ordinary dictionary . in this paper , we propose an approach for <task_0> for modern <material_7> . we formulate the <task_0> into a <task_3> . our point-wise prediction method uses as its feature set only <otherscientificterm_13> about the surrounding character strings . as a consequence , <material_10> is easy to obtain and maintain because we can exploit a partially <material_5> for <task_15> . we compared our proposed method as a <method_8> for <task_11> with a <method_14> , and confirmed that <method_9> out-performs <method_14> by a large margin .	4 6 2 1 18 16 -1 12 16 -1 0 7 16 -1 3 16 -1 13 16 -1 10 5 15 16 -1 17 19 20 16 -1
Bayesian Maximum Margin Principal Component Analysis .	principal component analysis ; weight and penalty parameter ; mean-field variational inference algorithm ; maximum likelihood framework ; supervised dimensionality reduction ; max-margin learning machine ; maximum margin principle ; posterior-regularized bayesian approach ; pca sub-space ; bayesian framework ; max-margin learning ; classification tasks ; predictive subspaces ; posterior	<method> <otherscientificterm> <method> <method> <method> <method> <method> <method> <otherscientificterm> <method> <method> <task> <otherscientificterm> <otherscientificterm>	11 5 7 ; 2 0 13 ; 4 0 12 ; 7 0 8	supervised dimensionality reduction has shown great advantages in finding <otherscientificterm_12> . previous methods rarely consider the popular <method_6> and are prone to overfitting to usually small training data , especially for those under the <method_3> . in this paper , we present a <method_7> to combine <method_0> with the <method_10> . based on the data augmentation idea for <method_10> and the probabilistic interpretation of <method_0> , our <method_7> can automatically infer the <otherscientificterm_1> of <method_5> , while finding the most appropriate <otherscientificterm_8> simultaneously under the <method_9> . we develop a fast <method_2> to approximate the <otherscientificterm_13> . experimental results on various <task_11> show that our <method_7> outperforms a number of competitors .	12 17 14 -1 6 3 14 -1 7 0 10 14 -1 1 5 8 9 18 14 -1 2 13 16 14 -1 15 14 -1
Combining Nearest Neighbor Classifiers Through Multiple Feature Subsets .	forward and backward selection of features ; error correcting output coding ; combining algorithm ; rule learners ; uci repository ; neural networks ; knn classiier ; irrelevant features ; decision trees ; eeective technique ; nn classiiers ; features ; mfs ; classiiers ; bagging ; accuracy	<otherscientificterm> <method> <method> <method> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method> <method> <metric>	3 1 5 ; 5 6 13 ; 7 4 6 ; 14 6 13 ; 10 3 12 ; 8 6 13 ; 11 0 10 ; 14 1 3 ; 8 1 3 ; 3 6 13 ; 11 0 12	combining multiple <method_13> is an <method_9> for improving <metric_15> . there are many general combining algorithms , such as <method_14> or <method_1> , that signiicantly improve <method_13> like <otherscientificterm_8> , <method_3> , or <method_5> . unfortunately , many combining methods do not improve the nearest neighbor classiier . in this paper , we present <method_12> , a <method_2> designed to improve the <metric_15> of the nearest neighbor -lrb- nn -rrb- classiier . <method_12> combines multiple <method_10> each using only a random subset of <otherscientificterm_11> . the experimental results are encouraging : on 25 datasets from the <material_4> , <method_12> sig-niicantly improved upon the nn , k nearest neighbor -lrb- knn -rrb- , and <method_10> with <otherscientificterm_0> . <method_12> was also robust to corruption by <otherscientificterm_7> compared to the <method_6> . finally , we show that <method_12> is able to reduce both bias and variance components of error .	13 9 15 16 -1 14 1 8 3 5 17 18 20 22 24 25 26 16 -1 16 -1 12 2 16 -1 10 11 21 23 27 16 -1 4 16 -1 0 19 16 -1 7 6 16 -1
An Unsupervised Bayesian Modelling Approach for Storyline Detection on News Articles .	dynamic storyline detection model ; large scale news corpus ; unsupervised bayesian model ; construction of storylines ; structured representations ; hierarchical structures ; news stories ; storyline detection ; news articles ; storyline generation ; storyline	<method> <material> <method> <task> <otherscientificterm> <otherscientificterm> <material> <task> <material> <task> <otherscientificterm>	1 5 0 ; 2 0 4 ; 5 0 9 ; 8 0 7	storyline detection from <material_8> aims at summarizing events described under a certain news topic and revealing how those events evolve over time . it is a difficult task because it requires first the detection of events from <material_8> published in different time periods and then the <task_3> by linking events into coherent <material_6> . moreover , each <otherscientificterm_10> has different <otherscientificterm_5> which are dependent across epochs . existing approaches often ignore the dependency of <otherscientificterm_5> in <task_9> . in this paper , we propose an <method_2> , called <method_0> , to extract <otherscientificterm_4> and evolution patterns of storylines . the proposed <method_0> is evaluated on a <material_1> . experimental results show that our proposed <method_0> outperforms several baseline approaches .	8 15 11 -1 3 6 11 -1 10 5 11 -1 9 14 11 -1 2 0 4 13 11 -1 12 11 -1 1 11 -1
Active Surveying : A Probabilistic Approach for Identifying Key Opinion Leaders .	active surveying method ; information gathering process ; data acquisition ; partial knowledge ; opinion leaders ; secondary data ; medical field ; opinion leaders	<method> <task> <task> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm>	5 1 3 ; 0 0 4 ; 3 0 0 ; 5 0 0	opinion leaders play an important role in influencing people 's beliefs , actions and behaviors . although a number of methods have been proposed for identifying influentials using secondary sources of information , the use of primary sources , such as surveys , is still favored in many domains . in this work we present a new <method_0> which combines <material_5> with <otherscientificterm_3> from primary sources to guide the <task_1> . we apply our proposed <method_0> to the problem of identifying key <otherscientificterm_4> in the <material_6> , and show how we are able to accurately identify the <otherscientificterm_4> while minimizing the amount of primary data required , which results in significant cost reduction in <task_2> without sacrificing its integrity .	8 -1 8 -1 0 5 3 1 9 11 12 8 -1 4 6 10 8 -1
Consistent Knowledge Discovery from Evolving Ontologies .	-lrb- description logics -rrb- reasoning ; incomplete and dynamic data ; representative association semantic rules ; semantics of data ; real world applications ; inductive learning ; data incompleteness ; deductive reasoning ; consistent knowledge	<method> <material> <otherscientificterm> <otherscientificterm> <task> <method> <metric> <method> <otherscientificterm>	7 1 5	deductive reasoning and <method_5> are the most common approaches for deriving knowledge . in <task_4> when data is dynamic and incomplete , especially those exposed by sensors , reasoning is limited by dynamics of data while learning is biased by <metric_6> . therefore discovering <otherscientificterm_8> from <material_1> is a challenging open problem . in our approach the <otherscientificterm_3> is captured through ontologies to empower learning -lrb- mining -rrb- with <method_0> . consistent knowledge discovery is achieved by applying generic , significative , <otherscientificterm_2> . the experiments have shown scalable , accurate and <otherscientificterm_8> discovery with data from dublin .	5 10 9 -1 4 6 9 -1 8 1 9 -1 3 0 9 -1 2 9 -1 7 9 -1
The complex Double Gaussian distribution .	independent complex gaussian random variables ; doubly-infinite summation of terms ; blind tr detection systems ; monte carlo simulations ; time reversal scenario ; double gaussian distribution ; neyman-pearson optimal detector ; theoretical analysis ; summation terms ; near-optimal detection	<otherscientificterm> <otherscientificterm> <method> <material> <otherscientificterm> <method> <method> <method> <otherscientificterm> <method>	7 1 3 ; 6 0 2	-- we present the complex <method_5> that describes the product of two independent , non-zero mean , complex gaussian random variables , a <otherscientificterm_1> . this distribution is useful in a wide array of problems . we discuss its application to <method_2> by deriving the <method_6> when the channel is modeled as the product of two <otherscientificterm_0> , such as in a <otherscientificterm_4> . we show that <method_9> performance can be achieved with as few as 25 <otherscientificterm_8> . <method_7> and <material_3> illustrate our results .	5 1 10 -1 10 -1 2 6 0 4 12 10 -1 9 8 7 10 -1 3 11 10 -1
Manifold regularized deep neural networks .	automatic speech recognition tasks ; asr word error rates ; deep neural networks ; manifold based locality preserving constraints ; manifold learning based regularization framework ; hybrid acoustic mod-eling scenarios ; discriminative feature extraction ; low dimensional manifold ; speech feature vectors ; estimating network parameters ; bottleneck dnn architecture ; regularization approaches ; speech-in-noise task ; loss functions ; dnn training ; mani-fold constraints ; feature extraction ; dnn-bottleneck networks ; optimization procedure ; tandem configuration	<task> <metric> <method> <otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm> <task> <method> <method> <task> <method> <task> <otherscientificterm> <task> <method> <method> <otherscientificterm>	12 0 1 ; 17 0 12 ; 17 0 1 ; 13 1 11 ; 10 0 16 ; 18 0 9 ; 4 0 14 ; 6 1 5 ; 2 0 0	deep neural networks -lrb- dnns -rrb- have been successfully applied to a variety of <task_0> , both in <task_6> and <task_5> . the development of improved <method_13> and <method_11> have resulted in consistent reductions in <metric_1> . this paper presents a <method_4> for <task_14> . the associated techniques attempt to preserve the underlying <otherscientificterm_7> based relationships amongst <otherscientificterm_8> as part of the <method_18> for <task_9> . this is achieved by imposing <otherscientificterm_3> on the outputs of the network . the techniques are presented in the context of a <method_10> for <task_16> in a <otherscientificterm_19> . the <metric_1> obtained using these networks is evaluated on a <task_12> and compared to that obtained using <method_17> trained without <otherscientificterm_15> .	0 6 5 28 29 20 -1 13 11 1 24 20 -1 4 14 27 20 -1 7 8 18 9 26 20 -1 3 20 -1 10 16 19 25 20 -1 21 22 23 20 -1
Google 's cross-dialect Arabic voice search .	commercial automatic speech recognition product ; united arab emirates ; word error rate ; diacritized vs. non-diacritized text ; voice control ; voice search ; arabic dialects ; saudi arabia ; arabic ; dictation ; recognizers	<method> <material> <metric> <material> <task> <task> <material> <material> <material> <task> <method>	9 1 4 ; 7 1 1 ; 5 1 9 ; 10 0 6	we present a large scale effort to build a <method_0> for <material_8> . our goal is to support <task_5> , <task_9> , and <task_4> for the general arabic-speaking public , including support for multiple <material_6> . we describe our <method_0> and compare <method_10> for five <material_6> , with the potential to reach more than 125 million people in egypt , jordan , lebanon , <material_7> , and the <material_1> . we compare systems built on <material_3> . we also conduct cross-dialect experiments , where we train on one dialect and test on the others . our average <metric_2> is 24.8 % for <task_5> .	0 8 11 -1 5 9 4 6 12 14 11 -1 10 7 1 13 15 11 -1 3 11 -1 11 -1 2 11 -1
Why speech recognizers make errors ? a robustness view .	stationary signal-to-noise ratio ; tracking time-varying or nonstationary extraneous events ; natural language dialog services ; data selection algorithm ; field data ; background noise ; problematic speech ; robustness perspective ; recognition errors ; music	<metric> <task> <task> <method> <material> <otherscientificterm> <material> <otherscientificterm> <task> <material>	9 1 5 ; 2 0 4 ; 2 0 7 ; 4 0 7	the performance of large vocabulary speech recognizers often varies depending on the input speech and the quality of the trained models . the particular attributes that cause <task_8> are a research area that has not been well studied . this paper addresses this issue from a <otherscientificterm_7> using a large amount of <material_4> collected from <task_2> . in particular , we present a method for <task_1> , such as <material_9> , <otherscientificterm_5> , etc. . we show that this measure is a better predictor of <task_8> than a standard measure of <metric_0> . combining the two measures provides a <method_3> for detecting <material_6> .	10 -1 8 10 -1 7 4 2 12 13 14 10 -1 1 9 5 11 10 -1 0 10 -1 3 10 -1
Hierarchical Bayesian learning for electrical transient classification .	markov-chain monte carlo algorithm ; posterior distributions of the features ; real-world electrical transients signals ; non-intrusive load monitoring ; class-specific distribution parameters ; supervised signal classification ; hierarchical bayesian method ; feature extraction step ; electrical transient classification ; class-specific posterior distribution ; learning step ; learning signals ; features	<method> <otherscientificterm> <material> <task> <otherscientificterm> <task> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	8 0 3 ; 6 0 5 ; 7 1 10 ; 0 0 1	this paper addresses the problem of the <task_5> , by using a <method_6> . each signal is characterized by a set of parameters , the <otherscientificterm_12> , which are estimated from a set of <otherscientificterm_11> . moreover , these parameters are distributed according to a <otherscientificterm_9> which allows one to capture the variability of the <otherscientificterm_12> within the same class . within the <method_6> , the <method_7> and the <method_10> can be performed jointly . unfortunately , the estimation of the <otherscientificterm_4> requires the computation of intractable multi-dimensional integrals . then a <method_0> is used to sample the <otherscientificterm_1> over all the training signals of each class . an application to <task_8> for <task_3> is introduced . simulations over <material_2> are driven and show the capacity of the proposed <method_0> to discriminate two classes of transients .	5 6 15 13 -1 12 11 13 -1 9 13 -1 7 10 16 13 -1 4 13 -1 0 1 17 13 -1 14 13 -1 8 3 13 -1
Collusion-resistant fingerprinting for multimedia .	o -lrb- ‚àö n -rrb- bits ; anti-collusion codes ; binary code vectors ; block matrix structure ; antipodal cdma-type watermarking ; digital fingerprinting ; trace colluders ; detection capability ; digital fingerprints ; combinatorial designs ; computational complexity ; designing fingerprints ; correlation contributions ; multimedia content ; watermarking techniques ; collusion ; colluders ; images ; watermarks	<otherscientificterm> <method> <otherscientificterm> <method> <method> <task> <method> <metric> <material> <method> <metric> <task> <otherscientificterm> <material> <method> <otherscientificterm> <method> <material> <otherscientificterm>	17 6 13 ; 3 0 1 ; 14 0 5 ; 12 0 4	digital fingerprinting is an effective method to identify users who might try to redistribute <material_13> , such as <material_17> and video . these <task_5> are typically embedded into the content using <method_14> that are designed to be robust to a variety of attacks . a cheap and effective attack against such <material_8> is <otherscientificterm_15> , where several differently marked copies of the same content are averaged or combined to disrupt the underlying fingerprint . in this paper , we study the problem of <task_11> that can withstand <otherscientificterm_15> , yet <method_6> . since , in <method_4> , the <otherscientificterm_12> only decrease where <otherscientificterm_18> differ , by constructing <otherscientificterm_2> where any subset of k or fewer of these vectors have unique overlap , we may identify groups of k or less <method_16> . our construction of such <method_1> uses the theory of <method_9> , and for n users requires <otherscientificterm_0> . further , we explore a <method_3> for the <method_1> that reduces the <metric_10> for identifying <method_16> and improves the <metric_7> when <method_16> belong to the same subgroup .	13 17 20 19 -1 5 14 22 19 -1 8 15 19 -1 11 6 19 -1 4 12 23 19 -1 18 2 16 19 -1 1 9 0 21 19 -1
Online Streaming Feature Selection .	online streaming feature selection ; streaming feature selection algorithms ; standard feature selection methods ; fast-osfs algorithm ; selection efficiency ; candidate features ; streaming features ; feature relevance ; features ; compactness ; accuracy	<task> <method> <method> <method> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <metric> <metric>	4 5 3 ; 10 5 1	we study an interesting and challenging problem , <task_0> , in which the size of the feature set is unknown , and not all <otherscientificterm_8> are available for learning while leaving the number of observations constant . in this problem , the <otherscientificterm_5> arrive one at a time , and the learner 's task is to select a '' best so far '' set of <otherscientificterm_8> from <otherscientificterm_6> . <method_2> can not perform well in this scenario . thus , we present a novel framework based on <otherscientificterm_7> . under this framework , a promising alternative method , online streaming feature selection -lrb- osfs -rrb- , is presented to online select strongly relevant and non-redundant <otherscientificterm_8> . in addition to osfs , a faster <method_3> is proposed to further improve the <metric_4> . experimental results show that our algorithms achieve more <metric_9> and better <metric_10> than existing <method_1> on various datasets .	0 8 11 -1 5 6 2 11 -1 11 -1 7 11 -1 11 -1 12 11 -1 3 4 13 11 -1
Distributed Dual Averaging In Networks .	local -lrb- possibly nonsmooth -rrb- convex functions ; dual averaging of subgradients ; theoretical lower bounds ; spectral gap ; decentralized optimization ; convergence rates ; network size ; optimization algorithm ; distributed algorithms ; local computation ; network structure ; global objective ; communication constraints ; iterations ; topology	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <metric> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	10 0 12 ; 1 0 8 ; 6 1 14 ; 4 0 11	the goal of <method_4> over a network is to optimize a <otherscientificterm_11> formed by a sum of <otherscientificterm_0> using only <otherscientificterm_9> and communication . we develop and analyze <method_8> based on <otherscientificterm_1> , and provide sharp bounds on their <metric_5> as a function of the <otherscientificterm_6> and <otherscientificterm_14> . our analysis clearly separates the convergence of the <method_7> itself from the effects of <otherscientificterm_12> arising from the <otherscientificterm_10> . we show that the number of <otherscientificterm_13> required by our algorithm scales inversely in the <otherscientificterm_3> of the network . the sharpness of this prediction is confirmed both by <otherscientificterm_2> and simulations for various networks .	4 11 0 9 19 15 -1 8 1 5 6 14 17 18 15 -1 7 12 10 16 15 -1 13 3 15 -1 2 15 -1
Higher Order Whitening of Natural Images .	power law -rrb- linear processing ; second order spatial correlations ; higher order whitening ; linear processing ; non-linear method ; natural images ; power law ; power spectrum ; con-volution ; redundancy ; images ; coefficients ; image	<method> <otherscientificterm> <otherscientificterm> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm>	8 6 3 ; 8 6 0	natural <material_10> are approximately scale invariant resulting in long range statistical regularities that typically obey a <method_6> . for example , <material_10> have considerable regularity in their <otherscientificterm_1> as measured by the <otherscientificterm_7> . processing <material_10> to remove these expected correlations is known as whitening an <otherscientificterm_12> . because the expected value of the <otherscientificterm_7> has a regular form -lrb- a <method_0> such as <otherscientificterm_8> can be used to whiten an <otherscientificterm_12> . after whitening an <otherscientificterm_12> , higher order regularities that can not be removed with <method_3> still exist in the form of correlations in the magnitude . in this paper it is shown that these correlations also obey a <method_6> and a <method_4> is used to remove them , a process referred to as <otherscientificterm_2> . the method is invertible demonstrating that while <otherscientificterm_9> is removed no information is lost . experiments are given showing that after <otherscientificterm_2> the <otherscientificterm_11> can be severely quantized yet a good reconstruction is possible despite the nonlinearities .	10 6 13 -1 1 7 13 -1 12 13 -1 0 8 14 15 13 -1 3 13 -1 13 -1 4 2 13 -1 9 13 -1
Insights into machine lip reading .	active appearance models ; professional human lip-readers ; linear predictive trackers ; signal processing challenges ; connected words ; human speech ; viseme accuracy ; multiview dataset ; automatic systems ; computer lipreading ; human lip-readers ; fallibil-ity	<method> <method> <method> <task> <otherscientificterm> <material> <metric> <method> <method> <task> <method> <otherscientificterm>	0 1 10 ; 2 1 0 ; 9 6 3 ; 6 5 8 ; 4 0 7 ; 0 0 8 ; 2 0 8 ; 2 1 10 ; 4 0 8	computer lipreading is one of the great <task_3> . not only is the signal noisy , it is variable . however it is almost unknown to compare the performance with <method_10> . partly this is because of the paucity of <method_10> and partly because most <method_8> only handle data that are trivial and therefore not representative of <material_5> . here we generate a <method_7> using <otherscientificterm_4> that can be analysed by an <method_8> , based on <method_2> and <method_0> , and <method_10> . the <method_8> we devise has a <metric_6> of ‚âà 46 % which is comparable to poor <method_1> . however , unlike <method_10> our <method_8> is good at guessing its <otherscientificterm_11> .	3 15 12 -1 12 -1 10 12 -1 8 5 12 -1 7 4 2 0 13 14 17 18 19 20 21 12 -1 6 1 16 12 -1 12 -1
Context-aware Argumentative Relation Mining .	context-aware argumentative relation mining ; argumentative relation classification tasks ; argument mining methods ; contex-tual features ; argumentative relations ; student essays ; writing topics ; context	<method> <task> <method> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm>	3 0 2 ; 7 0 4 ; 0 0 0 ; 6 0 0	context is crucial for identifying <otherscientificterm_4> in text , but many <method_2> make little use of <otherscientificterm_3> . this paper presents <method_0> that uses <method_0> extracted from <material_6> as well as from windows of context sentences . experiments on <material_5> demonstrate that the proposed <method_0> improve predictive performance in two <task_1> .	4 2 3 9 10 8 -1 0 6 11 12 8 -1 5 1 7 8 -1
Mondrian Forests : Efficient Online Random Forests .	ensembles of random decision trees ; distribution of online mondrian forests ; computation vs accuracy tradeoff ; randomized decision trees ; real-world prediction tasks ; online random forests ; random forest variants ; batch mondrian forests ; online methods ; machine learning ; mondrian processes ; mondrian forests ; incremental/online fashion ; batch counterpart ; random forests ; random forests ; statistics ; classification	<otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <task> <otherscientificterm> <method> <otherscientificterm> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <task>	14 0 4 ; 10 0 0 ; 1 4 7	ensembles of <otherscientificterm_3> , usually referred to as <otherscientificterm_15> , are widely used for <task_17> and regression tasks in <task_9> and <material_16> . <otherscientificterm_14> achieve competitive predictive performance and are computationally efficient to train and test , making <otherscientificterm_14> excellent candidates for <task_4> . the most popular <method_6> -lrb- such as breiman 's random forest and extremely randomized trees -rrb- operate on batches of training data . <method_8> are now in greater demand . existing <otherscientificterm_5> , however , require more training data than their <otherscientificterm_13> to achieve comparable predictive performance . in this work , we use <method_10> -lrb- roy and teh , 2009 -rrb- to construct <otherscientificterm_0> we call <otherscientificterm_11> . <otherscientificterm_11> can be grown in an <method_12> and remarkably , the <otherscientificterm_1> is the same as that of <otherscientificterm_7> . <otherscientificterm_11> achieve competitive predictive performance comparable with existing <otherscientificterm_5> and periodically retrained batch <otherscientificterm_15> , while being more than an order of magnitude faster , thus representing a better <metric_2> .	3 15 17 9 16 14 18 -1 4 19 18 -1 6 8 18 -1 18 -1 5 13 18 -1 10 20 18 -1 0 11 21 18 -1 12 1 7 18 -1
Voicebuilder : a framework for automatic speech application development .	speech user interface specialists ; mixed initiative dialogue strategies ; stand-alone gui application ; speech ui ; markup language ; automatic coding ; system initiative ; speech applications ; suiml documents ; web-based interface ; voicexml code ; e-mail reader ; voice toolkits ; flight reservations ; suiml ; macro-processor ; voicebuilder ; ui	<method> <method> <method> <material> <otherscientificterm> <task> <method> <task> <material> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <method> <method> <method> <method>	6 1 1 ; 13 6 7 ; 2 1 9 ; 8 0 15 ; 11 6 7 ; 15 0 5 ; 16 0 7 ; 8 0 10 ; 15 0 10 ; 11 1 13	in this paper we present <method_16> , a <method_16> for automating the process of developing <task_7> . our <method_16> allows <method_0> to introduce <method_17> 's in two ways : a <method_2> , and a <otherscientificterm_9> ; in which <material_3> 's are stored in a <otherscientificterm_4> previously proposed called <method_14> -lsb- 1 -rsb- , supporting either <method_6> or <method_1> . for <task_5> , we propose an algorithm based on a <method_15> that generates <otherscientificterm_10> by parsing <material_8> . this algorithm was designed to generate various kinds of code with a minimal initial effort . we performed experiments considering both <method_6> and <method_1> with three different <task_7> : auto-attendant , <material_11> , and <otherscientificterm_13> . <method_16> is very useful for building <task_7> in new domains , requires no programming effort and could be incorporated into several <method_12> .	16 7 18 -1 0 17 2 9 3 4 14 6 1 21 18 -1 5 15 10 8 22 24 26 27 18 -1 18 -1 19 20 23 28 18 -1 11 13 25 18 -1
Exploiting global connectivity constraints for reconstruction of 3D line segments from images .	automatic 3d reconstruction of man-made environments ; reconstruction of straight 3d line segments ; synthetic and real scenes ; global topologi-cal constraints ; independent reconstructions ; ground truth ; partial occlusion ; image noise ; base images ; 2d images ; outliers	<task> <task> <material> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material> <otherscientificterm>	7 1 6	given a set of <material_9> , we propose a novel approach for the <task_1> that represent the underlying geometry of static 3d objects in the scene . such an algorithm is especially useful for the <task_0> . the main contribution of our approach is the generation of an improved <task_1> by imposing <otherscientificterm_3> given by connections between neighbouring lines . additionally , our approach does not employ explicit line matching between views , thus making it more robust against <otherscientificterm_7> and <otherscientificterm_6> . furthermore , we suggest a technique to merge <method_4> , that are generated from different <material_8> , which also helps to remove <otherscientificterm_10> . the proposed algorithm is evaluated on <material_2> by comparison with <otherscientificterm_5> .	9 1 11 -1 0 11 -1 3 11 -1 7 6 12 11 -1 4 8 11 -1 10 11 -1
Actions ~ Transformations .	high-level feature space ; action recognition datasets ; cross-category generalization ; act dataset ; video representation ; siamese network ; deep learning ; ucf101 ; hmdb51	<otherscientificterm> <material> <task> <material> <method> <method> <method> <material> <material>	7 6 1 ; 7 1 8 ; 8 6 1 ; 6 0 4 ; 2 5 5 ; 1 5 5	what defines an action like '' kicking ball '' ? we argue that the true meaning of an action lies in the change or transformation an action brings to the environment . in this paper , we propose a novel representation for actions by modeling an action as a transformation which changes the state of the environment before the action happens -lrb- precondition -rrb- to the state after the action -lrb- effect -rrb- . motivated by recent advancements of <method_4> using <method_6> , we design a <method_5> which models the action as a transformation on a <otherscientificterm_0> . we show that our <method_5> gives improvements on standard <material_1> including <material_7> and <material_8> . more importantly , our <method_5> is able to generalize beyond learned action categories and shows significant performance improvement on <task_2> on our new <material_3> .	9 -1 9 -1 4 6 5 0 9 -1 13 9 -1 1 7 8 10 11 12 15 9 -1 2 3 14 9 -1
Space Kernel Analysis .	space kernel analysis ; weighted least squared cost function ; radial basis function network ; general regression neural network ; nonparametric modeling techniques ; space kernel matrix ; nonparametric modeling technique ; kernel-based learning methods ; similarity based modeling ; weight matrix ; bias/variance dilemma ; kernel regression ; accuracy ; robustness	<method> <otherscientificterm> <method> <method> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <metric> <metric>	3 1 2 ; 3 1 8 ; 11 1 8 ; 0 4 7 ; 11 1 3 ; 0 1 4 ; 11 1 2 ; 12 5 7 ; 0 6 6 ; 8 1 2 ; 0 0 1	in this paper , we propose a novel <method_6> , namely <method_0> , as a result of the definition of the space kernel . we analyze the uncertainty of <method_0> and show that <method_0> is subjected to the <otherscientificterm_10> . nevertheless , we demonstrate that , by a proper choice of the <method_5> , <method_0> is able to balance between the <metric_13> and <metric_12> and hence outperforms other <method_7> . the cost function of <method_0> is derived , and it proves that <method_0> minimizes the <otherscientificterm_1> whose <otherscientificterm_9> is diagonal and determined by the <method_5> . the parallels between <method_0> and several other <method_4> are examined . study shows that the traditional <method_11> , <method_3> , <method_8> and <method_2> are examples of <method_0> with specified space kernel matrices .	6 0 23 14 -1 10 14 -1 5 13 12 7 18 22 14 -1 1 9 25 14 -1 20 14 -1 4 15 16 17 19 21 24 14 -1
A Metalogic Programming Approach to Reasoning about Time in Knowledge Bases .	historical time and belief time ; information models reality/belief time ; theory of time ; notions of time ; knowledge base applications ; theorem prover ; temporal reasoning ; legal reasoning ; historical time ; fold/unfold transformations ; prolog program ; multi-agent reasoning ; knowledge bases ; metalogic program ; logic ; metalanguage	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <task> <otherscientificterm> <otherscientificterm> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm>	13 0 4 ; 15 0 2 ; 6 0 4 ; 10 0 13 ; 13 0 6 ; 14 0 2 ; 9 0 13 ; 12 2 3	the problem of representing and reasoning about two <otherscientificterm_3> that are relevant in the context of <material_12> is addressed . these are called <otherscientificterm_0> respectively . <otherscientificterm_8> denotes the time for which <otherscientificterm_1> denotes the time lor which a belief is held -lrb- by an agent or a knowledge base -rrb- . we formalize an appropriate <otherscientificterm_2> using <otherscientificterm_14> as a <otherscientificterm_15> . we then present a <method_13> derived from this <otherscientificterm_2> through <otherscientificterm_9> . the <method_13> enables the <method_6> required for <task_4> to be carried out efficiently . the <method_13> is directly implementable as a <method_10> and hence the need for a more complex <method_5> is obviated . the <method_13> is applicable for such <task_4> as legislation and <task_7> and in the context of <method_11> where an agent reasons about the beliefs of another agent .	3 12 24 16 -1 0 8 16 -1 1 16 -1 2 14 15 18 22 16 -1 13 9 23 16 -1 6 4 19 21 16 -1 10 20 16 -1 5 17 16 -1
Beyond Doddington menagerie , a first step towards .	speaker verification systems ; open source system ; nist-sre 2008 ; voice samples ; speaker factor ; speaker models ; error rate ; accuracy	<method> <method> <material> <material> <method> <method> <metric> <metric>	3 0 5 ; 6 5 0	during the last decade , <method_0> have shown significant progress and have reached a level of performance and <metric_7> that support their utilization in practical applications , including the forensic ones . this context emphasizes the importance of a deeper analysis of the <method_0> 's performance over basic <metric_6> . in this paper , the influence of the speaker -lrb- his/her ` voice ' -rrb- on the performance is studied and the effect of the model -lrb- the training excerpt -rrb- is investigated . the experimental setup is based on an <method_1> and the experimental context of <material_2> . the results confirm that the lower performances are obtained from a reduced number of speakers . even more than <method_4> , <method_0> performances are shown to be highly dependant on the <material_3> used to train <method_5> .	0 7 8 -1 6 10 8 -1 8 -1 1 2 8 -1 8 -1 9 8 -1
Musical Instrument Classification using Non-Negative Matrix Factorization Algorithms and Subset Feature Selection .	automatic classification of individual musical instrument sounds ; non-negative matrix factorization ; sound classification applications ; mel-frequency cepstral coefficient ; mpeg-7 descriptors ; audiospectrumflatness descrip-tor ; audiospectrumspread descriptors ; perceptual features ; branch-and-bound search ; nmf algorithms ; discriminant nmf ; feature subsets ; features ; classifiers ; classification ; accuracy	<task> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <task> <metric>	3 1 5 ; 5 1 6 ; 1 0 13 ; 12 0 14 ; 7 0 2	in this paper , a class of algorithms for <task_0> is presented . several <otherscientificterm_7> used in <task_2> as well as <material_4> were measured for 300 sound recordings consisting of 6 different musical instrument classes . subsets of the feature set are selected using <method_8> , obtaining the most suitable <otherscientificterm_12> for <task_14> . a class of <method_13> is developed based on the <method_1> . the standard <method_1> is examined as well as its modifications : the local , the sparse , and the <method_10> . the experimental results compare <otherscientificterm_11> of varying sizes alongside the various <method_9> . it has been found that a subset containing the mean and the variance of the first <otherscientificterm_3> and the <otherscientificterm_5> along with the means of the audiospectrumenvelope and the <otherscientificterm_6> when is fed to a standard <method_1> yields an <metric_15> exceeding 95 % .	0 16 -1 7 2 4 21 16 -1 8 12 14 20 16 -1 13 1 19 16 -1 10 16 -1 11 9 16 -1 17 18 16 -1
Near Real-Time Reliable Stereo Matching Using Programmable Graphics Hardware .	middlebury stereo vision research website ; reliability-based dynamic programming algorithm ; near-real-time stereo matching technique ; dynamic programming based technique ; dense disparity maps ; programmable graphics hardware ; graph cuts approaches ; semi-dense disparity maps ; middlebury stereo datasets ; dynamic programming passes ; computation time ; variable window ; reference images ; processing speed ; error rate ; accuracy	<material> <method> <method> <method> <otherscientificterm> <task> <method> <method> <material> <method> <otherscientificterm> <otherscientificterm> <material> <metric> <metric> <metric>	11 1 6 ; 6 6 3	a <method_2> is presented in this paper , which is based on the <method_1> we proposed earlier . the new algorithm can generate <method_7> using only two <method_9> , while our previous approach requires 20 ~ 30 passes . we also implement the algorithm on <task_5> , which further improves the <metric_13> . the experiments on the four <material_8> show that the new algorithm can produce dense -lrb- > 85 % of the pixels -rrb- and reliable -lrb- <metric_14> < 0.3 % -rrb- matches in near real-time -lrb- 0.05 ~ 0.1 sec -rrb- . if needed , it can also be used to generate <otherscientificterm_4> . based on the evaluation conducted by the <material_0> , the new algorithm is ranked between the <otherscientificterm_11> and the <method_6> and currently is the most accurate <method_3> . when more than one <material_12> are available , the <metric_15> can be further improved with little extra <otherscientificterm_10> .	2 1 16 -1 7 9 16 -1 5 13 16 -1 8 14 16 -1 16 -1 4 17 18 16 -1 0 11 6 3 16 -1
Multi-Step Stochastic ADMM in High Dimensions : Applications to Sparse Optimization and Matrix Decomposition .	o rate ; natural noise models ; stochastic admm method ; tight convergence guarantees ; general loss function ; sparse optimization problem ; matrix decomposition problems ; multi-step version ; matrix decomposition ; convergence rate ; t steps ; multi-step admm ; high-dimensional problems ; optimization problem ; loss function ; s-sparse problems ; minimax rate ; multi-block setting ; sparse optimization ; multi-block admm ; scaling ; matrix	<method> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <method> <otherscientificterm> <metric> <otherscientificterm> <method> <task> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	4 0 5 ; 16 5 2 ; 14 3 13 ; 2 0 12 ; 18 1 6 ; 3 0 19	in this paper , we consider a <method_7> of the <method_2> with efficient guarantees for <task_12> . we first analyze the simple setting , where the <task_13> consists of a <otherscientificterm_14> and a single regularizer -lrb- e.g. <otherscientificterm_18> -rrb- , and then extend to the <otherscientificterm_17> with multiple regularizers and multiple variables -lrb- e.g. <otherscientificterm_8> into sparse and low rank components -rrb- . for the <task_5> , our <method_2> achieves the <metric_16> of o -lrb- s log d/t -rrb- for <otherscientificterm_15> in d dimensions in <otherscientificterm_10> , and is thus , unimprovable by any <method_2> up to constant factors . for the <task_5> with a <otherscientificterm_4> , we analyze the <method_11> with multiple blocks . we establish <method_0> and efficient <method_20> as the size of <otherscientificterm_21> grows . for <method_1> -lrb- e.g. independent noise -rrb- , our <metric_9> is minimax-optimal . thus , we establish <otherscientificterm_3> for <otherscientificterm_19> in high dimensions . experiments show that for both <otherscientificterm_18> and <task_6> , our <method_2> outperforms the state-of-the-art methods .	7 2 12 26 22 -1 13 14 18 17 8 25 22 -1 5 16 15 10 24 22 -1 23 22 -1 4 11 22 -1 0 20 21 22 -1 1 9 28 22 -1 3 19 27 22 -1
A comparative study of some discriminative feature reduction algorithms on the AURORA 2000 and the daimlerchrysler in-car ASR tasks .	linear discriminant analysis mapping ; neural nets ; aurora 2000 digit task ; approximating class posterior probabilities ; poorly trained parameters ; consecutive feature frames ; feature reduction problem ; contextual information ; lda classes ; nn topology ; acoustic modelling ; in-car task ; nn-based approaches ; processing time ; asr ; feature ; hmm-states	<method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <method> <task> <method> <metric> <method> <otherscientificterm> <otherscientificterm>	13 3 10 ; 11 5 1 ; 11 5 12	a common practice in <method_14> to add <otherscientificterm_7> is to append <otherscientificterm_5> in a single large <otherscientificterm_15> vector . however , this increases the <metric_13> in the <method_10> and may lead to <otherscientificterm_4> . a possible solution is to use a <method_0> to reduce the dimensionality of the <otherscientificterm_15> , but this is not optimal , at least in the case where the <otherscientificterm_8> are <otherscientificterm_16> . it is shown in this paper that the <task_6> is essentially a problem of <otherscientificterm_3> . these can be approximated using <otherscientificterm_1> . some approaches using different choices for the classes and <method_9> are presented and tested on the <material_2> and on our <task_11> . results on <otherscientificterm_1> show a significant performance increase compared to <otherscientificterm_1> , but none of the <method_12> outperforms <otherscientificterm_1> on our <task_11> .	14 7 5 15 17 -1 13 10 4 18 17 -1 0 8 16 17 -1 6 3 17 -1 1 17 -1 9 17 -1 2 11 19 20 17 -1
The AMI System for the Transcription of Speech in Meetings .	discriminative and speaker adaptive training ; nist rt '06 evaluations ; heteroscedastic linear discriminant analysis ; maximum likelihood linear regression ; vocal tract length normalisation ; phone posterior based features ; word error rate ; ami transcription system ; channel adaptive training ; meeting data ; generic techniques ; domain adaptation ; web-data collection ; cross-talk suppression ; beam-forming ; segmentation	<method> <metric> <method> <method> <method> <otherscientificterm> <metric> <method> <method> <material> <method> <task> <task> <task> <method> <task>	13 1 14 ; 0 6 10 ; 13 1 11 ; 15 1 13 ; 14 1 11 ; 15 1 11 ; 12 1 8 ; 2 1 3 ; 5 6 10 ; 6 5 7 ; 4 1 3 ; 4 1 2 ; 2 1 5 ; 2 6 10 ; 3 1 5 ; 14 1 12 ; 10 3 7 ; 1 5 7 ; 0 3 7 ; 2 3 7 ; 15 1 14 ; 0 1 4 ; 3 6 10 ; 11 1 12 ; 3 3 7 ; 11 1 8 ; 4 6 10 ; 0 1 2 ; 5 3 7	this paper describes the <method_7> for speech in meetings developed in collaboration by five research groups . the <method_7> includes <method_10> such as <method_0> , <method_4> , <method_2> , <method_3> , and <otherscientificterm_5> , as well as techniques specifically designed for <material_9> . these include <task_15> and <task_13> , <method_14> , <task_11> , <task_12> , and <method_8> . the <method_7> was improved by more than 20 % relative in <metric_6> compared to our previous <method_7> and was usd in the <metric_1> where it was found to yield competitive performance .	7 16 -1 10 0 4 2 3 5 9 18 24 25 27 28 29 30 31 33 35 36 38 39 41 43 44 45 16 -1 15 13 14 11 12 8 17 19 20 21 22 23 32 37 40 42 16 -1 6 1 26 34 16 -1
Polyphase filters - A model for teaching the art of discovery in DSP .	mathematical developments ; polyphase decimation ; mathematical approaches ; dsp topics ; dsp ; interpolation	<otherscientificterm> <task> <method> <material> <method> <task>	1 1 5	by its very nature <method_4> is a mathematically heavy topic and to fully understand it students need to understand the <otherscientificterm_0> underlying <material_3> . however , relying solely on <otherscientificterm_0> often clouds the true nature of the foundation of a result . it is likely that students who master the mathematics may still not truly grasp the key ideas of a topic . furthermore , teaching <material_3> by merely '' going through the mathematics '' deprives students of learning the art of discovery that will make them good researchers . this paper uses the topic of <task_1> and <task_5> to illustrate how it is possible to maintain rigor yet teach using less <method_2> that show students how researchers think when developing new ideas .	4 0 3 6 -1 6 -1 6 -1 6 -1 1 5 7 6 -1
Switching Hypothesized Measurements : A Dynamic Model with Applications to Occlusion Adaptive Joint Tracking .	switching hypothesized measurements model ; multimodal state space probability distributions ; history of measurement data ; tracking multiple objects ; online joint tracking ; dynamic model ; occlusion relationship ; visual occlusions ; hypothesized measurements ; filtering algorithms ; dynamic processes ; propagation	<method> <task> <material> <task> <task> <method> <otherscientificterm> <task> <otherscientificterm> <method> <method> <otherscientificterm>	5 0 3 ; 5 0 1 ; 9 0 4 ; 5 0 7 ; 8 0 5	this paper proposes a <method_5> supporting <task_1> and presents the application of the <method_5> in dealing with <task_7> when <task_3> jointly . for a set of hypotheses , multiple measurements are acquired at each time instant . the <method_5> switches among a set of <otherscientificterm_8> during the <otherscientificterm_11> . two computationally efficient <method_9> are derived for <task_4> . both the <otherscientificterm_6> and state of the objects are recursively estimated from the <material_2> . the <method_0> is generally applicable to describe various <method_10> with multiple alternative measurement methods .	5 1 7 3 13 14 16 12 -1 12 -1 8 11 17 12 -1 9 4 15 12 -1 6 2 12 -1 0 10 12 -1
Effects of Sampling and Compression on Human IRIS Verification .	subsampling and compression of human iris images ; m1 biometric data interchange format ; identity verification systems ; normalized iris images ; radial fourier coefficients ; fourier domain processing ; noise reduction ; identity verification ; rectangular format ; file size ; verification ; compression	<task> <method> <method> <material> <otherscientificterm> <method> <task> <task> <otherscientificterm> <metric> <task> <method>	9 5 1	the resilience of <method_2> to <task_0> is investigated for three high performance iris matching algorithms . for evaluation , 2156 images from 308 eyes are mapped into a <otherscientificterm_8> with 512 pixels circumferentially and 80 radially . for <task_7> , the 48 rows nearest the pupil were taken and the images were subsampled by <method_5> . negligible degradation in <task_10> is observed if at least 171 circumferential and 16 <otherscientificterm_4> are preserved , corresponding to sampling at 342 by 32 pixels . with <method_11> by jpeg 2000 , improved performance is observed down to 0.3 bpp , attributed to <task_6> without significant loss of texture . to ensure that no algorithm is degraded , it is recommended that <material_3> should be exchanged at 512 x 80 pixel resolution , compressed by jpeg 2000 to 0.5 bpp . this achieves a smaller <metric_9> than the proposed <method_1> .	2 0 12 -1 8 12 -1 7 5 12 -1 10 4 12 -1 11 6 12 -1 12 -1 3 13 12 -1
Coupled information-theoretic encoding for face photo-sketch recognition .	inter-modality face recognition approach ; automatic face photo-sketch recognition ; coupled information-theoretic projection tree ; discriminative local face structures ; face sketch database ; feature extraction stage ; quantized feature spaces ; large scale dataset ; classification algorithms ; information-theoretic encoding ; random-ized forest ; feret database ; law enforcement ; mutual information ; face descriptor ; modality gap ; coupled encoding ; features ; photos	<method> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <method> <method> <otherscientificterm> <material> <task> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material>	1 0 12 ; 8 0 15 ; 7 5 0 ; 15 2 5 ; 14 0 3 ; 15 0 0 ; 2 0 16 ; 2 0 10	automatic face photo-sketch recognition has important applications for <task_12> . recent research has fo-cused on transforming <material_18> and sketches into the same modality for matching or developing advanced <method_8> to reduce the <otherscientificterm_15> between <otherscientificterm_17> extracted from <material_18> and sketches . in this paper , we propose a new <method_0> by reducing the <otherscientificterm_15> at the <otherscientificterm_5> . a new <method_14> based on coupled <method_9> is used to capture <otherscientificterm_3> and to effectively match <material_18> and sketches . guided by maximizing the <otherscientificterm_13> between <material_18> and sketches in the <otherscientificterm_6> , the <otherscientificterm_16> is achieved by the proposed <otherscientificterm_2> , which is extended to the <otherscientificterm_10> to further boost the performance . we create the largest <material_4> including sketches of 1 , 194 people from the <material_11> . experiments on this <material_7> show that our <method_0> significantly outper-forms the state-of-the-art methods .	12 20 19 -1 18 8 15 17 21 19 -1 0 5 23 25 19 -1 14 9 3 24 19 -1 13 6 16 2 26 27 19 -1 10 19 -1 4 11 22 19 -1
Learning Exemplar-Based Categorization for the Detection of Multi-View Multi-Pose Objects .	multi-view multi-pose people and vehicle data ; manually clustering multi-view multi-pose training data ; adaboost-based object detection framework ; multi-view multi-pose object detection ; nested adaboost loops ; discriminative shape-based exemplars ; real-time implementation ; labeling ambiguity ; two-class classifiers ; discriminative features ; inner adaboost ; objective function ; discriminative exemplars ; exemplar selection ; intra-class category ; categorization ; classifier ; classifiers	<material> <material> <method> <task> <otherscientificterm> <method> <task> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <task> <method> <method>	10 0 9 ; 17 3 16 ; 8 0 3 ; 4 0 11	this paper proposes a novel approach for <task_3> using <method_5> . the key idea underlying this method is motivated by numerous previous observations that <material_1> into different categories and then combining the separately trained <method_8> greatly improved the <task_3> performance . a novel computational framework is proposed to unify different processes of <task_15> , training individual <method_16> for each <otherscientificterm_14> , and training a strong <method_16> combining the individual <method_17> . the individual processes employ a single <otherscientificterm_11> that is optimized using two <otherscientificterm_4> . the outer adaboost loop is used to select <otherscientificterm_12> and the <method_10> is used to select <otherscientificterm_9> on the selected exemplars . the proposed approach replaces the manual time-consuming process of <task_13> as well as addresses the problem of <task_7> inherent in this process . also , our approach fully complies with the standard <method_2> in terms of <task_6> . experiments on <material_0> demonstrate the efficacy of the proposed approach .	3 5 18 -1 1 8 21 18 -1 15 16 14 17 20 18 -1 11 4 22 18 -1 12 10 19 18 -1 9 18 -1 13 7 18 -1 2 6 18 -1
Optimization of the Gaussian Mixture Model Evaluation on GPU .	cuda or opencl gpu programming frameworks ; gaussian mixture acoustic model evaluation algorithm ; optimization of acoustic likelihoods computation ; real-time speech recognition engines ; model selection techniques ; automatics speech recognizers ; acoustic models ; gpu resources ; low-end gpu ; fusion techniques ; conditional likelihoods ; gpu devices ; lvcsr decoder ; cuda ; opencl	<method> <method> <task> <method> <method> <method> <method> <material> <method> <method> <otherscientificterm> <method> <method> <method> <material>	9 1 4 ; 6 3 3 ; 9 0 6 ; 1 0 11 ; 13 0 2 ; 13 4 14	in this paper we present a highly optimized implementation of <method_1> . evaluation of these likelihoods is one of the most computationally intensive parts of <method_5> but <method_1> can be well-parallelized and offloaded to <method_11> . our <method_1> offers significant speed-up compared to the recently published approaches , since <method_1> exploits the <method_11> better . all the recent implementations were programmed either in <method_0> . we present results for both ; <method_13> as well as <material_14> . results suggest that even very large <method_6> can be utilized in <method_3> on computers and laptops equipped with a <method_8> . <task_2> on <method_13> enables to use the remaining <material_7> for offloading of other compute-intensive parts of <method_12> . other possible use of the freed <material_7> is to evaluate several <method_6> at the same time and use <method_9> or <method_4> to improve the quality of resulting <otherscientificterm_10> under diverse conditions .	1 15 -1 5 11 15 -1 19 15 -1 0 15 -1 13 14 21 15 -1 6 3 8 2 17 15 -1 20 15 -1 7 12 16 18 15 -1
Modeling Cantonese pronunciation variation by acoustic model refinement .	lower , phonetic or subphonetic level ; surfaceform phone ; baseform phone ; relative word error rate ; cantonese speech recognition database ; gaussian mixture components ; pronunciation modeling algorithms ; canonical phone ; sound change ; mixture components ; surfaceform models ; pronunciation variations ; phone change ; acoustic models ; baseform	<otherscientificterm> <method> <method> <metric> <material> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	2 0 1 ; 4 5 6 ; 12 1 8	pronunciation variations can be roughly classified into two types : a <otherscientificterm_12> or a <otherscientificterm_8> -lsb- 1 -rsb- -lsb- 2 -rsb- . a <otherscientificterm_12> happens when a <otherscientificterm_7> is produced as a different phone . such a change can be modeled by converting the <method_2> to a <method_1> . a <otherscientificterm_8> happens at a <otherscientificterm_0> within a phone and it can not be modeled well by either the <otherscientificterm_14> or the surfaceform phone alone . we propose here to refine the <method_13> to cope with sound changes by -lrb- 1 -rrb- sharing the <method_5> of hmm states in the <otherscientificterm_14> and the <method_10> ; -lrb- 2 -rrb- adapting the <method_9> of the <method_13> towards those of the <method_10> ; -lrb- 3 -rrb- selectively reconstructing new <method_13> through sharing or adapting . the proposed <method_6> are generic and can , in principle , be applied to different languages . specifically , <method_6> were tested in a <material_4> . <metric_3> reductions of 5.45 % , 2.53 % , and 3.04 % have been achieved using the three approaches , respectively .	12 8 18 15 -1 7 15 -1 2 1 16 15 -1 0 14 15 -1 13 5 15 -1 10 9 15 -1 6 17 15 -1 4 3 15 -1
Distribution-Free Learning of Bayesian Network Structure in Continuous Domains .	bayesian networks ; probability distribution of the domain ; independence-based bn structure learning algorithm ; conditional independence test ; parametric distribution families ; bn structure learning ; local conditional probabilities ; real-world data ; continuous variables ; statistical approaches ; statistical consistency ; independence-based methods ; graphical models ; bayesian networks ; distributional assumptions ; continuous domains ; non-parametric ; prediscretization	<method> <task> <method> <method> <otherscientificterm> <method> <otherscientificterm> <material> <otherscientificterm> <method> <metric> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method>	3 0 8 ; 3 4 9 ; 17 0 9	in this paper we present a method for learning the structure of <method_0> without making any assumptions on the <task_1> . this is mainly useful for <otherscientificterm_15> , where there is little guidance and many choices for the <otherscientificterm_4> to be used for the <otherscientificterm_6> of the <method_13> , and only a few have been examined analytically . we therefore focus on <method_5> in <otherscientificterm_15> . we address the problem by developing a <method_3> for <otherscientificterm_8> , which can be readily used by any existing <method_2> . our test is <method_16> , making no assumptions on the distribution of the domain . we also provide an effective and computationally efficient method for calculating it from data . we demonstrate the learning of the structure of <method_12> in <otherscientificterm_15> from <material_7> , to our knowledge for the first time using <method_11> and without <otherscientificterm_14> . we also experimentally show that our test compares favorably with existing <method_9> which use <method_17> , and verify desirable properties such as <metric_10> .	0 1 18 -1 15 4 6 13 18 -1 5 18 -1 3 8 2 19 18 -1 16 18 -1 18 -1 18 -1 12 7 11 14 20 21 18 -1
3D Mixed Invariant and its Application on Object Classification .	classi ¬ø - cation procedure ; characteristic curves ; integro-differential invariant ; noise ; derivatives ; curves ; invariant	<method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	1 0 0	a new <otherscientificterm_2> for <otherscientificterm_5> in 3d transformed by af ¬ø ne group action is presented in this paper . the <otherscientificterm_4> involved are of the ¬ø rst order , and therefore this <otherscientificterm_6> is signi ¬ø - cantly less sensitive to <otherscientificterm_3> than classical af ¬ø ne differential invari-ants , the simplest of which involves <otherscientificterm_4> of order 5 . a <method_0> based on <otherscientificterm_1> of an object surface is considered using our proposed mixed invariants . substantiating examples are provided to verify ef ¬ø ciency and discriminant power of the characteristic spatial curve based 3d object classi ¬ø cation .	2 5 7 -1 4 6 3 7 -1 0 1 8 7 -1 7 -1
Soft Syntactic Constraints for Hierarchical Phrase-Based Translation Using Latent Syntactic Distributions .	syntactic analysis of the source side ; source-side parsed , word-aligned parallel corpus ; syntactic structure of the source side ; hierarchical phrase-based machine translation systems ; linguistically-guided latent syntactic categories ; linguistically motivated syntactic features ; soft syntactic constraints ; latent syntactic categories ; real-valued feature vector ; scfg rules ; feature vectors ; x non-terminal ; hierarchical structure ; scfg rule ; treebank categories	<otherscientificterm> <material> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	8 0 13	in this paper , we present a novel approach to enhance <task_3> with <otherscientificterm_5> . rather than directly using <otherscientificterm_14> as in previous studies , we learn a set of <otherscientificterm_4> automatically from a <material_1> , based on the <otherscientificterm_12> among phrase pairs as well as the <otherscientificterm_2> . in our model , each <otherscientificterm_11> in a <otherscientificterm_13> is decorated with a <otherscientificterm_8> computed based on its distribution of <otherscientificterm_7> . these <otherscientificterm_10> are utilized at decoding time to measure the similarity between the <otherscientificterm_0> and the syntax of the <otherscientificterm_9> that are applied to derive translations . our approach maintains the advantages of <task_3> while at the same time naturally incorporates <otherscientificterm_6> .	3 5 15 -1 14 4 1 12 2 15 -1 11 13 8 7 16 15 -1 10 0 9 15 -1 15 -1
Approaching user capacity in a DSL system via harmonic mean-rate optimization .	digital subscriber line system ; n orthogonal narrowband tones ; computationally-efficient power allocation technique ; -lrb- non-convex -rrb- integer-program ; power allocation techniques ; ` user capacity ; harmonic mean-rate objective ; alternate approach ; power allocation ; features	<method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	1 2 0 ; 9 0 2 ; 2 0 0 ; 0 4 4	in this paper we consider a <method_0> with <otherscientificterm_1> . each user has a limited power budget , and our goal is to determine the <otherscientificterm_8> of each user that enables the <otherscientificterm_5> ' of the <method_0> to be approached . in this paper , we use <otherscientificterm_5> ' to denote the maximum number of users that can be supported by the <method_0> , provided that each user is guaranteed to have a data rate that lies within a prescribed range . finding a <otherscientificterm_8> that enables this capacity to be approached directly can be quite cumbersome because <otherscientificterm_8> involves solving a <method_3> . in order to circumvent this difficulty , in this paper we propose an <method_7> that is based on exploiting the fairness and per-tone convexity of the <otherscientificterm_6> . using these <otherscientificterm_9> , we devise a <method_2> that enables the user capacity of the <method_0> to be approached more closely than <method_4> that are more computationally demanding .	0 1 11 10 -1 8 5 10 -1 10 -1 10 -1 3 10 -1 7 6 12 13 14 10 -1
Using text and acoustic features to diagnose progressive aphasia and its subtypes .	automatically diagnosing primary progressive aphasia ; progressive nonfluent aphasia ; semantic dementia ; acoustics of recorded narratives ; statistical significance ; classifier optimization ; textual analysis ; feature selection ; ppa ; features ; minimum-redundancy-maximum-relevance	<task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <method> <method> <method> <method> <otherscientificterm> <material>	2 1 1 ; 3 1 1	this paper presents experiments in <task_0> and two of its subtypes , <otherscientificterm_2> and <otherscientificterm_1> , from the <material_3> and <method_6> of the resultant transcripts . in order to train each of three types of classifier -lrb- na ¬® ƒ±ve bayes , support vector machine , random forest -rrb- , a large set of 81 available <otherscientificterm_9> must be reduced in size . two methods of <method_7> are therefore compared -- one based on <otherscientificterm_4> and the other based on <material_10> . after <method_5> , <method_8> -lrb- or absence thereof -rrb- is correctly diagnosed across 87.4 % of conditions , and the two subtypes of <method_8> are correctly classified 75.6 % of the time .	0 2 1 3 6 12 13 11 -1 9 11 -1 7 4 10 11 -1 5 8 11 -1
Importance of nasality measures for speaker recognition data selection and performance prediction .	equal error rates ; speaker recognition ; feature vectors of phones ; feature vector distributions ; computational costs ; performance prediction ; data-selection scheme ; features ; sre08 ; nasality	<metric> <task> <otherscientificterm> <otherscientificterm> <metric> <task> <method> <otherscientificterm> <method> <otherscientificterm>	3 0 5 ; 3 0 1	we improve upon our measures relating <otherscientificterm_3> to <task_1> performances for <task_5> and potential arbitrary data selection for <task_1> , as described in -lsb- 1 -rsb- . in particular , we examine the means and variances of 11 <otherscientificterm_7> pertaining to <otherscientificterm_9> -lrb- each of which is denoted as a measure -rrb- , computing them on <otherscientificterm_2> to determine which measures give good sr <task_5> of phones . we 've found that the combination of <otherscientificterm_9> measures give a 0.917 correlation with the <metric_0> of phones on <method_8> , exceeding the correlation of our previous best measure -lrb- mutual information -rrb- by 12.7 % . when implemented in our <method_6> -lrb- which does not require a <task_1> to be run -rrb- , the <otherscientificterm_9> measures allow us to select data with combined <metric_0> better than data selected via running a <task_1> in certain cases , at a fortieth of the <metric_4> . the <otherscientificterm_9> measures also require a tenth of the <metric_4> to compute compared to our previous best measure .	3 1 5 11 12 10 -1 7 9 2 10 -1 0 8 10 -1 10 -1 6 4 10 -1
Generalized interior-point method for constrained peak power minimization of OFDM signals .	orthogonal frequency division multiplexing symbols ; interior-point method algorithm ; constellation extension ; hybrid ce constraint ; optimal distortion set ; convex functions ; distortion	<otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 0 2 ; 5 0 6 ; 2 0 0 ; 1 0 4	in this paper we present two results on reducing the peak power of <otherscientificterm_0> via <method_2> . the first result is a derivation of the <method_1> needed to find the <otherscientificterm_4> , where the <otherscientificterm_6> is constrained by <otherscientificterm_5> . next we optimize the parameters of a <otherscientificterm_3> set to minimize the <method_2> . numerical examples are provided to illustrate the findings .	0 2 10 7 -1 1 4 6 5 9 11 7 -1 3 8 7 -1 7 -1
Content Models with Attitude .	social media review snippets ; variational mean-field inference algorithm ; large snippet collections ; aggregate user sentiments ; probabilistic topic model ; yelp reviews	<material> <method> <material> <otherscientificterm> <method> <material>	2 0 1 ; 4 0 3	we present a <method_4> for jointly identifying properties and attributes of <material_0> . our <method_4> simultaneously learns a set of properties of a product and captures <otherscientificterm_3> towards these properties . this <method_4> directly enables discovery of highly rated or inconsistent properties of a product . our <method_4> admits an efficient <method_1> which can be paral-lelized and run on <material_2> . we evaluate our <method_4> on a large corpus of snippets from <material_5> to assess property and attribute prediction . we demonstrate that <method_4> outperforms applicable baselines by a considerable margin .	4 0 6 -1 3 8 6 -1 6 -1 1 2 7 6 -1 5 6 -1 6 -1
Resolving Event Noun Phrases to Their Verbal Mentions .	lexical , syntactic and positional features ; cascaded event template extraction ; event noun phrase resolution ; pair-wise candidate preference knowledge ; event noun phrases ; event anaphora resolution ; flat features baseline ; syntactic structural information ; noun phrase resolution ; twin-candidate based model ; event pronoun resolution ; composite kernel ; ontonotes corpus ; tree kernel ; flat features ; nlp study ; morphology relation ; parse tree ; f-score ; features ; synonym	<otherscientificterm> <task> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <method> <task> <method> <material> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	11 0 7 ; 7 0 17 ; 5 0 1 ; 0 0 2 ; 9 0 3 ; 20 6 0 ; 1 1 15 ; 13 2 17 ; 16 1 20 ; 13 0 7	event anaphora resolution is an important <task_5> for <task_1> and other <task_15> . previous study only touched on <task_10> . in this paper , we provide the first systematic study to resolve <otherscientificterm_4> to their verbal mentions crossing long distances . our study shows various <otherscientificterm_0> are needed for <task_2> and most of <otherscientificterm_0> , such as <otherscientificterm_16> , <otherscientificterm_20> and etc , are different from those <otherscientificterm_19> used for conventional <task_8> . <otherscientificterm_7> in the <otherscientificterm_17> modeled with <otherscientificterm_13> is combined with the above diverse <otherscientificterm_14> using a <method_11> , which shows more than 10 % <metric_18> improvement over the <otherscientificterm_6> . in addition , we employed a <method_9> to capture the <otherscientificterm_3> , which further demonstrates a statistically significant improvement . all the above contributes to an encouraging performance of 61.36 % <metric_18> on <material_12> .	5 1 15 24 28 21 -1 10 21 -1 4 21 -1 0 2 16 20 19 8 7 25 27 30 21 -1 17 13 14 11 18 22 23 29 31 21 -1 6 26 21 -1 9 3 21 -1
A Lemmatization Method for Modern Mongolian and its Application to Information Retrieval .	natural language processing ; content word ; technical abstracts ; information retrieval ; modern mongolian ; lemmatization method ; indexing	<task> <otherscientificterm> <otherscientificterm> <task> <material> <method> <task>	5 0 3 ; 5 0 4 ; 6 0 3 ; 0 1 3 ; 5 0 6 ; 2 0 5	in <material_4> , a <otherscientificterm_1> can be inflected when concatenated with suffixes . identifying the original forms of content words is crucial for <task_0> and <task_3> . we propose a <method_5> for <material_4> and apply our <method_5> to <task_6> for <task_3> . we use <otherscientificterm_2> to show the effectiveness of our <method_5> experimentally .	4 1 7 -1 0 3 11 7 -1 5 6 8 9 10 12 7 -1 2 13 7 -1
Region-Based Segmentation via Non-Rigid Template Matching .	global regularization of the template variations ; segmentation of irregular shapes ; computed tomography images ; non-rigid template matching ; region segmentation method ; fluid registration model ; contour-based segmenta-tion techniques ; 3d shape models ; posteriori distributions ; intensity distributions ; geometric deformation ; intensity model ; binary template ; leaks ; accuracy	<task> <task> <material> <method> <method> <method> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <metric>	4 0 1 ; 3 0 4 ; 11 1 8 ; 5 0 12 ; 5 0 0 ; 5 0 10	we propose a new <method_4> based on <method_3> . we align a <otherscientificterm_12> to an image by maximizing the likelihood of <otherscientificterm_9> within a region of interest and its background . the <method_11> and the corresponding a <otherscientificterm_8> are estimated and updated throughout the alignment . the <otherscientificterm_10> of the <otherscientificterm_12> is based on a <method_5> . unlike <method_6> , this <method_5> allows for a <task_0> . this enables the <task_1> while avoiding <otherscientificterm_13> . we apply our <method_4> to the <task_1> in <material_2> , a challenging task due to the high inter-patient variability in the shape of this organ . we show that our segmentation results are equivalent or superior in <metric_14> to results obtained using existing techniques based on <method_7> .	4 3 17 15 -1 12 9 15 -1 11 8 18 15 -1 10 5 19 21 15 -1 6 0 20 15 -1 1 13 15 -1 2 16 15 -1 15 -1
Dynamic Depth Recovery from Multiple Synchronized Video Streams .	extracting depth information of non-rigid dynamic 3d scenes ; 3d piecewise planar surface patches ; 3d geometric , motion ; sharp depth discontinuity estimation ; spatial color consistency constraint ; color based image segmentation ; temporally consistent depth estimation ; smooth scene motion model ; global visibility constraint ; synchronized video streams ; global visibility constraints ; object boundaries ; cost function ; incremental formulation	<task> <otherscientificterm> <otherscientificterm> <metric> <otherscientificterm> <method> <task> <method> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	13 0 1 ; 6 1 3 ; 5 0 1 ; 4 1 7 ; 9 0 0	this paper addresses the problem of <task_0> from multiple <material_9> . three main issues are discussed in this context : -lrb- i -rrb- <task_6> , -lrb- ii -rrb- <metric_3> around <otherscientificterm_11> , and -lrb- iii -rrb- enforcement of the <otherscientificterm_8> . we present a framework in which the scene is modeled as a collection of <otherscientificterm_1> induced by <method_5> . this <otherscientificterm_1> is continuously estimated using an <method_13> in which the <otherscientificterm_2> , and <otherscientificterm_10> are enforced over space and time . the proposed algorithm optimizes a <otherscientificterm_12> that incorporates the <otherscientificterm_4> and a <method_7> .	0 9 19 14 -1 6 3 11 8 16 14 -1 1 5 17 14 -1 13 2 10 15 14 -1 12 4 7 18 14 -1
Hierarchically Gated Deep Networks for Semantic Segmentation .	multi-scale convolutional neural networks ; hierarchically gated deep networks ; learning feature representations ; semantic seg-mentation task ; multi-scale deep network ; multi-scale deep networks ; fine-grained local structures ; global scene structure ; spatial contexts ; image structures ; customized scales ; memory gates ; memory cells ; semantic segmentation ; pixels ; patches ; pix-el	<method> <method> <method> <task> <task> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm>	3 5 5 ; 14 6 6 ; 14 1 15 ; 15 6 6 ; 1 0 16	semantic segmentation aims to parse the scene structure of images by annotating the labels to each pixel so that images can be segmented into different regions . while <otherscientificterm_9> usually have various scales , it is difficult to use a single scale to model the <otherscientificterm_8> for all individual <otherscientificterm_14> . <method_0> and their variants have made striking success for modeling the <otherscientificterm_7> for an image . however , <method_0> are limited in labeling <otherscientificterm_6> like <otherscientificterm_14> and <otherscientificterm_15> , since <otherscientificterm_8> might be blindly mixed up without appropriately customizing their scales . to address this challenge , we develop a novel paradigm of <task_4> to model <otherscientificterm_8> surrounding different <otherscientificterm_14> at various scales . <task_4> builds multiple layers of <otherscientificterm_12> , <method_2> for individual <otherscientificterm_14> at their <otherscientificterm_10> by hierarchically absorbing relevant <otherscientificterm_8> via <otherscientificterm_11> between layers . such <method_1> can customize a suitable scale for each <otherscientificterm_16> , thereby delivering better performance on labeling scene structures of various scales . we conduct the experiments on two datasets , and show competitive results compared with the other <method_5> on the <task_3> .	17 -1 9 8 14 0 17 -1 7 17 -1 6 15 19 20 21 17 -1 17 -1 4 17 -1 12 2 10 11 22 17 -1 1 16 18 17 -1
Planar Structure Matching under Projective Uncertainty for Geolocation .	uncertainty of line segments ; human delineated line segments ; uncertainty based representation ; false candidate regions ; image based geolocation ; distance transform matching ; geometric matching framework ; ground image ; ortho images ; visual appearances ; projective transformations	<otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <task> <method> <method> <material> <material> <material> <otherscientificterm>	10 0 0 ; 2 3 6 ; 10 0 2	image based geolocation aims to answer the question : where was this ground photograph taken ? we present an approach to geoloca-lating a single image based on matching <otherscientificterm_1> in the <material_7> to automatically detected line segments in <material_8> . our approach is based on <method_5> . by observing that the <otherscientificterm_0> is non-linearly amplified by <otherscientificterm_10> , we develop an <method_2> and incorporate <method_2> into a <method_6> . we show that our approach is able to rule out a considerable portion of <otherscientificterm_3> even in a database composed of geographic areas with similar <material_9> .	1 7 8 11 -1 5 11 -1 0 10 2 6 11 -1 3 9 4 12 13 14 11 -1 11 -1
Projective Factorization of Multiple Rigid-Body Motions .	subspace of dimension ; point correspondences ; known depths ; segmentation error ; affine methods ; motion segmentation ; hopkins155 database ; subspace separation ; point trajec-tories ; execution time ; lsa ; gpca ; segmentation	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <task> <material> <method> <otherscientificterm> <metric> <method> <method> <otherscientificterm>	11 1 10 ; 3 5 4 ; 10 6 7 ; 3 1 9 ; 11 6 7 ; 7 0 5 ; 9 5 4 ; 2 0 5	given <otherscientificterm_1> in multiple perspective views of a scene containing multiple rigid-body motions , we present an algorithm for segmenting the correspondences according to the multiple motions . we exploit the fact that when the depths of the points are known , the <otherscientificterm_8> associated with a single motion live in a <otherscientificterm_0> at most four . thus <task_5> with <otherscientificterm_2> can be achieved by methods of <method_7> , such as <method_11> or <method_10> . when the depths are unknown , we proceed iteratively . given the <otherscientificterm_12> , we compute the depths using standard techniques . given the depths , we use <method_11> or <method_10> to segment the scene into multiple motions . experiments on the <material_6> show that our method outperforms existing <method_4> in terms of <otherscientificterm_3> and <metric_9> . our methods achieves an error of 2.5 % on 155 sequences .	1 13 -1 8 0 13 -1 5 2 7 11 10 16 18 19 21 13 -1 13 -1 12 13 -1 14 13 -1 15 17 20 13 -1 6 4 3 9 13 -1
Practical Bayesian Optimization of Machine Learning Algorithms .	gaussian process ; human expert-level optimization ; latent dirichlet allocation ; convolutional neural networks ; machine learning algorithms ; rules of thumb ; automatic approaches ; bayesian optimization ; brute-force search ; parallel experimentation ; automatic procedures ; learning parameters ; model hyperparameters ; structured svms ; kernel ; tuning	<method> <task> <task> <method> <method> <otherscientificterm> <method> <method> <method> <task> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method>	2 1 13 ; 0 0 4 ; 5 1 8 ; 11 0 4 ; 12 0 4 ; 13 1 3 ; 14 6 0	the use of <method_4> frequently involves careful <method_15> of <otherscientificterm_11> and <method_12> . unfortunately , this <method_15> is often a '' black art '' requiring expert experience , <otherscientificterm_5> , or sometimes <method_8> . there is therefore great appeal for <method_6> that can optimize the performance of any given <method_4> to the problem at hand . in this work , we consider this problem through the framework of <method_7> , in which a <method_4> 's generalization performance is modeled as a sample from a <method_0> . we show that certain choices for the nature of the <method_0> , such as the type of <otherscientificterm_14> and the treatment of its hyperparame-ters , can play a crucial role in obtaining a good optimizer that can achieve expert-level performance . we describe new algorithms that take into account the variable cost -lrb- duration -rrb- of <method_4> experiments and that can leverage the presence of multiple cores for <task_9> . we show that these proposed algorithms improve on previous <method_10> and can reach or surpass <task_1> for many algorithms including <task_2> , <method_13> and <method_3> .	4 15 11 12 20 21 16 -1 5 8 19 16 -1 6 16 -1 7 0 18 16 -1 23 16 -1 14 16 -1 9 17 22 16 -1
Hilbert space embeddings of conditional distributions with applications to dynamical systems .	<i> conditional </i> distributions ; hilbert space embedding approach ; conditional embeddings ; conditional embeddings ; kernel estimate ; dynamical systems ; hilbert spaces ; nonparametric method ; conditional embedding ; embeddings	<otherscientificterm> <method> <method> <method> <method> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm>	1 0 0 ; 7 0 5 ; 4 0 8	in this paper , we extend the <method_1> to handle <otherscientificterm_0> . we derive a <method_4> for the <otherscientificterm_8> , and show its connection to ordinary <otherscientificterm_9> . <method_2> largely extend our ability to manipulate distributions in <otherscientificterm_6> , and as an example , we derive a <method_7> for modeling <method_5> where the belief state of the system is maintained as a <otherscientificterm_8> . our <method_7> is very general in terms of both the domains and the types of distributions that it can handle , and we demonstrate the effectiveness of our <method_7> in various <method_5> . we expect that <method_3> will have wider applications beyond modeling <method_5> .	1 0 11 10 -1 4 8 9 2 13 10 -1 6 7 5 10 -1 12 10 -1 10 -1
Polar coordinate based nonlinear function for frequency-domain blind source separation .	frequency-domain blind source separation ; independent component analysis ; probability density function ; nonlinear function ; polar coordinates ; cartesian coordinates ; complex-valued signals ; speech signals	<task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <material>	4 0 3 ; 3 0 1 ; 1 0 6 ; 1 0 0 ; 3 0 0 ; 3 0 6	this paper presents a new type of <otherscientificterm_3> for <task_1> to process <material_6> , which is used in <task_0> . the new <otherscientificterm_3> is based on the <otherscientificterm_4> of a complex number , whereas the conventional one is based on the <otherscientificterm_5> . the new <otherscientificterm_3> is derived from the <otherscientificterm_2> of frequency-domain signals that are assumed to be independent of the phase . we show that the difference between the two types of functions is in the assumed densities of independent components . experimental results for separating <material_7> show that the new <otherscientificterm_3> behaves better than the conventional one .	3 1 6 0 10 11 12 13 14 8 -1 4 5 9 8 -1 2 8 -1 8 -1 7 8 -1
Learning Non-Generative Grammatical Models for Document Analysis .	hierarchical seg-mentation and labeling of document layout structures ; uwiii document image database ; document image analysis tasks ; page layout structure extraction ; document analysis problems ; mathematical expression interpretation ; printed mathematical expressions ; grammatical cost function ; machine learning ; optimal parse ; document structure ; global search ; layout analysis ; page grammar ; parsing process ; document layout ; features ; grammars ; grammar ; latex	<task> <material> <task> <task> <task> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <method> <method> <otherscientificterm> <otherscientificterm> <method> <method> <method>	11 0 9 ; 3 6 2 ; 3 1 5 ; 18 0 15 ; 17 0 10 ; 5 6 2	-- we present a general approach for the <task_0> . this approach models <otherscientificterm_15> as a <method_18> and performs a <otherscientificterm_11> for the <otherscientificterm_9> based on a <otherscientificterm_7> . our contribution is to utilize <method_8> to discriminatively select <otherscientificterm_16> and set all parameters in the <method_14> . therefore , and unlike many other approaches for <task_12> , ours can easily adapt itself to a variety of <task_4> . one need only specify the <method_13> and provide a set of correctly labeled pages . experiments demonstrate the effectiveness of this technique on two <task_2> : <task_3> and <task_5> . experiments demonstrate that the learned <method_17> can be used to extract the <otherscientificterm_10> in 57 files from the <material_1> . a second set of experiments demonstrate that the same framework can be used to automatically interpret <otherscientificterm_6> so as to recreate the original <method_19> .	0 20 -1 15 18 11 9 7 21 24 20 -1 8 16 14 20 -1 12 4 20 -1 13 20 -1 2 3 5 22 23 26 20 -1 25 20 -1 17 10 1 20 -1
Temporal episodic memory model : an evolution of minerva2 .	automatic speech recognition ; human episodic memory ; hmm/gmm baseline systems ; temporal sequence ; prediction mechanism ; asr task ; recognition	<task> <otherscientificterm> <method> <otherscientificterm> <method> <task> <task>	5 5 2 ; 3 0 6	this paper introduces a new model for <task_0> called temm-temporal episodic memory model . temm is derived from a simulation of <otherscientificterm_1> called minerva2 , and it not only overcomes the inability of minerva2 to use <otherscientificterm_3> for <task_6> flexibly , but it also employs a <method_4> as an additional source of information . the performance of temm on an <task_5> is compared to state-of-the-art <method_2> , and a first analysis shows both promising results and a need to further stabilise the consistency of the output of the new model .	0 7 -1 1 3 6 4 9 7 -1 5 2 8 7 -1
Nonbinary LDPC decoding by min-sum with Adaptive Message Control .	low-complexity decoding of nonbinary ldpc codes ; adaptive message control ; ms decoding ; message length of belief information ; nonbinary ldpc codes ; decoding iteration ; decoding algorithm ; arithmetic operations ; belief information ; decoding complexity ; non-truncated cases ; computation	<task> <method> <method> <otherscientificterm> <otherscientificterm> <task> <method> <task> <otherscientificterm> <metric> <material> <metric>	7 5 6 ; 11 5 6 ; 6 0 0	-- a new <method_6> , referred to as min-sum with <method_1> , is proposed to reduce the <metric_9> of <otherscientificterm_4> . the proposed <method_6> adaptively trims the <otherscientificterm_3> to reduce the amount of <task_7> . exploiting the fact that during the <task_5> , the distribution of <otherscientificterm_8> will become more concentrated around the correct element in the case of convergence , the messages can be truncated accordingly by considering only a few entries with large likelihood . simulation results with a gf -lrb- 16 -rrb- nonbinary ldpc code indicate that the proposed <method_6> can reduce <task_7> by up to 65 % compared with <material_10> . compared with the state-of-the-art extended <method_2> , the proposed <method_6> can reduce the <metric_11> by up to 50 % , thereby enabling <task_0> .	6 1 9 4 12 -1 3 7 12 -1 5 8 12 -1 13 12 -1 10 14 15 12 -1
Amplitude and gain error influence on time error estimation algorithm for time interleaved A/D converter system .	blind estimation of static time errors ; time inter-leaved a/d converters ; time error estimation ; gain errors ; amplitude	<task> <otherscientificterm> <metric> <otherscientificterm> <otherscientificterm>	4 1 3	a method for <task_0> in <otherscientificterm_1> is investigated . the method assumes that <otherscientificterm_4> and <otherscientificterm_3> are removed before the <metric_2> . even if the <otherscientificterm_4> and <otherscientificterm_3> are estimated and removed , there will be small errors left . in this paper , we investigate how the <otherscientificterm_4> and <otherscientificterm_3> influence the <metric_2> performance .	0 1 5 -1 4 3 2 5 -1 5 -1 6 5 -1
Atom decomposition-based intonation modelling .	statistical parametric text-to-speech synthesis methods ; physiological aspects of prosody production ; extraction of physiologically meaningful atoms ; gamma distribution shaped atoms ; matching pursuit algorithm ; intonation decomposition ; intonation modelling ; tts system ; neutral speech ; prosody ; intonation	<method> <task> <task> <otherscientificterm> <method> <task> <task> <method> <material> <method> <task>	10 0 7 ; 4 0 5 ; 1 0 6 ; 2 0 7 ; 1 0 0 ; 2 0 10 ; 6 0 0	current <method_0> allow production of <material_8> with acceptable quality . however , <method_9> is often qualified as unsatisfactory and sounding too flat . in this paper , we address <task_6> for <method_0> based on <task_1> . a set of <otherscientificterm_3> is defined and then <task_5> is performed using a <method_4> . some preliminary experiments show that this model allows easy <task_2> that could be used to generate <task_10> in a <method_7> .	0 8 11 -1 9 11 -1 6 1 14 16 18 11 -1 3 5 4 13 11 -1 2 10 7 12 15 17 11 -1
Conducting Neuroscience to Guide the Development of AI .	human brain grounds language ; watching video stimuli ; artificial intelligence ; visual perception ; cross-modal studies ; computer-vision approaches ; brain activity ; activity recognition ; vice versa ; brain processing ; fmri decoding ; scanning ; accuracy ; ai ; fmri	<otherscientificterm> <task> <material> <otherscientificterm> <method> <method> <otherscientificterm> <task> <otherscientificterm> <task> <method> <task> <metric> <task> <method>	12 5 5 ; 10 4 5 ; 14 0 2 ; 4 0 6 ; 5 0 7	study of the human brain through <method_14> can potentially benefit the pursuit of <material_2> . four examples are presented . first , <method_10> of the <otherscientificterm_6> of subjects watching video clips yields higher <metric_12> than state-of-the-art <method_5> to <task_7> . second , novel methods are presented that decode aggregate representations of complex visual stimuli by decoding their independent constituents . third , <method_4> demonstrate the ability to decode the <otherscientificterm_6> induced in subjects <task_1> when trained on the <otherscientificterm_6> induced in subjects seeing text or hearing speech stimuli and <otherscientificterm_8> . fourth , the time course of <task_9> while <task_1> is probed with <task_11> that trades off the amount of the brain scanned for the frequency at which it is scanned . techniques like these can be used to study how the <otherscientificterm_0> in <otherscientificterm_3> and may motivate development of novel approaches in <task_13> .	14 2 18 15 -1 15 -1 10 6 12 5 7 16 17 20 15 -1 15 -1 4 1 8 19 15 -1 9 15 -1 11 15 -1
Forward-backward retraining of recurrent neural networks .	letter posterior probability estimator ; oo-line handwriting recognition system ; hidden markov model ; supervised training algorithm ; recurrent neural network ; posterior distributions ; forward-backward algorithm ; handwritten word ; error rate ; recognizer	<method> <method> <method> <method> <method> <otherscientificterm> <method> <material> <metric> <method>	4 0 5 ; 0 0 4 ; 0 0 2 ; 6 0 9 ; 4 0 2	this paper describes the training of a <method_4> as the <method_0> for a <method_2> , <method_1> . the <method_4> estimates <otherscientificterm_5> for each of a series of frames representing sections of a <material_7> . the <method_3> , backpropagation through time , requires target outputs to be provided for each frame . three methods for deriving these targets are presented . a novel method based upon the <method_6> is found to result in the <method_9> with the lowest <metric_8> .	4 0 2 1 12 13 15 10 -1 5 7 11 10 -1 3 10 -1 10 -1 6 9 8 14 10 -1
Phonology & the Interpretation of Fine Phonetic Detail in Berlin German .	reaction times ; interpretation of fine phonetic detail ; lax front vowel ; categorization of items ; perceptual divergence ; stigmatized vicinities ; perception studies ; older listeners ; phonetic input ; phonological generalization ; associative information ; zd	<metric> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method>	10 0 8 ; 4 2 10 ; 10 0 9	young multi-ethnolectal speakers of hamburg-german introduced an alternation of / √ß / to -lsb-  É -rsb- following a <otherscientificterm_2> / …™ / -lsb- 1 -rsb- . we conducted <task_6> exploiting this contrast in berlin -lrb- germany -rrb- , a city with large multi-ethnic neighborhoods . this alternation is pervasive and noticeable , it is mocked and stigmatized and there is an awareness that many young speakers -lrb- including ethnically germans -rrb- from neighborhoods with larger migrant populations like kreuzberg -lrb- kb -rrb- substitute / √ß / with /  É / while speakers from less <otherscientificterm_5> like zehlendorf -lrb- <method_11> -rrb- do not . the <task_3> on two 14-step synthesized continua from fichte ` spruce ' to fischte ' 3 rd p. sg . to fish ' by 99 listeners shows that the <otherscientificterm_1> is strongly influenced by the co-presentation of the label kb or <method_11> in contrast to no label -lrb- control -rrb- . analyses of the <metric_0> show that significantly more time is needed to process stimuli in kb and less in <method_11> . moreover , younger listeners -lrb- below 30 years -rrb- perceive more /  É / variants than <otherscientificterm_7> . <method_9> over <otherscientificterm_8> is dependent on <otherscientificterm_10> : <otherscientificterm_4> is found within the confines of a single large urban area -lsb- 2,3,4 -rsb- .	2 12 -1 6 12 -1 5 11 12 -1 12 -1 3 12 -1 1 12 -1 0 12 -1 7 9 13 14 15 12 -1
Size Matters : Metric Visual Search Constraints from Monocular Metadata .	3-d size constraints ; purely monocular sources ; appearance gradient statistics ; associated exif metadata ; metric branch-and-bound algorithm ; category size information ; explicit 3-d sensing ; 3-d sensor ; 3-d sensing ; search task ; local window ; stereo rig ; metric constraints ; camera intrinstics ; online images ; online imagery ; training data ; reconstruction ; features	<otherscientificterm> <material> <method> <material> <method> <otherscientificterm> <method> <method> <method> <task> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <material> <material> <material> <task> <otherscientificterm>	0 0 9 ; 14 0 5 ; 4 0 9	metric constraints are known to be highly discriminative for many objects , but if training is limited to data captured from a particular <method_7> the quantity of <material_16> may be severly limited . in this paper , we show how a crucial aspect of <method_7> -- object and feature absolute size -- can be added to models learned from commonly available <material_15> , without use of any <method_8> or <task_17> at training time . such models can be utilized at test time together with <method_6> to perform robust search . our model uses a '' 2.1 d '' local feature , which combines traditional <method_2> with an estimate of average absolute depth within the <otherscientificterm_10> . we show how <otherscientificterm_5> can be obtained from <material_14> by exploiting relatively unbiquitous metadata fields specifying <otherscientificterm_13> . we develop an efficient <method_4> for our <task_9> , imposing <otherscientificterm_0> as part of an optimal search for a set of <otherscientificterm_18> which indicate the presence of a category . experiments on test scenes captured with a traditional <material_11> are shown , exploiting <material_16> from from <material_1> with <material_3> .	7 16 19 -1 15 8 17 19 -1 6 19 -1 19 -1 2 10 21 19 -1 5 14 13 20 22 19 -1 4 9 0 18 19 -1
Automatic Detection of Cognates Using Orthographic Alignment .	automatically detecting pairs of cog-nates ; orthographic alignment method ; machine learning algorithms ; known cognates ; linguistic information ; language evolution ; sequence alignment ; aligned subsequences ; historical information ; computational biology ; linguistic changes ; rules ; features ; non-cognates	<task> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <task> <otherscientificterm> <otherscientificterm> <material> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm>	9 0 6 ; 1 0 6 ; 1 0 0 ; 12 0 2 ; 7 0 2 ; 2 0 10 ; 7 0 12	words undergo various changes when entering new languages . based on the assumption that these <otherscientificterm_10> follow certain <otherscientificterm_11> , we propose a method for <task_0> employing an <method_1> which proved relevant for <task_6> in <material_9> . we use <otherscientificterm_7> as <otherscientificterm_12> for <method_2> in order to infer <otherscientificterm_11> for <otherscientificterm_10> undergone by words when entering new languages and to discriminate between cognates and <otherscientificterm_13> . given a list of <otherscientificterm_3> , our approach does not require any other <otherscientificterm_4> . however , it can be customized to integrate <otherscientificterm_8> regarding <otherscientificterm_5> .	14 -1 10 11 0 1 6 9 15 16 17 14 -1 7 12 2 13 18 19 20 21 14 -1 3 4 14 -1 8 5 14 -1
Dynamic Bayesian socio-situational setting classification .	bigram dynamic bayesian classification ; lexical and part-of-speech information ; dynamic bayesian classifier ; socio-situational setting ; static classifiers ; part-of-speech tags ; prediction accuracy ; context-dependent models ; speech recognition ; classification	<method> <otherscientificterm> <method> <method> <method> <otherscientificterm> <metric> <method> <task> <task>	5 0 0 ; 6 5 2 ; 7 0 8 ; 2 0 3	we propose a <method_2> for the <method_3> of a conversation . knowledge of the <method_3> can be used to search for content recorded in a particular setting or to select <method_7> in <task_8> . the <method_2> has the advantage -- compared to <method_4> such a naive bayes and support vector machines -- that it can continuously update the <task_9> during a conversation . we experimented with several models that use <otherscientificterm_1> . our results show that the <metric_6> of the <method_2> using the first 25 % of a conversation is almost 98 % of the final <metric_6> , which is calculated on the entire conversation . the best final <metric_6> , 88.85 % , is obtained by <method_0> using words and <otherscientificterm_5> .	2 3 14 10 -1 7 8 13 10 -1 4 9 10 -1 1 10 -1 6 12 10 -1 11 10 -1
Learning Optimal Commitment to Overcome Insecurity .	defender 's strategy ; game-theoretic algorithms ; game model ; prior information ; physical security ; stackelberg game	<method> <method> <method> <otherscientificterm> <task> <otherscientificterm>	1 0 4	game-theoretic <method_1> for <task_4> have made an impressive real-world impact . these <method_1> compute an optimal strategy for the defender to commit to in a <otherscientificterm_5> , where the attacker observes the <method_0> and best-responds . in order to build the <method_2> , though , the payoffs of potential attackers for various outcomes must be estimated ; inaccurate estimates can lead to significant inefficiencies . we design an algorithm that optimizes the <method_0> with no <otherscientificterm_3> , by observing the attacker 's responses to randomized deployments of resources and learning his priorities . in contrast to previous work , our algorithm requires a number of queries that is polynomial in the representation of the game .	1 4 7 6 -1 5 0 6 -1 2 6 -1 3 6 -1 6 -1
Direct Code Access in Self-Organizing Neural Networks for Reinforcement Learning .	temporal difference methods ; direct code access procedure ; direct code access ; self-organizing neural network ; maximal reward values ; reinforcement learning ; decision cycle ; network complexity ; computation efficiency ; stable learning ; iterative process ; cognitive nodes ; td-falcon	<method> <method> <method> <method> <otherscientificterm> <task> <otherscientificterm> <metric> <metric> <method> <method> <otherscientificterm> <method>	2 1 12 ; 0 3 3 ; 3 0 5 ; 12 0 11 ; 2 0 12 ; 8 1 7 ; 0 0 5 ; 12 6 3	td-falcon is a <method_3> that incorporates <method_0> for <task_5> . despite the advantages of fast and <method_9> , <method_12> still relies on an <method_10> to evaluate each available action in a <otherscientificterm_6> . to remove this deficiency , this paper presents a <method_1> whereby <method_12> conducts instantaneous searches for <otherscientificterm_11> that match with the current states and at the same time provide <otherscientificterm_4> . our comparative experiments show that <method_12> with <method_2> produces comparable performance with the original <method_12> while improving significantly in <metric_8> and <metric_7> .	3 0 5 15 16 20 21 13 -1 9 12 10 6 13 -1 1 11 4 17 13 -1 2 8 7 14 18 19 13 -1
Fractional , canonical , and simplified fractional cosine transforms .	simplified fractional fourier transform ; simplified fractional cosine transform ; fractional cosine transform ; fractional fourier transform ; linear canonical transform ; canonical cosine transform ; space-variant pattem recognition ; optical system analysis ; fourier transform ; frft ; sfrft	<method> <method> <method> <method> <method> <method> <task> <method> <otherscientificterm> <material> <method>	9 1 4 ; 4 1 10 ; 9 0 8 ; 4 1 0 ; 9 1 10 ; 5 1 1 ; 2 1 5 ; 7 1 6 ; 3 0 8 ; 3 1 4	fourier transform can be generalized into the <method_3> , <method_4> , and <method_0> . they extend the utilities of original <otherscientificterm_8> , and can solve many problems that ca n't be solved well by original <otherscientificterm_8> . in this paper , we will generalize the <otherscientificterm_8> . we will derive <method_2> , <method_5> , and <method_1> . we will show <method_2> are very similar to the <material_9> , <method_4> , and <method_10> , but <method_2> are much more efficient to deal with the even , real even functions . for <otherscientificterm_8> , <material_9> and <method_10> can save 112 of the real number multiplications , and <material_9> can save 314 . we also discuss their applications , such as <method_7> and <task_6> .	3 4 0 15 20 21 11 -1 8 11 -1 11 -1 2 5 1 17 18 11 -1 9 10 12 13 11 -1 14 16 11 -1 19 11 -1
Temporal decomposition : a promising approach to low rate wideband speech compression .	line spectral frequencies ; temporal decomposition ; dynamic programming search algorithm ; low bit rates ; split vector quantisation ; wideband speech ; unicast streaming	<method> <task> <method> <otherscientificterm> <method> <material> <task>	3 5 4 ; 1 0 5 ; 1 4 4 ; 1 0 0 ; 2 0 1 ; 0 0 5	in this paper , we present new results on <task_1> applied to the <method_0> derived for <material_5> . the paper shows that by incorporating a <method_2> into <task_1> , near transparent quantisation of wideband lsfs can be obtained at approximately 1 kbps . we also show that <task_1> performs significantly better than <method_4> at <otherscientificterm_3> . we propose that <task_1> is a promising approach to low rate <material_5> coding for applications such as <task_6> .	1 0 5 9 11 13 7 -1 2 12 7 -1 4 3 8 10 7 -1 6 7 -1
Component-Enhanced Chinese Character Embeddings .	component-enhanced chinese character embedding models ; en-glish word embeddings ; distributed word representations ; bi-gram extensions ; semantic information ; semantic in-dictors ; text classification ; word similarity ; nlp tasks ; en-glish	<method> <otherscientificterm> <method> <method> <otherscientificterm> <otherscientificterm> <task> <task> <task> <material>	7 5 0 ; 6 5 0 ; 2 0 4 ; 7 1 6 ; 0 1 3 ; 9 6 8 ; 0 0 5 ; 2 0 8	distributed word representations are very useful for capturing <otherscientificterm_4> and have been successfully applied in a variety of <task_8> , especially on <material_9> . in this work , we innovatively develop two <method_0> and their <method_3> . distinguished from <otherscientificterm_1> , our <method_0> explore the compositions of chinese characters , which often serve as <otherscientificterm_5> inherently . the evaluations on both <task_7> and <task_6> demonstrate the effectiveness of our <method_0> .	4 8 9 13 16 18 10 -1 0 3 15 10 -1 1 5 17 10 -1 7 6 2 11 12 14 10 -1
Active learning based automatic face segmentation for kinect video .	color and depth data ; semi-supervised spline regression model ; active learning framework ; commodity kinect camera ; face region ; labeling information ; human interactions ; real videos ; segmentation approach ; seg-mentation ; videos	<material> <method> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <material> <method> <otherscientificterm> <material>	1 0 4	this paper presents a novel <method_8> for extracting faces from <material_10> . under an <method_2> , the <otherscientificterm_9> is conducted automatically without <otherscientificterm_6> . a small portion of pixels are first labeled as face or non-face . given these labeled samples , a <method_1> is then applied to obtain the <otherscientificterm_4> . based on the segmentation result , new pixels are selected and labeled . these two steps perform iterately until convergence . the main novelty is that <material_0> are combined to provide the <otherscientificterm_5> . our <method_8> is validated via comparisons with state-of-the-art methods on <material_7> captured from the <otherscientificterm_3> .	8 10 11 -1 2 9 6 11 -1 11 -1 1 4 12 11 -1 11 -1 11 -1 0 5 11 -1 7 11 -1
Automata Theory for Reasoning About Actions .	second order quantiication over-nite ; domain closure assumption ; innnite trees ; uncountable domains ; situation calculus ; automata ; actions	<otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	5 0 1	in this paper , we show decidability of a rather expressive fragment of the <otherscientificterm_4> . we allow <otherscientificterm_0> and innnite sets of situations . we do not impose a <otherscientificterm_1> on <otherscientificterm_6> ; therefore , innnite and even <otherscientificterm_3> are allowed . the <otherscientificterm_1> is based on <method_5> accepting <otherscientificterm_2> .	4 7 -1 0 7 -1 1 6 3 7 -1 5 2 8 7 -1
Joint Emotion Analysis via Multi-task Gaussian Processes .	low-rank coregionalisation approach ; rich parameterisation scheme ; vector-valued gaussian process ; news headlines dataset ; natural language sentences ; multi-task approaches ; single-task baselines	<method> <method> <method> <material> <material> <method> <method>	6 1 5 ; 2 3 0 ; 2 1 1 ; 1 3 0	we propose a model for jointly predicting multiple emotions in <material_4> . our model is based on a <method_0> , which combines a <method_2> with a <method_1> . we show that our approach is able to learn correlations and anti-correlations between emotions on a <material_3> . the proposed model outperforms both <method_6> and other <method_5> .	4 7 -1 0 2 1 9 10 11 7 -1 3 7 -1 6 5 8 7 -1
A General Regularization Framework for Domain Adaptation .	multi-task regularization framework ; domain adaptation framework ; feature augmentation technique ; negative transfer	<method> <method> <method> <otherscientificterm>	2 1 0	we propose a <method_1> , and formally prove that <method_1> generalizes the <method_2> in -lrb- daum√© iii , 2007 -rrb- and the <method_0> in -lrb- evgeniou and pontil , 2004 -rrb- . we show that our <method_1> is strictly more general than these approaches and allows practitioners to tune hyper-parameters to encourage transfer between close domains and avoid <otherscientificterm_3> between distant ones .	1 2 0 5 4 -1 3 4 -1
Max-Margin Multiple-Instance Dictionary Learning .	dictionary learning ; critical knowledge abstraction process ; image classification benchmarks ; weakly supervised learning ; codebook learning step ; representation problem ; machine learning ; randomized forests ; linear svm ; metric fusion ; dictionary learning ; dictionary learning ; classification margins ; multi-channel features ; mil ; classifier ; codes	<task> <method> <metric> <method> <method> <task> <task> <otherscientificterm> <method> <method> <task> <task> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm>	10 3 6 ; 10 0 5 ; 3 0 11 ; 8 6 15 ; 9 0 13	dictionary learning has became an increasingly important task in <task_6> , as <task_10> is fundamental to the <task_5> . a number of emerging techniques specifically include a <method_4> , in which a <method_1> is carried out . existing approaches in <task_0> are either generative -lrb- unsupervised e.g. k-means -rrb- or discriminative -lrb- supervised e.g. extremely <otherscientificterm_7> -rrb- . in this paper , we propose a multiple instance learning -lrb- <otherscientificterm_14> -rrb- strategy -lrb- along the line of <method_3> -rrb- for <task_11> . each code is represented by a <method_15> , such as a <method_8> , which naturally performs <method_9> for <otherscientificterm_13> . we design a formulation to simultaneously learn mixtures of <otherscientificterm_16> by maximizing <otherscientificterm_12> in <otherscientificterm_14> . state-of-the-art results are observed in <metric_2> based on the learned codebooks , which observe both com-pactness and effectiveness .	6 10 5 18 19 17 -1 4 1 17 -1 0 7 17 -1 14 3 11 20 17 -1 15 8 9 21 22 17 -1 13 17 -1 16 12 17 -1
Construction of discriminative Kernels from known and unknown non-targets for PLDA-SVM scoring .	impostor class data ; plda score space ; i-vector speaker verification ; speaker-and impostor-class data ; nist 2012 sre ; background speakers ; enrollment utterance ; resam-pling technique ; score vectors ; scoring process ; svm training ; plda-svm scoring ; known non-targets ; speaker-dependent svms ; resam-pling techniques ; target-speaker i-vectors ; plda scoring ; svms	<material> <otherscientificterm> <task> <material> <material> <otherscientificterm> <otherscientificterm> <method> <otherscientificterm> <method> <task> <task> <otherscientificterm> <method> <method> <otherscientificterm> <method> <method>	8 0 11 ; 13 0 9 ; 16 0 2 ; 3 0 10 ; 5 3 9 ; 7 0 15	conventional <method_16> in <task_2> involves the i-vectors of target speakers and claimants only . we have previously demonstrated that better performance can be achieved by incorporating the information of <otherscientificterm_5> in the <method_9> via <method_13> . this is achieved by defining a <otherscientificterm_1> with dimension equal to the number of training i-vectors for each target speaker . the new protocol in <material_4> permits systems to use the information of other target-speakers -lrb- called <otherscientificterm_12> -rrb- in each verification trial . in this paper , we exploit this new protocol to enhance the performance of <task_11> by using the <otherscientificterm_8> of both known and unknown non-targets as the <material_0> to train the <method_13> . because some target speakers have one <otherscientificterm_6> only , which results in severe imbalance in the <material_3> for <task_10> . this paper shows that if the <otherscientificterm_6> is sufficiently long , a number of <otherscientificterm_15> can be generated by an utterance partitioning and <method_7> , resulting in much better scoring <method_17> . results on <material_4> demonstrate the advantages of pooling the known and unknown non-targets for training the <method_17> and that the <method_14> can help the <task_10> algorithm to find better decision boundaries for those speakers with only a small number of enrollment utterances .	16 2 21 18 -1 5 9 13 20 23 18 -1 1 18 -1 4 12 18 -1 11 8 19 18 -1 0 22 18 -1 6 3 10 24 18 -1 15 7 17 18 -1
One sentence voice adaptation using GMM-based frequency-warping and shift with a sub-band basis spectrum model .	sub-band basis spectrum model ; dp -lrb- dynamic programming -rrb- algorithm ; unit-selection based voice adaptation framework ; gmm.-based linear transformation of mel-cepstra ; unit-fusion based text-to-speech synthesizer ; rapid voice adaptation algorithm ; frequency domain representation ; rapid voice adaptation ; gmm-based frequency warping ; frequency warping function ; sub-band basis ; frequency warping ; mixture component ; shift ; gmm ; log-spectrum	<method> <method> <method> <method> <method> <method> <method> <task> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm>	13 0 5 ; 11 0 0 ; 1 0 14 ; 10 0 5 ; 2 0 4 ; 10 0 15 ; 8 1 13 ; 2 0 5 ; 5 0 7 ; 0 0 5 ; 8 0 5	this paper presents a <method_5> using <otherscientificterm_8> and <otherscientificterm_13> with parameters of a <method_0> -lsb- 1 -rsb- . the <method_0> represents a shape of a spectrum of speech . <method_5> is calculated by fitting a <otherscientificterm_10> to the <otherscientificterm_15> . since the <method_0> is the <method_6> , <method_11> can be directly applied to the <method_0> . a <method_9> that minimize the distance between source and target <method_0> pairs in each <method_12> of a <method_14> is derived using a <method_1> . the proposed <method_5> is evaluated in an <method_2> applied to a <method_4> . the experimental results show that the proposed <method_5> is effective for <task_7> using just one sentence , compared to the conventional <method_3> .	5 8 13 0 17 23 26 27 16 -1 16 -1 10 15 20 22 16 -1 6 11 18 16 -1 9 12 14 1 19 16 -1 2 4 21 24 16 -1 25 16 -1
Improving Learning Performance Through Rational Resource Allocation .	parametric hypothesis selection problems ; synthetic and real-world problems ; resource optimization problem ; heuristic learning algorithm ; statistical learning problems ; rational analysis ; learning cost ; unknown parameters ; optimization problem ; effr-cient learning	<task> <task> <task> <method> <task> <method> <metric> <otherscientificterm> <task> <task>	6 0 4 ; 5 0 4 ; 2 0 9 ; 5 0 6 ; 3 0 8	this article shows how <method_5> can be used to minimize <metric_6> for a general class of <task_4> . we discuss the factors that influence <metric_6> and show that the problem of <task_9> can be cast as a <task_2> . solutions found in this way can be significantly more efficient than the best solutions that do not account for these factors . we introduce a <method_3> that approximately solves this <task_8> and document its performance improvements on <task_1> . se1191 -rsb- -rrb- of these factors to minimize <metric_6> . we discuss this in the context of <task_0> , an abstract class of <task_4> where a system must select one of a finite set of hypothesized courses of action , where the quality of each hypothesis is described as a function of some <otherscientificterm_7> -lrb- e.g. . a <method_3> determines and refines estimates of these parameters by '' paying for '' training examples .	5 6 4 11 12 14 10 -1 9 2 13 10 -1 10 -1 3 8 1 15 10 -1 10 -1 0 10 -1 7 10 -1
Design and evaluation of a voice conversion algorithm based on spectral envelope mapping and residual prediction .	voice conversion system ; speaker discrimination of same/difference pairs ; speaker discrimination of natural speech ; spectral parameter conversion function ; perceived speaker identity ; lpc coded speech ; converted utterances ; speech utterances ; lpc coded ; lpc spectrum ; residual ; accuracy	<method> <material> <material> <otherscientificterm> <otherscientificterm> <material> <material> <material> <otherscientificterm> <method> <otherscientificterm> <metric>	0 0 4 ; 0 4 2	the purpose of a <method_0> is to change the <otherscientificterm_4> of a speech signal . in this paper , we propose a new algorithm based on converting the <method_9> and predicting the <otherscientificterm_10> as a function of the target envelope parameters . we conduct listening tests based on <material_1> to measure the <metric_11> by which the converted voices match the desired target voices . to establish the level of human performance as a baseline , we first measure the ability of listeners to discriminate between original <material_7> under three conditions : normal , fundamental frequency and duration normalized , and <otherscientificterm_8> . additionally , the <otherscientificterm_3> is tested in isolation by listening to source , target , and converted speakers as <material_5> . the results show that the speaker identity of speech whose <method_9> has been converted can be recognized as the target speaker with the same level of performance as discriminating between <material_5> . however , the level of discrimination of <material_6> produced by the <method_0> is significantly below that of <material_2> .	0 4 13 12 -1 9 10 12 -1 1 11 12 -1 7 12 -1 8 12 -1 3 5 12 -1 14 12 -1
Distributed Box-Constrained Quadratic Optimization for Dual Linear SVM .	o communication cost ; non-strongly-convex linear svm dual problem ; box-constrained quadratic optimization algorithm ; training machine learning models ; distributed linear svm algorithms ; global linear convergence ; analytical solution ; distributed fashion ; large data ; fast convergence ; an-accurate solution ; disdca ; dsvm-ave ; tron	<otherscientificterm> <task> <method> <method> <method> <otherscientificterm> <method> <material> <material> <otherscientificterm> <task> <method> <method> <method>	13 6 4 ; 12 1 11 ; 6 4 4 ; 11 6 4 ; 12 6 4 ; 12 1 13 ; 11 1 13 ; 10 0 1 ; 0 0 6	training machine learning models sometimes needs to be done on large amounts of data that exceed the capacity of a single machine , motivating recent works on developing algorithms that train in a <material_7> . this paper proposes an efficient <method_2> for distributedly training linear support vector machines -lrb- svms -rrb- with <material_8> . our key technical contribution is an <method_6> to the problem of computing the optimal step size at each iteration , using an efficient <method_6> that requires only <otherscientificterm_0> to ensure <otherscientificterm_9> . with this optimal step size , our <method_6> is superior to other methods by possessing <otherscientificterm_5> , or , equivalently , o -lrb- log -lrb- 1 / / -rrb- -rrb- iteration complexity for <task_10> , for dis-tributedly solving the <task_1> . experiments also show that our <method_6> is significantly faster than state-of-the-art <method_4> including <method_12> , <method_11> and <method_13> .	7 14 -1 2 8 14 -1 6 0 9 23 14 -1 22 14 -1 5 10 1 15 16 17 18 19 20 21 14 -1
Rule Selection with Soft Syntactic Features for String-to-Tree Statistical Machine Translation .	soft source syntactic constraints ; discriminative rule selection model ; rule selection model ; syntax-based machine translation ; string-to-tree systems ; syntactic annotation ; rule selection ; translation rule ; rules ; features ; moses	<otherscientificterm> <method> <method> <task> <method> <otherscientificterm> <method> <otherscientificterm> <otherscientificterm> <otherscientificterm> <method>	6 0 3 ; 9 3 2	in <task_3> , <method_6> is the task of choosing the correct target side of a <otherscientificterm_7> among <otherscientificterm_8> with the same source side . we define a <method_1> for systems that have <otherscientificterm_5> on the target language side -lrb- string-to-tree -rrb- . this is a new and clean way to integrate <otherscientificterm_0> into <method_4> as <otherscientificterm_9> of the <method_2> . we release our implementation as part of <method_10> .	3 6 7 8 12 11 -1 1 5 11 -1 0 4 9 2 13 11 -1 10 11 -1
Stochastic cross-layer resource allocation for wireless networks using orthogonal access : Optimality and delay analysis .	average end-to-end rates ; stochastic approximation tools ; average queue delays ; channel state information ; cross-layer algorithms ; physical layers ; stochastic schemes ; stochastic algorithm ; parallel channels ; convex optimization ; closed form ; wireless networks ; nodes ; focus ; interference	<metric> <method> <metric> <otherscientificterm> <method> <otherscientificterm> <method> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm> <method> <otherscientificterm>	3 0 4 ; 1 0 7 ; 9 1 1 ; 9 0 7	efficient design of <method_11> requires implementation of <method_4> that exploit <otherscientificterm_3> . capitalizing on <method_9> and <method_1> , this paper develops a <method_7> that allocates resources at network , link , and <otherscientificterm_5> so that a sum-utility of the <metric_0> is maximized . <method_13> is placed on <method_11> where <otherscientificterm_14> is strong and <otherscientificterm_12> transmit orthogonally over a set of <otherscientificterm_8> . convergence of the developed <method_6> is characterized , and the <metric_2> are obtained in <otherscientificterm_10> .	11 4 3 16 15 -1 9 1 7 5 0 13 17 18 19 15 -1 14 12 8 15 -1 6 2 10 15 -1
Learning spectral mapping for speech dereverberation .	deep neural networks ; derever-ebrated speech signal ; automatic speech recognition ; daily listening environments ; speaker identification systems ; estimated spectral representation ; performance degradation ; dereverberation problem ; human speech ; spectral mapping ; reverberant speech ; hearing-impaired listeners ; speech intelligibility ; anechoic speech ; distortion ; reverberation	<method> <material> <task> <material> <task> <method> <metric> <task> <material> <method> <material> <otherscientificterm> <task> <material> <otherscientificterm> <otherscientificterm>	0 0 9 ; 2 1 4 ; 10 0 9	reverberation distorts <material_8> and usually has negative effects on <task_12> , especially for <otherscientificterm_11> . it also causes <metric_6> in <task_2> and <task_4> . therefore , the <task_7> must be dealt with in <material_3> . we propose to use <method_0> to learn a <method_9> from the <material_10> to the <material_13> . the trained <method_0> produces the <method_5> of the corresponding <material_13> . we demonstrate that <otherscientificterm_14> caused by <otherscientificterm_15> is substantially attenuated by the <method_0> whose outputs can be resynthesized to the <material_1> . the proposed <method_0> is simple , and our systematic evaluation shows promising dereverberation results , which are significantly better than those of related systems .	8 12 11 16 -1 6 2 4 18 16 -1 7 3 16 -1 0 9 10 13 17 19 16 -1 5 16 -1 14 15 1 16 -1 16 -1
Learning Step Size Controllers for Robust Neural Network Training .	learning rate of neural networks ; stochastic gradient descent ; learning methods ; adaptive controller ; nn setting ; learning rate ; learning problem ; features	<task> <method> <method> <method> <method> <metric> <task> <otherscientificterm>	2 0 4	this paper investigates algorithms to automatically adapt the <task_0> . starting with <method_1> , a large variety of <method_2> has been proposed for the <method_4> . however , these methods are usually sensitive to the initial <metric_5> which has to be chosen by the exper-imenter . we investigate several <otherscientificterm_7> and show how an <method_3> can adjust the <metric_5> without prior knowledge of the <task_6> at hand .	0 8 -1 1 2 4 9 8 -1 5 8 -1 7 3 6 8 -1
